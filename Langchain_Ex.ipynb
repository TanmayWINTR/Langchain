{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT2KB4lDTpFB+HT/dUah45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanmayWINTR/Langchain/blob/main/Langchain_Ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Necessary Packages:"
      ],
      "metadata": {
        "id": "FKOjRnIlBBi1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-FBbxyXZ2B3"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries and Initializing Components:"
      ],
      "metadata": {
        "id": "2-E3jtVDBETk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for the project.\n",
        "from PyPDF2 import PdfReader  # Used for reading PDF files.\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings  # Langchain module for utilizing OpenAI embeddings.\n",
        "from langchain.text_splitter import CharacterTextSplitter  # Langchain tool for splitting text based on character count.\n",
        "from langchain.vectorstores import FAISS  # Langchain module for working with FAISS vector stores.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZF_Q06fiBIuR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Environment Variables:"
      ],
      "metadata": {
        "id": "BF8_rAA3BbwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables for API keys.\n",
        "# OPENAI_API_KEY: Your OpenAI API key, necessary for accessing OpenAI's API services.\n",
        "# SERPAPI_API_KEY: Your SerpAPI key, assuming it's used for search-related features in this project.\n",
        "# Note: It's important to replace the empty string values with your actual API keys to ensure the APIs work correctly.\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "Z6t0NgYqaZ27"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifying PDF File for Processing:"
      ],
      "metadata": {
        "id": "aYSvIVLhDKF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path of the PDF file to be processed.\n",
        "# The PdfReader class from PyPDF2 is used to open and prepare the PDF for text extraction.\n",
        "# Replace '/content/bedrock-ug.pdf' with the actual path to your PDF file.\n",
        "pdfreader = PdfReader('/content/bedrock-ug.pdf')"
      ],
      "metadata": {
        "id": "QBKXN-NKa05x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Text from the PDF:"
      ],
      "metadata": {
        "id": "iTmrYViyDUlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary extensions for type annotations, enhancing code readability and error checking.\n",
        "from typing_extensions import Concatenate\n",
        "\n",
        "# Initialize a variable to hold the extracted text.\n",
        "raw_text = ''\n",
        "\n",
        "# Enumerate through each page of the PDF, extracting text content.\n",
        "# The 'enumerate' function provides a counter (i) along with the page object for any operations requiring indexing.\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()  # Attempt to extract text from the current page.\n",
        "    if content:  # Check if any text was successfully extracted.\n",
        "        raw_text += content  # Concatenate the content to the raw_text variable.\n",
        "\n",
        "# At this point, 'raw_text' contains the concatenated text from all readable pages of the PDF.\n"
      ],
      "metadata": {
        "id": "4D4ehzREa9Il"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "id": "t03Z0ZdRb6oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Text for Tokenization Compatibility:"
      ],
      "metadata": {
        "id": "HoSKYuAND5CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a CharacterTextSplitter to segment the extracted text into smaller chunks.\n",
        "# This approach ensures that each text chunk does not exceed the token size limit imposed by the model or application.\n",
        "# Parameters:\n",
        "# separator: Defines the character used to separate chunks, here set to a newline character.\n",
        "# chunk_size: The target size for each text chunk, set to 800 characters.\n",
        "# chunk_overlap: Allows for an overlap of 200 characters between consecutive chunks to maintain context.\n",
        "# length_function: The function used to measure the length of text, here simply using the built-in len function.\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "-6St9MU_cLh3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determining the Number of Text Chunks:"
      ],
      "metadata": {
        "id": "j7hBhjAHD_bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of chunks created after splitting the text.\n",
        "# This is useful for understanding the distribution and segmentation of the text for further processing.\n",
        "len(texts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDN5q4NKcOiK",
        "outputId": "499e6452-0336-49de-df84-9c101cdb53e4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1927"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing Embeddings from OpenAI:"
      ],
      "metadata": {
        "id": "kF0ouJKdEDml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the OpenAI embeddings.\n",
        "# This step involves setting up the OpenAIEmbeddings object to generate embeddings for text segments.\n",
        "# Embeddings are crucial for representing text in a form suitable for similarity searches and other vector-based operations.\n",
        "embeddings = OpenAIEmbeddings()\n"
      ],
      "metadata": {
        "id": "RQhNYHPecRAr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a FAISS Vector Store from Texts:"
      ],
      "metadata": {
        "id": "a4DSahxeEJQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a FAISS vector store to manage and search document embeddings.\n",
        "# This operation converts the text segments into embeddings and stores them in a FAISS index for efficient similarity searching.\n",
        "document_search = FAISS.from_texts(texts, embeddings)\n"
      ],
      "metadata": {
        "id": "5vLz4dUScTG_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting the Document Search Object:"
      ],
      "metadata": {
        "id": "3tlIFVmVESUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the document_search object.\n",
        "# This inspection is useful for verifying the successful creation of the FAISS vector store and its readiness for executing searches.\n",
        "document_search\n"
      ],
      "metadata": {
        "id": "odtuhsUgdcYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33ccf70-21b0-4537-b834-f6797dc55d73"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x7c2270a05720>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a Question Answering Chain:"
      ],
      "metadata": {
        "id": "AzM7qzhkEXyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a question answering (QA) chain using LangChain and OpenAI's model.\n",
        "# This chain is configured for processing input documents and questions to generate answers.\n",
        "# The 'chain_type' parameter specifies the configuration or model type to use, here indicated as \"stuff\".\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n"
      ],
      "metadata": {
        "id": "GRaOBtVGdnSe"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executing the QA Chain with a Specific Query:"
      ],
      "metadata": {
        "id": "QUlLdVS9EnMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a query and perform a similarity search to find relevant document segments.\n",
        "# The identified documents are then processed through the QA chain to generate an answer.\n",
        "query = \"How to add an action group to your agent in Amazon Bedrock\"\n",
        "docs = document_search.similarity_search(query)  # Find similar document segments to the query.\n",
        "chain.run(input_documents=docs, question=query)  # Process the documents and query through the QA chain.\n"
      ],
      "metadata": {
        "id": "8Z8Gt86JdfcT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2e4a357f-9890-4f06-f5d3-8204b2f518d3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' To add an action group to your agent in Amazon Bedrock, follow these steps: \\n1. Sign in to the AWS Management Console and open the Amazon Bedrock console at \\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents from the left navigation pane and choose an agent in the Agents section.\\n3. Choose an agent from the Agents section and then choose the Working draft in the Working Draft section.\\n4. Select Add in the Action groups section.\\n5. Fill out the action group details.\\n6. To define the schema for the action group, use the in-line OpenAPI schema editor. \\n7. Select Add and wait for the success banner to appear. \\n8. Select Prepare to apply the changes to your agent before testing it.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another Example of Executing the QA Chain:"
      ],
      "metadata": {
        "id": "KbFavY1kEtBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Do i need to pay for a foundation model in bedrock\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uVsNWrkO9ndR",
        "outputId": "17d7b2a0-fbfa-48fa-f99b-7c0cd49a786d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Yes, you do need to pay for a foundation model in Amazon Bedrock. Pricing is based on the volume of input tokens and output tokens, and on whether you have purchased provisioned throughput for the model. You can see the pricing for each model on the Model providers page in the Amazon Bedrock console.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7inWW51_XUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}