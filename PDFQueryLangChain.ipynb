{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT2KB4lDTpFB+HT/dUah45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanmayWINTR/Langchain/blob/main/PDFQueryLangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Necessary Packages:"
      ],
      "metadata": {
        "id": "FKOjRnIlBBi1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-FBbxyXZ2B3",
        "outputId": "36ef685d-d3e0-40af-8d65-9c336b74d3a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.12-py3-none-any.whl (809 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/809.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/809.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/809.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/809.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.28 (from langchain)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.31 (from langchain)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.27-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m811.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.31->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.12 langchain-community-0.0.28 langchain-core-0.1.32 langchain-text-splitters-0.0.1 langsmith-0.1.27 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.14.1-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.1\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries and Initializing Components:"
      ],
      "metadata": {
        "id": "2-E3jtVDBETk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for the project.\n",
        "from PyPDF2 import PdfReader  # Used for reading PDF files.\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings  # Langchain module for utilizing OpenAI embeddings.\n",
        "from langchain.text_splitter import CharacterTextSplitter  # Langchain tool for splitting text based on character count.\n",
        "from langchain.vectorstores import FAISS  # Langchain module for working with FAISS vector stores.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZF_Q06fiBIuR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Environment Variables:"
      ],
      "metadata": {
        "id": "BF8_rAA3BbwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables for API keys.\n",
        "# OPENAI_API_KEY: Your OpenAI API key, necessary for accessing OpenAI's API services.\n",
        "# SERPAPI_API_KEY: Your SerpAPI key, assuming it's used for search-related features in this project.\n",
        "# Note: It's important to replace the empty string values with your actual API keys to ensure the APIs work correctly.\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "Z6t0NgYqaZ27"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifying PDF File for Processing:"
      ],
      "metadata": {
        "id": "aYSvIVLhDKF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path of the PDF file to be processed.\n",
        "# The PdfReader class from PyPDF2 is used to open and prepare the PDF for text extraction.\n",
        "# Replace '/content/bedrock-ug.pdf' with the actual path to your PDF file.\n",
        "pdfreader = PdfReader('/content/bedrock-ug.pdf')"
      ],
      "metadata": {
        "id": "QBKXN-NKa05x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Text from the PDF:"
      ],
      "metadata": {
        "id": "iTmrYViyDUlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary extensions for type annotations, enhancing code readability and error checking.\n",
        "from typing_extensions import Concatenate\n",
        "\n",
        "# Initialize a variable to hold the extracted text.\n",
        "raw_text = ''\n",
        "\n",
        "# Enumerate through each page of the PDF, extracting text content.\n",
        "# The 'enumerate' function provides a counter (i) along with the page object for any operations requiring indexing.\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()  # Attempt to extract text from the current page.\n",
        "    if content:  # Check if any text was successfully extracted.\n",
        "        raw_text += content  # Concatenate the content to the raw_text variable.\n",
        "\n",
        "# At this point, 'raw_text' contains the concatenated text from all readable pages of the PDF.\n"
      ],
      "metadata": {
        "id": "4D4ehzREa9Il"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "t03Z0ZdRb6oK",
        "outputId": "65c13e4e-5b30-4d1f-f6a7-1556008a2e63"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'User Guide\\nAmazon Bedrock\\nCopyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.Amazon Bedrock User Guide\\nAmazon Bedrock: User Guide\\nCopyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\\nAmazon\\'s trademarks and trade dress may not be used in connection with any product or service \\nthat is not Amazon\\'s, in any manner that is likely to cause confusion among customers, or in any \\nmanner that disparages or discredits Amazon. All other trademarks not owned by Amazon are \\nthe property of their respective owners, who may or may not be aﬃliated with, connected to, or \\nsponsored by Amazon.Amazon Bedrock User Guide\\nTable of Contents\\nWhat is Amazon Bedrock?..............................................................................................................1\\nFeatures of Amazon Bedrock.....................................................................................................................1\\nAmazon Bedrock pricing.............................................................................................................................2\\nSupported AWS Regions.............................................................................................................................3\\nKey deﬁnitions...............................................................................................................................................4\\nBasic concepts..........................................................................................................................................4\\nAdvanced features...................................................................................................................................6\\nSet up ...............................................................................................................................................7\\nSign up for an AWS account......................................................................................................................7\\nCreate an administrative user....................................................................................................................8\\nGrant programmatic access........................................................................................................................9\\nConsole access............................................................................................................................................10\\nModel access...............................................................................................................................................11\\nAdd model access.................................................................................................................................12\\nRemove model access..........................................................................................................................12\\nControl model access permissions....................................................................................................13\\nAPI setup ......................................................................................................................................................15\\nAdd model access.................................................................................................................................16\\nAmazon Bedrock endpoints................................................................................................................16\\nSetting up the AWS CLI.......................................................................................................................16\\nAWS SDK setup.....................................................................................................................................17\\nUsing SageMaker notebooks..............................................................................................................19\\nWorking with AWS SDKs..........................................................................................................................21\\nFoundation model information....................................................................................................23\\nUsing foundation models .........................................................................................................................25\\nGet model information .............................................................................................................................27\\nModel support by AWS Region...............................................................................................................28\\nModel support by feature........................................................................................................................29\\nModel lifecycle............................................................................................................................................33\\nOn-Demand, Provisioned Throughput, and model customization.............................................34\\nLegacy versions.....................................................................................................................................34\\nAmazon Bedrock model IDs.....................................................................................................................35\\nBase models IDs (on-demand)...........................................................................................................36\\nBase model IDs (for Provisioned Throughput)................................................................................38\\niiiAmazon Bedrock User Guide\\nModel inference parameters....................................................................................................................40\\nAmazon Titan models..........................................................................................................................40\\nAnthropic\\xa0Claude models....................................................................................................................79\\nAI21 Labs\\xa0Jurassic-2 models ...............................................................................................................99\\nCohere models....................................................................................................................................103\\nMeta\\xa0Llama 2 models ........................................................................................................................115\\nMistral AI models ................................................................................................................................119\\nStability.ai Diﬀusion models............................................................................................................124\\nCustom model hyperparameters..........................................................................................................142\\nAmazon Titan text models...............................................................................................................142\\nAmazon Titan Image Generator G1................................................................................................144\\nAmazon Titan Multimodal Embeddings G1..................................................................................145\\nCohere\\xa0Command models.................................................................................................................146\\nMeta\\xa0Llama 2 models ........................................................................................................................149\\nConsole overview.........................................................................................................................151\\nGetting started.........................................................................................................................................151\\nFoundation models..................................................................................................................................152\\nPlaygrounds...............................................................................................................................................152\\nSafeguards.................................................................................................................................................153\\nOrchestration............................................................................................................................................153\\nAssessment and deployment................................................................................................................153\\nModel access.............................................................................................................................................154\\nModel invocation logging......................................................................................................................154\\nRun model inference...................................................................................................................155\\nInference parameters..............................................................................................................................157\\nRandomness and diversity................................................................................................................157\\nLength ...................................................................................................................................................159\\nPlaygrounds...............................................................................................................................................159\\nChat playground.................................................................................................................................160\\nText playground..................................................................................................................................161\\nImage playground..............................................................................................................................161\\nUse a playground...............................................................................................................................162\\nRun single-prompt inference.................................................................................................................164\\nInvoke model code examples...........................................................................................................165\\nInvoke model with streaming code example................................................................................166\\nRun batch inference................................................................................................................................167\\nivAmazon Bedrock User Guide\\nPermissions..........................................................................................................................................168\\nSet up data ..........................................................................................................................................171\\nCreate a batch inference job............................................................................................................172\\nStop a batch inference job...............................................................................................................174\\nGet details about a batch inference job........................................................................................175\\nList batch inference jobs...................................................................................................................177\\nCode samples ......................................................................................................................................179\\nPrompt engineering guidelines .................................................................................................184\\nIntroduction...............................................................................................................................................184\\nAdditional prompt resources............................................................................................................185\\nWhat is a prompt?...................................................................................................................................185\\nComponents of a prompt.................................................................................................................186\\nFew-shot prompting vs. zero-shot prompting.............................................................................187\\nPrompt template................................................................................................................................189\\nImportant notes on using Amazon Bedrock LLMs by API calls................................................190\\nWhat is prompt engineering?................................................................................................................191\\nGeneral guidelines for Amazon Bedrock LLM users.........................................................................192\\nDesign your prompt...........................................................................................................................192\\nUse inference parameters.................................................................................................................193\\nDetailed guidelines .............................................................................................................................194\\nOptimize prompts for text models on Amazon Bedrock—when the basics aren\\'t good \\nenough ..................................................................................................................................................200\\nPrompt templates and examples for Amazon Bedrock text models.............................................203\\nText classiﬁcation...............................................................................................................................203\\nQuestion-answer, without context..................................................................................................206\\nQuestion-answer, with context........................................................................................................210\\nSummarization ....................................................................................................................................214\\nText generation...................................................................................................................................216\\nCode generation .................................................................................................................................219\\nMathematics .........................................................................................................................................221\\nReasoning/logical thinking...............................................................................................................222\\nModel evaluation .........................................................................................................................225\\nGet started................................................................................................................................................226\\nAutomatic model evaluations ..........................................................................................................227\\nHuman worker based model evaluation jobs...............................................................................229\\nModel evaluation tasks ...........................................................................................................................233\\nvAmazon Bedrock User Guide\\nGeneral text generation....................................................................................................................234\\nText summarization............................................................................................................................235\\nQuestion and answer.........................................................................................................................236\\nText classiﬁcation...............................................................................................................................238\\nInput prompt datasets............................................................................................................................239\\nBuilt-in prompt datasets...................................................................................................................240\\nCustom prompt datasets..................................................................................................................243\\nWorker instructions.................................................................................................................................247\\nRating methods ...................................................................................................................................248\\nManage a work team..............................................................................................................................254\\nModel evaluation job results.................................................................................................................255\\nAutomated reports.............................................................................................................................256\\nHuman report cards...........................................................................................................................258\\nAmazon S3 output.............................................................................................................................265\\nRequired permissions..............................................................................................................................271\\nConsole permission requirements...................................................................................................272\\nService roles.........................................................................................................................................275\\nCORS permission requirements.......................................................................................................283\\nData encryption..................................................................................................................................284\\nKnowledge base for Amazon Bedrock.......................................................................................285\\nHow it works.............................................................................................................................................286\\nSupported regions and models............................................................................................................287\\nPrerequisites..............................................................................................................................................288\\nSet up a data source..........................................................................................................................289\\nSet up a vector store.........................................................................................................................290\\nCreate a knowledge base.......................................................................................................................297\\nSync your data sources...........................................................................................................................303\\nTest a knowledge base...........................................................................................................................305\\nManage a data source.............................................................................................................................308\\nView information about a data source..........................................................................................308\\nUpdate a data source........................................................................................................................310\\nDelete a data source..........................................................................................................................311\\nManage a knowledge base....................................................................................................................312\\nView information about a knowledge base..................................................................................312\\nUpdate a knowledge base................................................................................................................313\\nDelete a knowledge base.................................................................................................................314\\nviAmazon Bedrock User Guide\\nDeploy a knowledge base......................................................................................................................315\\nAgents for Amazon Bedrock.......................................................................................................317\\nHow it works.............................................................................................................................................318\\nBuild-time conﬁguration...................................................................................................................319\\nRuntime process.................................................................................................................................320\\nSupported regions and models............................................................................................................322\\nPrerequisites..............................................................................................................................................323\\nCreate an agent........................................................................................................................................324\\nCreate an action group...........................................................................................................................328\\nDeﬁne OpenAPI schemas ..................................................................................................................329\\nDeﬁne Lambda functions..................................................................................................................338\\nAdd an action group..........................................................................................................................342\\nAssociate a knowledge base..................................................................................................................345\\nTest an agent............................................................................................................................................346\\nTrace events.........................................................................................................................................350\\nManage an agent .....................................................................................................................................358\\nView information about an agent ..................................................................................................359\\nEdit an agent.......................................................................................................................................360\\nDelete an agent ..................................................................................................................................362\\nManage action groups.......................................................................................................................363\\nManage agent-knowledge bases associations..............................................................................367\\nCustomize an agent................................................................................................................................370\\nAdvanced prompts.............................................................................................................................371\\nControl session context.....................................................................................................................410\\nDeploy an agent.......................................................................................................................................412\\nManage versions.................................................................................................................................414\\nManage aliases ....................................................................................................................................416\\nCustom models ............................................................................................................................421\\nSupported regions and models............................................................................................................422\\nPrerequisites..............................................................................................................................................423\\nPrepare the datasets..........................................................................................................................424\\n(Optional) Set up a VPC....................................................................................................................426\\nSubmit a job .............................................................................................................................................432\\nManage a job ............................................................................................................................................435\\nMonitor a job .......................................................................................................................................435\\nStop a job ............................................................................................................................................436\\nviiAmazon Bedrock User Guide\\nAnalyze job results..................................................................................................................................437\\nUse a custom model ...............................................................................................................................439\\nCode samples ............................................................................................................................................439\\nGuidelines ..................................................................................................................................................451\\nAmazon Titan Text G1 - Express.....................................................................................................451\\nTroubleshooting.......................................................................................................................................452\\nPermissions issues..............................................................................................................................452\\nData issues ...........................................................................................................................................453\\nInternal error.......................................................................................................................................454\\nProvisioned Throughput.............................................................................................................455\\nSupported regions and models............................................................................................................456\\nProcedures.................................................................................................................................................459\\nCreating................................................................................................................................................459\\nUpdating ...............................................................................................................................................459\\nDeleting ................................................................................................................................................459\\nRunning inference..............................................................................................................................459\\nPermissions................................................................................................................................................460\\nConsole procedures.................................................................................................................................460\\nView Provisioned Throughput summary.......................................................................................460\\nPurchase Provisioned Throughput..................................................................................................460\\nView details of a Provisioned Throughput....................................................................................461\\nEdit a Provisioned Throughput........................................................................................................462\\nDelete a Provisioned Throughput...................................................................................................462\\nAPI operations ..........................................................................................................................................463\\nCreate Provisioned Throughput.......................................................................................................463\\nRun inference using Provisioned Throughput..............................................................................466\\nUpdate Provisioned Throughput.....................................................................................................467\\nGet Provisioned Throughput............................................................................................................468\\nDelete Provisioned Throughput.......................................................................................................468\\nList Provisioned Throughput resources..........................................................................................469\\nTag resources...............................................................................................................................471\\nUse the console........................................................................................................................................472\\nUse the API ...............................................................................................................................................472\\nBest practices and restrictions..............................................................................................................474\\nAmazon Titan Models..................................................................................................................475\\nAmazon Titan Text..................................................................................................................................475\\nviiiAmazon Bedrock User Guide\\nAmazon Titan Text G1 - Express.....................................................................................................475\\nAmazon Titan Text G1 - Lite............................................................................................................476\\nAmazon Titan Text Model Customization.....................................................................................476\\nAmazon Titan Text Prompt Engineering Guidelines...................................................................476\\nAmazon Titan Embeddings G1 - Text.................................................................................................477\\nAmazon Titan Multimodal Embeddings G1.......................................................................................478\\nEmbedding length ..............................................................................................................................478\\nFinetuning ............................................................................................................................................479\\nPreparing datasets..............................................................................................................................479\\nHyperparameters ................................................................................................................................480\\nAmazon Titan Image Generator G1.....................................................................................................480\\nFeatures................................................................................................................................................481\\nParameters...........................................................................................................................................482\\nFine-tuning ...........................................................................................................................................482\\nOutput ...................................................................................................................................................483\\nWatermark detection.........................................................................................................................483\\nPrompt Engineering Guidelines.......................................................................................................484\\nSecurity........................................................................................................................................486\\nData protection........................................................................................................................................487\\nData encryption..................................................................................................................................489\\nUse Amazon VPC and AWS PrivateLink.........................................................................................498\\nIdentity and access management.........................................................................................................501\\nAudience...............................................................................................................................................502\\nAuthenticating with identities .........................................................................................................502\\nManaging access using policies.......................................................................................................506\\nHow Amazon Bedrock works with IAM..........................................................................................508\\nIdentity-based policy examples.......................................................................................................515\\nAWS managed policies......................................................................................................................524\\nService roles.........................................................................................................................................528\\nTroubleshooting..................................................................................................................................541\\nCompliance validation............................................................................................................................543\\nIncident response.....................................................................................................................................544\\nResilience...................................................................................................................................................545\\nInfrastructure security.............................................................................................................................545\\nCross-service confused deputy prevention.........................................................................................546\\nConﬁguration and vulnerability analysis in Amazon Bedrock........................................................547\\nixAmazon Bedrock User Guide\\nUse interface VPC endpoints (AWS PrivateLink)...............................................................................498\\nConsiderations .....................................................................................................................................499\\nCreate an interface endpoint...........................................................................................................499\\nCreate an endpoint policy................................................................................................................500\\nMonitor Amazon Bedrock...........................................................................................................551\\nModel invocation logging......................................................................................................................551\\nSet up an Amazon S3 destination..................................................................................................551\\nSet up CloudWatch Logs destination.............................................................................................553\\nUsing the console...............................................................................................................................555\\nUsing APIs with invocation logging................................................................................................556\\nMonitor with CloudWatch......................................................................................................................556\\nRuntime metrics ..................................................................................................................................556\\nLogging CloudWatch metrics...........................................................................................................557\\nUse CloudWatch metrics for Amazon Bedrock.............................................................................558\\nView Amazon Bedrock metrics........................................................................................................558\\nMonitor events.........................................................................................................................................558\\nHow it works.......................................................................................................................................559\\nEventBridge schema...........................................................................................................................560\\nRules and targets................................................................................................................................561\\nCreate a rule to handle Amazon Bedrock events........................................................................562\\nCloudTrail logs..........................................................................................................................................563\\nAmazon Bedrock information in CloudTrail..................................................................................564\\nAmazon Bedrock data events in CloudTrail..................................................................................564\\nAmazon Bedrock management events in CloudTrail..................................................................566\\nUnderstanding Amazon Bedrock log ﬁle entries.........................................................................566\\nCode examples.............................................................................................................................568\\nAmazon Bedrock......................................................................................................................................569\\nActions..................................................................................................................................................575\\nScenarios...............................................................................................................................................589\\nAmazon Bedrock Runtime......................................................................................................................591\\nActions..................................................................................................................................................595\\nScenarios...............................................................................................................................................692\\nAgents for Amazon Bedrock..................................................................................................................702\\nActions..................................................................................................................................................706\\nScenarios...............................................................................................................................................731\\nAgents for Amazon Bedrock Runtime.................................................................................................744\\nxAmazon Bedrock User Guide\\nActions..................................................................................................................................................745\\nScenarios...............................................................................................................................................748\\nAbuse detection...........................................................................................................................751\\nQuotas ..........................................................................................................................................753\\nRuntime quotas ........................................................................................................................................753\\nBatch inference quotas...........................................................................................................................757\\nKnowledge base quotas.........................................................................................................................757\\nAgent quotas............................................................................................................................................758\\nModel customization quotas .................................................................................................................758\\nProvisioned Throughput quotas...........................................................................................................762\\nAPI reference...............................................................................................................................764\\nDocument history........................................................................................................................765\\nAWS Glossary...............................................................................................................................770\\nxiAmazon Bedrock User Guide\\nWhat is Amazon Bedrock?\\nAmazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) \\nfrom leading AI startups and Amazon available for your use through a uniﬁed API. You can choose \\nfrom a wide range of foundation models to ﬁnd the model that is best suited for your use case. \\nAmazon Bedrock also oﬀers a broad set of capabilities to build generative AI applications with \\nsecurity, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and \\nevaluate top foundation models for your use cases, privately customize them with your data using \\ntechniques such as ﬁne-tuning and Retrieval Augmented Generation (RAG), and build agents that \\nexecute tasks using your enterprise systems and data sources.\\nWith Amazon Bedrock\\'s serverless experience, you can get started quickly, privately customize \\nfoundation models with your own data, and easily and securely integrate and deploy them into \\nyour applications using AWS tools without having to manage any infrastructure.\\nTopics\\n•Features of Amazon Bedrock\\n•Amazon Bedrock pricing\\n•Supported AWS Regions\\n•Key deﬁnitions\\nFeatures of Amazon Bedrock\\nTake advantage of Amazon Bedrock foundation models to explore the following capabilities. To see \\nfeature limitations by Region, see Model support by AWS Region.\\n•Experiment with prompts and conﬁgurations – Run model inference by sending prompts using \\ndiﬀerent conﬁgurations and foundation models to generate responses. You can use the API or \\nthe text, image, and chat playgrounds in the console to experiment in a graphical interface. \\nWhen you\\'re ready, set up your application to make requests to the InvokeModel  APIs.\\n•Augment response generation with information from your data sources – Create knowledge \\nbases  by uploading data sources to be queried in order to augment a foundation model\\'s \\ngeneration of responses.\\nFeatures of Amazon Bedrock 1Amazon Bedrock User Guide\\n•Create applications that reason through how to help a customer – Build agents  that use \\nfoundation models, make API calls, and (optionally) query knowledge bases in order to reason \\nthrough and carry out tasks for your customers.\\n•Adapt models to speciﬁc tasks and domains with training data  – Customize an Amazon \\nBedrock foundation model by providing training data for ﬁne-tuning or continued-pretraining in \\norder to adjust a model\\'s parameters and improve its performance on speciﬁc tasks or in certain \\ndomains.\\n•Improve your FM-based application\\'s eﬃciency and output – Purchase Provisioned Throughput\\nfor a foundation model in order to run inference on models more eﬃciently and at discounted \\nrates.\\n•Determine the best model for your use case – Evaluate outputs of diﬀerent models with built-in \\nor custom prompt datasets to determine the model that is best suited for your application.\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change.\\n•Prevent inappropriate or unwanted content – Use Guardrails for Amazon Bedrock to \\nimplement safeguards for your generative AI applications.\\nNote\\nGuardrails for Amazon Bedrock is in limited preview release. To request access, contact \\nyour AWS account manager.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS, \\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost \\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If \\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models. \\nPricing is based on the volume of input tokens and output tokens, and on whether you have \\nAmazon Bedrock pricing 2Amazon Bedrock User Guide\\npurchased provisioned throughput for the model. For more information, see the Model providers\\npage in the Amazon Bedrock console. For each model, pricing is listed following the model version. \\nFor more information about purchasing Provisioned Throughput, see Provisioned Throughput.\\nFor more information, see Amazon Bedrock Pricing.\\nSupported AWS Regions\\nFor information about service endpoints for Regions that Amazon Bedrock supports, see Amazon \\nBedrock endpoints and quotas.\\nTo see what foundation models each Region supports, refer to Model support by AWS Region.\\nNote\\nAll features are available in US East (N. Virginia) and US West (Oregon).\\nSee the following table for features that are limited by region.\\nRegion Model \\nevaluationKnowledge \\nbaseAgents Fine-\\ntuning \\n(custom \\nmodels)Continued \\npre-\\ntraining \\n(custom \\nmodels)Provision \\ned \\nThroughpu \\nt\\nUS East (N. \\nVirginia)Yes Yes Yes Yes Yes Yes\\nUS West \\n(Oregon)Yes Yes Yes Yes Yes Yes\\nAsia Paciﬁc \\n(Singapor \\ne)No No No No No No\\nAsia Paciﬁc \\n(Tokyo)No No No No No No\\nSupported AWS Regions 3Amazon Bedrock User Guide\\nRegion Model \\nevaluationKnowledge \\nbaseAgents Fine-\\ntuning \\n(custom \\nmodels)Continued \\npre-\\ntraining \\n(custom \\nmodels)Provision \\ned \\nThroughpu \\nt\\nEurope \\n(Frankfurt)No No No No No No\\nAWS \\nGovCloud \\n(US-West)No No NoYes NoYes (only \\nfor ﬁne-\\ntuned \\nmodels, \\nwith no \\ncommitmen \\nt term)\\nKey deﬁnitions\\nThis chapter provides deﬁnitions for concepts that will help you understand what Amazon Bedrock \\noﬀers and how it works. If you are a ﬁrst-time user, you should ﬁrst read through the basic \\nconcepts. Once you familiarize yourself with the basics of Amazon Bedrock, we recommend for you \\nto explore the advanced concepts and features that Amazon Bedrock has to oﬀer.\\nBasic concepts\\nThe following list introduces you to the basic concepts of generative AI and Amazon Bedrock\\'s \\nfundamental capabilities.\\n•Foundation model (FM) – An AI model with a large number of parameters and trained on a \\nmassive amount of diverse data. A foundation model can generate a variety of responses for a \\nwide range of use cases. Foundation models can generate text or image, and can also convert \\ninput into embeddings . Before you can use an Amazon Bedrock foundation model, you must\\nrequest access. For more information about foundation models, see Supported foundation \\nmodels in Amazon Bedrock.\\nKey deﬁnitions 4Amazon Bedrock User Guide\\n•Base model  – A foundation model that is packaged by a provider and ready to use. Amazon \\nBedrock oﬀers a variety of industry-leading foundation models from leading providers. For more \\ninformation, see Supported foundation models in Amazon Bedrock.\\n•Model inference – The process of a foundation model generating an output (response) from a \\ngiven input (prompt). For more information, see Run model inference.\\n•Prompt  – An input provided to a model to guide it to generate an appropriate response or \\noutput for the input. For example, a text prompt can consist of a single line for the model \\nto respond to, or it can detail instructions or a task for the model to perform. The prompt \\ncan contain the context of the task, examples of outputs, or text for a model to use in its \\nresponse. Prompts can be used to carry out tasks such as classiﬁcation, question answering, \\ncode generation, creative writing, and more. For more information, see  Prompt engineering \\nguidelines .\\n•Token – A sequence of characters that a model can interpret or predict as a single unit of \\nmeaning. For example, with text models, a token could correspond not just to a word, but also to \\na part of a word with grammatical meaning (such as \"-ed\"), a punctuation mark (such as \"?\"), or a \\ncommon phrase (such as \"a lot\").\\n•Model parameters  – Values that deﬁne a model and its behavior in interpreting input and \\ngenerating responses. Model parameters are controlled and updated by providers. You can also \\nupdate model parameters to create a new model through the process of model customization .\\n•Inference parameters – Values that can be adjusted during model inference to inﬂuence a \\nresponse. Inference parameters can aﬀect how varied responses are and can also limit the length \\nof a response or the occurrence of speciﬁed sequences. For more information and deﬁnitions of \\nspeciﬁc inference parameters, see Inference parameters.\\n•Playground – A user-friendly graphical interface in the AWS Management Console in which \\nyou can experiment with running model inference to familiarize yourself with Amazon Bedrock. \\nUse the playground to test out the eﬀects of diﬀerent models, conﬁgurations, and inference \\nparameters on the responses generated for diﬀerent prompts that you enter. For more \\ninformation, see Playgrounds.\\n•Embedding  – The process of condensing information by transforming input into a vector \\nof numerical values, known as the embeddings , in order to compare the similarity between \\ndiﬀerent objects by using a shared numerical representation. For example, sentences can be \\ncompared to determine the similarity in meaning, images can be compared to determine visual \\nsimilarity, or text and image can be compared to see if they\\'re relevant to each other. You can \\nalso combine text and image inputs into an averaged embeddings vector if it\\'s relevant to your \\nBasic concepts 5Amazon Bedrock User Guide\\nuse case. For more information, see Run model inference and Knowledge base for Amazon \\nBedrock.\\nAdvanced features\\nThe following list introduces you to more advanced concepts that you can explore through using \\nAmazon Bedrock.\\n•Orchestration  – The process of coordinating between foundation models and enterprise data \\nand applications in order to carry out a task. For more information, see Agents for Amazon \\nBedrock.\\n•Agent  – An application that carry out orchestrations through cyclically interpreting inputs and \\nproducing outputs by using a foundation model. An agent can be used to carry out customer \\nrequests. For more information, see Agents for Amazon Bedrock.\\n•Retrieval augmented generation (RAG) – The process of querying and retrieving information \\nfrom a data source in order to augment a generated response to a prompt. For more \\ninformation, see Knowledge base for Amazon Bedrock.\\n•Model customization  – The process of using training data to adjust the model parameter values \\nin a base model in order to create a custom model . Examples of model customization include\\nFine-tuning , which uses labeled data (inputs and corresponding outputs), and Continued \\nPre-training , which uses unlabeled data (inputs only) to adjust model parameters. For more \\ninformation about model customization techniques available in Amazon Bedrock, see Custom \\nmodels .\\n•Hyperparameters  – Values that can be adjusted for model customization  to control the training \\nprocess and, consequently, the output custom model. For more information and deﬁnitions of \\nspeciﬁc hyperparameters, see Custom model hyperparameters.\\n•Model evaluation  – The process of evaluating and comparing model outputs in order to \\ndetermine the model that is best suited for a use case. For more information, see Model \\nevaluation .\\n•Provisioned Throughput – A level of throughput that you purchase for a base or custom model \\nin order to increase the amount and/or rate of tokens processed during model inference. When \\nyou purchase Provisioned Throughput for a model, a provisioned model is created that can be \\nused to carry out model inference. For more information, see Provisioned Throughput.\\nAdvanced features 6Amazon Bedrock User Guide\\nSet up Amazon Bedrock\\nBefore you use Amazon Bedrock for the ﬁrst time, complete the following tasks. Once you have set \\nup your account and requested model access in the console, you can set up the API.\\nImportant\\nBefore you can use any of the foundation models, you must request access to that model. \\nIf you try to use the model (with the API or within the console) before you have requested \\naccess to it, you will receive an error message. For more information, see Model access.\\nSetup tasks\\n•Sign up for an AWS account\\n•Create an administrative user\\n•Grant programmatic access\\n•Console access\\n•Model access\\n•Set up the Amazon Bedrock API\\n•Using this service with an AWS SDK\\nSign up for an AWS account\\nIf you do not have an AWS account, complete the following steps to create one.\\nTo sign up for an AWS account\\n1. Open https://portal.aws.amazon.com/billing/signup.\\n2. Follow the online instructions.\\nPart of the sign-up procedure involves receiving a phone call and entering a veriﬁcation code \\non the phone keypad.\\nWhen you sign up for an AWS account, an AWS account root user is created. The root user \\nhas access to all AWS services and resources in the account. As a security best practice, assign \\nSign up for an AWS account 7Amazon Bedrock User Guide\\nadministrative access to an administrative user, and use only the root user to perform tasks \\nthat require root user access.\\nAWS sends you a conﬁrmation email after the sign-up process is complete. At any time, you can \\nview your current account activity and manage your account by going to https://aws.amazon.com/\\nand choosing My Account.\\nCreate an administrative user\\nAfter you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity \\nCenter, and create an administrative user so that you don\\'t use the root user for everyday tasks.\\nSecure your AWS account root user\\n1. Sign in to the AWS Management Console as the account owner by choosing Root user and \\nentering your AWS account email address. On the next page, enter your password.\\nFor help signing in by using root user, see Signing in as the root user in the AWS Sign-In User \\nGuide .\\n2. Turn on multi-factor authentication (MFA) for your root user.\\nFor instructions, see Enable a virtual MFA device for your AWS account root user (console) in \\nthe IAM User Guide .\\nCreate an administrative user\\n1. Enable IAM Identity Center.\\nFor instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User \\nGuide .\\n2. In IAM Identity Center, grant administrative access to an administrative user.\\nFor a tutorial about using the IAM Identity Center directory as your identity source, see \\nConﬁgure user access with the default IAM Identity Center directory in the AWS IAM Identity \\nCenter User Guide .\\nCreate an administrative user 8Amazon Bedrock User Guide\\nSign in as the administrative user\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email \\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in \\nthe AWS Sign-In User Guide.\\nGrant programmatic access\\nUsers need programmatic access if they want to interact with AWS outside of the AWS \\nManagement Console. The way to grant programmatic access depends on the type of user that\\'s \\naccessing AWS.\\nTo grant users programmatic access, choose one of the following options.\\nWhich user needs \\nprogrammatic access?To By\\nWorkforce identity\\n(Users managed in IAM \\nIdentity Center)Use temporary credentials to \\nsign programmatic requests \\nto the AWS CLI, AWS SDKs, or \\nAWS APIs.Following the instructions for \\nthe interface that you want to \\nuse.\\n•For the AWS CLI, see\\nConﬁguring the AWS \\nCLI to use AWS IAM \\nIdentity Center in the AWS \\nCommand Line Interface \\nUser Guide .\\n•For AWS SDKs, tools, and \\nAWS APIs, see IAM Identity \\nCenter authentication  in \\nthe AWS SDKs and Tools \\nReference Guide.\\nIAM Use temporary credentials to \\nsign programmatic requests Following the instructions in\\nUsing temporary credentia \\nGrant programmatic access 9Amazon Bedrock User Guide\\nWhich user needs \\nprogrammatic access?To By\\nto the AWS CLI, AWS SDKs, or \\nAWS APIs.ls with AWS resources in the\\nIAM User Guide .\\nIAM (Not recommended)\\nUse long-term credentials to \\nsign programmatic requests \\nto the AWS CLI, AWS SDKs, or \\nAWS APIs.Following the instructions for \\nthe interface that you want to \\nuse.\\n•For the AWS CLI, see\\nAuthenticating using IAM \\nuser credentials in the AWS \\nCommand Line Interface \\nUser Guide .\\n•For AWS SDKs and tools, \\nsee Authenticate using \\nlong-term credentials in \\nthe AWS SDKs and Tools \\nReference Guide.\\n•For AWS APIs, see\\nManaging access keys for \\nIAM users  in the IAM User \\nGuide .\\nConsole access\\nTo access the Amazon Bedrock console and playground:\\n1.Sign in to your AWS account.\\n2.Navigate to: Amazon Bedrock console\\n3.Request model access by following the steps at Model access.\\nConsole access 10Amazon Bedrock User Guide\\nModel access\\nAccess to Amazon Bedrock foundation models isn\\'t granted by default. In order to gain access to \\na foundation model, an IAM user  with suﬃcient permissions  needs to request access to it through \\nthe console. Once access is provided to a model, it is available for all users in the account.\\nTo manage model access, select Model access at the bottom of the left navigation pane in the \\nAmazon Bedrock management console. The model access page lets you view a list of available \\nmodels, the output modality of the model, whether you have been granted access to it, and the\\nEnd User License Agreement (EULA). You should review the EULA for terms and conditions of \\nusing a model before requesting access to it. For information about model pricing, refer to Amazon \\nBedrock Pricing.\\nNote\\nYou can manage model access only through the console.\\nTopics\\n•Add model access\\nModel access 11Amazon Bedrock User Guide\\n•Remove model access\\n•Control model access permissions\\nAdd model access\\nBefore you can use a foundation model in Amazon Bedrock, you must request access to it.\\nTo request access to a model\\n1. On the Model access page, select Manage model access.\\n2. Select the checkboxes next to the models you want to add access to. To request access to all \\nmodels belonging to a provider, select the check box next to the provider.\\nNote\\nYou can\\'t remove access from Titan models after requesting it.\\nFor Anthropic models, select Submit use case details  and ﬁll out the form. Once the \\ndetails are submitted, you can then select the check box next to the Anthropic models \\nthat you want to request access to.\\n3. Select Save changes to request access. The changes may take several minutes to take place.\\nNote\\nYour use of Amazon Bedrock foundation models is subject to the seller\\'s pricing terms, \\nEULA, and the AWS service terms.\\n4. If your request is successful, the Access status changes to Access granted.\\nIf you don\\'t have permissions to request access to a model, an error banner appears. Contact \\nyour account administrator to ask them to request access to the model for you or to provide you \\npermissions to request access to the model.\\nRemove model access\\nIf you no longer need to use a foundation model, you can remove access to it.\\nAdd model access 12Amazon Bedrock User Guide\\nNote\\nYou can\\'t remove access from Amazon Titan models.\\n1. On the Model access page, select Manage model access.\\n2. Select the checkboxes next to the models for which you want to remove access. To remove \\naccess for all models belonging to a provider, select the checkbox next to the provider.\\n3. Select Save changes.\\n4. You will be prompted to conﬁrm you want to remove access to models. If you consent to the \\nterms and select Remove access,\\nNote\\nThe model may still be accessed through the API for some time after you complete this \\naction while the changes propagate. To immediately remove access in the meantime, \\nadd an IAM policy to a role to deny access to the model.\\nControl model access permissions\\nTo control a role\\'s permissions to request access to Amazon Bedrock models, attach an IAM policy\\nto the role using any of the following AWS Marketplace actions.\\n•aws-marketplace:Subscribe\\n•aws-marketplace:Unsubscribe\\n•aws-marketplace:ViewSubscriptions\\nFor the aws-marketplace:Subscribe  action only, you can use the aws-\\nmarketplace:ProductId  condition key to limit subscription to speciﬁc models. The following \\ntable lists product IDs for Amazon Bedrock foundation models.\\nModel Product ID\\nAI21 Labs Jurassic-2 Mid 1d288c71-65f9-489a-a3e2-9c7f4f6e6a85\\nControl model access permissions 13Amazon Bedrock User Guide\\nModel Product ID\\nAI21 Labs Jurassic-2 Ultra cc0bdd50-279a-40d8-829c-4009b77a1fcc\\nAnthropic Claude c468b48a-84df-43a4-8c46-8870630108a7\\nAnthropic Claude Instant b0eb9475-3a2c-43d1-94d3-56756fd43737\\nAnthropic Claude 3 Sonnet prod-6dw3qvchef7zy\\nAnthropic Claude 3 Haiku prod-ozonys2hmmpeu\\nCohere Command a61c46fe-1747-41aa-9af0-2e0ae8a9ce05\\nCohere Command Light 216b69fd-07d5-4c7b-866b-936456d68311\\nCohere Embed (English) b7568428-a1ab-46d8-bab3-37def50f6f6a\\nCohere Embed (Multilingual) 38e55671-c3fe-4a44-9783-3584906e7cad\\nMeta Llama 2 13B prod-ariujvyzvd2qy\\nMeta Llama 2 70B prod-2c2yc2s3guhqy\\nStable Diﬀusion XL 0.8 d0123e8d-50d6-4dba-8a26-3fed4899f388\\nStable Diﬀusion XL 1.0 prod-2lvuzn4iy6n6o\\nThe following is the format of the IAM policy you can attach to a role to control model access \\npermissions. You can see an example at Allow access to third-party model subscriptions.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \" Allow|Deny \", \\n            \"Action\": [ \\n                \"aws-marketplace: Subscribe \" \\n            ], \\n            \"Resource\": \"*\", \\n            \"Condition\": { \\nControl model access permissions 14Amazon Bedrock User Guide\\n                \"ForAnyValue:StringEquals\": { \\n                    \"aws-marketplace:ProductId\": [ \\n                         model-product-id-1 , \\n                         model-product-id-2 , \\n                        ... \\n                    ] \\n                } \\n            } \\n        }, \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"aws-marketplace:Unsubscribe\", \\n                \"aws-marketplace:ViewSubscriptions\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]\\n}\\nSet up the Amazon Bedrock API\\nThis section describes how to set up your environment to make Amazon Bedrock API calls and \\nprovides examples of common use-cases. You can access the Amazon Bedrock API using the AWS \\nCommand Line Interface (AWS CLI), an AWS SDK, or a SageMaker Notebook.\\nBefore you can access Amazon Bedrock APIs, you need to request access to the foundation models \\nthat you plan to use.\\nFor details about the API operations and parameters, see the Amazon Bedrock API Reference.\\nThe following resources provide additional information about the Amazon Bedrock API.\\n•AWS Command Line Interface\\n•Amazon Bedrock CLI commands\\n•Amazon Bedrock Runtime CLI commands\\n•Agents for Amazon Bedrock CLI commands\\n•Agents for Amazon Bedrock Runtime CLI commands\\nAPI setup 15Amazon Bedrock User Guide\\nAdd model access\\nImportant\\nBefore you can use any of the foundation models, you must request access to that model. \\nIf you try to use the model (with the API or within the console) before you have requested \\naccess to it, you will receive an error message. For more information, see Model access.\\nAmazon Bedrock endpoints\\nTo connect programmatically to an AWS service, you use an endpoint. Refer to the Amazon \\nBedrock endpoints and quotas chapter in the AWS General Reference for information about the \\nendpoints that you can use for Amazon Bedrock.\\nAmazon Bedrock provides the following service endpoints.\\n•bedrock – Contains control plane APIs for managing, training, and deploying models. For more \\ninformation, see Amazon Bedrock Actions and Amazon Bedrock Data Types.\\n•bedrock-runtime  – Contains data plane APIs for making inference requests for models hosted \\nin Amazon Bedrock. For more information, see Amazon Bedrock Runtime Actions and Amazon \\nBedrock Runtime Data Types.\\n•bedrock-agent  – Contains control plane APIs for creating and managing agents and \\nknowledge bases. For more information, see Agents for Amazon Bedrock Actions and Agents for \\nAmazon Bedrock Data Types.\\n•bedrock-agent-runtime  – Contains data plane APIs for invoking agents and querying \\nknowledge bases. For more information, see Agents for Amazon Bedrock Runtime Actions and\\nAgents for Amazon Bedrock Runtime Data Types.\\nSetting up the AWS CLI\\n1.If you plan to use the CLI, install and conﬁgure the AWS CLI by following the steps at Install or \\nupdate the latest version of the AWS Command Line Interface User Guide.\\n2.Conﬁgure your AWS credentials using the aws configure  CLI command by following the steps \\nat Conﬁgure the AWS CLI.\\nAdd model access 16Amazon Bedrock User Guide\\nRefer to the following references for AWS CLI commands and operations:\\n•Amazon Bedrock CLI commands\\n•Amazon Bedrock Runtime CLI commands\\n•Agents for Amazon Bedrock CLI commands\\n•Agents for Amazon Bedrock Runtime CLI commands\\nSetting up an AWS SDK\\nAWS software development kits (SDKs) are available for many popular programming languages. \\nEach SDK provides an API, code examples, and documentation that make it easier for developers \\nto build applications in their preferred language. SDKs automatically perform useful tasks for you, \\nsuch as:\\n•Cryptographically sign your service requests\\n•Retry requests\\n•Handle error responses\\nRefer to the following table to ﬁnd general information about and code examples for each SDK, as \\nwell as the Amazon Bedrock API references for each SDK. You can also ﬁnd code examples at Code \\nexamples for Amazon Bedrock using AWS SDKs.\\nSDK \\ndocumenta \\ntionCode \\nexamplesAmazon \\nBedrock \\npreﬁxAmazon \\nBedrock \\nruntime \\npreﬁxAgents for \\nAmazon \\nBedrock \\npreﬁxAgents for \\nAmazon \\nBedrock \\nruntime \\npreﬁx\\nAWS SDK for \\nC++AWS SDK \\nfor C++ code \\nexamplesbedrock bedrock-r \\nuntimebedrock-a \\ngentbedrock-a \\ngent-runtime\\nAWS SDK for \\nGoAWS SDK \\nfor Go code \\nexamplesbedrock bedrockru \\nntimebedrockag \\nentbedrockag \\nentruntime\\nAWS SDK setup 17Amazon Bedrock User Guide\\nSDK \\ndocumenta \\ntionCode \\nexamplesAmazon \\nBedrock \\npreﬁxAmazon \\nBedrock \\nruntime \\npreﬁxAgents for \\nAmazon \\nBedrock \\npreﬁxAgents for \\nAmazon \\nBedrock \\nruntime \\npreﬁx\\nAWS SDK for \\nJavaAWS SDK for \\nJava code \\nexamplesbedrockbedrockru \\nntimebedrockag \\nentbedrockag \\nentruntime\\nAWS SDK for \\nJavaScriptAWS SDK for \\nJavaScrip \\nt code \\nexamplesbedrockbedrock-r \\nuntimebedrock-a \\ngentbedrock-a \\ngent-runtime\\nAWS SDK for \\nKotlinAWS SDK for \\nKotlin code \\nexamplesbedrockbedrockru \\nntimebedrockag \\nentbedrockag \\nentruntime\\nAWS SDK \\nfor .NETAWS SDK \\nfor .NET code \\nexamplesBedrockBedrockRu \\nntimeBedrockAg \\nentBedrockAg \\nentRuntime\\nAWS SDK for \\nPHPAWS SDK for \\nPHP code \\nexamplesBedrockBedrockRu \\nntimeBedrockAg \\nentBedrockAg \\nentRuntime\\nAWS SDK \\nfor Python \\n(Boto3)AWS SDK \\nfor Python \\n(Boto3) code \\nexamplesbedrockbedrock-r \\nuntimebedrock-a \\ngentbedrock-a \\ngent-runtime\\nAWS SDK for \\nRubyAWS SDK for \\nRuby code \\nexamplesBedrockBedrockRu \\nntimeBedrockAg \\nentBedrockAg \\nentRuntime\\nAWS SDK setup 18Amazon Bedrock User Guide\\nSDK \\ndocumenta \\ntionCode \\nexamplesAmazon \\nBedrock \\npreﬁxAmazon \\nBedrock \\nruntime \\npreﬁxAgents for \\nAmazon \\nBedrock \\npreﬁxAgents for \\nAmazon \\nBedrock \\nruntime \\npreﬁx\\nAWS SDK for \\nRustAWS SDK for \\nRust code \\nexamplesaws-sdk-b \\nedrockaws-sdk-b \\nedrockrun \\ntimeaws-sdk-b \\nedrockagentaws-sdk-b \\nedrockage \\nntruntime\\nAWS SDK for \\nSAP ABAPAWS SDK \\nfor SAP \\nABAP code \\nexamplesBDK BDRBDABDZ\\nAWS SDK for \\nSwiftAWS SDK for \\nSwift code \\nexamplesAWSBedrockAWSBedroc \\nkRuntimeAWSBedroc \\nkAgentAWSBedroc \\nkAgentRun \\ntime\\nUsing SageMaker notebooks\\nYou can use the SDK for Python (Boto3) to invoke Amazon Bedrock API operations from a \\nSageMaker notebook.\\nConﬁgure the SageMaker role\\nAdd Amazon Bedrock permissions to the IAM role that will use this SageMaker notebook.\\nFrom the IAM console, perform these steps:\\n1.Choose the IAM role, then choose Add Permissions and select Create Inline Policies from the \\ndropdown list.\\n2.Include the following permission.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\nUsing SageMaker notebooks 19Amazon Bedrock User Guide\\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": \"bedrock:*\", \\n            \"Resource\": \"*\" \\n        } \\n    ]\\n}            \\nAdd the following permissions to the trust relationships.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"Service\": \"bedrock.amazonaws.com\" \\n            }, \\n            \"Action\": \"sts:AssumeRole\" \\n        }, \\n        { \\n            \"Sid\": \"\", \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"Service\": \"sagemaker.amazonaws.com\" \\n            }, \\n            \"Action\": \"sts:AssumeRole\" \\n        } \\n    ]\\n}                    \\nTest the Runtime setup\\nAdd the following code to your notebook and run the code.\\nimport boto3\\nimport json\\nbedrock = boto3.client(service_name=\\'bedrock-runtime\\')\\nbody = json.dumps({ \\n    \"prompt\": \"\\\\n\\\\nHuman:explain black holes to 8th graders\\\\n\\\\nAssistant:\", \\n    \"max_tokens_to_sample\": 300, \\n    \"temperature\": 0.1, \\nUsing SageMaker notebooks 20Amazon Bedrock User Guide\\n    \"top_p\": 0.9,\\n})\\nmodelId = \\'anthropic.claude-v2\\'\\naccept = \\'application/json\\'\\ncontentType = \\'application/json\\'\\nresponse = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, \\n contentType=contentType)\\nresponse_body = json.loads(response.get(\\'body\\').read())\\n# text\\nprint(response_body.get(\\'completion\\'))\\nTest the Amazon Bedrock setup\\nAdd the following code to your notebook and run the code.\\nimport boto3\\nbedrock = boto3.client(service_name=\\'bedrock\\')\\nbedrock.get_foundation_model(modelIdentifier=\\'anthropic.claude-v2\\')\\nUsing this service with an AWS SDK\\nAWS software development kits (SDKs) are available for many popular programming languages. \\nEach SDK provides an API, code examples, and documentation that make it easier for developers to \\nbuild applications in their preferred language.\\nSDK documentation Code examples\\nAWS SDK for C++ AWS SDK for C++ code examples\\nAWS SDK for Go AWS SDK for Go code examples\\nAWS SDK for Java AWS SDK for Java code examples\\nAWS SDK for JavaScript AWS SDK for JavaScript code examples\\nAWS SDK for Kotlin AWS SDK for Kotlin code examples\\nWorking with AWS SDKs 21Amazon Bedrock User Guide\\nSDK documentation Code examples\\nAWS SDK for .NET AWS SDK for .NET code examples\\nAWS SDK for PHP AWS SDK for PHP code examples\\nAWS SDK for Python (Boto3) AWS SDK for Python (Boto3) code examples\\nAWS SDK for Ruby AWS SDK for Ruby code examples\\nAWS SDK for Rust AWS SDK for Rust code examples\\nAWS SDK for SAP ABAP AWS SDK for SAP ABAP code examples\\nAWS SDK for Swift AWS SDK for Swift code examples\\nExample availability\\nCan\\'t ﬁnd what you need? Request a code example by using the Provide feedback link at \\nthe bottom of this page.\\nWorking with AWS SDKs 22Amazon Bedrock User Guide\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from the following providers. Select a link in \\nthe Provider column to see documentation for that provider.\\nProvider Model Input \\nmodalitiesOutput \\nmodalitiesInference \\nparametersHyperpara \\nmeters\\nTitan Text G1 \\n- ExpressText Text, Chat Link Link\\nTitan Text G1 \\n- LiteText Text Link Link\\nTitan Image \\nGenerator G1Text, Image Image Link Link\\nTitan \\nEmbeddings \\nG1 - TextText Embeddings Link N/AAmazon\\nTitan \\nMultimodal \\nEmbeddings \\nG1Text, Image Embeddings Link Link\\nClaude Text Text, Chat Link N/A\\nClaude \\nInstantText Text, Chat Link N/A\\nClaude 3 \\nSonnetText, Image Text, Chat Link N/AAnthropic\\nClaude 3 \\nHaikuText, Image Text, Chat Link N/A\\n23Amazon Bedrock User Guide\\nProvider Model Input \\nmodalitiesOutput \\nmodalitiesInference \\nparametersHyperpara \\nmeters\\nJurassic-2 \\nMidTextText, Chat Link N/A AI21 Labs\\nJurassic-2 \\nUltraTextText, Chat Link N/A\\nCommandTextText Link Link\\nCommand \\nLightTextText Link Link\\nEmbed \\nEnglishText Embeddings Link N/ACohere\\nEmbed \\nMultilingualText Embeddings Link N/A\\nLlama 2 Chat \\n13BTextText, Chat Link N/A\\nLlama 2 Chat \\n70BTextText, Chat Link N/A\\nLlama 2 13B \\n(see note \\nbelow)TextText Link LinkMeta\\nLlama 2 70B \\n(see note \\nbelow)TextText Link Link\\nMistral 7B \\nInstructTextText Link N/A Mistral AI\\nMixtral 8X7B \\nInstructTextText Link N/A\\n24Amazon Bedrock User Guide\\nProvider Model Input \\nmodalitiesOutput \\nmodalitiesInference \\nparametersHyperpara \\nmeters\\nStability AI Stable \\nDiﬀusion XLText, Image Image Link N/A\\nNote\\nThe Meta Llama 2 (non-chat) models can only be used after being customized and after\\npurchasing Provisioned Throughput for them.\\nThe following sections provide information about using foundation models and reference \\ninformation for models.\\nTopics\\n•Using foundation models\\n•Get information about foundation models\\n•Model support by AWS Region\\n•Model support by feature\\n•Model lifecycle\\n•Amazon Bedrock model IDs\\n•Inference parameters for foundation models\\n•Custom model hyperparameters\\nUsing foundation models\\nYou must request access to a model before you can use it. After doing so, you can then use FMs in \\nthe following ways.\\n•Run inference by sending prompts to a model and generating responses. The playgrounds oﬀer \\na user-friendly interface in the AWS Management Console for generating text, images, or chats. \\nSee the Output modality column to determine the models you can use in each playground.\\nUsing foundation models 25Amazon Bedrock User Guide\\nNote\\nThe console playgrounds don\\'t support running inference on embeddings models. Use \\nthe API to run inference on embeddings models.\\n•Evaluate models  to compare outputs and determine the best model for your use-case.\\n•Set up a knowledge base with the help of an embeddings model. Then use a text model to \\ngenerate responses to queries.\\n•Create an agent and use a model to run inference on prompts to carry out orchestration.\\n•Customize a model by feeding training and validation data to adjust model parameters for your \\nuse-case. To use a customized model, you must purchase Provisioned Throughput for it.\\n•Purchase Provisioned Throughput for a model to increase throughput for it.\\nTo use an FM in the API, you need to determine the appropriate model ID  to use.\\nUse case How to ﬁnd the model ID\\nUse a base model Look up the ID in the base model IDs chart\\nPurchase Provisioned Throughput for a base \\nmodelLook up the ID in the model IDs for Provision \\ned Throughput chart and use it as the\\nmodelId  in the CreateProvisionedModelThrou \\nghput  request.\\nPurchase Provisioned Throughput for a \\ncustom modelUse the name of the custom model or its ARN \\nas the modelId  in the CreateProvisionedM \\nodelThroughput request.\\nUse a provisioned model After you create a Provisioned Throughput, \\nit returns a provisionedModelArn . This \\nARN is the model ID.\\nUse a custom model Purchase Provisioned Throughput for \\nthe custom model and use the returned\\nprovisionedModelArn  as the model ID.\\nUsing foundation models 26Amazon Bedrock User Guide\\nGet information about foundation models\\nIn the Amazon Bedrock console, you can ﬁnd overarching information about Amazon Bedrock \\nfoundation model providers and the models they provide in the Providers and Base models\\nsections.\\nUse the API to retrieve information about Amazon Bedrock foundation model, including its \\nARN, model ID, modalities and features it supports, and whether it is deprecated or not, in a\\nFoundationModelSummary object.\\n•To return information about all the foundation models that Amazon Bedrock provides, send a\\nListFoundationModels request.\\nNote\\nThe response also returns model IDs that aren\\'t in the base model ID  or base model IDs \\nfor Provisioned Throughput charts. These model IDs are deprecated or for backwards \\ncompability.\\n•To return information about a speciﬁc foundation model, send a GetFoundationModel request, \\nspecifying the model ID .\\nSelect a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3  \\nbedrock = boto3.client(service_name=\\'bedrock\\')\\nGet model information 27Amazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3  \\nbedrock = boto3.client(service_name=\\'bedrock\\')\\nbedrock.get_foundation_model(modelIdentifier=\\'anthropic.claude-v2\\')\\nModel support by AWS Region\\nNote\\nAll models are supported in the US East (N. Virginia, us-east-1 ) and US West (Oregon,\\nus-west-2 ) Regions.\\nThe following table shows the FMs that are available in other Regions and whether they are \\nsupported in each Region.\\nModel Asia Paciﬁc \\n(Singapore)Asia Paciﬁc \\n(Tokyo)Europe \\n(Frankfurt)AWS GovCloud \\n(US-West)\\nAmazon Titan \\nText G1 - \\nExpressNo Yes Yes Yes\\nAmazon Titan \\nEmbeddings G1 \\n- TextNo Yes Yes No\\nAnthropic \\nClaude v2 (18K \\ncontext window)Yes No Yes No\\nAnthropic \\nClaude v2.1 No Yes Yes No\\nModel support by AWS Region 28Amazon Bedrock User Guide\\nModel Asia Paciﬁc \\n(Singapore)Asia Paciﬁc \\n(Tokyo)Europe \\n(Frankfurt)AWS GovCloud \\n(US-West)\\n(200K context \\nwindow)\\nAnthropic \\nClaude Instant \\nv1.x (18K \\ncontext window)Yes Yes No No\\nAnthropic \\nClaude Instant \\nv1.x (100K \\ncontext window)No No Yes No\\nModel support by feature\\nNote\\nYou can run inference on all available FMs.\\nThe following table details the support for features that are limited to certain FMs.\\nModel Model \\nevaluatio \\nnKnowledge \\nbase \\n(query)Knowledge \\nbase \\n(embeddin \\ngs)Agents Fine-\\ntuning \\n(custom \\nmodels)Continued \\npre-\\ntraining \\n(custom \\nmodels)Provision \\ned \\nThroughpu \\nt\\nAmazon \\nTitan \\nText G1 - \\nExpressYes No N/A No Yes Yes Yes\\nModel support by feature 29Amazon Bedrock User Guide\\nModel Model \\nevaluatio \\nnKnowledge \\nbase \\n(query)Knowledge \\nbase \\n(embeddin \\ngs)Agents Fine-\\ntuning \\n(custom \\nmodels)Continued \\npre-\\ntraining \\n(custom \\nmodels)Provision \\ned \\nThroughpu \\nt\\nAmazon \\nTitan \\nText G1 - \\nLiteYes No N/A NoYesYesYes\\nAmazon \\nTitan \\nEmbedding \\ns G1 - \\nTextNo No N/A No No NoYes\\nAmazon \\nTitan \\nMultimoda \\nl \\nEmbedding \\ns G1No NoYes NoYes NoYes\\nAmazon \\nTitan \\nImage \\nGenerator \\nG1 \\n(preview)No No N/A NoYes NoYes\\nAnthropic \\nClaude \\nv1Yes No N/A No No NoYes\\nAnthropic \\nClaude \\nv2YesYes N/AYes No NoYes\\nModel support by feature 30Amazon Bedrock User Guide\\nModel Model \\nevaluatio \\nnKnowledge \\nbase \\n(query)Knowledge \\nbase \\n(embeddin \\ngs)Agents Fine-\\ntuning \\n(custom \\nmodels)Continued \\npre-\\ntraining \\n(custom \\nmodels)Provision \\ned \\nThroughpu \\nt\\nAnthropic \\nClaude \\nv2.1NoYes N/AYes No NoYes\\nAnthropic \\nClaude \\nInstantYesYes N/AYes No NoYes\\nAnthropic \\nClaude 3 \\nSonnetNo No N/A No No No No\\nAnthropic \\nClaude 3 \\nHaikuNo No N/A No No No No\\nAI21 \\nLabs \\nJurassic- \\n2 MidYes No No No No No No\\nAI21 \\nLabs \\nJurassic- \\n2 UltraYes No No No No No No\\nCohere \\nCommandYes No N/A NoYes NoYes\\nCohere \\nCommand \\nLightYes No N/A NoYes NoYes\\nModel support by feature 31Amazon Bedrock User Guide\\nModel Model \\nevaluatio \\nnKnowledge \\nbase \\n(query)Knowledge \\nbase \\n(embeddin \\ngs)Agents Fine-\\ntuning \\n(custom \\nmodels)Continued \\npre-\\ntraining \\n(custom \\nmodels)Provision \\ned \\nThroughpu \\nt\\nCohere \\nEmbed \\nEnglishNo NoYes No No No No\\nCohere \\nEmbed \\nMultiling \\nualNo NoYes No No No No\\nMeta \\nLlama 2 \\nChat 13BYes No N/A No No NoYes\\nMeta \\nLlama 2 \\nChat 70BYes No N/A No No No No\\nMeta \\nLlama 2 \\n13BNo No N/A NoYes NoYes (see \\nnote \\nbelow)\\nMeta \\nLlama 2 \\n70BNo No N/A NoYes NoYes (see \\nnote \\nbelow)\\nMistral AI \\nMistral \\n7B \\nInstructNo No N/A No No NoYes\\nModel support by feature 32Amazon Bedrock User Guide\\nModel Model \\nevaluatio \\nnKnowledge \\nbase \\n(query)Knowledge \\nbase \\n(embeddin \\ngs)Agents Fine-\\ntuning \\n(custom \\nmodels)Continued \\npre-\\ntraining \\n(custom \\nmodels)Provision \\ned \\nThroughpu \\nt\\nMistral AI \\nMixtral \\n8X7B \\nInstructNo No N/A No No NoYes\\nStable \\nDiﬀusion \\nXL 0.8No No N/A No No No No\\nStable \\nDiﬀusion \\nXL 1.xNo No N/A No No NoYes\\nNote\\nThe Meta Llama 2 (non-chat) models can only be used after being customized and after\\npurchasing Provisioned Throughput for them.\\nModel lifecycle\\nAmazon Bedrock is continuously working to bring the latest versions of foundation models that \\nhave better capabilities, accuracy, and safety. As we launch new model versions, you can test them \\nwith the Amazon Bedrock console or API, and migrate your applications to beneﬁt from the latest \\nmodel versions.\\nA model oﬀered on Amazon Bedrock can be in one of these states: Active, Legacy, or  End-of-Life \\n(EOL).\\n•Active: The model provider is actively working on this version, and it will continue to get updates \\nsuch as bug ﬁxes and minor improvements.\\nModel lifecycle 33Amazon Bedrock User Guide\\n•Legacy: A version is marked Legacy when there is a more recent version which provides superior \\nperformance. Amazon Bedrock sets an EOL date for Legacy versions. The EOL date may vary \\ndepending on how you use the model (for example, whether you use on-demand throughput or \\nProvisioned Throughput for a base model, or Provisioned Throughput for a customized model). \\nWhile you can continue to use a Legacy version, you should plan to transition to an Active \\nversion before the EOL date.\\n•EOL: This version is no longer available for use. Any requests made to this version will fail.\\nThe console marks a model version\\'s state as Active or Legacy. When you make a\\nGetFoundationModel or ListFoundationModels call, you can ﬁnd the state of the model in the\\nmodelLifecycle  ﬁeld in the response. After the EOL date, the model version can only be fonud \\non this documentation page.\\nOn-Demand, Provisioned Throughput, and model customization\\nYou specify the version of a model when you use it in On-Demand  mode (for example,\\nanthropic.claude-v2 , anthropic.claude-v2:1 , etc.).\\nWhen you conﬁgure Provisioned Throughput, you must specify a model version that will remain \\nunchanged for the entire term. You can purchase a new Provisioned Throughput commitment (or \\nrenew an existing one) for a version if the commitment term ends before the version\\'s EOL date.\\nIf you customized a model, you can continue to use it until the EOL date of the base model version \\nthat you used for customization. You can also customize a legacy model version, but you should \\nplan to migrate before it reaches its EOL date.\\nNote\\nService quotas are shared among model minor versions.\\nLegacy versions\\nThe following table shows the legacy versions of models available on Amazon Bedrock.\\nOn-Demand, Provisioned Throughput, and model customization 34Amazon Bedrock User Guide\\nModel versionLegacy dateEOL dateRecommended \\nmodel version \\nreplacementRecommended \\nmodel ID\\nStable Diﬀusion \\nXL 0.8February 2, \\n2024April 30, 2024 Stable Diﬀusion \\nXL 1.xstability.stable-d \\niﬀusion-xl-v1\\nClaude v1.3 November 28, \\n2023February 28, \\n2024Claude v2.1 anthropic \\n.claude-v2:1\\nTitan \\nEmbeddings - \\nText v1.1November 7, \\n2023February 15, \\n2024Titan \\nEmbeddings - \\nText v1.2amazon.titan-\\nembed-text-v1\\nAmazon Bedrock model IDs\\nMany Amazon Bedrock API operations require the use of a model ID. Refer to the following table to \\ndetermine where to ﬁnd the model ID that you need to use.\\nUse case How to ﬁnd the model ID\\nUse a base model Look up the ID in the base model IDs chart\\nPurchase Provisioned Throughput for a base \\nmodelLook up the ID in the model IDs for Provision \\ned Throughput chart and use it as the\\nmodelId  in the CreateProvisionedModelThrou \\nghput  request.\\nPurchase Provisioned Throughput for a \\ncustom modelUse the name of the custom model or its ARN \\nas the modelId  in the CreateProvisionedM \\nodelThroughput request.\\nUse a provisioned model After you create a Provisioned Throughput, \\nit returns a provisionedModelArn . This \\nARN is the model ID.\\nAmazon Bedrock model IDs 35Amazon Bedrock User Guide\\nUse case How to ﬁnd the model ID\\nUse a custom model Purchase Provisioned Throughput for \\nthe custom model and use the returned\\nprovisionedModelArn  as the model ID.\\nTopics\\n•Base model IDs (on-demand throughput)\\n•Model IDs for purchasing Provisioned Throughput\\nBase model IDs (on-demand throughput)\\nThe following is a list of model IDs for the currently available base models. You use a \\nmodel ID through the API to identify the base model that you want to use with on-demand \\nthroughput, such as in a InvokeModel request, or that you want to customize, such as in a\\nCreateModelCustomizationJob request.\\nNote\\nYou should regularly check the Model lifecycle page for information about model \\ndeprecation and update model IDs as necessary. Once a model has reached end-of-life, the \\nmodel ID no longer works.\\nProvider Model name Version Model ID\\nAmazon Titan Text G1 - \\nExpress1.x amazon.titan-text- \\nexpress-v1\\nAmazon Titan Text G1 - Lite 1.x amazon.titan-text- \\nlite-v1\\nAmazon Titan Embeddings G1 \\n- Text1.x amazon.titan-embed-\\ntext-v1\\nBase models IDs (on-demand) 36Amazon Bedrock User Guide\\nProvider Model name Version Model ID\\nAmazon Titan Multimodal \\nEmbeddings G11.x amazon.titan-embed-\\nimage-v1\\nAmazon Titan Image \\nGenerator G11.x amazon.titan-image-\\ngenerator-v1\\nAnthropic Claude 2.0 anthropic.claude-v2\\nAnthropic Claude 2.1 anthropic.claude-v2:1\\nAnthropic Claude 3 Sonnet 1.0 anthropic.claude-3-\\nsonnet-20240229-v \\n1:0\\nAnthropic Claude 3 Haiku 1.0 anthropic.claude-3-\\nhaiku-20240307-v1:0\\nAnthropic Claude Instant 1.x anthropic.claude-i \\nnstant-v1\\nAI21 Labs Jurassic-2 Mid 1.x ai21.j2-mid-v1\\nAI21 Labs Jurassic-2 Ultra 1.x ai21.j2-ultra-v1\\nCohere Command 14.x cohere.command-tex \\nt-v14\\nCohere Command Light 15.x cohere.command-lig \\nht-text-v14\\nCohere Embed English 3.x cohere.embed-engli \\nsh-v3\\nCohere Embed Multilingual 3.x cohere.embed-multi \\nlingual-v3\\nMeta Llama 2 Chat 13B 1.x meta.llama2-13b-ch \\nat-v1\\nBase models IDs (on-demand) 37Amazon Bedrock User Guide\\nProvider Model name Version Model ID\\nMeta Llama 2 Chat 70B 1.x meta.llama2-70b-ch \\nat-v1\\nMistral AI Mistral 7B Instruct 0.x mistral.mistral-7b-\\ninstruct-v0:2\\nMistral AI Mixtral 8X7B Instruct 0.x mistral.mixtral-8x7b-\\ninstruct-v0:1\\nStability AI Stable Diﬀusion XL 0.x stability.stable-d \\niﬀusion-xl-v0\\nStability AI Stable Diﬀusion XL 1.x stability.stable-d \\niﬀusion-xl-v1\\nModel IDs for purchasing Provisioned Throughput\\nTo purchase Provisioned Throughput through the API, use the corresponding model ID when \\nprovisioning the model with a CreateProvisionedModelThroughput request. Provisioned \\nThroughput is available for the following models:\\nNote\\nSome models have multiple contextual versions whose availability diﬀers by region. For \\nmore information, see Model support by AWS Region.\\nModel name Model ID for provisioned throughput\\nTitan Text G1 - Express 8K amazon.titan-text-express-v1:0:8k\\nTitan Embeddings G1 - Text amazon.titan-embed-text-v1:2:8k\\nTitan Multimodal Embeddings G1 - Text amazon.titan-embed-image-v1:0\\nTitan Image Generator G1 amazon.titan-image-generator-v1:0\\nBase model IDs (for Provisioned Throughput) 38Amazon Bedrock User Guide\\nModel name Model ID for provisioned throughput\\nAnthropic Claude V2 18K anthropic.claude-v2:0:18k\\nAnthropic Claude V2 100K anthropic.claude-v2:0:100k\\nAnthropic Claude V2.1 18K anthropic.claude-v2:1:18k\\nAnthropic Claude V2.1 100K anthropic.claude-v2:1:100k\\nAnthropic Claude Instant V1 100K anthropic.claude-instant-v1:2:100K\\nCohere Command cohere.command-text-v14:7:4k\\nCohere Command Light cohere.command-light-text-v14:7:4k\\nStable Diﬀusion XL 1.0 stability.stable-diﬀusion-xl-v1:0\\nMeta Llama 2 Chat 13B meta.llama2-13b-chat-v1:0:4k\\nMeta Llama 2 13B (see note below)\\nMeta Llama 2 70B (see note below)\\nMistral 7B Instruct mistral.mistral-7b-instruct-v0:2:32k\\nMixtral 8X7B Instruct mistral.mixtral-8x7b-instruct-v0:1:32k\\nNote\\nThe Meta Llama 2 (non-chat) models can only be provisioned after they have been \\ncustomized. For more information, see Custom models . Use the name or ARN of the \\nresulting custom model to purchase Provisioned Throughput for it.\\nThe CreateProvisionedModelThroughput response returns a provisionedModelArn . You can use \\nthis ARN or the name of the provisioned model in supported Amazon Bedrock operations. For more \\ninformation about Provisioned Throughput, see Provisioned Throughput.\\nBase model IDs (for Provisioned Throughput) 39Amazon Bedrock User Guide\\nInference parameters for foundation models\\nThis section documents the inference parameters that you can use with the base models that \\nAmazon Bedrock provides.\\nOptionally, set inference parameters to inﬂuence the response generated by the model. You set \\ninference parameters in a playground in the console, or in the body  ﬁeld of the InvokeModel or\\nInvokeModelWithResponseStream API.\\nWhen you call a model, you also include a prompt for the model. For information about writing \\nprompts, see  Prompt engineering guidelines.\\nThe following sections deﬁne the inference parameters available for each base model. For \\na custom model, use the same inference parameters as the base model from which it was \\ncustomized.\\nTopics\\n•Amazon Titan models\\n•Anthropic\\xa0Claude models\\n•AI21 Labs\\xa0Jurassic-2 models\\n•Cohere models\\n•Meta\\xa0Llama 2 and Meta\\xa0Llama 2 Chat models\\n•Mistral AI models\\n•Stability.ai Diﬀusion models\\nAmazon Titan models\\nThe following pages describe inference parameters for Amazon Titan models.\\nTopics\\n•Amazon Titan Text models\\n•Amazon Titan Image Generator G1\\n•Amazon Titan Embeddings G1 - Text\\n•Amazon Titan Multimodal Embeddings G1\\nModel inference parameters 40Amazon Bedrock User Guide\\nAmazon Titan Text models\\nThe Amazon Titan Text models support the following inference parameters.\\nFor more information on Titan Text prompt engineering guidelines, see Titan Text Prompt \\nEngineering Guidelines .\\nFor more information on Titan models, see Amazon Titan Models.\\nTopics\\n•Request and response\\n•Code examples\\nRequest and response\\nThe request body is passed in the body  ﬁeld of an InvokeModel or\\nInvokeModelWithResponseStream request.\\nRequest\\n{ \\n    \"inputText\": string, \\n    \"textGenerationConfig\": { \\n        \"temperature\": float,   \\n        \"topP\": float, \\n        \"maxTokenCount\": int, \\n        \"stopSequences\": [string] \\n    }\\n}\\nThe following parameters are required:\\n•inputText – The prompt to provide the model for generating a response. To generate \\nresponses in a conversational style, wrap the prompt by using the following format:\\n\"inputText\": \"User: <prompt> \\\\nBot:\\nThe textGenerationConfig  is optional. You can use it to conﬁgure the following inference \\nparameters :\\nAmazon Titan models 41Amazon Bedrock User Guide\\n•temperature  – Use a lower value to decrease randomness in responses.\\nDefault Minimum Maximum\\n0.0 0.0 1.0\\n•topP  – Use a lower value to ignore less probable options and decrease the diversity of \\nresponses.\\nDefault Minimum Maximum\\n1 1.00E-45 1\\n•maxTokenCount – Specify the maximum number of tokens to generate in the response.\\nDefault Minimum Maximum\\n512 0 8,000\\n•stopSequences – Specify a character sequence to indicate where the model should stop. \\nCurrently, you can only specify one of the following options:\\n•|\\n•User:\\nInvokeModel Response\\nThe response body contains the following possible ﬁelds:\\n{ \\n    \\'inputTextTokenCount\\': int, \\n    \\'results\\': [{ \\n        \\'tokenCount\\': int, \\n        \\'outputText\\': \\'\\\\n <response> \\\\n\\', \\n        \\'completionReason\\': string \\n    }]\\n}\\nMore information about each ﬁeld is provided below.\\nAmazon Titan models 42Amazon Bedrock User Guide\\n•inputTextTokenCount  – The number of tokens in the prompt.\\n•tokenCount  – The number of tokens in the response.\\n•outputText  – The text in the response.\\n•completionReason  – The reason the response ﬁnished being generated. The following \\nreasons are possible.\\n•FINISHED  – The response was fully generated.\\n•LENGTH – The response was truncated because of the response length you set.\\nInvokeModelWithResponseStream Response\\nEach chunk of text in the body of the response stream is in the following format. You must \\ndecode the bytes  ﬁeld (see Use the API to invoke a model with a single prompt for an \\nexample).\\n{ \\n    \\'chunk\\': { \\n        \\'bytes\\': b\\'{ \\n            \"index\": int, \\n            \"inputTextTokenCount\": int, \\n            \"totalOutputTextTokenCount\": int, \\n            \"outputText\": \" <response-chunk> \", \\n            \"completionReason\": string \\n        }\\' \\n    }\\n}\\n•index – The index of the chunk in the streaming response.\\n•inputTextTokenCount  – The number of tokens in the prompt.\\n•totalOutputTextTokenCount  – The number of tokens in the response.\\n•outputText  – The text in the response.\\n•completionReason  – The reason the response ﬁnished being generated. The following \\nreasons are possible.\\n•FINISHED  – The response was fully generated.\\n•LENGTH – The response was truncated because of the response length you set.\\nAmazon Titan models 43Amazon Bedrock User Guide\\nCode examples\\nThe following example shows how to run inference with the Amazon Titan Text G1 - Express model \\nwith the Python SDK.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to create a list of action items from a meeting transcript\\nwith the Amazon &titan-text-express; model (on demand).\\n\"\"\"\\nimport json\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nclass ImageError(Exception): \\n    \"Custom exception for errors returned by Amazon &titan-text-express; model\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_text(model_id, body): \\n    \"\"\" \\n    Generate text using Amazon &titan-text-express; model on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        response (json): The response from the model. \\n    \"\"\" \\n    logger.info( \\n        \"Generating text with Amazon &titan-text-express; model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\nAmazon Titan models 44Amazon Bedrock User Guide\\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\"body\").read()) \\n    finish_reason = response_body.get(\"error\") \\n    if finish_reason is not None: \\n        raise ImageError(f\"Text generation error. Error is {finish_reason}\") \\n    logger.info( \\n        \"Successfully generated text with Amazon &titan-text-express; model %s\", \\n model_id) \\n    return response_body\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Amazon &titan-text-express; example. \\n    \"\"\" \\n    try: \\n        logging.basicConfig(level=logging.INFO, \\n                            format=\"%(levelname)s: %(message)s\") \\n        model_id = \\'amazon.titan-text-express-v1\\' \\n        prompt = \"\"\"Meeting transcript: Miguel: Hi Brant, I want to discuss the \\n workstream   \\n            for our new product launch Brant: Sure Miguel, is there anything in \\n particular you want \\n            to discuss? Miguel: Yes, I want to talk about how users enter into the \\n product. \\n            Brant: Ok, in that case let me add in Namita. Namita: Hey everyone  \\n            Brant: Hi Namita, Miguel wants to discuss how users enter into the product. \\n            Miguel: its too complicated and we should remove friction.   \\n            for example, why do I need to fill out additional forms?   \\n            I also find it difficult to find where to access the product \\n            when I first land on the landing page. Brant: I would also add that \\n            I think there are too many steps. Namita: Ok, I can work on the \\n            landing page to make the product more discoverable but brant \\nAmazon Titan models 45Amazon Bedrock User Guide\\n            can you work on the additonal forms? Brant: Yes but I would need  \\n            to work with James from another team as he needs to unblock the sign up \\n workflow. \\n            Miguel can you document any other concerns so that I can discuss with James \\n only once? \\n            Miguel: Sure. \\n            From the meeting transcript above, Create a list of action items for each \\n person. \"\"\" \\n        body = json.dumps({ \\n            \"inputText\": prompt, \\n            \"textGenerationConfig\": { \\n                \"maxTokenCount\": 4096, \\n                \"stopSequences\": [], \\n                \"temperature\": 0, \\n                \"topP\": 1 \\n            } \\n        }) \\n        response_body = generate_text(model_id, body) \\n        print(f\"Input token count: {response_body[\\'inputTextTokenCount\\']}\") \\n        for result in response_body[\\'results\\']: \\n            print(f\"Token count: {result[\\'tokenCount\\']}\") \\n            print(f\"Output text: {result[\\'outputText\\']}\") \\n            print(f\"Completion reason: {result[\\'completionReason\\']}\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    except ImageError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print( \\n            f\"Finished generating text with the Amazon &titan-text-express; model \\n {model_id}.\")\\nif __name__ == \"__main__\": \\nAmazon Titan models 46Amazon Bedrock User Guide\\n    main()\\nAmazon Titan Image Generator G1\\nThe Amazon Titan Image Generator G1 model supports the following inference parameters and \\nmodel responses when carrying out model inference.\\nTopics\\n•Request and response format\\n•Code examples\\nRequest and response format\\nWhen you make an InvokeModel call using the Amazon Titan Image Generator G1, replace \\nthe body ﬁeld of the request with the format that matches your use-case. All tasks share an\\nimageGenerationConfig  object, but each task has a parameters object speciﬁc to that task. The \\nfollowing use-cases are supported.\\ntaskType Task parameters \\nﬁeldType of task Deﬁnition\\nTEXT_IMAGE textToIma \\ngeParamsGeneration Generate an image \\nusing a text prompt.\\nINPAINTING inPaintin \\ngParamsEditing Modify an image by \\nchanging the inside \\nof a mask  to match \\nthe surrounding \\nbackground.\\nOUTPAINTING outPainti \\nngParamsEditing Modify an image by \\nseamlessly extending \\nthe region deﬁned by \\nthe mask .\\nIMAGE_VARIATION imageVari \\nationParamsEditing Modify an image by \\nproducing variations \\nof the original image.\\nAmazon Titan models 47Amazon Bedrock User Guide\\nEditing tasks require an image ﬁeld in the input. This ﬁeld consists of a string that deﬁnes the \\npixels in the image. Each pixel is deﬁned by 3 RGB channels, each of which ranges from 0 to \\n255 (for example, (255 255 0) would represent the color yellow). These channels are encoded in \\nbase64.\\nThe image you use must be in JPEG or PNG format.\\nIf you carry out inpainting or outpainting, you also deﬁne a mask , a region or regions that deﬁne \\nparts of the image to be modiﬁed. You can deﬁne the mask in one of two ways.\\n•maskPrompt  – Write a text prompt to describe the part of the image to be masked.\\n•maskImage  – Input a base64-encoded string that deﬁnes the masked regions by marking each \\npixel in the input image as (0 0 0) or (255 255 255).\\n•A pixel deﬁned as (0 0 0) is a pixel inside the mask.\\n•A pixel deﬁned as (255 255 255) is a pixel outside the mask.\\nYou can use a photo editing tool to draw masks. You can then convert the output JPEG or PNG \\nimage to base64-encoding to input into this ﬁeld. Otherwise, use the maskPrompt  ﬁeld instead \\nto allow the model to infer the mask.\\nSelect a tab to view API request bodies for diﬀerent image generation use-cases and explanations \\nof the ﬁelds.\\nText-to-image generation (Request)\\n{ \\n    \"taskType\": \"TEXT_IMAGE\", \\n    \"textToImageParams\": { \\n        \"text\": \"string\",       \\n        \"negativeText\": \"string\" \\n    }, \\n    \"imageGenerationConfig\": { \\n        \"numberOfImages\": int, \\n        \"height\": int, \\n        \"width\": int, \\n        \"cfgScale\": float, \\n        \"seed\": int \\n    }\\n}\\nAmazon Titan models 48Amazon Bedrock User Guide\\nThe textToImageParams  ﬁelds are described below.\\n•text (Required) – A text prompt to generate the image.\\n•negativeText (Optional) – A text prompt to deﬁne what not to include in the image.\\nNote\\nDon\\'t use negative words in the negativeText  prompt. For example, if you don\\'t \\nwant to include mirrors in an image, enter mirrors  in the negativeText  prompt. \\nDon\\'t enter no mirrors .\\nInpainting (Request)\\n{ \\n    \"taskType\": \"INPAINTING\", \\n    \"inPaintingParams\": { \\n        \"image\": \"base64-encoded string\",                          \\n        \"text\": \"string\", \\n        \"negativeText\": \"string\",         \\n        \"maskPrompt\": \"string\",                       \\n        \"maskImage\": \"base64-encoded string\",                    \\n    },                                                  \\n    \"imageGenerationConfig\": { \\n        \"numberOfImages\": int, \\n        \"height\": int, \\n        \"width\": int, \\n        \"cfgScale\": float \\n    }\\n}\\nThe inPaintingParams  ﬁelds are described below. The mask  deﬁnes the part of the image \\nthat you want to modify.\\n•image  (Required) – The JPEG or PNG image to modify, formatted as a string that speciﬁes a \\nsequence of pixels, each deﬁned in RGB values and encoded in base64. For examples of how \\nto encode an image into base64 and decode a base64-encoded string and transform it into an \\nimage, see the code examples.\\n•You must deﬁne one of the following ﬁelds (but not both) in order to deﬁne.\\n•maskPrompt  – A text prompt that deﬁnes the mask.\\nAmazon Titan models 49Amazon Bedrock User Guide\\n•maskImage  – A string that deﬁnes the mask by specifying a sequence of pixels that is the \\nsame size as the image. Each pixel is turned into an RGB value of (0 0 0) (a pixel inside the \\nmask) or (255 255 255) (a pixel outside the mask). For examples of how to encode an image \\ninto base64 and decode a base64-encoded string and transform it into an image, see the\\ncode examples.\\n•text (Optional) – A text prompt to deﬁne what to change inside the mask. If you don\\'t include \\nthis ﬁeld, the model tries to replace the entire mask area with the background.\\n•negativeText (Optional) – A text prompt to deﬁne what not to include in the image.\\nNote\\nDon\\'t use negative words in the negativeText  prompt. For example, if you don\\'t \\nwant to include mirrors in an image, enter mirrors  in the negativeText  prompt. \\nDon\\'t enter no mirrors .\\nOutpainting (Request)\\n{ \\n    \"taskType\": \"OUTPAINTING\", \\n    \"outPaintingParams\": { \\n        \"text\": \"string\", \\n        \"negativeText\": \"string\",         \\n        \"image\": \"base64-encoded string\",                          \\n        \"maskPrompt\": \"string\",                       \\n        \"maskImage\": \"base64-encoded string\",                              \\n        \"outPaintingMode\": \"DEFAULT | PRECISE\"                  \\n    },                                                  \\n    \"imageGenerationConfig\": { \\n        \"numberOfImages\": int, \\n        \"height\": int, \\n        \"width\": int, \\n        \"cfgScale\": float \\n    }\\n}\\nThe outPaintingParams  ﬁelds are deﬁned below. The mask  deﬁnes the region in the image \\nwhose that you don\\'t want to modify. The generation seamlessly extends the region you deﬁne.\\nAmazon Titan models 50Amazon Bedrock User Guide\\n•image  (Required) – The JPEG or PNG image to modify, formatted as a string that speciﬁes a \\nsequence of pixels, each deﬁned in RGB values and encoded in base64. For examples of how \\nto encode an image into base64 and decode a base64-encoded string and transform it into an \\nimage, see the code examples.\\n•You must deﬁne one of the following ﬁelds (but not both) in order to deﬁne.\\n•maskPrompt  – A text prompt that deﬁnes the mask.\\n•maskImage  – A string that deﬁnes the mask by specifying a sequence of pixels that is the \\nsame size as the image. Each pixel is turned into an RGB value of (0 0 0) (a pixel inside the \\nmask) or (255 255 255) (a pixel outside the mask). For examples of how to encode an image \\ninto base64 and decode a base64-encoded string and transform it into an image, see the\\ncode examples.\\n•text (Required) – A text prompt to deﬁne what to change outside the mask.\\n•negativeText (Optional) – A text prompt to deﬁne what not to include in the image.\\nNote\\nDon\\'t use negative words in the negativeText  prompt. For example, if you don\\'t \\nwant to include mirrors in an image, enter mirrors  in the negativeText  prompt. \\nDon\\'t enter no mirrors .\\n•outPaintingMode – Speciﬁes whether to allow modiﬁcation of the pixels inside the mask or \\nnot. The following values are possible.\\n•DEFAULT – Use this option to allow modiﬁcation of the image inside the mask in order to \\nkeep it consistent with the reconstructed background.\\n•PRECISE – Use this option to prevent modiﬁcation of the image inside the mask.\\nImage variation (Request)\\n{ \\n     \"taskType\": \"IMAGE_VARIATION\", \\n     \"imageVariationParams\": { \\n         \"text\": \"string\", \\n         \"negativeText\": \"string\", \\n         \"images\": [\"base64-encoded string\"], \\n     }, \\n     \"imageGenerationConfig\": { \\n         \"numberOfImages\": int, \\nAmazon Titan models 51Amazon Bedrock User Guide\\n         \"height\": int, \\n         \"width\": int, \\n         \"cfgScale\": float \\n     }\\n}\\nThe imageVariationParams  ﬁelds are deﬁned below.\\n•images  (Required) – A list of images for which to generate variations. Currently, you can only \\ninclude one image. An image is deﬁned as a base64-encoded image string. For examples of \\nhow to encode an image into base64 and decode a base64-encoded string and transform it \\ninto an image, see the code examples.\\n•text (Optional) – A text prompt that can deﬁne what to preserve and what to change in the \\nimage.\\n•negativeText (Optional) – A text prompt to deﬁne what not to include in the image.\\nNote\\nDon\\'t use negative words in the negativeText  prompt. For example, if you don\\'t \\nwant to include mirrors in an image, enter mirrors  in the negativeText  prompt. \\nDon\\'t enter no mirrors .\\nResponse body\\n{ \\n  \"images\": [ \\n    \"base64-encoded string\",  \\n    ... \\n  ], \\n  \"error\": \"string\"  \\n}\\nThe response body is a streaming object that contains one of the following ﬁelds.\\n•images – If the request is successful, it returns this ﬁeld, a list of base64-encoded strings, \\neach deﬁning a generated image. Each image is formatted as a string that speciﬁes a \\nsequence of pixels, each deﬁned in RGB values and encoded in base64. For examples of how \\nAmazon Titan models 52Amazon Bedrock User Guide\\nto encode an image into base64 and decode a base64-encoded string and transform it into an \\nimage, see the code examples.\\n•error – If the request violates the content moderation policy in one of the following \\nsituations, a message is returned in this ﬁeld.\\n•If the input text, image, or mask image is ﬂagged by the content moderation policy.\\n•If at least one output image is ﬂagged by the content moderation policy\\nThe shared and optional imageGenerationConfig  contains the following ﬁelds. If you don\\'t \\ninclude this object, the default conﬁgurations are used.\\n•numberOfImages  (Optional) – The number of images to generate.\\nMinimum Maximum Default\\n1 5 1\\n•cfgScale (Optional) – Speciﬁes how strongly the generated image should adhere to the prompt. \\nUse a lower value to introduce more randomness in the generation.\\nMinimum Maximum Default\\n1.1 10.0 8.0\\n•The following parameters deﬁne the size that you want the output image to be. For more details \\nabout pricing by image size, see Amazon Bedrock pricing.\\n•height  (Optional) – The height of the image in pixels. The default value is 1024.\\n•width  (Optional) – The width of the image in pixels. The default value is 1024.\\nThe following sizes are permissible.\\nWidth Height Aspect ratio Price equivalent to\\n1024 1024 1:1 1024 x 1024\\n768 768 1:1 512 x 512\\n512 512 1:1 512 x 512\\nAmazon Titan models 53Amazon Bedrock User Guide\\nWidth Height Aspect ratioPrice equivalent to\\n768 1152 2:3 1024 x 1024\\n384 576 2:3 512 x 512\\n1152 768 3:2 1024 x 1024\\n576 384 3:2 512 x 512\\n768 1280 3:5 1024 x 1024\\n384 640 3:5 512 x 512\\n1280 768 5:3 1024 x 1024\\n640 384 5:3 512 x 512\\n896 1152 7:9 1024 x 1024\\n448 576 7:9 512 x 512\\n1152 896 9:7 1024 x 1024\\n576 448 9:7 512 x 512\\n768 1408 6:11 1024 x 1024\\n384 704 6:11 512 x 512\\n1408 768 11:6 1024 x 1024\\n704 384 11:6 512 x 512\\n640 1408 5:11 1024 x 1024\\n320 704 5:11 512 x 512\\n1408 640 11:5 1024 x 1024\\n704 320 11:5 512 x 512\\nAmazon Titan models 54Amazon Bedrock User Guide\\nWidth Height Aspect ratioPrice equivalent to\\n1152 640 9:5 1024 x 1024\\n1173 640 16:9 1024 x 1024\\n•seed  (Optional) – Use to control and reproduce results. Determines the initial noise setting. Use \\nthe same seed and the same settings as a previous run to allow inference to create a similar \\nimage.\\nNote\\nYou can only set a seed for a TEXT_IMAGE generation task.\\nMinimum Maximum Default\\n0 2,147,483,646 0\\nCode examples\\nThe following examples show how to invoke the Amazon Titan Image Generator G1 model with on-\\ndemand throughput in the Python SDK. Select a tab to view an example for each use-case. Each \\nexample displays the image at the end.\\nText-to-image generation\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate an image from a text prompt with the Amazon Titan Image \\n Generator G1 model (on demand).\\n\"\"\"\\nimport base64\\nimport io\\nimport json\\nimport logging\\nimport boto3\\nfrom PIL import Image\\nAmazon Titan models 55Amazon Bedrock User Guide\\nfrom botocore.exceptions import ClientError\\nclass ImageError(Exception): \\n    \"Custom exception for errors returned by Amazon Titan Image Generator G1\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_image(model_id, body): \\n    \"\"\" \\n    Generate an image using Amazon Titan Image Generator G1 model on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        image_bytes (bytes): The image generated by the model. \\n    \"\"\" \\n    logger.info( \\n        \"Generating image with Amazon Titan Image Generator G1 model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\"body\").read()) \\n    base64_image = response_body.get(\"images\")[0] \\n    base64_bytes = base64_image.encode(\\'ascii\\') \\n    image_bytes = base64.b64decode(base64_bytes) \\n    finish_reason = response_body.get(\"error\") \\nAmazon Titan models 56Amazon Bedrock User Guide\\n    if finish_reason is not None: \\n        raise ImageError(f\"Image generation error. Error is {finish_reason}\") \\n    logger.info( \\n        \"Successfully generated image with Amazon Titan Image Generator G1 model \\n %s\", model_id) \\n    return image_bytes\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Amazon Titan Image Generator G1 example. \\n    \"\"\" \\n    logging.basicConfig(level=logging.INFO, \\n                        format=\"%(levelname)s: %(message)s\") \\n    model_id = \\'amazon.titan-image-generator-v1\\' \\n    prompt = \"\"\"A photograph of a cup of coffee from the side.\"\"\" \\n    body = json.dumps({ \\n        \"taskType\": \"TEXT_IMAGE\", \\n        \"textToImageParams\": { \\n            \"text\": prompt \\n        }, \\n        \"imageGenerationConfig\": { \\n            \"numberOfImages\": 1, \\n            \"height\": 1024, \\n            \"width\": 1024, \\n            \"cfgScale\": 8.0, \\n            \"seed\": 0 \\n        } \\n    }) \\n    try: \\n        image_bytes = generate_image(model_id=model_id, \\n                                     body=body) \\n        image = Image.open(io.BytesIO(image_bytes)) \\n        image.show() \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\nAmazon Titan models 57Amazon Bedrock User Guide\\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    except ImageError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print( \\n            f\"Finished generating image with Amazon Titan Image Generator G1 model \\n {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nInpainting\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to use inpainting to generate an image from a source image with  \\nthe Amazon Titan Image Generator G1 model (on demand).\\nThe example uses a mask prompt to specify the area to inpaint.\\n\"\"\"\\nimport base64\\nimport io\\nimport json\\nimport logging\\nimport boto3\\nfrom PIL import Image\\nfrom botocore.exceptions import ClientError\\nclass ImageError(Exception): \\n    \"Custom exception for errors returned by Amazon Titan Image Generator G1\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nAmazon Titan models 58Amazon Bedrock User Guide\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_image(model_id, body): \\n    \"\"\" \\n    Generate an image using Amazon Titan Image Generator G1 model on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        image_bytes (bytes): The image generated by the model. \\n    \"\"\" \\n    logger.info( \\n        \"Generating image with Amazon Titan Image Generator G1 model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\"body\").read()) \\n    base64_image = response_body.get(\"images\")[0] \\n    base64_bytes = base64_image.encode(\\'ascii\\') \\n    image_bytes = base64.b64decode(base64_bytes) \\n    finish_reason = response_body.get(\"error\") \\n    if finish_reason is not None: \\n        raise ImageError(f\"Image generation error. Error is {finish_reason}\") \\n    logger.info( \\n        \"Successfully generated image with Amazon Titan Image Generator G1 model \\n %s\", model_id) \\n    return image_bytes\\ndef main(): \\n    \"\"\" \\nAmazon Titan models 59Amazon Bedrock User Guide\\n    Entrypoint for Amazon Titan Image Generator G1 example. \\n    \"\"\" \\n    try: \\n        logging.basicConfig(level=logging.INFO, \\n                            format=\"%(levelname)s: %(message)s\") \\n        model_id = \\'amazon.titan-image-generator-v1\\' \\n        # Read image from file and encode it as base64 string. \\n        with open(\"/path/to/image\", \"rb\") as image_file: \\n            input_image = base64.b64encode(image_file.read()).decode(\\'utf8\\') \\n        body = json.dumps({ \\n            \"taskType\": \"INPAINTING\", \\n            \"inPaintingParams\": { \\n                \"text\": \"Modernize the windows of the house\", \\n                \"negativeText\": \"bad quality, low res\", \\n                \"image\": input_image, \\n                \"maskPrompt\": \"windows\" \\n            }, \\n            \"imageGenerationConfig\": { \\n                \"numberOfImages\": 1, \\n                \"height\": 512, \\n                \"width\": 512, \\n                \"cfgScale\": 8.0 \\n            } \\n        }) \\n        image_bytes = generate_image(model_id=model_id, \\n                                     body=body) \\n        image = Image.open(io.BytesIO(image_bytes)) \\n        image.show() \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    except ImageError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print( \\nAmazon Titan models 60Amazon Bedrock User Guide\\n            f\"Finished generating image with Amazon Titan Image Generator G1 model \\n {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nOutpainting\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to use outpainting to generate an image from a source image with  \\nthe Amazon Titan Image Generator G1 model (on demand).\\nThe example uses a mask image to outpaint the original image.\\n\"\"\"\\nimport base64\\nimport io\\nimport json\\nimport logging\\nimport boto3\\nfrom PIL import Image\\nfrom botocore.exceptions import ClientError\\nclass ImageError(Exception): \\n    \"Custom exception for errors returned by Amazon Titan Image Generator G1\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_image(model_id, body): \\n    \"\"\" \\n    Generate an image using Amazon Titan Image Generator G1 model on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\nAmazon Titan models 61Amazon Bedrock User Guide\\n    Returns: \\n        image_bytes (bytes): The image generated by the model. \\n    \"\"\" \\n    logger.info( \\n        \"Generating image with Amazon Titan Image Generator G1 model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\"body\").read()) \\n    base64_image = response_body.get(\"images\")[0] \\n    base64_bytes = base64_image.encode(\\'ascii\\') \\n    image_bytes = base64.b64decode(base64_bytes) \\n    finish_reason = response_body.get(\"error\") \\n    if finish_reason is not None: \\n        raise ImageError(f\"Image generation error. Error is {finish_reason}\") \\n    logger.info( \\n        \"Successfully generated image with Amazon Titan Image Generator G1 model \\n %s\", model_id) \\n    return image_bytes\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Amazon Titan Image Generator G1 example. \\n    \"\"\" \\n    try: \\n        logging.basicConfig(level=logging.INFO, \\n                            format=\"%(levelname)s: %(message)s\") \\n        model_id = \\'amazon.titan-image-generator-v1\\' \\n        # Read image and mask image from file and encode as base64 strings. \\nAmazon Titan models 62Amazon Bedrock User Guide\\n        with open(\"/path/to/image\", \"rb\") as image_file: \\n            input_image = base64.b64encode(image_file.read()).decode(\\'utf8\\') \\n        with open(\"/path/to/mask_image\", \"rb\") as mask_image_file: \\n            input_mask_image = base64.b64encode( \\n                mask_image_file.read()).decode(\\'utf8\\') \\n        body = json.dumps({ \\n            \"taskType\": \"OUTPAINTING\", \\n            \"outPaintingParams\": { \\n                \"text\": \"Draw a chocolate chip cookie\", \\n                \"negativeText\": \"bad quality, low res\", \\n                \"image\": input_image, \\n                \"maskImage\": input_mask_image, \\n                \"outPaintingMode\": \"DEFAULT\" \\n            }, \\n            \"imageGenerationConfig\": { \\n                \"numberOfImages\": 1, \\n                \"height\": 512, \\n                \"width\": 512, \\n                \"cfgScale\": 8.0 \\n            } \\n        } \\n        ) \\n        image_bytes = generate_image(model_id=model_id, \\n                                     body=body) \\n        image = Image.open(io.BytesIO(image_bytes)) \\n        image.show() \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    except ImageError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print( \\n            f\"Finished generating image with Amazon Titan Image Generator G1 model \\n {model_id}.\")\\nAmazon Titan models 63Amazon Bedrock User Guide\\nif __name__ == \"__main__\": \\n    main()\\nImage variation\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate an image variation from a source image with the\\nAmazon Titan Image Generator G1 model (on demand).\\n\"\"\"\\nimport base64\\nimport io\\nimport json\\nimport logging\\nimport boto3\\nfrom PIL import Image\\nfrom botocore.exceptions import ClientError\\nclass ImageError(Exception): \\n    \"Custom exception for errors returned by Amazon Titan Image Generator G1\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_image(model_id, body): \\n    \"\"\" \\n    Generate an image using Amazon Titan Image Generator G1 model on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        image_bytes (bytes): The image generated by the model. \\n    \"\"\" \\n    logger.info( \\nAmazon Titan models 64Amazon Bedrock User Guide\\n        \"Generating image with Amazon Titan Image Generator G1 model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\"body\").read()) \\n    base64_image = response_body.get(\"images\")[0] \\n    base64_bytes = base64_image.encode(\\'ascii\\') \\n    image_bytes = base64.b64decode(base64_bytes) \\n    finish_reason = response_body.get(\"error\") \\n    if finish_reason is not None: \\n        raise ImageError(f\"Image generation error. Error is {finish_reason}\") \\n    logger.info( \\n        \"Successfully generated image with Amazon Titan Image Generator G1 model \\n %s\", model_id) \\n    return image_bytes\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Amazon Titan Image Generator G1 example. \\n    \"\"\" \\n    try: \\n        logging.basicConfig(level=logging.INFO, \\n                            format=\"%(levelname)s: %(message)s\") \\n        model_id = \\'amazon.titan-image-generator-v1\\' \\n        # Read image from file and encode it as base64 string. \\n        with open(\"/path/to/image\", \"rb\") as image_file: \\n            input_image = base64.b64encode(image_file.read()).decode(\\'utf8\\') \\n        body = json.dumps({ \\n            \"taskType\": \"IMAGE_VARIATION\", \\nAmazon Titan models 65Amazon Bedrock User Guide\\n            \"imageVariationParams\": { \\n                \"text\": \"Modernize the house, photo-realistic, 8k, hdr\", \\n                \"negativeText\": \"bad quality, low resolution, cartoon\", \\n                \"images\": [input_image], \\n            }, \\n            \"imageGenerationConfig\": { \\n                \"numberOfImages\": 1, \\n                \"height\": 512, \\n                \"width\": 512, \\n                \"cfgScale\": 8.0 \\n            } \\n        }) \\n        image_bytes = generate_image(model_id=model_id, \\n                                     body=body) \\n        image = Image.open(io.BytesIO(image_bytes)) \\n        image.show() \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    except ImageError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print( \\n            f\"Finished generating image with Amazon Titan Image Generator G1 model \\n {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nAmazon Titan Embeddings G1 - Text\\nTitan Embeddings G1 - Text doesn\\'t support the use of inference parameters. The following \\nsections detail the request and response formats and provides a code example.\\nTopics\\nAmazon Titan models 66Amazon Bedrock User Guide\\n•Request and response\\n•Example code\\nRequest and response\\nThe request body is passed in the body  ﬁeld of an InvokeModel request.\\nRequest\\nThe only available ﬁeld is inputText , in which you can include text to convert into \\nembeddings.\\n{ \\n    \"inputText\": string\\n}\\nResponse\\nThe body of the response contains the following ﬁelds.\\n{ \\n    \"embedding\": [float, float, ...], \\n    \"inputTextTokenCount\": int\\n}\\nThe ﬁelds are described below.\\n•embedding  – An array that represents the embeddings vector of the input you provided.\\n•inputTextTokenCount – The number of tokens in the input.\\nExample code\\nThis example shows how to call the Amazon Titan Embeddings G1 - Text model to generate \\nembeddings.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate embeddings with the Amazon Titan Embeddings G1 - Text model (on \\n demand).\\nAmazon Titan models 67Amazon Bedrock User Guide\\n\"\"\"\\nimport json\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_embeddings(model_id, body): \\n    \"\"\" \\n    Generate a vector of embeddings for a text input using Amazon Titan Embeddings G1 - \\n Text on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        response (JSON): The text that the model generated, token information, and the \\n        reason the model stopped generating text. \\n    \"\"\" \\n    logger.info(\"Generating embeddings with Amazon Titan Embeddings G1 - Text model \\n %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\\'body\\').read()) \\n    return response_body\\ndef main(): \\nAmazon Titan models 68Amazon Bedrock User Guide\\n    \"\"\" \\n    Entrypoint for Amazon Titan Embeddings G1 - Text example. \\n    \"\"\" \\n    logging.basicConfig(level=logging.INFO, \\n                        format=\"%(levelname)s: %(message)s\") \\n    model_id = \"amazon.titan-embed-text-v1\" \\n    input_text = \"What are the different services that you offer?\" \\n    # Create request body. \\n    body = json.dumps({ \\n        \"inputText\": input_text, \\n    }) \\n    try: \\n        response = generate_embeddings(model_id, body) \\n        print(f\"Generated embeddings: {response[\\'embedding\\']}\") \\n        print(f\"Input Token count:  {response[\\'inputTextTokenCount\\']}\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    else: \\n        print(f\"Finished generating embeddings with Amazon Titan Embeddings G1 - Text \\n model {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nAmazon Titan Multimodal Embeddings G1\\nThis section provides request and respnose body formats and code examples for using Amazon \\nTitan Multimodal Embeddings G1.\\nAmazon Titan models 69Amazon Bedrock User Guide\\nTopics\\n•Request and response\\n•Example code\\nRequest and response\\nThe request body is passed in the body  ﬁeld of an InvokeModel request.\\nRequest\\nThe request body for Amazon Titan Multimodal Embeddings G1 includes the following ﬁelds.\\n{ \\n    \"inputText\": string, \\n    \"inputImage\": base64-encoded string, \\n    \"embeddingConfig\": { \\n        \"outputEmbeddingLength\": 256 | 384 | 1024 \\n    }\\n}\\nAt least one of the following ﬁelds is required. Include both to generate an embeddings vector \\nthat averages the resulting text embeddings and image embeddings vectors.\\n•inputText – Enter text to convert to embeddings.\\n•inputImage  – Encode the image that you want to convert to embeddings in base64 and enter \\nthe string in this ﬁeld. For examples of how to encode an image into base64 and decode a \\nbase64-encoded string and transform it into an image, see the code examples.\\nThe following ﬁeld is optional.\\n•embeddingConﬁg  – Contains an outputEmbeddingLength  ﬁeld, in which you specify one \\nof the following lengths for the output embeddings vector.\\n•256\\n•384\\n•1024 (default)\\nAmazon Titan models 70Amazon Bedrock User Guide\\nResponse\\nThe body of the response contains the following ﬁelds.\\n{ \\n    \"embedding\": [float, float, ...], \\n    \"inputTextTokenCount\": int, \\n    \"message\": string\\n}\\nThe ﬁelds are described below.\\n•embedding  – An array that represents the embeddings vector of the input you provided.\\n•inputTextTokenCount – The number of tokens in the text input.\\n•message  – Speciﬁes any errors that occur during generation.\\nExample code\\nThe following examples show how to invoke the Amazon Titan Multimodal Embeddings G1 model \\nwith on-demand throughput in the Python SDK. Select a tab to view an example for each use-case.\\nText embeddings\\nThis example shows how to call the Amazon Titan Multimodal Embeddings G1 model to \\ngenerate text embeddings.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate embeddings from text with the Amazon Titan Multimodal \\n Embeddings G1 model (on demand).\\n\"\"\"\\nimport json\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nclass EmbedError(Exception): \\nAmazon Titan models 71Amazon Bedrock User Guide\\n    \"Custom exception for errors returned by Amazon Titan Multimodal Embeddings G1\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_embeddings(model_id, body): \\n    \"\"\" \\n    Generate a vector of embeddings for a text input using Amazon Titan Multimodal \\n Embeddings G1 on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        response (JSON): The embeddings that the model generated, token information, \\n and the \\n        reason the model stopped generating embeddings. \\n    \"\"\" \\n    logger.info(\"Generating embeddings with Amazon Titan Multimodal Embeddings G1 \\n model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\\'body\\').read()) \\n    finish_reason = response_body.get(\"message\") \\n    if finish_reason is not None: \\n        raise EmbedError(f\"Embeddings generation error: {finish_reason}\") \\n    return response_body\\nAmazon Titan models 72Amazon Bedrock User Guide\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Amazon Titan Multimodal Embeddings G1 example. \\n    \"\"\" \\n    logging.basicConfig(level=logging.INFO, \\n                        format=\"%(levelname)s: %(message)s\") \\n    model_id = \"amazon.titan-embed-image-v1\" \\n    input_text = \"What are the different services that you offer?\" \\n    output_embedding_length = 256 \\n    # Create request body. \\n    body = json.dumps({ \\n        \"inputText\": input_text, \\n        \"embeddingConfig\": { \\n            \"outputEmbeddingLength\": output_embedding_length \\n        } \\n    }) \\n    try: \\n        response = generate_embeddings(model_id, body) \\n        print(f\"Generated text embeddings of length {output_embedding_length}: \\n {response[\\'embedding\\']}\") \\n        print(f\"Input text token count:  {response[\\'inputTextTokenCount\\']}\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n         \\n    except EmbedError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print(f\"Finished generating text embeddings with Amazon Titan Multimodal \\n Embeddings G1 model {model_id}.\")\\nAmazon Titan models 73Amazon Bedrock User Guide\\nif __name__ == \"__main__\": \\n    main()\\nImage embeddings\\nThis example shows how to call the Amazon Titan Multimodal Embeddings G1 model to \\ngenerate image embeddings.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate embeddings from an image with the Amazon Titan Multimodal \\n Embeddings G1 model (on demand).\\n\"\"\"\\nimport base64\\nimport json\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nclass EmbedError(Exception): \\n    \"Custom exception for errors returned by Amazon Titan Multimodal Embeddings G1\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_embeddings(model_id, body): \\n    \"\"\" \\n    Generate a vector of embeddings for an image input using Amazon Titan Multimodal \\n Embeddings G1 on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        response (JSON): The embeddings that the model generated, token information, \\n and the \\n        reason the model stopped generating embeddings. \\nAmazon Titan models 74Amazon Bedrock User Guide\\n    \"\"\" \\n    logger.info(\"Generating embeddings with Amazon Titan Multimodal Embeddings G1 \\n model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\\'body\\').read()) \\n    finish_reason = response_body.get(\"message\") \\n    if finish_reason is not None: \\n        raise EmbedError(f\"Embeddings generation error: {finish_reason}\") \\n    return response_body\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Amazon Titan Multimodal Embeddings G1 example. \\n    \"\"\" \\n    logging.basicConfig(level=logging.INFO, \\n                        format=\"%(levelname)s: %(message)s\") \\n    # Read image from file and encode it as base64 string. \\n    with open(\"/path/to/image\", \"rb\") as image_file: \\n        input_image = base64.b64encode(image_file.read()).decode(\\'utf8\\') \\n    model_id = \\'amazon.titan-embed-image-v1\\' \\n    output_embedding_length = 256 \\n    # Create request body. \\n    body = json.dumps({ \\n        \"inputImage\": input_image, \\n        \"embeddingConfig\": { \\n            \"outputEmbeddingLength\": output_embedding_length \\nAmazon Titan models 75Amazon Bedrock User Guide\\n        } \\n    }) \\n    try: \\n        response = generate_embeddings(model_id, body) \\n        print(f\"Generated image embeddings of length {output_embedding_length}: \\n {response[\\'embedding\\']}\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n         \\n    except EmbedError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print(f\"Finished generating image embeddings with Amazon Titan Multimodal \\n Embeddings G1 model {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nText and image embeddings\\nThis example shows how to call the Amazon Titan Multimodal Embeddings G1 model to \\ngenerate embeddings from a combined text and image input. The resulting vector is the \\naverage of the generated text embeddings vector and the image embeddings vector.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate embeddings from an image and accompanying text with the Amazon \\n Titan Multimodal Embeddings G1 model (on demand).\\n\"\"\"\\nimport base64\\nAmazon Titan models 76Amazon Bedrock User Guide\\nimport json\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nclass EmbedError(Exception): \\n    \"Custom exception for errors returned by Amazon Titan Multimodal Embeddings G1\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_embeddings(model_id, body): \\n    \"\"\" \\n    Generate a vector of embeddings for a combined text and image input using Amazon \\n Titan Multimodal Embeddings G1 on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        response (JSON): The embeddings that the model generated, token information, \\n and the \\n        reason the model stopped generating embeddings. \\n    \"\"\" \\n    logger.info(\"Generating embeddings with Amazon Titan Multimodal Embeddings G1 \\n model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\\'body\\').read()) \\n    finish_reason = response_body.get(\"message\") \\nAmazon Titan models 77Amazon Bedrock User Guide\\n    if finish_reason is not None: \\n        raise EmbedError(f\"Embeddings generation error: {finish_reason}\") \\n    return response_body\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Amazon Titan Multimodal Embeddings G1 example. \\n    \"\"\" \\n    logging.basicConfig(level=logging.INFO, \\n                        format=\"%(levelname)s: %(message)s\") \\n    model_id = \"amazon.titan-embed-image-v1\" \\n    input_text = \"A family eating dinner\" \\n    # Read image from file and encode it as base64 string. \\n    with open(\"/path/to/image\", \"rb\") as image_file: \\n        input_image = base64.b64encode(image_file.read()).decode(\\'utf8\\') \\n    output_embedding_length = 256 \\n    # Create request body. \\n    body = json.dumps({ \\n        \"inputText\": input_text, \\n        \"inputImage\": input_image, \\n        \"embeddingConfig\": { \\n            \"outputEmbeddingLength\": output_embedding_length \\n        } \\n    }) \\n    try: \\n        response = generate_embeddings(model_id, body) \\n        print(f\"Generated embeddings of length {output_embedding_length}: \\n {response[\\'embedding\\']}\") \\n        print(f\"Input text token count:  {response[\\'inputTextTokenCount\\']}\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\nAmazon Titan models 78Amazon Bedrock User Guide\\n              format(message)) \\n         \\n    except EmbedError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print(f\"Finished generating embeddings with Amazon Titan Multimodal \\n Embeddings G1 model {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nAnthropic\\xa0Claude models\\nThis section provides inference parameters and code examples for using Anthropic Claude models.\\nYou can use Amazon Bedrock to send Anthropic\\xa0Claude Text Completions API or Anthropic\\xa0Claude \\nMessages API  inference requests.\\nYou use the messages API to create conversational applications, such as a virtual assistant or a \\ncoaching application. Use the text completion API for single-turn text generation applications. For \\nexample, generating text for a blog post or summarizing text that a user supplies.\\nYou make inference requests to an Anthropic Claude model with InvokeModel or\\nInvokeModelWithResponseStream (streaming). You need the model ID for the model that you \\nwant to use. To get the model ID for Anthropic Claude models, see Base model IDs (on-demand \\nthroughput)  and Model IDs for purchasing Provisioned Throughput.\\nNote\\nTo use system prompts in inference calls, you must use Anthropic Claude version 2.1 or \\nAnthropic Claude 3 Sonnet. For information about creating system prompts, see https:// \\ndocs.anthropic.com/claude/docs/how-to-use-system-prompts in the Anthropic Claude \\ndocumentation.\\nTo avoid timeouts with Anthropic Claude version 2.1, we recommend limiting the input \\ntoken count in the prompt ﬁeld to 180K. We expect to address this timeout issue soon.\\nAnthropic\\xa0Claude models 79Amazon Bedrock User Guide\\nIn the inference call, ﬁll the body ﬁeld with a JSON object that conforms the type call you want to \\nmake, Anthropic\\xa0Claude Text Completions API or Anthropic\\xa0Claude Messages API.\\nFor information about creating prompts for Anthropic Claude models, see Introduction to prompt \\ndesign  in the Anthropic Claude documentation.\\nTopics\\n•Anthropic\\xa0Claude Text Completions API\\n•Anthropic\\xa0Claude Messages API\\nAnthropic\\xa0Claude Text Completions API\\nThis section provides inference parameters and code examples for using Anthropic Claude models \\nwith the Text Completions API.\\nTopics\\n•Anthropic\\xa0Claude Text Completions API overview\\n•Supported models\\n•Request and Response\\n•Code example\\nAnthropic\\xa0Claude Text Completions API overview\\nUse the Text Completion API for single-turn text generation from a user supplied prompt. For \\nexample, you can use the Text Completion API to generate text for a blog post or to summarize \\ntext input from a user.\\nFor information about creating prompts for Anthropic Claude models, see Introduction to prompt \\ndesign . If you want to use your existing Text Completions prompts with the Anthropic\\xa0Claude \\nMessages API , see Migrating from Text Completions.\\nSupported models\\nYou can use the Text Completions API with the following Anthropic Claude models.\\n•Anthropic Claude Instant v1.2\\n•Anthropic Claude v2\\nAnthropic\\xa0Claude models 80Amazon Bedrock User Guide\\n•Anthropic Claude v2.1\\nRequest and Response\\nThe request body is passed in the body ﬁeld of a request to InvokeModel or\\nInvokeModelWithResponseStream.\\nFor more information, see https://docs.anthropic.com/claude/reference/complete_post in the \\nAnthropic Claude documentation.\\nRequest\\nAnthropic Claude has the following inference parameters for a Text Completion inference call.\\n{ \\n    \"prompt\": \"\\\\n\\\\nHuman: <prompt> \\\\n\\\\nAssistant:\", \\n    \"temperature\": float, \\n    \"top_p\": float, \\n    \"top_k\": int, \\n    \"max_tokens_to_sample\": int, \\n    \"stop_sequences\": [string]\\n}\\nThe following are required parameters.\\n•prompt  – (Required) The prompt that you want Claude to complete. For proper response \\ngeneration you need to format your prompt using alternating \\\\n\\\\nHuman:  and \\\\n\\n\\\\nAssistant:  conversational turns. For example:\\n\"\\\\n\\\\nHuman: {userQuestion}\\\\n\\\\nAssistant:\"\\nFor more information, see Prompt validation in the Anthropic Claude documentation.\\n•max_tokens_to_sample – (Required) The maximum number of tokens to generate before \\nstopping. We recommend a limit of 4,000 tokens for optimal performance.\\nNote that Anthropic Claude models might stop generating tokens before reaching the value \\nof max_tokens_to_sample . Diﬀerent Anthropic Claude models have diﬀerent maximum \\nvalues for this parameter. For more information, see Model comparison in the Anthropic \\nClaude documentation.\\nAnthropic\\xa0Claude models 81Amazon Bedrock User Guide\\nDefault Minimum Maximum\\n200 0 4096\\nThe following are optional parameters.\\n•stop_sequences – (Optional) Sequences that will cause the model to stop generating.\\nAnthropic Claude models stop on \"\\\\n\\\\nHuman:\" , and may include additional built-in stop \\nsequences in the future. Use the stop_sequences  inference parameter to include additional \\nstrings that will signal the model to stop generating text.\\n•temperature  – (Optional) The amount of randomness injected into the response.\\nDefaults to 1. Ranges from 0 to 1. Use temp closer to 0 for analytical / multiple choice, and \\ncloser to 1 for creative and generative tasks.\\nDefault Minimum Maximum\\n0.5 0 4096\\n•top_p  – (Optional) Use nucleus sampling.\\nIn nucleus sampling, Anthropic Claude computes the cumulative distribution over all the \\noptions for each subsequent token in decreasing probability order and cuts it oﬀ once it \\nreaches a particular probability speciﬁed by top_p. You should alter either temperature  or\\ntop_p , but not both.\\nDefault Minimum Maximum\\n1 0 1\\n•top_k  – (Optional) Only sample from the top K options for each subsequent token.\\nUse top_k to remove long tail low probability responses.\\nAnthropic\\xa0Claude models 82Amazon Bedrock User Guide\\nDefault Minimum Maximum\\n250 0 500\\nResponse\\nThe Anthropic Claude model returns the following ﬁelds for a Text Completion inference call.\\n{ \\n    \"completion\": string, \\n    \"stop_reason\": string, \\n    \"stop\": string\\n}\\n•completion – The resulting completion up to and excluding the stop sequences.\\n•stop_reason  – The reason why the model stopped generating the response.\\n•\"stop_sequence\" – The model reached a stop sequence — either provided by you with the\\nstop_sequences  inference parameter, or a stop sequence built into the model.\\n•\"max_tokens\" – The model exceeded max_tokens_to_sample  or the model\\'s maximum \\nnumber of tokens.\\n•stop  – If you specify the stop_sequences  inference parameter, stop contains the stop \\nsequence that signalled the model to stop generating text. For example, holes  in the \\nfollowing response.\\n{ \\n    \"completion\": \" Here is a simple explanation of black \", \\n    \"stop_reason\": \"stop_sequence\", \\n    \"stop\": \"holes\"\\n}\\nIf you don\\'t specify stop_sequences , the value for stop is empty.\\nCode example\\nThese examples shows how to call the Anthropic Claude V2  model with on demand throughput. To \\nuse Anthropic Claude version 2.1, change the value of modelId  to anthropic.claude-v2:1 .\\nAnthropic\\xa0Claude models 83Amazon Bedrock User Guide\\nimport boto3\\nimport json\\nbrt = boto3.client(service_name=\\'bedrock-runtime\\')\\nbody = json.dumps({ \\n    \"prompt\": \"\\\\n\\\\nHuman: explain black holes to 8th graders\\\\n\\\\nAssistant:\", \\n    \"max_tokens_to_sample\": 300, \\n    \"temperature\": 0.1, \\n    \"top_p\": 0.9,\\n})\\nmodelId = \\'anthropic.claude-v2\\'\\naccept = \\'application/json\\'\\ncontentType = \\'application/json\\'\\nresponse = brt.invoke_model(body=body, modelId=modelId, accept=accept, \\n contentType=contentType)\\nresponse_body = json.loads(response.get(\\'body\\').read())\\n# text\\nprint(response_body.get(\\'completion\\'))\\nThe following example shows how to generate streaming text with Python using the prompt\\nwrite an essay for living on mars in 1000 words  and the Anthropic Claude V2 model:\\nimport boto3\\nimport json\\nbrt = boto3.client(service_name=\\'bedrock-runtime\\')\\nbody = json.dumps({ \\n    \\'prompt\\': \\'\\\\n\\\\nHuman: write an essay for living on mars in 1000 words\\\\n\\n\\\\nAssistant:\\', \\n    \\'max_tokens_to_sample\\': 4000\\n}) \\n                    \\nresponse = brt.invoke_model_with_response_stream( \\n    modelId=\\'anthropic.claude-v2\\',  \\n    body=body\\n) \\n     \\nstream = response.get(\\'body\\')\\nAnthropic\\xa0Claude models 84Amazon Bedrock User Guide\\nif stream: \\n    for event in stream: \\n        chunk = event.get(\\'chunk\\') \\n        if chunk: \\n            print(json.loads(chunk.get(\\'bytes\\').decode()))\\nAnthropic\\xa0Claude Messages API\\nThis section provides inference parameters and code examples for using the Anthropic Claude \\nMessages API.\\nTopics\\n•Anthropic\\xa0Claude Messages API overview\\n•Supported models\\n•Request and Response\\n•Code examples\\nAnthropic\\xa0Claude Messages API overview\\nYou can use the Messages API to create chat bots or virtual assistant applications. The API manages \\nthe conversational exchanges between a user and an Anthropic Claude model (assistant).\\nAnthropic trains Claude models to operate on alternating user and assistant conversational turns. \\nWhen creating a new message, you specify the prior conversational turns with the messages \\nparameter. The model then generates the next Message in the conversation.\\nEach input message must be an object with a role and content. You can specify a single user-role \\nmessage, or you can include multiple user and assistant messages. The ﬁrst message must always \\nuse the user role.\\nIf you are using the technique of preﬁlling the response from Claude (ﬁlling in the beginning of \\nClaude\\'s response by using a ﬁnal assistant role Message), Claude will respond by picking up from \\nwhere you left oﬀ. With this technique, Claude will still return a response with the assistant role.\\nIf the ﬁnal message uses the assistant role, the response content will continue immediately from \\nthe content in that message. You can use this to constrain part of the model\\'s response.\\nExample with a single user message:\\nAnthropic\\xa0Claude models 85Amazon Bedrock User Guide\\n[{\"role\": \"user\", \"content\": \"Hello, Claude\"}]\\nExample with multiple conversational turns:\\n[ \\n  {\"role\": \"user\", \"content\": \"Hello there.\"}, \\n  {\"role\": \"assistant\", \"content\": \"Hi, I\\'m Claude. How can I help you?\"}, \\n  {\"role\": \"user\", \"content\": \"Can you explain LLMs in plain English?\"},\\n]\\nExample with a partially-ﬁlled response from Claude:\\n[ \\n  {\"role\": \"user\", \"content\": \"Please describe yourself using only JSON\"}, \\n  {\"role\": \"assistant\", \"content\": \"Here is my JSON description:\\\\n{\"},\\n]\\nEach input message content may be either a single string or an array of content blocks, where \\neach block has a speciﬁc type. Using a string is shorthand for an array of one content block of type \\n\"text\". The following input messages are equivalent:\\n{\"role\": \"user\", \"content\": \"Hello, Claude\"}\\n{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Hello, Claude\"}]}\\nFor information about creating prompts for Anthropic Claude models, see Intro to prompting in the \\nAnthropic Claude documentation. If you have existing Text Completion prompts that you want to \\nmigrate to the messages API, see Migrating from Text Completions.\\nSystem prompts\\nYou can also include a system prompt in the request. A system prompt lets you provide context \\nand instructions to Anthropic Claude, such as specifying a particular goal or role. Specify a system \\nprompt in the system ﬁeld, as shown in the following example.\\n\"system\": \"You are Claude, an AI assistant created by Anthropic to be helpful, \\n                harmless, and honest. Your goal is to provide informative and \\n substantive responses \\n                to queries while avoiding potential harms.\"\\nAnthropic\\xa0Claude models 86Amazon Bedrock User Guide\\nFor more information, see System prompts in the Anthropic documentation.\\nMultimodal prompts\\nA multimodal prompt combines multiple modalities (images and text) in a single prompt. You \\nspecify the modalities in the content input ﬁeld. The following example shows how you could ask \\nAnthropic Claude to describe the content of a supplied image. For example code, see Multimodal \\ncode examples.\\n{ \\n    \"anthropic_version\": \"bedrock-2023-05-31\",  \\n    \"max_tokens\": 1024, \\n    \"messages\": [ \\n        { \\n            \"role\": \"user\", \\n            \"content\": [ \\n                { \\n                    \"type\": \"image\", \\n                    \"source\": { \\n                        \"type\": \"base64\", \\n                        \"media_type\": \"image/jpeg\", \\n                        \"data\": \"iVBORw...\" \\n                    } \\n                }, \\n                { \\n                    \"type\": \"text\", \\n                    \"text\": \"What\\'s in these images?\" \\n                } \\n            ] \\n        } \\n    ]\\n}\\nYou can supply up to 20 images to the model. You can\\'t put images in the assistant role.\\nEach image you include in a request counts towards your token usage. For more information, see\\nImage costs in the Anthropic documentation.\\nSupported models\\nYou can use the Messages API with the following Anthropic Claude models.\\n•Anthropic Claude Instant v1.2\\nAnthropic\\xa0Claude models 87Amazon Bedrock User Guide\\n•Anthropic Claude 2 v2\\n•Anthropic Claude 2 v2.1\\n•Anthropic Claude 3 Sonnet\\n•Anthropic Claude 3 Haiku\\nRequest and Response\\nThe request body is passed in the body ﬁeld of a request to InvokeModel or\\nInvokeModelWithResponseStream. The maximum size of the payload you can send in a request is \\n20MB.\\nFor more information, see https://docs.anthropic.com/claude/reference/messages_post.\\nRequest\\nAnthropic Claude has the following inference parameters for a messages inference call.\\n{ \\n    \"anthropic_version\": \"bedrock-2023-05-31\",     \\n    \"max_tokens\": int, \\n    \"system\": string,     \\n    \"messages\": [ \\n        { \\n            \"role\": string, \\n            \"content\": [ \\n                { \"type\": \"image\", \"source\": { \"type\": \"base64\", \"media_type\": \\n \"image/jpeg\", \"data\": \" content image bytes \" } }, \\n                { \"type\": \"text\", \"text\": \" content text \" } \\n      ] \\n        } \\n    ], \\n    \"temperature\": float, \\n    \"top_p\": float, \\n    \"top_k\": int, \\n    \"stop_sequences\": [string]\\n}               \\nThe following are required parameters.\\n•anthropic_version – (Required) The anthropic version. The value must be\\nbedrock-2023-05-31 .\\nAnthropic\\xa0Claude models 88Amazon Bedrock User Guide\\n•max_tokens – (Required) The maximum number of tokens to generate before stopping.\\nNote that Anthropic Claude models might stop generating tokens before reaching the value \\nof max_tokens . Diﬀerent Anthropic Claude models have diﬀerent maximum values for this \\nparameter. For more information, see Model comparison.\\n•messages  – (Required) The input messages.\\n•role – The role of the conversation turn. Valid values are user  and assistant .\\n•content – (required) The content of the conversation turn.\\n•type – (required) The type of the content. Valid values are image  and text .\\nIf you specify image, you must also specify the image source in the following format\\nsource – (required) The content of the conversation turn.\\n•type – (required) The encoding type for the image. You can specify base64 .\\n•media_type – (required) The type of the image. You can specify the following image \\nformats.\\n•image/jpeg\\n•image/png\\n•image/webp\\n•image/gif\\n•data  – (required) The base64 encoded image bytes for the image. The maximum image \\nsize is 3.75MB. The maximum height and width of an image is 8000 pixels.\\nIf you specify text, you must also specify the prompt in text .\\nThe following are optional parameters.\\n•system  – (Optional) The system prompt for the request.\\nA system prompt is a way of providing context and instructions to Anthropic Claude, such as \\nspecifying a particular goal or role. For more information, see How to use system prompts in \\nthe Anthropic documentation.\\nAnthropic\\xa0Claude models 89Amazon Bedrock User Guide\\nNote\\nYou can use system prompts with Anthropic Claude version 2.1 or higher.\\n•stop_sequences – (Optional) Custom text sequences that cause the model to stop generating. \\nAnthropic Claude models normally stop when they have naturally completed their turn, in \\nthis case the value of the stop_reason  response ﬁeld is end_turn . If you want the model to \\nstop generating when it encounters custom strings of text, you can use the stop_sequences\\nparameter. If the model encounters one of the custom text strings, the value of the\\nstop_reason  response ﬁeld is stop_sequence  and the value of stop_sequence  contains \\nthe matched stop sequence.\\nThe maximum number of entries is 8191.\\n•temperature  – (Optional) The amount of randomness injected into the response.\\nDefault Minimum Maximum\\n1 0 1\\n•top_p  – (Optional) Use nucleus sampling.\\nIn nucleus sampling, Anthropic Claude computes the cumulative distribution over all the \\noptions for each subsequent token in decreasing probability order and cuts it oﬀ once it \\nreaches a particular probability speciﬁed by top_p. You should alter either temperature  or\\ntop_p , but not both.\\nDefault Minimum Maximum\\n0.999 0 1\\nThe following are optional parameters.\\n•top_k  – (Optional) Only sample from the top K options for each subsequent token.\\nUse top_k to remove long tail low probability responses.\\nAnthropic\\xa0Claude models 90Amazon Bedrock User Guide\\nDefault Minimum Maximum\\nDisabled by default 0 100,000,000\\nResponse\\nThe Anthropic Claude model returns the following ﬁelds for a messages inference call.\\n{ \\n    \"id\": string, \\n    \"model\": string, \\n    \"type\" : \"message\", \\n    \"role\" : \"assistant\", \\n    \"content\": [ \\n        { \\n            \"type\": \"text\", \\n            \"text\": string \\n        } \\n    ], \\n    \"stop_reason\": string, \\n    \"stop_sequence\": string, \\n    \"usage\": { \\n        \"input_tokens\": integer, \\n        \"output_tokens\": integer \\n    } \\n     \\n}\\n•id – The unique identiﬁer for the response. The format and length of the ID might change \\nover time.\\n•model  – The ID for the Anthropic Claude model that made the request.\\n•stop_reason  – The reason why Anthropic Claude stopped generating the response.\\n•end_turn  – The model reached a natural stopping point\\n•max_tokens – The generated text exceeded the value of the max_tokens  input ﬁeld or \\nexceeded the maximum number of tokens that the model supports.\\' .\\n•stop_sequence – The model generated one of the stop sequences that you speciﬁed in the\\nstop_sequences  input ﬁeld.\\nAnthropic\\xa0Claude models 91Amazon Bedrock User Guide\\n•type – The type of response. The value is always message .\\n•role – The conversational role of the generated message. The value is always assistant .\\n•content – The content generated by the model. Returned as an array.\\n•type – The type of the content. Currently the only supported value is text .\\n•text – The text of the content.\\n•usage  – Container for the number of tokens that you supplied in the request and the number \\ntokens of that the model generated in the response.\\n•input_tokens – The number of input tokens in the request.\\n•output_tokens – The number tokens of that the model generated in the response.\\n•stop_sequence – The model generated one of the stop sequences that you speciﬁed in the\\nstop_sequences  input ﬁeld.\\nCode examples\\nThe following code examples show how to use the messges API.\\nTopics\\n•Messages code example\\n•Multimodal code examples\\nMessages code example\\nThis example shows how to send a single turn user message and a user turn with a preﬁlled \\nassistant message to an Anthropic Claude 3 Sonnet model.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate a message with Anthropic Claude (on demand).\\n\"\"\"\\nimport boto3\\nimport json\\nimport logging\\nfrom botocore.exceptions import ClientError\\nAnthropic\\xa0Claude models 92Amazon Bedrock User Guide\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_message(bedrock_runtime, model_id, system_prompt, messages, max_tokens): \\n    body=json.dumps( \\n        { \\n            \"anthropic_version\": \"bedrock-2023-05-31\", \\n            \"max_tokens\": max_tokens, \\n            \"system\": system_prompt, \\n            \"messages\": messages \\n        }   \\n    )   \\n     \\n    response = bedrock_runtime.invoke_model(body=body, modelId=model_id) \\n    response_body = json.loads(response.get(\\'body\\').read()) \\n    \\n    return response_body\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Anthropic Claude message example. \\n    \"\"\" \\n    try: \\n        bedrock_runtime = boto3.client(service_name=\\'bedrock-runtime\\') \\n        model_id = \\'anthropic.claude-3-sonnet-20240229-v1:0\\' \\n        system_prompt = \"Please respond only with emoji.\" \\n        max_tokens = 1000 \\n        # Prompt with user turn only. \\n        user_message =  {\"role\": \"user\", \"content\": \"Hello World\"} \\n        messages = [user_message] \\n        response = generate_message (bedrock_runtime, model_id, system_prompt, \\n messages, max_tokens) \\n        print(\"User turn only.\") \\n        print(json.dumps(response, indent=4)) \\n        # Prompt with both user turn and prefilled assistant response. \\nAnthropic\\xa0Claude models 93Amazon Bedrock User Guide\\n        #Anthropic Claude continues by using the prefilled assistant text. \\n        assistant_message =  {\"role\": \"assistant\", \"content\": \"<emoji>\"} \\n        messages = [user_message, assistant_message] \\n        response = generate_message(bedrock_runtime, model_id,system_prompt, messages, \\n max_tokens) \\n        print(\"User turn and prefilled assistant response.\") \\n        print(json.dumps(response, indent=4)) \\n    except ClientError as err: \\n        message=err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n            format(message))\\nif __name__ == \"__main__\": \\n    main()\\nMultimodal code examples\\nThe following examples show how to pass an image and prompt text in a multimodal message to \\nan Anthropic Claude 3 Sonnet model.\\nTopics\\n•Multimodal prompt with InvokeModel\\n•Streaming multimodal prompt with InvokeModelWithResponseStream\\nMultimodal prompt with InvokeModel\\nThe following example shows how to send a multimodal prompt to Anthropic Claude 3 Sonnet \\nwith InvokeModel.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to run a multimodal prompt with Anthropic Claude (on demand) and InvokeModel.\\n\"\"\"\\nimport json\\nimport logging\\nimport base64\\nimport boto3\\nAnthropic\\xa0Claude models 94Amazon Bedrock User Guide\\nfrom botocore.exceptions import ClientError\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef run_multi_modal_prompt(bedrock_runtime, model_id, messages, max_tokens): \\n    \"\"\" \\n    Invokes a model with a multimodal prompt. \\n    Args: \\n        bedrock_runtime: The Amazon Bedrock boto3 client. \\n        model_id (str): The model ID to use. \\n        messages (JSON) : The messages to send to the model. \\n        max_tokens (int) : The maximum  number of tokens to generate. \\n    Returns: \\n        None. \\n    \"\"\" \\n    body = json.dumps( \\n        { \\n            \"anthropic_version\": \"bedrock-2023-05-31\", \\n            \"max_tokens\": max_tokens, \\n             \"messages\": messages \\n        } \\n    ) \\n    response = bedrock_runtime.invoke_model( \\n        body=body, modelId=model_id) \\n    response_body = json.loads(response.get(\\'body\\').read()) \\n    return response_body\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Anthropic Claude multimodal prompt example. \\n    \"\"\" \\n    try: \\nAnthropic\\xa0Claude models 95Amazon Bedrock User Guide\\n        bedrock_runtime = boto3.client(service_name=\\'bedrock-runtime\\') \\n        model_id = \\'anthropic.claude-3-sonnet-20240229-v1:0\\' \\n        max_tokens = 1000 \\n        input_image = \"/path/to/image\" \\n        input_text = \"What\\'s in this image?\" \\n  \\n        # Read reference image from file and encode as base64 strings. \\n        with open(input_image, \"rb\") as image_file: \\n            content_image = base64.b64encode(image_file.read()).decode(\\'utf8\\') \\n        message = {\"role\": \"user\", \\n             \"content\": [ \\n                {\"type\": \"image\", \"source\": {\"type\": \"base64\", \\n                    \"media_type\": \"image/jpeg\", \"data\": content_image}}, \\n                {\"type\": \"text\", \"text\": input_text} \\n                ]} \\n     \\n        messages = [message] \\n        response = run_multi_modal_prompt( \\n            bedrock_runtime, model_id, messages, max_tokens) \\n        print(json.dumps(response, indent=4)) \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message))\\nif __name__ == \"__main__\": \\n    main()\\nStreaming multimodal prompt with InvokeModelWithResponseStream\\nThe following example shows how to stream the response from a multimodal prompt sent to \\nAnthropic Claude 3 Sonnet with InvokeModelWithResponseStream.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\nAnthropic\\xa0Claude models 96Amazon Bedrock User Guide\\n\"\"\"\\nShows how to stream the response from Anthropic Claude Sonnet (on demand) for a  \\nmultimodal request.\\n\"\"\"\\nimport json\\nimport base64\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef stream_multi_modal_prompt(bedrock_runtime, model_id, input_text, image, \\n max_tokens): \\n    \"\"\" \\n    Streams the response from a multimodal prompt. \\n    Args: \\n        bedrock_runtime: The Amazon Bedrock boto3 client. \\n        model_id (str): The model ID to use. \\n        input_text (str) : The prompt text \\n        image (str) : The path to  an image that you want in the prompt. \\n        max_tokens (int) : The maximum  number of tokens to generate. \\n    Returns: \\n        None. \\n    \"\"\" \\n    with open(image, \"rb\") as image_file: \\n        encoded_string = base64.b64encode(image_file.read()) \\n    body = json.dumps({ \\n        \"anthropic_version\": \"bedrock-2023-05-31\", \\n        \"max_tokens\": max_tokens, \\n        \"messages\": [ \\n            { \\n                \"role\": \"user\", \\n                \"content\": [ \\n                    {\"type\": \"text\", \"text\": input_text}, \\n                    {\"type\": \"image\", \"source\": {\"type\": \"base64\", \\n                                                 \"media_type\": \"image/jpeg\", \"data\": \\n encoded_string.decode(\\'utf-8\\')}} \\nAnthropic\\xa0Claude models 97Amazon Bedrock User Guide\\n                ] \\n            } \\n        ] \\n    }) \\n    response = bedrock_runtime.invoke_model_with_response_stream( \\n        body=body, modelId=model_id) \\n    for event in response.get(\"body\"): \\n        chunk = json.loads(event[\"chunk\"][\"bytes\"]) \\n        if chunk[\\'type\\'] == \\'message_delta\\': \\n            print(f\"\\\\nStop reason: {chunk[\\'delta\\'][\\'stop_reason\\']}\") \\n            print(f\"Stop sequence: {chunk[\\'delta\\'][\\'stop_sequence\\']}\") \\n            print(f\"Output tokens: {chunk[\\'usage\\'][\\'output_tokens\\']}\") \\n        if chunk[\\'type\\'] == \\'content_block_delta\\': \\n            if chunk[\\'delta\\'][\\'type\\'] == \\'text_delta\\': \\n                print(chunk[\\'delta\\'][\\'text\\'], end=\"\")\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Anthropic Claude Sonnet multimodal prompt example. \\n    \"\"\" \\n    model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\" \\n    input_text = \"What can you tell me about this image?\" \\n    image = \"/path/to/image\" \\n    max_tokens = 100 \\n    try: \\n        bedrock_runtime = boto3.client(\\'bedrock-runtime\\') \\n        stream_multi_modal_prompt( \\n            bedrock_runtime, model_id, input_text, image, max_tokens) \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message))\\nAnthropic\\xa0Claude models 98Amazon Bedrock User Guide\\nif __name__ == \"__main__\": \\n    main()\\nAI21 Labs\\xa0Jurassic-2 models\\nThis section provides inference parameters and a code example for using AI21 Labs AI21 Labs \\nJurassic-2 models.\\nTopics\\n•Inference parameters\\n•Code example\\nInference parameters\\nThe AI21 Labs Jurassic-2 models support the following inference parameters.\\nTopics\\n•Randomness and Diversity\\n•Length\\n•Repetitions\\n•Model invocation request body ﬁeld\\n•Model invocation response body ﬁeld\\nRandomness and Diversity\\nThe AI21 Labs Jurassic-2 models support the following parameters to control randomness and \\ndiversity in the response.\\n•Temperature (temperature )– Use a lower value to decrease randomness in the response.\\n•Top P (topP) – Use a lower value to ignore less probable options.\\nLength\\nThe AI21 Labs Jurassic-2 models support the following parameters to control the length of the \\ngenerated response.\\nAI21 Labs\\xa0Jurassic-2 models 99Amazon Bedrock User Guide\\n•Max completion length (maxTokens ) – Specify the maximum number of tokens to use in the \\ngenerated response.\\n•Stop sequences (stopSequences ) – Conﬁgure stop sequences that the model recognizes and \\nafter which it stops generating further tokens. Press the Enter key to insert a newline character \\nin a stop sequence. Use the Tab key to ﬁnish inserting a stop sequence.\\nRepetitions\\nThe AI21 Labs Jurassic-2 models support the following parameters to control repetition in the \\ngenerated response.\\n•Presence penalty (presencePenalty ) – Use a higher value to lower the probability of \\ngenerating new tokens that already appear at least once in the prompt or in the completion.\\n•Count penalty (countPenalty ) – Use a higher value to lower the probability of generating new \\ntokens that already appear at least once in the prompt or in the completion. Proportional to the \\nnumber of appearances.\\n•Frequency penalty (frequencyPenalty ) – Use a high value to lower the probability of \\ngenerating new tokens that already appear at least once in the prompt or in the completion. The \\nvalue is proportional to the frequency of the token appearances (normalized to text length).\\n•Penalize special tokens – Reduce the probability of repetition of special characters. The default \\nvalues are true .\\n•Whitespaces (applyToWhitespaces ) – A true value applies the penalty to whitespaces and \\nnew lines.\\n•Punctuations (applyToPunctuation ) – A true value applies the penalty to punctuation.\\n•Numbers  (applyToNumbers ) – A true value applies the penalty to numbers.\\n•Stop words (applyToStopwords ) – A true value applies the penalty to stop words.\\n•Emojis  (applyToEmojis ) – A true value excludes emojis from the penalty.\\nModel invocation request body ﬁeld\\nWhen you make an InvokeModel or InvokeModelWithResponseStream call using an AI21 Labs \\nmodel, ﬁll the body ﬁeld with a JSON object that conforms to the one below. Enter the prompt in \\nthe prompt  ﬁeld.\\n{ \\n    \"prompt\": string, \\nAI21 Labs\\xa0Jurassic-2 models 100Amazon Bedrock User Guide\\n    \"temperature\": float, \\n    \"topP\": float, \\n    \"maxTokens\": int, \\n    \"stopSequences\": [string], \\n    \"countPenalty\": { \\n        \"scale\": float \\n    }, \\n    \"presencePenalty\": { \\n        \"scale\": float \\n    }, \\n    \"frequencyPenalty\": { \\n        \"scale\": float \\n    }\\n}\\nTo penalize special tokens, add those ﬁelds to any of the penalty objects. For example, you can \\nmodify the countPenalty  ﬁeld as follows.\\n\"countPenalty\": { \\n    \"scale\": float, \\n    \"applyToWhitespaces\": boolean, \\n    \"applyToPunctuations\": boolean, \\n    \"applyToNumbers\": boolean, \\n    \"applyToStopwords\": boolean, \\n    \"applyToEmojis\": boolean\\n}\\nThe following table shows the minimum, maximum, and default values for the numerical \\nparameters.\\nCategory Parameter JSON object \\nformatMinimum Maximum Default\\nTemperature temperature 0 1 0.5 Randomness \\nand diversity\\nTop P topP 0 1 0.5\\nLength Max tokens \\n(mid, ultra, \\nand large \\nmodels)maxTokens 0 8,191 200\\nAI21 Labs\\xa0Jurassic-2 models 101Amazon Bedrock User Guide\\nCategoryParameterJSON object \\nformatMinimum Maximum Default\\nMax tokens \\n(other \\nmodels)0 2,048 200\\nPresence \\npenaltypresenceP \\nenalty0 5 0\\nCount \\npenaltycountPenalty 0 1 0Repetitions\\nFrequency \\npenaltyfrequency \\nPenalty0 500 0\\nModel invocation response body ﬁeld\\nFor information about the format of the body ﬁeld in the response, see https://docs.ai21.com/ \\nreference/j2-complete-ref.\\nNote\\nAmazon Bedrock returns the response identiﬁer (id) as an integer value.\\nCode example\\nThis examples shows how to call the A2I AI21 Labs Jurassic-2 Mid  model.\\nimport boto3\\nimport json\\nbrt = boto3.client(service_name=\\'bedrock-runtime\\')\\nbody = json.dumps({ \\n    \"prompt\": \"Translate to spanish: \\'Amazon Bedrock is the easiest way to build and \\n scale generative AI applications with base models (FMs)\\'.\",  \\n    \"maxTokens\": 200, \\nAI21 Labs\\xa0Jurassic-2 models 102Amazon Bedrock User Guide\\n    \"temperature\": 0.5, \\n    \"topP\": 0.5\\n})\\nmodelId = \\'ai21.j2-mid-v1\\'\\naccept = \\'application/json\\'\\ncontentType = \\'application/json\\'\\nresponse = brt.invoke_model( \\n    body=body,  \\n    modelId=modelId,  \\n    accept=accept,  \\n    contentType=contentType\\n)\\nresponse_body = json.loads(response.get(\\'body\\').read())\\n# text\\nprint(response_body.get(\\'completions\\')[0].get(\\'data\\').get(\\'text\\'))\\nCohere models\\nThe following is inference parameters information for the Cohere models that Amazon Bedrock \\nsupports.\\nTopics\\n•Cohere\\xa0Command models\\n•Cohere\\xa0Embed models\\nCohere\\xa0Command models\\nYou make inference requests to an Cohere Command model with InvokeModel or\\nInvokeModelWithResponseStream (streaming). You need the model ID for the model that you want \\nto use. To get the model ID, see Amazon Bedrock model IDs.\\nTopics\\n•Request and Response\\n•Code example\\nCohere models 103Amazon Bedrock User Guide\\nRequest and Response\\nRequest\\nThe Cohere Command models have the following inference parameters.\\n{ \\n    \"prompt\": string, \\n    \"temperature\": float, \\n    \"p\": float, \\n    \"k\": float, \\n    \"max_tokens\": int, \\n    \"stop_sequences\": [string], \\n    \"return_likelihoods\": \"GENERATION|ALL|NONE\", \\n    \"stream\": boolean, \\n    \"num_generations\": int, \\n    \"logit_bias\": {token_id: bias}, \\n    \"truncate\": \"NONE|START|END\"\\n}\\nThe following are required parameters.\\n•prompt  – (Required) The input text that serves as the starting point for generating the \\nresponse.\\nThe following are text per call and character limits.\\nThe following are optional parameters.\\n•return_likelihoods – Specify how and if the token likelihoods are returned with the response. \\nYou can specify the following options.\\n•GENERATION  – Only return likelihoods for generated tokens.\\n•ALL – Return likelihoods for all tokens.\\n•NONE – (Default) Don\\'t return any likelihoods.\\n•stream  – ( Required to support streaming) Specify true to return the response piece-by-piece \\nin real-time and false to return the complete response after the process ﬁnishes.\\n•logit_bias – Prevents the model from generating unwanted tokens or incentivizes the model \\nto include desired tokens. The format is {token_id: bias}  where bias is a ﬂoat between \\nCohere models 104Amazon Bedrock User Guide\\n-10 and 10. Tokens can be obtained from text using any tokenization service, such as Cohere’s \\nTokenize endpoint. For more information, see Cohere documentation.\\nDefault Minimum Maximum\\nN/A -10 (for a token bias) 10 (for a token bias)\\n•num_generations  – The maximum number of generations that the model should return.\\nDefault Minimum Maximum\\n1 1 5\\n•truncate  – Speciﬁes how the API handles inputs longer than the maximum token length. Use \\none of the following:\\n•NONE – Returns an error when the input exceeds the maximum input token length.\\n•START – Discard the start of the input.\\n•END – (Default) Discards the end of the input.\\nIf you specify START  or END, the model discards the input until the remaining input is exactly \\nthe maximum input token length for the model.\\n•temperature  – Use a lower value to decrease randomness in the response.\\nDefault Minimum Maximum\\n0.9 0 5\\n•p – Top P. Use a lower value to ignore less probable options. Set to 0 or 1.0 to disable. If both\\np and k are enabled, p acts after k.\\nDefault Minimum Maximum\\n0.75 0 1\\n•k – Top K. Specify the number of token choices the model uses to generate the next token. If \\nboth p and k are enabled, p acts after k.\\nCohere models 105Amazon Bedrock User Guide\\nDefault Minimum Maximum\\n0 0 500\\n•max_tokens – Specify the maximum number of tokens to use in the generated response.\\nDefault Minimum Maximum\\n20 1 4096\\n•stop_sequences – Conﬁgure up to four sequences that the model recognizes. After a stop \\nsequence, the model stops generating further tokens. The returned text doesn\\'t contain the \\nstop sequence.\\nResponse\\nThe response has the following possible ﬁelds:\\n{ \\n    \"generations\": [ \\n        { \\n            \"finish_reason\": \"COMPLETE | MAX_TOKENS | ERROR | ERROR_TOXIC\", \\n            \"id\": string, \\n            \"text\": string, \\n            \"likelihood\" : float, \\n            \"token_likelihoods\" : [{\"token\" : float}], \\n            \"is_finished\" : true | false, \\n            \"index\" : integer \\n            \\n        } \\n    ], \\n    \"id\": string, \\n    \"prompt\": string\\n}\\n•generations  — A list of generated results along with the likelihoods for tokens requested. \\n(Always returned). Each generation object in the list contains the following ﬁelds.\\n•id — An identiﬁer for the generation. (Always returned).\\nCohere models 106Amazon Bedrock User Guide\\n•likelihood  — The likelihood of the output. The value is the average of the token \\nlikelihoods in token_likelihoods . Returned if you specify the return_likelihoods\\ninput parameter.\\n•token_likelihoods  — An array of per token likelihoods. Returned if you specify the\\nreturn_likelihoods  input parameter.\\n•finish_reason  — The reason why the model ﬁnished generating tokens. COMPLETE  - the \\nmodel sent back a ﬁnished reply. MAX_TOKENS  – the reply was cut oﬀ because the model \\nreached the maximum number of tokens for its context length. ERROR  – something went \\nwrong when generating the reply. ERROR_TOXIC  – the model generated a reply that was \\ndeemed toxic. finish_reason  is returned only when is_finished =true. (Not always \\nreturned).\\n•is_finished  — A boolean ﬁeld used only when stream  is true, signifying whether or \\nnot there are additional tokens that will be generated as part of the streaming response. \\n(Not always returned)\\n•text — The generated text.\\n•index — In a streaming response, use to determine which generation a given token \\nbelongs to. When only one response is streamed, all tokens belong to the same generation \\nand index is not returned. index therefore is only returned in a streaming request with a \\nvalue for num_generations  that is larger than one.\\n•prompt — The prompt from the input request (always returned).\\n•id — An identiﬁer for the request (always returned).\\nFor more information, see https://docs.cohere.com/reference/generate in the Cohere \\ndocumentations.\\nCode example\\nThis examples shows how to call the Cohere Command  model.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate text using a Cohere model.\\n\"\"\"\\nimport json\\nimport logging\\nCohere models 107Amazon Bedrock User Guide\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_text(model_id, body): \\n    \"\"\" \\n    Generate text using a Cohere model. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The reqest body to use. \\n    Returns: \\n        dict: The response from the model. \\n    \"\"\" \\n    logger.info(\"Generating text with Cohere model %s\", model_id) \\n    accept = \\'application/json\\' \\n    content_type = \\'application/json\\' \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    response = bedrock.invoke_model( \\n        body=body, \\n        modelId=model_id, \\n        accept=accept, \\n        contentType=content_type \\n    ) \\n    logger.info(\"Successfully generated text with Cohere model %s\", model_id) \\n    return response\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Cohere example. \\n    \"\"\" \\n    logging.basicConfig(level=logging.INFO, \\nCohere models 108Amazon Bedrock User Guide\\n                        format=\"%(levelname)s: %(message)s\") \\n    model_id = \\'cohere.command-text-v14\\' \\n    prompt = \"\"\"Summarize this dialogue:  \\n\"Customer: Please connect me with a support agent.\\nAI: Hi there, how can I assist you today?\\nCustomer: I forgot my password and lost access to the email affiliated to my account. \\n Can you please help me?\\nAI: Yes of course. First I\\'ll need to confirm your identity and then I can connect you \\n with one of our support agents.\\n\"\"\" \\n    try: \\n        body = json.dumps({ \\n            \"prompt\": prompt, \\n            \"max_tokens\": 200, \\n            \"temperature\": 0.6, \\n            \"p\": 1, \\n            \"k\": 0, \\n            \"num_generations\": 2, \\n            \"return_likelihoods\": \"GENERATION\" \\n        }) \\n        response = generate_text(model_id=model_id, \\n                                 body=body) \\n        response_body = json.loads(response.get(\\'body\\').read()) \\n        generations = response_body.get(\\'generations\\') \\n        for index, generation in enumerate(generations): \\n            print(f\"Generation {index + 1}\\\\n------------\") \\n            print(f\"Text:\\\\n {generation[\\'text\\']}\\\\n\") \\n            if \\'likelihood\\' in generation: \\n                print(f\"Likelihood:\\\\n {generation[\\'likelihood\\']}\\\\n\") \\n             \\n            print(f\"Reason: {generation[\\'finish_reason\\']}\\\\n\\\\n\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    else: \\n        print(f\"Finished generating text with Cohere model {model_id}.\")\\nCohere models 109Amazon Bedrock User Guide\\nif __name__ == \"__main__\": \\n    main()\\nCohere\\xa0Embed models\\nYou make inference requests to an Embed model with InvokeModel You need the model ID for the \\nmodel that you want to use. To get the model ID, see Amazon Bedrock model IDs.\\nNote\\nAmazon Bedrock doesn\\'t support streaming responses from Cohere Embed models.\\nTopics\\n•Request and Response\\n•Code example\\nRequest and Response\\nRequest\\nThe Cohere Embed models have the following inference parameters.\\n{ \\n    \"texts\":[string], \\n    \"input_type\": \"search_document|search_query|classification|clustering\", \\n    \"truncate\": \"NONE|LEFT|RIGHT\"\\n}\\nThe following are required parameters.\\n•texts – (Required) An array of strings for the model to embed. For optimal performance, \\nwe recommend reducing the length of each text to less than 512 tokens. 1 token is about 4 \\ncharacters.\\nThe following are text per call and character limits.\\nTexts per call\\nCohere models 110Amazon Bedrock User Guide\\nMinimum Maximum\\n0 texts 128 texts\\nCharacters\\nMinimum Maximum\\n0 characters 2048 characters\\nThe following are optional parameters.\\n•input_type – Prepends special tokens to diﬀerentiate each type from one another. You \\nshould not mix diﬀerent types together, except when mixing types for for search and \\nretrieval. In this case, embed your corpus with the search_document  type and embedded \\nqueries with type search_query  type.\\n•search_document  – In search use-cases, use search_document  when you encode \\ndocuments for embeddings that you store in a vector database.\\n•search_query  – Use search_query  when querying your vector DB to ﬁnd relevant \\ndocuments.\\n•classification  – Use classification  when using embeddings as an input to a text \\nclassiﬁer.\\n•clustering  – Use clustering  to cluster the embeddings.\\n•truncate  – Speciﬁes how the API handles inputs longer than the maximum token length. Use \\none of the following:\\n•NONE – (Default) Returns an error when the input exceeds the maximum input token length.\\n•LEFT – Discard the start of the input.\\n•RIGHT – Discards the end of the input.\\nIf you specify LEFT  or RIGHT, the model discards the input until the remaining input is \\nexactly the maximum input token length for the model.\\nCohere models 111Amazon Bedrock User Guide\\nFor more information, see https://docs.cohere.com/reference/embed in the Cohere \\ndocumentation.\\nResponse\\nThe body response from a call to InvokeModel  is the following:\\n{ \\n    \"embeddings\": [ \\n        [ <array of 1024 floats>  ] \\n    ], \\n    \"id\": string, \\n    \"response_type\" : \"embeddings_floats, \\n    \"texts\": [string]\\n} \\n                     \\n                 \\nThe body response has the following ﬁelds:\\n•id – An identiﬁer for the response.\\n•response_type – The response type. This value is always embeddings_floats .\\n•embeddings  – An array of embeddings, where each embedding is an array of ﬂoats with \\n1024 elements. The length of the embeddings  array will be the same as the length of the \\noriginal texts array.\\n•texts – An array containing the text entries for which embeddings were returned.\\nFor more information, see https://docs.cohere.com/reference/embed.\\nCode example\\nThis examples shows how to call the Cohere Command Embed  model.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate text embeddings using the Cohere Embed English model.\\n\"\"\"\\nimport json\\nimport logging\\nCohere models 112Amazon Bedrock User Guide\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_text_embeddings(model_id, body): \\n    \"\"\" \\n    Generate text embedding by using the Cohere Embed model. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The reqest body to use. \\n    Returns: \\n        dict: The response from the model. \\n    \"\"\" \\n    logger.info( \\n        \"Generating text emdeddings with the Cohere Embed model %s\", model_id) \\n    accept = \\'*/*\\' \\n    content_type = \\'application/json\\' \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    response = bedrock.invoke_model( \\n        body=body, \\n        modelId=model_id, \\n        accept=accept, \\n        contentType=content_type \\n    ) \\n    logger.info(\"Successfully generated text with Cohere model %s\", model_id) \\n    return response\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Cohere Embed example. \\n    \"\"\" \\nCohere models 113Amazon Bedrock User Guide\\n    logging.basicConfig(level=logging.INFO, \\n                        format=\"%(levelname)s: %(message)s\") \\n    model_id = \\'cohere.embed-english-v3\\' \\n    text1 = \"hello world\" \\n    text2 = \"this is a test\" \\n    input_type = \"search_document\" \\n    try: \\n        body = json.dumps({ \\n            \"texts\": [ \\n                text1, \\n                text2], \\n            \"input_type\": input_type} \\n        ) \\n        response = generate_text_embeddings(model_id=model_id, \\n                                            body=body) \\n        response_body = json.loads(response.get(\\'body\\').read()) \\n        print(f\"ID: {response_body.get(\\'id\\')}\") \\n        print(f\"Response type: {response_body.get(\\'response_type\\')}\") \\n        print(\"Embeddings\") \\n        for i, embedding in enumerate(response_body.get(\\'embeddings\\')): \\n            print(f\"\\\\tEmbedding {i}\") \\n            print(*embedding) \\n        print(\"Texts\") \\n        for i, text in enumerate(response_body.get(\\'texts\\')): \\n            print(f\"\\\\tText {i}: {text}\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    else: \\n        print( \\n            f\"Finished generating text embeddings with Cohere model {model_id}.\")\\nif __name__ == \"__main__\": \\nCohere models 114Amazon Bedrock User Guide\\n    main()\\nMeta\\xa0Llama 2 and Meta\\xa0Llama 2 Chat models\\nThis section provides inference parameters and a code example for using Meta Llama 2 and Meta \\nLlama 2 Chat models.\\nTopics\\n•Request and response\\n•Example code\\nRequest and response\\nThe request body is passed in the body ﬁeld of a request to InvokeModel or\\nInvokeModelWithResponseStream.\\nRequest\\nMeta Llama 2 Chat and Llama 2 models have the following inference parameters.\\n{ \\n    \"prompt\": string, \\n    \"temperature\": float, \\n    \"top_p\": float, \\n    \"max_gen_len\": int\\n}\\nThe following are required parameters.\\n•prompt  – (Required) The prompt that you want to pass to the model.\\nThe following are optional parameters.\\n•temperature  – Use a lower value to decrease randomness in the response.\\nDefault Minimum Maximum\\n0.5 0 1\\nMeta\\xa0Llama 2 models 115Amazon Bedrock User Guide\\n•top_p  – Use a lower value to ignore less probable options. Set to 0 or 1.0 to disable.\\nDefault Minimum Maximum\\n0.9 0 1\\n•max_gen_len – Specify the maximum number of tokens to use in the generated response. \\nThe model truncates the response once the generated text exceeds max_gen_len .\\nDefault Minimum Maximum\\n512 1 2048\\nResponse\\nMeta Llama 2 and Llama 2 Chat models return the following ﬁelds for a text completion \\ninference call.\\n{ \\n    \"generation\": \"\\\\n\\\\n <response> \", \\n    \"prompt_token_count\": int, \\n    \"generation_token_count\": int, \\n    \"stop_reason\" : string\\n}\\nMore information about each ﬁeld is provided below.\\n•generation  – The generated text.\\n•prompt_token_count – The number of tokens in the prompt.\\n•generation_token_count – The number of tokens in the generated text.\\n•stop_reason  – The reason why the response stopped generating text. Possible values are:\\n•stop  – The model has ﬁnished generating text for the input prompt.\\n•length – The length of the tokens for the generated text exceeds the value of\\nmax_gen_len  in the call to InvokeModel  (InvokeModelWithResponseStream , if \\nyou are streaming output). The response is truncated to max_gen_len  tokens. Consider \\nincreasing the value of max_gen_len  and trying again.\\nMeta\\xa0Llama 2 models 116Amazon Bedrock User Guide\\nExample code\\nThis example shows how to call the Meta Llama 2 Chat 13B  model.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate text with Meta Llama 2 Chat (on demand).\\n\"\"\"\\nimport json\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_text(model_id, body): \\n    \"\"\" \\n    Generate an image using Meta Llama 2 Chat on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        response (JSON): The text that the model generated, token information, and the \\n        reason the model stopped generating text. \\n    \"\"\" \\n    logger.info(\"Generating image with Meta Llama 2 Chat model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\nMeta\\xa0Llama 2 models 117Amazon Bedrock User Guide\\n    response_body = json.loads(response.get(\\'body\\').read()) \\n    return response_body\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Meta Llama 2 Chat example. \\n    \"\"\" \\n    logging.basicConfig(level=logging.INFO, \\n                        format=\"%(levelname)s: %(message)s\") \\n    model_id = \\'meta.llama2-13b-chat-v1\\' \\n    prompt = \"\"\"What is the average lifespan of a Llama?\"\"\" \\n    max_gen_len = 128 \\n    temperature = 0.1 \\n    top_p = 0.9 \\n    # Create request body. \\n    body = json.dumps({ \\n        \"prompt\": prompt, \\n        \"max_gen_len\": max_gen_len, \\n        \"temperature\": temperature, \\n        \"top_p\": top_p \\n    }) \\n    try: \\n        response = generate_text(model_id, body) \\n        print(f\"Generated Text: {response[\\'generation\\']}\") \\n        print(f\"Prompt Token count:  {response[\\'prompt_token_count\\']}\") \\n        print(f\"Generation Token count:  {response[\\'generation_token_count\\']}\") \\n        print(f\"Stop reason:  {response[\\'stop_reason\\']}\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\nMeta\\xa0Llama 2 models 118Amazon Bedrock User Guide\\n    else: \\n        print( \\n            f\"Finished generating text with Meta Llama 2 Chat model {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nMistral AI models\\nYou make inference requests to Mistral 7B Instruct and Mixtral 8X7B Instruct models with\\nInvokeModel or InvokeModelWithResponseStream (streaming). You need the model ID for the \\nmodel that you want to use. To get the model ID, see Amazon Bedrock model IDs.\\nMistral AI models are available under the Apache 2.0 license. For more information about using \\nMistral AI models, see the Mistral AI documentation .\\nTopics\\n•Request and Response\\n•Code example\\nRequest and Response\\nRequest\\nThe Mistral AI models have the following inference parameters.\\n{ \\n    \"prompt\": string, \\n    \"max_tokens\" : int, \\n    \"stop\" : [string],     \\n    \"temperature\": float, \\n    \"top_p\": float, \\n    \"top_k\": int\\n}\\nThe following are required parameters.\\n•prompt  – (Required) The prompt that you want to pass to the model, as shown in the \\nfollowing example.\\nMistral AI models 119Amazon Bedrock User Guide\\n<s>[INST] What is your favourite condiment? [/INST]\\nThe following example shows how to format is a multi-turn prompt.\\n<s>[INST] What is your favourite condiment? [/INST]\\nWell, I\\'m quite partial to a good squeeze of fresh lemon juice.  \\nIt adds just the right amount of zesty flavour to whatever I\\'m cooking up in the \\n kitchen!</s>  \\n[INST] Do you have mayonnaise recipes? [/INST]\\nText for the user role is inside the [INST]...[/INST]  tokens, text outside is the assistant \\nrole. The beginning and ending of a string are represented by the <s> (beginning of string) \\nand </s> (end of string) tokens. For information about sending a chat prompt in the correct \\nformat, see Chat template  in the Mistral AI documentation.\\nThe following are optional parameters.\\n•max_tokens – Specify the maximum number of tokens to use in the generated response. The \\nmodel truncates the response once the generated text exceeds max_tokens .\\nDefault Minimum Maximum\\n512 1 Mistral 7B Instruct – 8,192\\nMixtral 8X7B Instruct – \\n4,096\\n•stop  – A list of stop sequences that if generated by the model, stops the model from \\ngenerating further output.\\nDefault Minimum Maximum\\n0 0 10\\n•temperature  – Controls the randomness of predictions made by the model. For more \\ninformation, see Inference parameters.\\nMistral AI models 120Amazon Bedrock User Guide\\nDefault Minimum Maximum\\n0.5 0 1\\n•top_p  – Controls the diversity of text that the model generates by setting the percentage of \\nmost-likely candidates that the model considers for the next token. For more information, see\\nInference parameters.\\nDefault Minimum Maximum\\n0.9 0 1\\n•top_k  – Controls the number of most-likely candidates that the model considers for the next \\ntoken. For more information, see Inference parameters.\\nDefault Minimum Maximum\\n50 1 200\\nResponse\\nThe body response from a call to InvokeModel  is the following:\\n{ \\n  \"outputs\": [ \\n    { \\n        \"text\": string, \\n        \"stop_reason\": string \\n    } \\n  ]\\n} \\n                     \\n                 \\nThe body response has the following ﬁelds:\\n•outputs  – A list of outputs from the model. Each output has the following ﬁelds.\\n•text – The text that the model generated.\\nMistral AI models 121Amazon Bedrock User Guide\\n•stop_reason  – The reason why the response stopped generating text. Possible values are:\\n•stop  – The model has ﬁnished generating text for the input prompt. The model stops \\nbecause it has no more content to generate or if the model generates one of the stop \\nsequences that you deﬁne in the stop request parameter.\\n•length – The length of the tokens for the generated text exceeds the value of\\nmax_tokens  in the call to InvokeModel  (InvokeModelWithResponseStream , if you \\nare streaming output). The response is truncated to max_tokens  tokens.\\nCode example\\nThis examples shows how to call the Mistral 7B Instruct model.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate text using a Mistral AI model.\\n\"\"\"\\nimport json\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_text(model_id, body): \\n    \"\"\" \\n    Generate text using a Mistral AI model. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        JSON: The response from the model. \\n    \"\"\" \\n    logger.info(\"Generating text with Mistral AI model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\nMistral AI models 122Amazon Bedrock User Guide\\n    response = bedrock.invoke_model( \\n        body=body, \\n        modelId=model_id \\n    ) \\n    logger.info(\"Successfully generated text with Mistral AI model %s\", model_id) \\n    return response\\ndef main(): \\n    \"\"\" \\n    Entrypoint for Mistral AI example. \\n    \"\"\" \\n    logging.basicConfig(level=logging.INFO, \\n                        format=\"%(levelname)s: %(message)s\") \\n    try: \\n        model_id = \\'mistral.mistral-7b-instruct-v0:2\\' \\n        prompt = \"\"\"<s>[INST] In Bash, how do I list all text files in the current \\n directory \\n          (excluding subdirectories) that have been modified in the last month? [/\\nINST]\"\"\" \\n        body = json.dumps({ \\n            \"prompt\": prompt, \\n            \"max_tokens\": 400, \\n            \"temperature\": 0.7, \\n            \"top_p\": 0.7, \\n            \"top_k\": 50 \\n        }) \\n        response = generate_text(model_id=model_id, \\n                                 body=body) \\n        response_body = json.loads(response.get(\\'body\\').read()) \\n        outputs = response_body.get(\\'outputs\\') \\n        for index, output in enumerate(outputs): \\nMistral AI models 123Amazon Bedrock User Guide\\n            print(f\"Output {index + 1}\\\\n----------\") \\n            print(f\"Text:\\\\n{output[\\'text\\']}\\\\n\") \\n            print(f\"Stop reason: {output[\\'stop_reason\\']}\\\\n\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    else: \\n        print(f\"Finished generating text with Mistral AI model {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nStability.ai Diﬀusion models\\nThe following is inference parameters information for the Stability.ai Diﬀusion models that \\nAmazon Bedrock supports.\\nModels\\n•Stability.ai Diﬀusion 0.8\\n•Stability.ai Diﬀusion 1.0 text to image\\n•Stability.ai Diﬀusion 1.0 image to image\\n•Stability.ai Diﬀusion 1.0 image to image (masking)\\nStability.ai Diﬀusion 0.8\\nThe Stability.ai Diﬀusion models have the following controls.\\n•Prompt strength  (cfg_scale ) – Determines how much the ﬁnal image portrays the prompt. \\nUse a lower number to increase randomness in the generation.\\n•Generation step  (steps) – Generation step determines how many times the image is sampled. \\nMore steps can result in a more accurate result.\\n•Seed  (seed) – The seed determines the initial noise setting. Use the same seed and the same \\nsettings as a previous run to allow inference to create a similar image. If you don\\'t set this value, \\nit is set as a random number.\\nStability.ai Diﬀusion models 124Amazon Bedrock User Guide\\nModel invocation request body ﬁeld\\nWhen you make an InvokeModel or InvokeModelWithResponseStream call using a Stability.ai \\nmodel, ﬁll the body ﬁeld with a JSON object that conforms to the one below. Enter the prompt in \\nthe text  ﬁeld in the text_prompts  object.\\n{ \\n    \"text_prompts\": [ \\n        {\"text\": \"string\"} \\n    ], \\n    \"cfg_scale\": float, \\n    \"steps\": int, \\n    \"seed\": int\\n}\\nThe following table shows the minimum, maximum, and default values for the numerical \\nparameters.\\nParameter JSON object \\nformatMinimum Maximum Default\\nPrompt strength cfg_scale 0 30 10\\nGeneration step steps 10 150 30\\nModel invocation response body ﬁeld\\nFor information about the format of the body ﬁeld in the response, see https:// \\nplatform.stability.ai/docs/api-reference#tag/v1generation.\\nStability.ai Diﬀusion 1.0 text to image\\nThe Stability.ai Diﬀusion 1.0 model has the following inference parameters and model response for \\nmaking text to image inference calls.\\nTopics\\n•Request and Response\\n•Code example\\nStability.ai Diﬀusion models 125Amazon Bedrock User Guide\\nRequest and Response\\nThe request body is passed in the body ﬁeld of a request to InvokeModel or\\nInvokeModelWithResponseStream.\\nFor more information, see https://platform.stability.ai/docs/api-reference#tag/v1generation.\\nRequest\\nThe Stability.ai Diﬀusion 1.0 model has the following inference parameters for a text to image \\ninference call.\\n{ \\n        \"text_prompts\": [ \\n            { \\n                \"text\": string, \\n                \"weight\": float \\n            } \\n        ], \\n        \"height\": int, \\n        \"width\": int, \\n        \"cfg_scale\": float, \\n        \"clip_guidance_preset\": string, \\n        \"sampler\": string, \\n        \"samples\", \\n        \"seed\": int, \\n        \"steps\": int, \\n        \"style_preset\": string, \\n        \"extras\" :JSON object \\n         \\n} \\n                        \\n•text_prompts (Required) – An array of text prompts to use for generation. Each element is a \\nJSON object that contains a prompt and a weight for the prompt.\\n•text – The prompt that you want to pass to the model.\\nMinimum Maximum\\n0 2000\\nStability.ai Diﬀusion models 126Amazon Bedrock User Guide\\n•weight (Optional) – The weight that the model should apply to the prompt. A value that is \\nless than zero declares a negative prompt. Use a negative prompt to tell the model to avoid \\ncertain concepts. The default value for weight  is one.\\n•cfg_scale – (Optional) Determines how much the ﬁnal image portrays the prompt. Use a \\nlower number to increase randomness in the generation.\\nMinimum Maximum Default\\n0 35 7\\n•clip_guidance_preset– (Optional) Enum: FAST_BLUE, FAST_GREEN, NONE, SIMPLE \\nSLOW, SLOWER, SLOWEST .\\n•height  – (Optional) Height of the image to generate, in pixels, in an increment divible by 64.\\nThe value must be one of 1024x1024, 1152x896, 1216x832, 1344x768, 1536x640, \\n640x1536, 768x1344, 832x1216, 896x1152 .\\n•width  – (Optional) Width of the image to generate, in pixels, in an increment divible by 64.\\nThe value must be one of 1024x1024, 1152x896, 1216x832, 1344x768, 1536x640, \\n640x1536, 768x1344, 832x1216, 896x1152 .\\n•sampler – (Optional) The sampler to use for the diﬀusion process. If this value is omitted, the \\nmodel automatically selects an appropriate sampler for you.\\nEnum: DDIM, DDPM, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, \\nK_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN K_LMS .\\n•samples – (Optional) The number of image to generate. Currently Amazon Bedrock supports \\ngenerating one image. If you supply a value for samples , the value must be one.\\nDefault Minimum Maximum\\n1 1 1\\n•seed  – (Optional) The seed determines the initial noise setting. Use the same seed and the \\nsame settings as a previous run to allow inference to create a similar image. If you don\\'t set \\nthis value, or the value is 0, it is set as a random number.\\nStability.ai Diﬀusion models 127Amazon Bedrock User Guide\\nMinimum Maximum Default\\n0 4294967295 0\\n•steps  – (Optional) Generation step determines how many times the image is sampled. More \\nsteps can result in a more accurate result.\\nMinimum Maximum Default\\n10 50 30\\n•style_preset (Optional) – A style preset that guides the image model towards a particular \\nstyle. This list of style presets is subject to change.\\nEnum: 3d-model, analog-film, anime, cinematic, comic-book, digital-\\nart, enhance, fantasy-art, isometric, line-art, low-poly, modeling-\\ncompound, neon-punk, origami, photographic, pixel-art, tile-texture .\\n•extras (Optional) – Extra parameters passed to the engine. Use with caution. These \\nparameters are used for in-development or experimental features and might change without \\nwarning.\\nResponse\\nThe Stability.ai Diﬀusion 1.0 model returns the following ﬁelds for a text to image inference \\ncall.\\n{ \\n    \"result\": string, \\n    \"artifacts\": [ \\n        { \\n            \"seed\": int, \\n            \"base64\": string, \\n            \"finishReason\": string \\n        } \\n    ]\\n}\\n•result  – The result of the operation. If successful, the response is success .\\nStability.ai Diﬀusion models 128Amazon Bedrock User Guide\\n•artifacts – An array of images, one for each requested image.\\n•seed  – The value of the seed used to generate the image.\\n•base64  – The base64 encoded image that the model generated.\\n•ﬁnishedReason – The result of the image generation process. Valid values are:\\n•SUCCESS – The image generation process succeeded.\\n•ERROR – An error occured.\\n•CONTENT_FILTERED – The content ﬁlter ﬁltered the image and the image might be \\nblurred.\\nCode example\\nThe following example shows how to run inference with the Stability.ai Diﬀusion 1.0 model and on \\ndemand throughput. The example submits a text prompt to a model, retrieves the response from \\nthe model, and ﬁnally shows the image.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate an image with SDXL 1.0 (on demand).\\n\"\"\"\\nimport base64\\nimport io\\nimport json\\nimport logging\\nimport boto3\\nfrom PIL import Image\\nfrom botocore.exceptions import ClientError\\nclass ImageError(Exception): \\n    \"Custom exception for errors returned by SDXL\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_image(model_id, body): \\nStability.ai Diﬀusion models 129Amazon Bedrock User Guide\\n    \"\"\" \\n    Generate an image using SDXL 1.0 on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        image_bytes (bytes): The image generated by the model. \\n    \"\"\" \\n    logger.info(\"Generating image with SDXL model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\"body\").read()) \\n    print(response_body[\\'result\\']) \\n    base64_image = response_body.get(\"artifacts\")[0].get(\"base64\") \\n    base64_bytes = base64_image.encode(\\'ascii\\') \\n    image_bytes = base64.b64decode(base64_bytes) \\n    finish_reason = response_body.get(\"artifacts\")[0].get(\"finishReason\") \\n    if finish_reason == \\'ERROR\\' or finish_reason == \\'CONTENT_FILTERED\\': \\n        raise ImageError(f\"Image generation error. Error code is {finish_reason}\") \\n    logger.info(\"Successfully generated image withvthe SDXL 1.0 model %s\", model_id) \\n    return image_bytes\\ndef main(): \\n    \"\"\" \\n    Entrypoint for SDXL example. \\n    \"\"\" \\n    logging.basicConfig(level = logging.INFO, \\nStability.ai Diﬀusion models 130Amazon Bedrock User Guide\\n                        format = \"%(levelname)s: %(message)s\") \\n    model_id=\\'stability.stable-diffusion-xl-v1\\' \\n    prompt=\"\"\"Sri lanka tea plantation.\"\"\" \\n    # Create request body. \\n    body=json.dumps({ \\n        \"text_prompts\": [ \\n        { \\n        \"text\": prompt \\n        } \\n    ], \\n    \"cfg_scale\": 10, \\n    \"seed\": 0, \\n    \"steps\": 50, \\n    \"samples\" : 1, \\n    \"style_preset\" : \"photographic\" \\n    }) \\n    try: \\n        image_bytes=generate_image(model_id = model_id, \\n                                 body = body) \\n        image = Image.open(io.BytesIO(image_bytes)) \\n        image.show() \\n    except ClientError as err: \\n        message=err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    except ImageError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print(f\"Finished generating text with SDXL model {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nStability.ai Diﬀusion models 131Amazon Bedrock User Guide\\nStability.ai Diﬀusion 1.0 image to image\\nThe Stability.ai Diﬀusion 1.0 model has the following inference parameters and model response for \\nmaking image to image inference calls.\\nTopics\\n•Request and Response\\n•Code example\\nRequest and Response\\nThe request body is passed in the body ﬁeld of a request to InvokeModel or\\nInvokeModelWithResponseStream.\\nFor more information, see https://platform.stability.ai/docs/api-reference#tag/v1generation/ \\noperation/imageToImage.\\nRequest\\nThe Stability.ai Diﬀusion 1.0 model has the following inference parameters for an image to \\nimage inference call.\\n{ \\n        \"text_prompts\": [ \\n            { \\n                \"text\": string, \\n                \"weight\": float \\n            } \\n        ], \\n        \"init_image\" : string , \\n        \"init_image_mode\" : string, \\n        \"image_strength\" : float, \\n        \"cfg_scale\": float, \\n        \"clip_guidance_preset\": string, \\n        \"sampler\": string, \\n        \"samples\" : int, \\n        \"seed\": int, \\n        \"steps\": int, \\nStability.ai Diﬀusion models 132Amazon Bedrock User Guide\\n        \"style_preset\": string, \\n        \"extras\" : json object\\n} \\n                        \\nThe following are required parameters.\\n•text_prompts – (Required) An array of text prompts to use for generation. Each element is a \\nJSON object that contains a prompt and a weight for the prompt.\\n•text – The prompt that you want to pass to the model.\\nMinimum Maximum\\n0 2000\\n•weight – (Optional) The weight that the model should apply to the prompt. A value that is \\nless than zero declares a negative prompt. Use a negative prompt to tell the model to avoid \\ncertain concepts. The default value for weight  is one.\\n•init_image  – (Required) The base64 encoded image that you want to use to initialize the \\ndiﬀusion process.\\nThe following are optional parameters.\\n•init_image_mode  – (Optional) Determines whether to use image_strength  or\\nstep_schedule_*  to control how much inﬂuence the image in init_image  has on \\nthe result. Possible values are IMAGE_STRENGTH  or STEP_SCHEDULE . The default is \\nIMAGE_STRENGTH.\\n•image_strength  – (Optional) Determines how much inﬂuence the source image in\\ninit_image  has on the diﬀusion process. Values close to 1 yield images very similar to the \\nsource image. Values close to 0 yield images very diﬀerent than the source image.\\n•cfg_scale – (Optional) Determines how much the ﬁnal image portrays the prompt. Use a \\nlower number to increase randomness in the generation.\\nDefault Minimum Maximum\\n7 0 35\\nStability.ai Diﬀusion models 133Amazon Bedrock User Guide\\n•clip_guidance_preset – (Optional) Enum: FAST_BLUE, FAST_GREEN, NONE, SIMPLE, \\nSLOW, SLOWER, SLOWEST .\\n•sampler – (Optional) The sampler to use for the diﬀusion process. If this value is omitted, the \\nmodel automatically selects an appropriate sampler for you.\\nEnum: DDIM DDPM, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, \\nK_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN K_LMS .\\n•samples – (Optional) The number of image to generate. Currently Amazon Bedrock supports \\ngenerating one image. If you supply a value for samples , the value must be one.\\nDefault Minimum Maximum\\n1 1 1\\n•seed  – (Optional) The seed determines the initial noise setting. Use the same seed and the \\nsame settings as a previous run to allow inference to create a similar image. If you don\\'t set \\nthis value, or the value is 0, it is set as a random number.\\nDefault Minimum Maximum\\n0 0 4294967295\\n•steps  – (Optional) Generation step determines how many times the image is sampled. More \\nsteps can result in a more accurate result.\\nDefault Minimum Maximum\\n30 10 50\\n•style_preset – (Optional) A style preset that guides the image model towards a particular \\nstyle. This list of style presets is subject to change.\\nEnum: 3d-model, analog-film, anime, cinematic, comic-book, digital-\\nart, enhance, fantasy-art, isometric, line-art, low-poly, modeling-\\ncompound, neon-punk, origami, photographic, pixel-art, tile-texture\\nStability.ai Diﬀusion models 134Amazon Bedrock User Guide\\n•extras – (Optional) Extra parameters passed to the engine. Use with caution. These \\nparameters are used for in-development or experimental features and might change without \\nwarning.\\nResponse\\nThe Stability.ai Diﬀusion 1.0 model returns the following ﬁelds for a text to image inference \\ncall.\\n{ \\n    \"result\": string, \\n    \"artifacts\": [ \\n        { \\n            \"seed\": int, \\n            \"base64\": string, \\n            \"finishReason\": string \\n        } \\n    ]\\n}\\n•result  – The result of the operation. If successful, the response is success .\\n•artifacts – An array of images, one for each requested image.\\n•seed  – The value of the seed used to generate the image.\\n•base64  – The base64 encoded image that the model generated.\\n•ﬁnishedReason – The result of the image generation process. Valid values are:\\n•SUCCESS – The image generation process succeeded.\\n•ERROR – An error occured.\\n•CONTENT_FILTERED – The content ﬁlter ﬁltered the image and the image might be \\nblurred.\\nCode example\\nThe following example shows how to run inference with the Stability.ai Diﬀusion 1.0 model and on \\ndemand throughput. The example submits a text prompt and reference image to a model, retrieves \\nthe response from the model, and ﬁnally shows the image.\\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\nStability.ai Diﬀusion models 135Amazon Bedrock User Guide\\n# SPDX-License-Identifier: Apache-2.0\\n\"\"\"\\nShows how to generate an image from a reference image with SDXL 1.0 (on demand).\\n\"\"\"\\nimport base64\\nimport io\\nimport json\\nimport logging\\nimport boto3\\nfrom PIL import Image\\nfrom botocore.exceptions import ClientError\\nclass ImageError(Exception): \\n    \"Custom exception for errors returned by SDXL\" \\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_image(model_id, body): \\n    \"\"\" \\n    Generate an image using SDXL 1.0 on demand. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        image_bytes (bytes): The image generated by the model. \\n    \"\"\" \\n    logger.info(\"Generating image with SDXL model %s\", model_id) \\n    bedrock = boto3.client(service_name=\\'bedrock-runtime\\') \\n    \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = bedrock.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\"body\").read()) \\nStability.ai Diﬀusion models 136Amazon Bedrock User Guide\\n    print(response_body[\\'result\\']) \\n    base64_image = response_body.get(\"artifacts\")[0].get(\"base64\") \\n    base64_bytes = base64_image.encode(\\'ascii\\') \\n    image_bytes = base64.b64decode(base64_bytes) \\n    finish_reason = response_body.get(\"artifacts\")[0].get(\"finishReason\") \\n    if finish_reason == \\'ERROR\\' or finish_reason == \\'CONTENT_FILTERED\\': \\n        raise ImageError(f\"Image generation error. Error code is {finish_reason}\") \\n    logger.info(\"Successfully generated image withvthe SDXL 1.0 model %s\", model_id) \\n    return image_bytes\\ndef main(): \\n    \"\"\" \\n    Entrypoint for SDXL example. \\n    \"\"\" \\n    logging.basicConfig(level = logging.INFO, \\n                        format = \"%(levelname)s: %(message)s\") \\n    model_id=\\'stability.stable-diffusion-xl-v1\\' \\n    prompt=\"\"\"A space ship.\"\"\" \\n    # Read reference image from file and encode as base64 strings. \\n    with open(\"/path/to/image\", \"rb\") as image_file: \\n        init_image = base64.b64encode(image_file.read()).decode(\\'utf8\\') \\n    # Create request body. \\n    body=json.dumps({ \\n        \"text_prompts\": [ \\n        { \\n        \"text\": prompt \\n        } \\n    ], \\n    \"init_image\": init_image, \\n    \"style_preset\" : \"isometric\" \\n    }) \\nStability.ai Diﬀusion models 137Amazon Bedrock User Guide\\n    try: \\n        image_bytes=generate_image(model_id = model_id, \\n                                 body = body) \\n        image = Image.open(io.BytesIO(image_bytes)) \\n        image.show() \\n    except ClientError as err: \\n        message=err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    except ImageError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print(f\"Finished generating text with SDXL model {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nStability.ai Diﬀusion 1.0 image to image (masking)\\nThe Stability.ai Diﬀusion 1.0 model has the following inference parameters and model response for \\nusing masks with image to image inference calls.\\nRequest and Response\\nThe request body is passed in the body ﬁeld of a request to InvokeModel or\\nInvokeModelWithResponseStream.\\nFor more information, see https://platform.stability.ai/docs/api-reference#tag/v1generation/ \\noperation/masking .\\nRequest\\nThe Stability.ai Diﬀusion 1.0 model has the following inference parameters for an image to \\nimage (masking) inference call.\\nStability.ai Diﬀusion models 138Amazon Bedrock User Guide\\n{ \\n        \"text_prompts\": [ \\n            { \\n                \"text\": string, \\n                \"weight\": float \\n            } \\n        ], \\n        \"init_image\" : string , \\n        \"mask_source\" : string, \\n        \"mask_image\" : string, \\n        \"cfg_scale\": float, \\n        \"clip_guidance_preset\": string, \\n        \"sampler\": string, \\n        \"samples\" : int, \\n        \"seed\": int, \\n        \"steps\": int, \\n        \"style_preset\": string, \\n        \"extras\" : json object\\n} \\n                        \\nThe following are required parameters.\\n•text_prompt – (Required) An array of text prompts to use for generation. Each element is a \\nJSON object that contains a prompt and a weight for the prompt.\\n•text – The prompt that you want to pass to the model.\\nMinimum Maximum\\n0 2000\\n•weight – (Optional) The weight that the model should apply to the prompt. A value that is \\nless than zero declares a negative prompt. Use a negative prompt to tell the model to avoid \\ncertain concepts. The default value for weight  is one.\\n•init_image  – (Required) The base64 encoded image that you want to use to initialize the \\ndiﬀusion process.\\n•mask_source – (Required) Determines where to source the mask from. Possible values are:\\n•MASK_IMAGE_WHITE – Use the white pixels of the mask image in mask_image  as the \\nmask. White pixels are replaced and black pixels are left unchanged.\\nStability.ai Diﬀusion models 139Amazon Bedrock User Guide\\n•MASK_IMAGE_BLACK – Use the black pixels of the mask image in mask_image  as the \\nmask. Black pixels are replaced and white pixels are left unchanged.\\n•INIT_IMAGE_ALPHA  – Use the alpha channel of the image in init_image  as the mask, \\nFully transparent pixels are replaced and fully opaque pixels are left unchanged.\\n•mask_image  – (Required) The base64 encoded mask image that you want to use as a mask \\nfor the source image in init_image . Must be the same dimensions as the source image. Use \\nthe mask_source  option to specify which pixels should be replaced.\\nThe following are optional parameters.\\n•cfg_scale – (Optional) Determines how much the ﬁnal image portrays the prompt. Use a \\nlower number to increase randomness in the generation.\\nDefault Minimum Maximum\\n7 0 35\\n•clip_guidance_preset – (Optional) Enum: FAST_BLUE, FAST_GREEN, NONE, SIMPLE, \\nSLOW, SLOWER, SLOWEST .\\n•sampler – (Optional) The sampler to use for the diﬀusion process. If this value is omitted, the \\nmodel automatically selects an appropriate sampler for you.\\nEnum: DDIM, DDPM, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, \\nK_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN K_LMS .\\n•samples – (Optional) The number of image to generate. Currently Amazon Bedrock supports \\ngenerating one image. If you supply a value for samples , the value must be one.  generates\\nDefault Minimum Maximum\\n1 1 1\\n•seed  – (Optional) The seed determines the initial noise setting. Use the same seed and the \\nsame settings as a previous run to allow inference to create a similar image. If you don\\'t set \\nthis value, or the value is 0, it is set as a random number.\\nStability.ai Diﬀusion models 140Amazon Bedrock User Guide\\nDefault Minimum Maximum\\n0 0 4294967295\\n•steps  – (Optional) Generation step determines how many times the image is sampled. More \\nsteps can result in a more accurate result.\\nDefault Minimum Maximum\\n30 10 50\\n•style_preset – (Optional) A style preset that guides the image model towards a particular \\nstyle. This list of style presets is subject to change.\\nEnum: 3d-model, analog-film, anime, cinematic, comic-book, digital-\\nart, enhance, fantasy-art, isometric, line-art, low-poly, modeling-\\ncompound, neon-punk, origami, photographic, pixel-art, tile-texture\\n•extras – (Optional) Extra parameters passed to the engine. Use with caution. These \\nparameters are used for in-development or experimental features and might change without \\nwarning.\\nResponse\\nThe Stability.ai Diﬀusion 1.0 model returns the following ﬁelds for a text to image inference \\ncall.\\n{ \\n    \"result\": string, \\n    \"artifacts\": [ \\n        { \\n            \"seed\": int, \\n            \"base64\": string, \\n            \"finishReason\": string \\n        } \\n    ]\\n}\\n•result  – The result of the operation. If successful, the response is success .\\nStability.ai Diﬀusion models 141Amazon Bedrock User Guide\\n•artifacts – An array of images, one for each requested image.\\n•seed  – The value of the seed used to generate the image.\\n•base64  – The base64 encoded image that the model generated.\\n•ﬁnishedReason – The result of the image generation process. Valid values are:\\n•SUCCESS – The image generation process succeeded.\\n•ERROR – An error occured.\\n•CONTENT_FILTERED – The content ﬁlter ﬁltered the image and the image might be \\nblurred.\\nCustom model hyperparameters\\nThe following reference content covers the hyperparameters that are available for training each \\nAmazon Bedrock custom model.\\nA hyperparameter is a parameter that controls the training process, such as the learning rate \\nor epoch count. You set hyperparameters for custom model training when you submit  the ﬁne \\ntuning job with the Amazon Bedrock console or by calling the CreateModelCustomizationJob API \\noperation. For guidelines on hyperparameter settings, see Guidelines for model customization .\\nTopics\\n•Amazon Titan text model customization hyperparameters\\n•Amazon Titan Image Generator G1 model customization hyperparameters\\n•Amazon Titan Multimodal Embeddings G1 customization hyperparameters\\n•Cohere\\xa0Command model customization hyperparameters\\n•Meta\\xa0Llama 2 model customization hyperparameters\\nAmazon Titan text model customization hyperparameters\\nTitan text models support the following hyperparameters for model customization.\\nCustom model hyperparameters 142Amazon Bedrock User Guide\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter \\n(API)DeﬁnitionType Minimum Maximum Default\\nEpochs epochs The \\nnumber of \\niteration \\ns through \\nthe entire \\ntraining \\ndatasetinteger 1 10 5\\nBatch sizebatchSize The \\nnumber of \\nsamples \\nprocessed \\nbefore \\nupdating \\nmodel \\nparameter \\nsinteger 1 64 1\\nLearning \\nratelearningR \\nateThe rate \\nat which \\nmodel \\nparameter \\ns are \\nupdated \\nafter each \\nbatchﬂoat 0.0 1 1.00E-5\\nLearning \\nrate \\nwarmup \\nstepslearningR \\nateWarmup \\nStepsThe \\nnumber of \\niteration \\ns over \\nwhich the \\nlearning integer 0 250 5\\nAmazon Titan text models 143Amazon Bedrock User Guide\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter \\n(API)DeﬁnitionType Minimum Maximum Default\\nrate is \\ngradually \\n increased \\nto the \\nspeciﬁed \\nrate\\nAmazon Titan Image Generator G1 model customization \\nhyperparameters\\nThe Amazon Titan Image Generator G1 model supports the following hyperparameters for model \\ncustomization.\\nNote\\nstepCount  has no default value and must be speciﬁed. stepCount  supports the value\\nauto . auto prioritizes model performance over training cost by automatically determining \\na number based on the size of your dataset. Training job costs depend on the number \\nthat auto determines. To understand how job cost is calculated and to see examples, see\\nAmazon Bedrock Pricing.\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter (API)Deﬁnition Minimum Maximum Default\\nBatch size batchSize Number of \\nsamples \\nprocessed \\nbefore \\nupdating 8 192 8\\nAmazon Titan Image Generator G1 144Amazon Bedrock User Guide\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter (API)Deﬁnition Minimum Maximum Default\\nmodel \\nparameters\\nSteps stepCount Number of \\ntimes the \\nmodel is \\nexposed to \\neach batch10 40,000 N/A\\nLearning rate learningRate Rate at \\nwhich model \\nparameters \\nare updated \\nafter each \\nbatch1.00E-7 1 1.00E-5\\nAmazon Titan Multimodal Embeddings G1 customization \\nhyperparameters\\nThe Amazon Titan Multimodal Embeddings G1 model supports the following hyperparameters for \\nmodel customization.\\nNote\\nepochs  has no default value and must be speciﬁed. epochs supports the value Auto .\\nAuto prioritizes model performance over training cost by automatically determining a \\nnumber based on the size of your dataset. Training job costs depend on the number that\\nAuto determines. To understand how job cost is calculated and to see examples, see\\nAmazon Bedrock Pricing.\\nAmazon Titan Multimodal Embeddings G1 145Amazon Bedrock User Guide\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter \\n(API)DeﬁnitionType Minimum Maximum Default\\nEpochs epochs The \\nnumber of \\niteration \\ns through \\nthe entire \\ntraining \\ndatasetinteger 1 100 N/A\\nBatch sizebatchSize The \\nnumber of \\nsamples \\nprocessed \\nbefore \\nupdating \\nmodel \\nparameter \\nsinteger 256 9,216 576\\nLearning \\nratelearningR \\nateThe rate \\nat which \\nmodel \\nparameter \\ns are \\nupdated \\nafter each \\nbatchﬂoat 5.00E-8 1 5.00E-5\\nCohere\\xa0Command model customization hyperparameters\\nThe Cohere Command and Cohere Command Light models support the following hyperparameters \\nfor model customization. For more information, see Custom models .\\nCohere\\xa0Command models 146Amazon Bedrock User Guide\\nFor information about ﬁne tuning Cohere models, see the Cohere documentation at https:// \\ndocs.cohere.com/docs/ﬁne-tuning.\\nNote\\nThe epochCount  quota is adjustable.\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter \\n(API)Deﬁnition Type Minimum Maximum Default\\nEpochs epochCoun \\ntThe \\nnumber of \\niteration \\ns through \\nthe entire \\ntraining \\ndatasetinteger 1 100 1\\nBatch size batchSize The \\nnumber of \\nsamples \\nprocessed \\nbefore \\nupdating \\nmodel \\nparameter \\nsinteger 8 8 \\n(Command)\\n32 (Light)8\\nLearning \\nratelearningR \\nateThe rate \\nat which \\nmodel \\nparameter \\ns are \\nupdated \\nafter each ﬂoat 5.00E-6 0.1 1.00E-5\\nCohere\\xa0Command models 147Amazon Bedrock User Guide\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter \\n(API)DeﬁnitionType Minimum Maximum Default\\nbatch. If \\nyou use a \\nvalidatio \\nn dataset, \\nwe \\nrecommend \\nthat you \\ndon\\'t \\nprovide a \\nvalue for\\nlearningR \\nate .\\nEarly \\nstopping \\nthresholdearlyStop \\npingThres \\nholdThe \\nminimum \\nimproveme \\nnt in loss \\nrequired \\nto prevent \\npremature \\nterminati \\non of the \\ntraining \\nprocessﬂoat 0 0.1 0.01\\nCohere\\xa0Command models 148Amazon Bedrock User Guide\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter \\n(API)DeﬁnitionType Minimum Maximum Default\\nEarly \\nstopping \\npatienceearlyStop \\npingPatie \\nnceThe \\ntolerance \\nfor \\nstagnatio \\nn in the \\nloss metric \\nbefore \\nstopping \\nthe \\ntraining \\nprocessinteger 1 10 6\\nEvaluation \\npercentageevalPerce \\nntageThe \\npercentag \\ne of the \\ndataset \\nallocated \\nfor model \\nevaluatio \\nn, if you \\ndon\\'t \\nprovide a \\nseparate \\nvalidation \\ndatasetﬂoat 5 50 20\\nMeta\\xa0Llama 2 model customization hyperparameters\\nThe Meta Llama 2 13B and 70B models support the following hyperparameters for model \\ncustomization. For more information, see Custom models .\\nFor information about ﬁne tuning Meta Llama models, see the Meta documentation at https:// \\nai.meta.com/llama/get-started/#ﬁne-tuning.\\nMeta\\xa0Llama 2 models 149Amazon Bedrock User Guide\\nNote\\nThe epochCount  quota is adjustable.\\nHyperpara \\nmeter \\n(console)Hyperpara \\nmeter \\n(API)Deﬁnition Type Minimum Maximum Default\\nEpochs epochCoun \\ntThe \\nnumber of \\niteration \\ns through \\nthe entire \\ntraining \\ndatasetinteger 1 10 5\\nBatch size batchSize The \\nnumber of \\nsamples \\nprocessed \\nbefore \\nupdating \\nmodel \\nparameter \\nsinteger 1 1 1\\nLearning \\nratelearningR \\nateThe rate \\nat which \\nmodel \\nparameter \\ns are \\nupdated \\nafter each \\nbatchﬂoat 5.00E-6 0.1 1.00E-4\\nMeta\\xa0Llama 2 models 150Amazon Bedrock User Guide\\nAmazon Bedrock console overview\\nThe Amazon Bedrock console provides the following features.\\nFeatures\\n•Getting started\\n•Foundation models\\n•Playgrounds\\n•Safeguards\\n•Orchestration\\n•Assessment and deployment\\n•Model access\\n•Model invocation logging\\nTo open the Amazon Bedrock console, sign in at https://console.aws.amazon.com/bedrock/home.\\nGetting started\\nFrom Getting started in the navigation pane, you can get an Overview of the foundation models, \\nexamples, and playgrounds that Amazon Bedrock provides. You can also get Examples of the \\nprompts you can use with Amazon Bedrock models.\\nThe examples page shows example prompts for the available models. You can search the examples \\nand ﬁlter the list of examples using one or more of the following attributes:\\n•Model\\n•Modality (text, image, or embedding)\\n•Category\\n•Provider\\nFilter the example prompts by choosing the Search in examples edit box and then selecting the \\nﬁlter that you want to apply to the search. Apply multiple ﬁlters by again choosing Search in \\nexamples and then selecting another ﬁlter.\\nGetting started 151Amazon Bedrock User Guide\\nWhen you choose an example, the Amazon Bedrock console displays the following information \\nabout the example:\\n•A description of what the example accomplishes.\\n•The model name (and model provider) where the example runs.\\n•The example prompt and the expected response.\\n•The inference conﬁguration parameter settings for the example.\\n•The API request that runs the example.\\nTo run the example, choose Open in playground.\\nFoundation models\\nFrom Foundation models in the navigation pane, you can view the available Base models , and \\ngroup them by various attributes. You can also ﬁlter the model view, search for models, and view \\ninformation about the model providers.\\nYou can customize a base foundation model to improve the model\\'s performance on speciﬁc tasks \\nor teach the model a new domain of knowledge. Choose Custom models  under foundation models \\nto create and manage your custom models. Customize a model by creating a model customization \\njob with a training dataset that you provide. For more information, see Custom models .\\nYou can experiment with base models and custom models by using the console playgrounds.\\nPlaygrounds\\nThe console playgrounds are where you can experiment with models before deciding to use them \\nin an application. There are three playgrounds.\\nChat playground\\nThe chat playground lets you experiment with the chat models that Amazon Bedrock provides. \\nYou can submit a chat to a model and the chat playground shows the response from the model \\nand includes model metrics. Optionally, choose Compare mode  to compare the output from up to \\nthree models. For more information, see Chat playground.\\nText playground\\nFoundation models 152Amazon Bedrock User Guide\\nThe text playground lets you experiment with the text models that Amazon Bedrock provides. You \\ncan submit text to a model and the text playground shows the text that the model generates from \\nthe prompt. For more information, see Text playground.\\nImage playground\\nThe image playground lets you experiment with the image models that Amazon Bedrock provides. \\nYou can submit a text prompt to a model and the image playground shows the image that the \\nmodel generates for the prompt. For more information, see Image playground.\\nIn the console, access the playgrounds by choosing Playgrounds in the navigation pane. For more \\ninformation, see Playgrounds.\\nSafeguards\\nTitan Image Generator G1 automatically puts an invisible watermark on all images created by the \\nmodel. Watermark detection detects if the image was generated by Titan Image Generator G1. To \\nuse watermark detection, choose Overview in the left navigation pane and then Build and Test\\ntab. Go to the Safeguards  section and choose View watermark detection. For more information, \\nsee Watermark detection.\\nOrchestration\\nWith Amazon Bedrock, you can enable a Retrieval-Augmented Generation (RAG)ß workﬂow by \\nusing knowledge bases to build contextual applications by using the reasoning capabilities of LLMs. \\nTo use a knowledge base, choose Orchestration  in the left navigation pane and then Knowledge \\nbase . For more information, see Knowledge base for Amazon Bedrock.\\nAgents for Amazon Bedrock enables developers to conﬁgure an agent to complete actions based \\non organization data and user input. For example you might create an agent to take actions to \\nfulﬁll a customer\\'s request. To use an Agent, choose Orchestration  in the left navigation pane and \\nthen Agent . For more information, see Agents for Amazon Bedrock.\\nAssessment and deployment\\nAs you use Amazon Bedrock models, you need to to assess their performance and to deploy them \\ninto your solutions.\\nSafeguards 153Amazon Bedrock User Guide\\nWith Model Evaluation, you can evaluate and compare model output, and then choose the one \\nbest suited for your applications. Choose Assessment and deployment and then choose Model \\nevaluation .\\nWhen you conﬁgure Provisioned Throughput for a model, you receive a level of throughput at a \\nﬁxed cost. To provision throughput, choose Assessment and deployment in the navigation pane \\nand then Provisioned Throughput. For more information, see Provisioned Throughput.\\nModel access\\nTo use a model in Amazon Bedrock, you must ﬁrst request access to the model. On the left \\nnavigation pane, choose Model access. For more information, see Model access.\\nModel invocation logging\\nYou can log model invocation events by choosing Settings in the left navigation pane. For more \\ninformation, see Model invocation logging.\\nModel access 154Amazon Bedrock User Guide\\nRun model inference\\nInference refers to the process of generating an output from an input provided to a model. \\nFoundation models use probability to construct the words in a sequence. Given an input, the model \\npredicts a probable sequence of tokens that follows, and returns that sequence as the output. \\nAmazon Bedrock provides you the capability of running inference in the foundation model of your \\nchoice. When you run inference, you provide the following inputs.\\n•Prompt  – An input provided to the model in order for it to generate a response. For information \\nabout writing prompts, see  Prompt engineering guidelines.\\n•Inference parameters – A set of values that can be adjusted to limit or inﬂuence the model \\nresponse. For information about inference parameters, see Inference parameters and Inference \\nparameters for foundation models .\\nAmazon Bedrock oﬀers a suite of foundation models that you can use to generate outputs of the \\nfollowing modalities. To see modality support by foundation model, refer to Supported foundation \\nmodels in Amazon Bedrock.\\nOutput modality Description Example use cases\\nText Provide text input and \\ngenerate various types of textChat, question-and-\\nanswering, brainstorming, \\nsummarization, code \\ngeneration, table creation, \\ndata formatting, rewriting\\nImage Provide text or input images \\nand generate or modify \\nimagesImage generation, image \\nediting, image variation\\nEmbeddings Provide text, images, or \\nboth text and images and \\ngenerate a vector of numeric \\nvalues that represent the \\ninput. The output vector \\ncan be compared to other Text and image search, query, \\ncategorization, recommend \\nations, personalization,\\nknowledge base creation\\n155Amazon Bedrock User Guide\\nOutput modality Description Example use cases\\nembeddings vectors to \\ndetermine semantic similarit \\ny (for text) or visual similarity \\n(for images).\\nYou can run model inference in the following ways.\\n•Use any of the Playgrounds to run inference in a user-friendly graphical interface.\\n•Send an InvokeModel or InvokeModelWithResponseStream request.\\n•Prepare a dataset of prompts with your desired conﬁgurations and run batch inference with a\\nCreateModelInvocationJob  request.\\n•The following Amazon Bedrock features use model inference as a step in a larger orchestration. \\nRefer to those sections for more details.\\n•Set up a knowledge base and send a RetrieveAndGenerate request.\\n•Set up an agent  and send an InvokeAgent request.\\nYou can run inference with base models, custom models, or provisioned models. To run inference \\non a custom model, ﬁrst purchase Provisioned Throughput for it (for more information, see\\nProvisioned Throughput).\\nUse these methods to test foundation model responses with diﬀerent prompts and inference \\nparameters. Once you have suﬃciently explored these methods, you can set up your application to \\nrun model inference by calling these APIs.\\nSelect a topic to learn more about running model inference through that method. To learn more \\nabout using agents, see Agents for Amazon Bedrock.\\nTopics\\n•Inference parameters\\n•Playgrounds\\n•Use the API to invoke a model with a single prompt\\n•Run batch inference\\n156Amazon Bedrock User Guide\\nInference parameters\\nInference parameters are values that you can adjust to limit or inﬂuence the model response. The \\nfollowing categories of parameters are commonly found across diﬀerent models.\\nRandomness and diversity\\nFor any given sequence, a model determines a probability distribution of options for the next token \\nin the sequence. To generate each token in an output, the model samples from this distribution. \\nRandomness and diversity refer to the amount of variation in a model\\'s response. You can control \\nthese factors by limiting or adjusting the distribution. Foundation models typically support the \\nfollowing parameters to control randomness and diversity in the response.\\n•Temperature– Aﬀects the shape of the probability distribution for the predicted output and \\ninﬂuences the likelihood of the model selecting lower-probability outputs.\\n•Choose a lower value to inﬂuence the model to select higher-probability outputs.\\n•Choose a higher value to inﬂuence the model to select lower-probability outputs.\\nIn technical terms, the temperature modulates the probability mass function for the next token. \\nA lower temperature steepens the function and leads to more deterministic responses, and a \\nhigher temperature ﬂattens the function and leads to more random responses.\\n•Top K – The number of most-likely candidates that the model considers for the next token.\\n•Choose a lower value to decrease the size of the pool and limit the options to more likely \\noutputs.\\n•Choose a higher value to increase the size of the pool and allow the model to consider less \\nlikely outputs.\\nFor example, if you choose a value of 50 for Top K, the model selects from 50 of the most \\nprobable tokens that could be next in the sequence.\\n•Top P – The percentage of most-likely candidates that the model considers for the next token.\\n•Choose a lower value to decrease the size of the pool and limit the options to more likely \\noutputs.\\n•Choose a higher value to increase the size of the pool and allow the model to consider less \\nlikely outputs.\\nIn technical terms, the model computes the cumulative probability distribution for the set of \\nresponses and considers only the top P% of the distribution.\\nInference parameters 157Amazon Bedrock User Guide\\nFor example, if you choose a value of 0.8 for Top P, the model selects from the top 80% of the \\nprobability distribution of tokens that could be next in the sequence.\\nThe following table summarizes the eﬀects of these parameters.\\nParameter Eﬀect of lower value Eﬀect of higher value\\nTemperature Increase likelihood of higher-\\nprobability tokens\\nDecrease likelihood of lower-\\nprobability tokensIncrease likelihood of lower-\\nprobability tokens\\nDecrease likelihood of higher-\\nprobability tokens\\nTop K Remove lower-probability \\ntokensAllow lower-probability \\ntokens\\nTop P Remove lower-probability \\ntokensAllow lower-probability \\ntokens\\nAs an example to understand these parameters, consider the example prompt I hear the hoof \\nbeats of \" . Let\\'s say that the model determines the following three words to be candidates for \\nthe next token. The model also assigns a probability for each word.\\n{ \\n    \"horses\": 0.7, \\n    \"zebras\": 0.2, \\n    \"unicorns\": 0.1\\n}\\n•If you set a high temperature , the probability distribution is ﬂattened and the probabilities \\nbecome less diﬀerent, which would increase the probability of choosing \"unicorns\" and decrease \\nthe probability of choosing \"horses\".\\n•If you set Top K as 2, the model only considers the top 2 most likely candidates: \"horses\" and \\n\"zebras.\"\\n•If you set Top P as 0.7, the model only considers \"horses,\" because it is the only candidate that \\nlies in the top 70% of the probability distribution.\\nRandomness and diversity 158Amazon Bedrock User Guide\\nLength\\nFoundation models typically support parameters that limit the length of the response. Examples of \\nthese parameters are provided below.\\n•Response length – An exact value to specify the minimum or maximum number of tokens to \\nreturn in the generated response.\\n•Penalties – Specify the degree to which to penalize outputs in a response. Examples include the \\nfollowing.\\n•The length of the response.\\n•Repeated tokens in a response.\\n•Frequency of tokens in a response.\\n•Types of tokens in a response.\\n•Stop sequences – Specify sequences of characters that stop the model from generating further \\ntokens. If the model generates a stop sequence that you specify, it will stop generating after that \\nsequence.\\nPlaygrounds\\nImportant\\nBefore you can use any of the foundation models, you must request access to that model. \\nIf you try to use the model (with the API or within the console) before you have requested \\naccess to it, you will receive an error message. For more information, see Model access.\\nThe Amazon Bedrock playgrounds provide you a console environment to experiment with running \\ninference on diﬀerent models and with diﬀerent conﬁgurations, before deciding to use them in an \\napplication. In the console, access the playgrounds by choosing Playgrounds in the left navigation \\npane. You can also navigate directly to the playground when you choose a model from a model \\ndetails page or the examples page.\\nThere are playgrounds for text, chat, and image models.\\nLength 159Amazon Bedrock User Guide\\nWithin each playground you can enter prompts and experiment with inference parameters. \\nPrompts are usually one or more sentences of text that set up a scenario, question, or task for a \\nmodel. For information about creating prompts, see  Prompt engineering guidelines.\\nInference parameters inﬂuence the response generated by a model, such as the randomness of \\ngenerated text. When you load a model into a playground, the playground conﬁgures the model \\nwith its default inference settings. You can change and reset the settings as you experiment \\nwith the model. Each model has its own set of inference parameters. For more information, see\\nInference parameters for foundation models.\\nWhen you submit a response, the model responds with its generated output.\\nIf a chat or text model supports streaming, the default is to stream the responses from a model. \\nYou can turn oﬀ streaming, if desired.\\nTopics\\n•Chat playground\\n•Text playground\\n•Image playground\\n•Use a playground\\nChat playground\\nThe chat playground lets you experiment with the chat models that Amazon Bedrock provides. You \\ncan submit a chat to a model and the chat playground shows the response from the model, and the \\nfollowing metrics.\\n•Latency — The time it takes for the model to generate each token (word) in a sequence.\\n•Input token count — The number of tokens that are fed into the model as input during \\ninference.\\n•Output token count — The number of tokens generated in response to a prompt. Longer, more \\nconversational, responses require more tokens.\\n•Cost  — The cost of processing the input and generating output tokens.\\nYou can also deﬁne criteria that you want the model response to match.\\nChat playground 160Amazon Bedrock User Guide\\nBy turning on compare model, you can compare the chat responses for a single prompt with the \\nresponses from up to three models. This helps you to understand the comparative performance \\nof each model, without having to switch between models. For more information, see Use a \\nplayground.\\nText playground\\nThe text playground lets you experiment with the text models that Amazon Bedrock provides. You \\ncan submit text to a model and the text playground shows the text that the model generates from \\nthe prompt.\\nImage playground\\nThe image playground lets you experiment with the image models that Amazon Bedrock provides. \\nYou can submit a text prompt to a model and the image playground shows the image that the \\nmodel generates for the prompt.\\nAlong with setting inference parameters, you can make additional conﬁgururation changes (diﬀers \\nby model):\\n•Mode  – The model generates a new image ( Generate ) or edits ( Edit) the image that you supply \\nin Reference image. If you edit a reference image, the model needs a segmentation mask that \\ncovers the area of the image that you want the model to edit. Create the segmentation mask by \\nusing the image plaground to draw a rectangle on the reference image. Alternatively, you can \\ncreate the segmentation mask by specifying a mask prompt (Amazon Titan Image Generator G1 \\nGenerator G1 image only).\\n•Mask prompt  – If you edit an image with the Amazon Titan Image Generator G1 model, you can \\nuse a mask prompt to specify the objects that you want the segmentation mask to cover. For \\nexample, you can specify the mask prompt sky to create a segmentation mask that covers the \\nsky in an image. You can then run the prompt An image of a rainy day to make the sky in the \\nimage appear rainy.\\n•Negative prompt – items or concepts that you don\\'t want the model to generate, such as\\ncartoon or violence .\\n•Reference image – The image on which to generate the response or that you want the model to \\nedit.\\n•Response image – Output settings for the generated image, such as quality, orientation, size, \\nand the number of images to generate.\\nText playground 161Amazon Bedrock User Guide\\n•Advanced conﬁgurations – The inference parameters to pass to the model.\\nUse a playground\\nThe following procedure shows how to submit a prompt to a playground and view the response. \\nIn each playground, you can conﬁgure the inference parameters for the model. In the chat \\nplayground, you can view metrics, and optionally compare the output of up to three models. In the\\nimage playground you can make advanced conﬁguration changes, which also vary by model.\\nTo use a playground\\n1. If you haven\\'t already, request access to the models that you want to use. For more \\ninformation, see Model access.\\n2. Open the Amazon Bedrock console.\\n3. From the navigation pane, under Playgrounds, choose Chat , Text, or Image .\\n4. Choose Select model to open the Select model dialog box.\\na. In Category select from the available providers or custom models.\\nb. In Model  select a model.\\nc. In Throughput  select the throughput (on-demand, or provisioned throughput) that you \\nwant the model to use. If you are using a custom model, you must have set up Provisioned \\nThroughput for the model beforehand. For more information, see Provisioned Throughput\\nd. Choose Apply .\\n5. (Optional) In Conﬁgurations  choose the inference parameters that you want to use. For \\nmore information, see Inference parameters for foundation models. For information about \\nconﬁguration changes you can make in the image playground, see Image playground.\\n6. Enter your prompt into the text ﬁeld. A prompt is a natural language phrase or command, \\nsuch as Tell me about the best restaurants to visit in Seattle. . For more \\ninformation, see  Prompt engineering guidelines.\\nIf you are using the chat playground with a model that supports multimodal prompts, add \\nimages to the prompt by choosing Image  or by dragging an image onto the prompt text ﬁeld.\\nUse a playground 162Amazon Bedrock User Guide\\nNote\\nIf the response violates the content moderation policy, Amazon Bedrock doesn\\'t \\ndisplay it. If you have turned on streaming, Amazon Bedrock clears the entire response \\nif it generates content that violates the policy. For more details, navigate to the \\nAmazon Bedrock console, select Providers, and read the text under the Content \\nlimitations  section.\\nFor information about prompt engineering, see  Prompt engineering guidelines.\\n7. choose Run. to run the prompt.\\n8. If you are using the chat playground, view the model metrics and compare models by doing \\nthe following.\\na. In the Model metrics  section, view the metrics for each model.\\nb. (Optional) Deﬁne criteria that you want to match by doing the following:\\ni. Choose Deﬁne metric criteria .\\nii. For the metrics you want to use, choose the condition and value. You can set the \\nfollowing conditions:\\n•less than – The metric value is less than the speciﬁed value.\\n•greater than  – the metric value is more than the speciﬁed value.\\niii. Choose Apply  to apply your criteria.\\niv.View which criteria are met. If all criteria are met, the Overall summary is Meets all \\ncriteria . If 1 or more criteria are not met, the Overall summary is n criteria unmet\\nand the unmet criteria are highlighted in red.\\nc. (Optional) Add models to compare by doing the following:\\ni. Turn on Compare mode .\\nii. Choose Select model to select a model.\\niii. In the dialog box, choose a provider, model, and throughput.\\niv.Choose Apply .\\nv.(Optional) Choose the menu icon next to each model to conﬁgure inference \\nparameters for that model. For more information, see Inference parameters for \\nfoundation models .\\nUse a playground 163Amazon Bedrock User Guide\\nvi. Chooses the + icon on the right of the Chat playground section to add a second or \\nthird model to compare.\\nvii. Repeat steps a-c to choose the models that you want to compare.\\nviii. Enter your a prompt into the text ﬁeld and choose Run.\\nUse the API to invoke a model with a single prompt\\nRun inference on a model through the API by sending an InvokeModel or\\nInvokeModelWithResponseStream request. You can specify the media type for the request and \\nresponse bodies in the contentType  and accept  ﬁelds. The default value for both ﬁelds is\\napplication/json  if you don\\'t specify a value.\\nStreaming is supported for all text output models except AI21 Labs Jurassic-2 models. To check if \\na model supports streaming, send a GetFoundationModel or ListFoundationModels request and \\ncheck the value in the responseStreamingSupported  ﬁeld.\\nSpecify the following ﬁelds, depending on the model that you use.\\n1.modelId  – Use either the model ID or its ARN. The method for ﬁnding the modelId  or\\nmodelArn  depends on the type of model you use.\\n•Base model  – Do one of the following.\\n•To see a list of model IDs for all base models supported by Amazon Bedrock, see Base \\nmodel IDs (on-demand throughput) .\\n•Send a ListFoundationModels request and ﬁnd the modelId  or modelArn  of the model to \\nuse in the response.\\n•In the console, select a model in Providers and ﬁnd the modelId  in the API request\\nexample.\\n•Custom model  – Purchase Provisioned Throughput for the custom model (for more \\ninformation, see Provisioned Throughput) and ﬁnd the model ID or ARN of the provisioned \\nmodel.\\n•Provisioned model – If you have created a Provisioned Throughput for a base or custom \\nmodel, do one of the following.\\n•Send a ListProvisionedModelThroughputs request and ﬁnd the provisionedModelArn  or\\nprovisionedModelName  of the model to use in the response.\\nRun single-prompt inference 164Amazon Bedrock User Guide\\n•In the console, select a model in Provisioned Throughput and ﬁnd the model ARN or name \\nin the Model details  section.\\n2.body – Each base model has its own inference parameters that you set in the body  ﬁeld. The \\ninference parameters for a custom or provisioned model depends on the base model from which \\nit was created. For more information, see Inference parameters for foundation models.\\nInvoke model code examples\\nThe following examples show how to run inference with the InvokeModel API. For examples \\nwith diﬀerent models, see the inference parameter reference for the desired model (Inference \\nparameters for foundation models ).\\nCLI\\nThe following example saves the generated response to the prompt story of two dogs  to a \\nﬁle called invoke-model-output.txt .\\naws bedrock-runtime invoke-model \\\\ \\n    --model-id anthropic.claude-v2 \\\\ \\n    --body \\'{\"prompt\": \"\\\\n\\\\nHuman: story of two dogs\\\\n\\\\nAssistant:\", \\n \"max_tokens_to_sample\" : 300}\\' \\\\ \\n    --cli-binary-format raw-in-base64-out \\\\ \\n    invoke-model-output.txt\\nPython\\nThe following example returns a generated response to the prompt explain black holes \\nto 8th graders .\\nimport boto3\\nimport json\\nbrt = boto3.client(service_name=\\'bedrock-runtime\\')\\nbody = json.dumps({ \\n    \"prompt\": \"\\\\n\\\\nHuman: explain black holes to 8th graders\\\\n\\\\nAssistant:\", \\n    \"max_tokens_to_sample\": 300, \\n    \"temperature\": 0.1, \\n    \"top_p\": 0.9,\\n})\\nInvoke model code examples 165Amazon Bedrock User Guide\\nmodelId = \\'anthropic.claude-v2\\'\\naccept = \\'application/json\\'\\ncontentType = \\'application/json\\'\\nresponse = brt.invoke_model(body=body, modelId=modelId, accept=accept, \\n contentType=contentType)\\nresponse_body = json.loads(response.get(\\'body\\').read())\\n# text\\nprint(response_body.get(\\'completion\\'))\\nInvoke model with streaming code example\\nNote\\nThe AWS CLI does not support streaming.\\nThe following example shows how to use the InvokeModelWithResponseStream API to generate \\nstreaming text with Python using the prompt write an essay for living on mars in \\n1000 words .\\nimport boto3\\nimport json\\nbrt = boto3.client(service_name=\\'bedrock-runtime\\')\\nbody = json.dumps({ \\n    \\'prompt\\': \\'\\\\n\\\\nHuman: write an essay for living on mars in 1000 words\\\\n\\n\\\\nAssistant:\\', \\n    \\'max_tokens_to_sample\\': 4000\\n}) \\n                    \\nresponse = brt.invoke_model_with_response_stream( \\n    modelId=\\'anthropic.claude-v2\\',  \\n    body=body\\n) \\n     \\nstream = response.get(\\'body\\')\\nif stream: \\nInvoke model with streaming code example 166Amazon Bedrock User Guide\\n    for event in stream: \\n        chunk = event.get(\\'chunk\\') \\n        if chunk: \\n            print(json.loads(chunk.get(\\'bytes\\').decode()))\\nRun batch inference\\nNote\\nBatch inference is in preview and is subject to change. Batch inference is currently only \\navailable through the API. Access batch APIs through the following SDKs.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nWe recommend that you create a virtual environment to use the SDK. Because batch \\ninference APIs aren\\'t available in the latest SDKs, we recommend that you uninstall the \\nlatest version of the SDK from the virtual environment before installing the version with \\nthe batch inference APIs. For a guided example, see ???.\\nWith batch inference, you can run multiple inference requests asynchronously to process a large \\nnumber of requests eﬃciently by running inference on data that is stored in an S3 bucket. You can \\nuse batch inference to improve the performance of model inference on large datasets.\\nNote\\nBatch inference isn\\'t supported for provisioned models.\\nTo see quotas for batch inference, see Batch inference quotas.\\nAmazon Bedrock supports batch inference on the following modalities.\\n•Text to embeddings\\n•Text to text\\n•Text to image\\nRun batch inference 167Amazon Bedrock User Guide\\n•Image to image\\n•Image to embeddings\\nYou store your data in an Amazon S3 bucket to prepare it for batch inference. You can then carry \\nout and manage batch inference jobs through using the ModelInvocationJob  APIs.\\nBefore you can carry out batch inference, you must receive permissions to call the batch inference \\nAPIs. You then conﬁgure an IAM Amazon Bedrock service role to have permissions to carry out \\nbatch inference jobs.\\nYou can use the batch inference APIs by downloading and installing one of the following AWS SDK \\npackages.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nTopics\\n•Set up permissions for batch inference\\n•Format and upload your inference data\\n•Create a batch inference job\\n•Stop a batch inference job\\n•Get details about a batch inference job\\n•List batch inference jobs\\n•Code samples\\nSet up permissions for batch inference\\nNote\\nBatch inference is in preview and is subject to change. Batch inference is currently only \\navailable through the API. Access batch APIs through the following SDKs.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nPermissions 168Amazon Bedrock User Guide\\nWe recommend that you create a virtual environment to use the SDK. Because batch \\ninference APIs aren\\'t available in the latest SDKs, we recommend that you uninstall the \\nlatest version of the SDK from the virtual environment before installing the version with \\nthe batch inference APIs. For a guided example, see ???.\\nTo set up a role for batch inference, create an IAM role by following the steps at Creating a role to \\ndelegate permissions to an AWS service. Attach the following policies to the role:\\n•Trust policy\\n•Access to the Amazon S3 buckets containing the input data for your batch inference jobs and to \\nwrite the output data.\\n1. The following policy allows Amazon Bedrock to assume this role and carry out batch inference \\njobs. The following shows an example policy you can use. You can restrict the scope of the \\npermission by using one or more global condition context keys. For more information, see AWS \\nglobal condition context keys. Set the aws:SourceAccount  value to your account ID. Use the\\nArnEquals  or ArnLike condition to restrict the scope.\\nNote\\nAs a best practice for security purposes, replace the * with speciﬁc batch inference job \\nIDs after you have created them.\\n{ \\n  \"Version\": \"2012-10-17\", \\n  \"Statement\": [ \\n    { \\n      \"Effect\": \"Allow\", \\n      \"Principal\": { \\n        \"Service\": \"bedrock.amazonaws.com\" \\n      }, \\n      \"Action\": \"sts:AssumeRole\", \\n      \"Condition\": { \\n          \"StringEquals\": { \\n            \"aws:SourceAccount\": \" account-id \"  \\nPermissions 169Amazon Bedrock User Guide\\n          }, \\n          \"ArnEquals\": { \\n            \"aws:SourceArn\": \"arn:aws:bedrock: region:account-id :model-invocation-\\njob/*\" \\n          } \\n     } \\n    } \\n  ]\\n}\\n2. Attach the following policy to allow Amazon Bedrock to access the S3 bucket containing input \\ndata for your batch inference jobs (replace my_input_bucket ) and the S3 bucket to write \\noutput data to (replace my_output_bucket ). Replace the account-id  with the account ID of \\nthe user to whom you are providing S3 bucket access permissions.\\n{ \\n  \"Version\": \"2012-10-17\", \\n  \"Statement\": [ \\n    { \\n      \"Effect\": \"Allow\", \\n      \"Action\": [ \\n        \"s3:GetObject\", \\n        \"s3:PutObject\", \\n        \"s3:ListBucket\" \\n      ], \\n      \"Resource\": [ \\n        \"arn:aws:s3::: my_input_bucket \", \\n        \"arn:aws:s3::: my_input_bucket/* \", \\n        \"arn:aws:s3::: my_output_bucket \", \\n        \"arn:aws:s3::: my_output_bucket/* \" \\n      ], \\n      \"Condition\": { \\n        \"StringEquals\": { \\n          \"aws:ResourceAccount\": [ \\n            \" account-id \" \\n          ] \\n        } \\n      } \\n    } \\n  ]\\n}\\nPermissions 170Amazon Bedrock User Guide\\nFormat and upload your inference data\\nNote\\nBatch inference is in preview and is subject to change. Batch inference is currently only \\navailable through the API. Access batch APIs through the following SDKs.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nWe recommend that you create a virtual environment to use the SDK. Because batch \\ninference APIs aren\\'t available in the latest SDKs, we recommend that you uninstall the \\nlatest version of the SDK from the virtual environment before installing the version with \\nthe batch inference APIs. For a guided example, see ???.\\nUpload JSONL ﬁles containing the data to input to the model to your S3 bucket with the following \\nformat. Each line should match the following format and is a diﬀerent item for inference. If you \\nleave the recordId  ﬁeld out, Amazon Bedrock adds it in the output.\\nNote\\nThe format of the modelInput  JSON object should match the body  ﬁeld for the model \\nthat you use in the InvokeModel  request. For more information, see Inference parameters \\nfor foundation models .\\n{ \"recordId\" : \" 12 character alphanumeric string \", \"modelInput\" : {JSON body}  }\\n...\\nFor example, you might provide an JSONL ﬁle containing the following data and run batch \\ninference on a Titan text model.\\n{ \"recordId\" : \" 3223593EFGH \", \"modelInput\" : {\"inputText\": \" Roses are red, violets \\n are\"} }\\n{ \"recordId\" : \" 1223213ABCD \", \"modelInput\" : {\"inputText\": \" Hello world \"} }\\nSet up data 171Amazon Bedrock User Guide\\nCreate a batch inference job\\nNote\\nBatch inference is in preview and is subject to change. Batch inference is currently only \\navailable through the API. Access batch APIs through the following SDKs.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nWe recommend that you create a virtual environment to use the SDK. Because batch \\ninference APIs aren\\'t available in the latest SDKs, we recommend that you uninstall the \\nlatest version of the SDK from the virtual environment before installing the version with \\nthe batch inference APIs. For a guided example, see ???.\\nRequest format\\nPOST /model-invocation-job HTTP/1.1\\nContent-type: application/json\\n{ \\n   \"clientRequestToken\": \"string\", \\n   \"inputDataConfig\": {  \\n        \"s3InputDataConfig\": {  \\n            \"s3Uri\": \"string\", \\n            \"s3InputFormat\": \"JSONL\" \\n        } \\n   }, \\n   \"jobName\": \"string\", \\n   \"modelId\": \"string\", \\n   \"outputDataConfig\": { \\n        \"s3OutputDataConfig\": { \\n            \"s3Uri\": \"string\" \\n        } \\n   }, \\n   \"roleArn\": \"string\", \\n   \"tags\": [  \\n      {  \\n         \"key\": \"string\", \\nCreate a batch inference job 172Amazon Bedrock User Guide\\n         \"value\": \"string\" \\n      } \\n   ]\\n}\\nResponse format\\nHTTP/1.1 200\\nContent-type: application/json\\n{ \\n   \"jobArn\": \"string\"\\n}\\nTo create a batch inference job, send a CreateModelInvocationJob  request. Provide the \\nfollowing information.\\n•The ARN of a role with permissions to run batch inference in roleArn .\\n•Information for the S3 bucket containing the input data in inputDataConfig  and the bucket \\nwhere to write information in outputDataConfig .\\n•The ID of the model to use for inference in modelId  (see Base model IDs (on-demand \\nthroughput) ).\\n•A name for the job in jobName .\\n•(Optional) Any tags that you want to attach to the job in tags .\\nThe response returns a jobArn that you can use for other batch inference-related API calls.\\nYou can check the status  of the job with either the GetModelInvocationJob  or\\nListModelInvocationJobs  APIs.\\nWhen the job is Completed , you can extract the results of the batch inference job from the ﬁles in \\nthe S3 bucket you speciﬁed in the request for the outputDataConfig . The S3 bucket contains the \\nfollowing ﬁles:\\n1.Output ﬁles containing the result of the model inference.\\n•If the output is text, Amazon Bedrock generates an output JSONL ﬁle for each input JSONL \\nﬁle. The output ﬁles contain outputs from the model for each input in the following format. \\nAn error object replaces the modelOutput  ﬁeld in any line where there was an error in \\nCreate a batch inference job 173Amazon Bedrock User Guide\\ninference. The format of the modelOutput  JSON object matches the body  ﬁeld for the model \\nthat you use in the InvokeModel  response. For more information, see Inference parameters \\nfor foundation models .\\n{ \"recordId\" : \" 12 character alphanumeric string \", \"modelInput\": {JSON body} , \\n \"modelOutput\": {JSON body}  }\\nThe following example shows a possible output ﬁle.\\n{ \"recordId\" : \"3223593EFGH\", \"modelInput\" : {\"inputText\": \"Roses are red, violets \\n are\"}, \"modelOutput\" : {\\'inputTextTokenCount\\': 8, \\'results\\': [{\\'tokenCount\\': 3, \\n \\'outputText\\': \\'blue\\\\n\\', \\'completionReason\\': \\'FINISH\\'}]}}\\n{ \"recordId\" : \"1223213ABCDE\", \"modelInput\" : {\"inputText\": \"Hello world\"}, \\n \"error\" : {\"errorCode\" : 400, \"errorMessage\" : \"bad request\" }}\\n•If the output is image, Amazon Bedrock generates a ﬁle for each image.\\n2.A manifest.json.out  ﬁle containing a summary of the batch inference job.\\n{ \\n    \"processedRecordCount\" : number, \\n    \"successRecordCount\": number, \\n    \"errorRecordCount\": number, \\n    \"inputTextTokenCount\": number, // For embedding/text to text models \\n    \"outputTextTokenCount\" : number, // For text to text models  \\n    \"outputImgCount512x512pStep50\": number, // For text to image models  \\n    \"outputImgCount512x512pStep150\" : number, // For text to image models  \\n    \"outputImgCount512x896pStep50\" : number, // For text to image models  \\n    \"outputImgCount512x896pStep150\" : number // For text to image models  \\n}\\nStop a batch inference job\\nNote\\nBatch inference is in preview and is subject to change. Batch inference is currently only \\navailable through the API. Access batch APIs through the following SDKs.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nStop a batch inference job 174Amazon Bedrock User Guide\\nWe recommend that you create a virtual environment to use the SDK. Because batch \\ninference APIs aren\\'t available in the latest SDKs, we recommend that you uninstall the \\nlatest version of the SDK from the virtual environment before installing the version with \\nthe batch inference APIs. For a guided example, see ???.\\nRequest format\\nPOST /model-invocation-job/ jobIdentifier /stop HTTP/1.1\\nResponse format\\nHTTP/1.1 200\\nTo stop a batch inference job, send a StopModelInvocationJob  and provide the ARN of the job \\nin the jobIdentifier  ﬁeld.\\nIf the job was successfully stopped, you receive an HTTP 200 response.\\nGet details about a batch inference job\\nNote\\nBatch inference is in preview and is subject to change. Batch inference is currently only \\navailable through the API. Access batch APIs through the following SDKs.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nWe recommend that you create a virtual environment to use the SDK. Because batch \\ninference APIs aren\\'t available in the latest SDKs, we recommend that you uninstall the \\nlatest version of the SDK from the virtual environment before installing the version with \\nthe batch inference APIs. For a guided example, see ???.\\nGet details about a batch inference job 175Amazon Bedrock User Guide\\nRequest format\\nGET /model-invocation-job/ jobIdentifier  HTTP/1.1\\nResponse format\\nHTTP/1.1 200\\nContent-type: application/json\\n{ \\n   \"clientRequestToken\": \"string\", \\n   \"endTime\": \"string\", \\n   \"inputDataConfig\": { \\n        \"s3InputDataConfig\": {  \\n            \"s3Uri\": \"string\", \\n            \"s3InputFormat\": \"JSONL\" \\n        } \\n    }, \\n   \"jobArn\": \"string\", \\n   \"jobName\": \"string\", \\n   \"lastModifiedTime\": \"string\", \\n   \"message\": \"string\", \\n   \"modelId\": \"string\", \\n   \"outputDataConfig\": { \\n        \"s3OutputDataConfig\": {  \\n            \"s3Uri\": \"string\" \\n        } \\n   }, \\n   \"roleArn\": \"string\", \\n   \"status\": \"Submitted | InProgress | Completed | Failed | Stopping | Stopped\", \\n   \"submitTime\": \"string\"\\n}\\nTo get information about a batch inference job, send a GetModelInvocationJob  and provide the \\nARN of the job in the jobIdentifier  ﬁeld.\\nSee the GetModelInvocationJob  page for details about the information provided in the \\nresponse.\\nGet details about a batch inference job 176Amazon Bedrock User Guide\\nList batch inference jobs\\nNote\\nBatch inference is in preview and is subject to change. Batch inference is currently only \\navailable through the API. Access batch APIs through the following SDKs.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nWe recommend that you create a virtual environment to use the SDK. Because batch \\ninference APIs aren\\'t available in the latest SDKs, we recommend that you uninstall the \\nlatest version of the SDK from the virtual environment before installing the version with \\nthe batch inference APIs. For a guided example, see ???.\\nRequest format\\nGET /model-invocation-jobs?\\nmaxResults= maxResults &nameContains= nameContains &nextToken= nextToken &sortBy= sortBy&sortOrder= sortOrder &statusEquals= statusEquals &submitTimeAfter= submitTimeAfter &submitTimeBefore= submitTimeBefore\\n HTTP/1.1\\nResponse format\\nHTTP/1.1 200\\nContent-type: application/json\\n{ \\n   \"invocationJobSummaries\": [  \\n      {  \\n         \"clientRequestToken\": \"string\", \\n         \"endTime\": \"string\", \\n         \"inputDataConfig\": {  \\n            \"s3InputDataConfig\": {  \\n                \"s3Uri\": \"string\", \\n                \"s3InputFormat\": \"JSONL\" \\n            }  \\n         }, \\n         \"jobArn\": \"string\", \\n         \"jobName\": \"string\", \\nList batch inference jobs 177Amazon Bedrock User Guide\\n         \"lastModifiedTime\": \"string\", \\n         \"message\": \"string\", \\n         \"modelId\": \"string\", \\n         \"outputDataConfig\": {  \\n            \"s3OutputDataConfig\": {  \\n                \"s3Uri\": \"string\" \\n            }  \\n         }, \\n         \"roleArn\": \"string\", \\n         \"status\": \"Submitted | InProgress | Completed | Failed | Stopping | \\n Stopped\", \\n         \"submitTime\": \"string\" \\n      } \\n   ], \\n   \"nextToken\": \"string\"\\n}\\nTo get information about a batch inference job, send a ListModelInvocationJobs . You can set \\nthe following speciﬁcations.\\n•Filter for results by specifying the status, submission time, or substrings in the name of the job. \\nYou can specify the following statuses.\\n•Submitted\\n•InProgress\\n•Completed\\n•Failed\\n•Stopping\\n•Stopped\\n•Sort by the time that the job was created (CreationTime ). You can sort in Ascending  or\\nDescending  order.\\n•The maximum number of results to return in a response. If there are more results than \\nthe number you set, the response returns a nextToken  that you can send in another\\nListModelInvocationJobs  request to see the next batch of jobs.\\nThe response returns a list of InvocationJobSummary  objects. Each object contains information \\nabout a batch inference job.\\nList batch inference jobs 178Amazon Bedrock User Guide\\nCode samples\\nNote\\nBatch inference is in preview and is subject to change. Batch inference is currently only \\navailable through the API. Access batch APIs through the following SDKs.\\n•AWS SDK for Python.\\n•AWS SDK for Java.\\nWe recommend that you create a virtual environment to use the SDK. Because batch \\ninference APIs aren\\'t available in the latest SDKs, we recommend that you uninstall the \\nlatest version of the SDK from the virtual environment before installing the version with \\nthe batch inference APIs. For a guided example, see ???.\\nSelect a language to see a code sample to call the batch inference API operations.\\nPython\\nAfter downloading the Python SDK and CLI ﬁles containing the batch inference API operations, \\nnavigate to the folder containing the ﬁles and run ls in a terminal. You should see the \\nfollowing 2 ﬁles, at the least.\\nbotocore-1.32.4-py3-none-any.whl\\nboto3-1.29.4-py3-none-any.whl\\nCreate and activate a virtual environment for the batch inference APIs by running the following \\ncommands in a terminal. You can replace bedrock-batch  with a name of your choice for the \\nenvironment.\\npython3 -m venv bedrock-batch\\nsource bedrock-batch /bin/activate\\nTo ensure that there aren\\'t artifacts from later version of boto3  and botocore , uninstall any \\nexisting versions by running the following commands in a terminal.\\npython3 -m pip uninstall botocore\\nCode samples 179Amazon Bedrock User Guide\\npython3 -m pip uninstall boto3\\nInstall the Python SDK containing the Amazon Bedrock control plane APIs by running the \\nfollowing commands in a terminal.\\npython3 -m pip install botocore-1.32.4-py3-none-any.whl\\npython3 -m pip install boto3-1.29.4-py3-none-any.whl\\nRun all the following code in the virtual environment you created.\\nCreate a batch inference job with a ﬁle named abc.jsonl  that you uploaded to S3. Write the \\noutput to a bucket in s3://output-bucket/output/ . Get the jobArn from the response.\\nimport boto3\\nbedrock = boto3.client(service_name=\"bedrock\")\\ninputDataConfig=({ \\n    \"s3InputDataConfig\": { \\n        \"s3Uri\": \"s3://input-bucket/input/abc.jsonl\" \\n    }\\n})\\noutputDataConfig=({ \\n    \"s3OutputDataConfig\": { \\n        \"s3Uri\": \"s3://output-bucket/output/\" \\n    }\\n})\\nresponse=bedrock.create_model_invocation_job( \\n    roleArn=\"arn:aws:iam::123456789012:role/MyBatchInferenceRole\", \\n    modelId=\"amazon.titan-text-express-v1\", \\n    jobName=\"my-batch-job\", \\n    inputDataConfig=inputDataConfig, \\n    outputDataConfig=outputDataConfig\\n)\\njobArn = response.get(\\'jobArn\\')\\nReturn the status  of the job.\\nbedrock.get_model_invocation_job(jobIdentifier=jobArn)[\\'status\\']\\nCode samples 180Amazon Bedrock User Guide\\nList batch inference jobs that Failed .\\nbedrock.list_model_invocation_jobs( \\n    maxResults=10, \\n    statusEquals=\"Failed\", \\n    sortOrder=\"Descending\"\\n)\\nStop the job that you started.\\nbedrock.stop_model_invocation_job(jobIdentifier=jobArn)\\nJava\\npackage com.amazon.aws.sample.bedrock.inference;\\nimport com.amazonaws.services.bedrock.AmazonBedrockAsync;\\nimport com.amazonaws.services.bedrock.AmazonBedrockAsyncClientBuilder;\\nimport com.amazonaws.services.bedrock.model.CreateModelInvocationJobRequest;\\nimport com.amazonaws.services.bedrock.model.CreateModelInvocationJobResult;\\nimport com.amazonaws.services.bedrock.model.GetModelInvocationJobRequest;\\nimport com.amazonaws.services.bedrock.model.GetModelInvocationJobResult;\\nimport com.amazonaws.services.bedrock.model.InvocationJobInputDataConfig;\\nimport com.amazonaws.services.bedrock.model.InvocationJobOutputDataConfig;\\nimport com.amazonaws.services.bedrock.model.InvocationJobS3InputDataConfig;\\nimport com.amazonaws.services.bedrock.model.InvocationJobS3OutputDataConfig;\\nimport com.amazonaws.services.bedrock.model.ListModelInvocationJobsRequest;\\nimport com.amazonaws.services.bedrock.model.ListModelInvocationJobsResult;\\nimport com.amazonaws.services.bedrock.model.StopModelInvocationJobRequest;\\nimport com.amazonaws.services.bedrock.model.StopModelInvocationJobResult;\\npublic class BedrockAsyncInference {\\nprivate final AmazonBedrockAsync amazonBedrockAsyncClient = \\n AmazonBedrockAsyncClientBuilder.defaultClient();\\npublic void createModelInvokeJobSampleCode() { \\n    final InvocationJobS3InputDataConfig invocationJobS3InputDataConfig = new \\n InvocationJobS3InputDataConfig() \\n            .withS3Uri(\"s3://Input-bucket-name/input/abc.jsonl\") \\n            .withS3InputFormat(\"JSONL\"); \\n    final InvocationJobInputDataConfig inputDataConfig = new \\n InvocationJobInputDataConfig() \\nCode samples 181Amazon Bedrock User Guide\\n            .withS3InputDataConfig(invocationJobS3InputDataConfig); \\n    final InvocationJobS3OutputDataConfig invocationJobS3OutputDataConfig = new \\n InvocationJobS3OutputDataConfig() \\n            .withS3Uri(\"s3://output-bucket-name/output/\"); \\n    final InvocationJobOutputDataConfig invocationJobOutputDataConfig = new \\n InvocationJobOutputDataConfig() \\n            .withS3OutputDataConfig(invocationJobS3OutputDataConfig); \\n    final CreateModelInvocationJobRequest createModelInvocationJobRequest = new \\n CreateModelInvocationJobRequest() \\n            .withModelId(\"anthropic.claude-v2\") \\n            .withJobName(\"unique-job-name\") \\n            .withClientRequestToken(\"Client-token\") \\n            .withInputDataConfig(inputDataConfig) \\n            .withOutputDataConfig(invocationJobOutputDataConfig); \\n    final CreateModelInvocationJobResult createModelInvocationJobResult = \\n amazonBedrockAsyncClient \\n            .createModelInvocationJob(createModelInvocationJobRequest); \\n    System.out.println(createModelInvocationJobResult.getJobArn());\\n}\\npublic void getModelInvokeJobSampleCode() { \\n    final GetModelInvocationJobRequest getModelInvocationJobRequest = new \\n GetModelInvocationJobRequest() \\n            .withJobIdentifier(\"jobArn\"); \\n    final GetModelInvocationJobResult getModelInvocationJobResult = \\n amazonBedrockAsyncClient \\n            .getModelInvocationJob(getModelInvocationJobRequest);\\n}\\npublic void listModelInvokeJobSampleCode() { \\n    final ListModelInvocationJobsRequest listModelInvocationJobsRequest = new \\n ListModelInvocationJobsRequest() \\n            .withMaxResults(10) \\n            .withNameContains(\"matchin-string\"); \\nCode samples 182Amazon Bedrock User Guide\\n    final ListModelInvocationJobsResult listModelInvocationJobsResult = \\n amazonBedrockAsyncClient \\n            .listModelInvocationJobs(listModelInvocationJobsRequest);\\n}\\npublic void stopModelInvokeJobSampleCode() { \\n    final StopModelInvocationJobRequest stopModelInvocationJobRequest = new \\n StopModelInvocationJobRequest() \\n            .withJobIdentifier(\"jobArn\"); \\n    final StopModelInvocationJobResult stopModelInvocationJobResult = \\n amazonBedrockAsyncClient \\n            .stopModelInvocationJob(stopModelInvocationJobRequest);\\n}\\n}\\nCode samples 183Amazon Bedrock User Guide\\nPrompt engineering guidelines\\nTopics\\n•Introduction\\n•What is a prompt?\\n•What is prompt engineering?\\n•General guidelines for Amazon Bedrock LLM users\\n•Prompt templates and examples for Amazon Bedrock text models\\nIntroduction\\nWelcome to the prompt engineering guide for large language models (LLMs) on Amazon Bedrock. \\nAmazon Bedrock is Amazon’s service for foundation models (FMs), which oﬀers access to a range of \\npowerful FMs for text and images.\\nPrompt engineering  refers to the practice of optimizing textual input to LLMs to obtain desired \\nresponses. Prompting helps LLMs perform a wide variety of tasks, including classiﬁcation, question \\nanswering, code generation, creative writing, and more. The quality of prompts that you provide to \\nLLMs can impact the quality of their responses. These guidelines provide you with all the necessary \\ninformation to get started with prompt engineering. It also covers tools to help you ﬁnd the best \\npossible prompt format for your use case when using LLMs on Amazon Bedrock.\\nWhether you’re a beginner in the world of generative AI and language models, or an expert with \\nprevious experience, these guidelines can help you optimize your prompts for Amazon Bedrock \\ntext models. Experienced users can skip to the General Guidelines for Amazon Bedrock LLM Users  or\\nPrompt Templates and Examples for Amazon Bedrock Text Models sections.\\nNote\\nAll examples in this doc are obtained via API calls. The response may vary due to the \\nstochastic nature of the LLM generation process. If not otherwise speciﬁed, the prompts are \\nwritten by employees of AWS.\\nDisclaimer: The examples in this document use the current text models available within Amazon \\nBedrock. Also, this document is for general prompting guidelines. For model-speciﬁc guides, refer \\nIntroduction 184Amazon Bedrock User Guide\\nto their respective docs on Amazon Bedrock. This document provides a starting point. While the \\nfollowing example responses are generated using speciﬁc models on Amazon Bedrock, you can use \\nother models in Amazon Bedrock to get results as well. The results may diﬀer between models as \\neach model has its own performance characteristics. The output that you generate using AI services \\nis your content. Due to the nature of machine learning, output may not be unique across customers \\nand the services may generate the same or similar results across customers.\\nAdditional prompt resources\\nThe following resources oﬀer additional guidelines on prompt engineering.\\n•Anthropic Claude model prompt guide:  https://docs.anthropic.com/claude/docs\\n•Anthropic Claude prompt engineering resources: https://docs.anthropic.com/claude/docs/\\nguide-to-anthropics-prompt-engineering-resources\\n•Cohere prompt guide:  https://txt.cohere.com/how-to-train-your-pet-llm-prompt-engineering\\n•AI21 Labs Jurassic model prompt guide:  https://docs.ai21.com/docs/prompt-engineering\\n•Meta Llama 2 prompt guide:   https://ai.meta.com/llama/get-started/#prompting\\n•Stability documentation: https://platform.stability.ai/docs/getting-started\\n•Mistral AI prompt guide:  https://docs.mistral.ai/guides/prompting-capabilities/\\nWhat is a prompt?\\nPrompts are a speciﬁc set of inputs provided by you, the user, that guide LLMs on Amazon Bedrock \\nto generate an appropriate response or output for a given task or instruction.\\nUser Prompt:\\nWho invented the airplane?\\nWhen queried by this prompt, Titan provides an output:\\nOutput:\\nThe Wright brothers, Orville and Wilbur Wright are widely credited  \\nwith inventing and manufacturing the world\\'s first successful airplane.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nAdditional prompt resources 185Amazon Bedrock User Guide\\nComponents of a prompt\\nA single prompt includes several components, such as the task or instruction you want the \\nLLMs to perform, the context of the task (for example, a description of the relevant domain), \\ndemonstration examples, and the input text that you want LLMs on Amazon Bedrock to use in \\nits response. Depending on your use case, the availability of the data, and the task, your prompt \\nshould combine one or more of these components.\\nConsider this example prompt asking Titan to summarize a review:\\nUser Prompt:\\nThe following is text from a restaurant review:\\n“I finally got to check out Alessandro’s Brilliant Pizza and it is now  \\none of my favorite restaurants in Seattle. The dining room has a beautiful view  \\nover the Puget Sound but it was surprisingly not crowded. I ordered  \\nthe fried castelvetrano olives, a spicy Neapolitan-style pizza  \\nand a gnocchi dish. The olives were absolutely decadent, and the pizza came  \\nwith a smoked mozzarella, which was delicious. The gnocchi was fresh and wonderful.  \\nThe waitstaff were attentive, and overall the experience was lovely.  \\nI hope to return soon.\"  \\nSummarize the above restaurant review in one sentence.\\n(Source of prompt: AWS)\\nBased on this prompt, Titan responds with a succinct one-line summary of the restaurant review. \\nThe review mentions key facts and conveys the main points, as desired.\\nOutput: \\nAlessandro\\'s Brilliant Pizza is a fantastic restaurant in Seattle  \\nwith a beautiful view over Puget Sound, decadent and delicious food,  \\nand excellent service.\\n(Model used: Amazon Titan Text G1 - Express)\\nThe instruction Summarize the above restaurant review in one sentence  and the \\nreview text I finally got to check out ...  were both necessary for this type of output. \\nWithout either one, the model would not have enough information to produce a sensible summary. \\nThe instruction  tells the LLM what to do, and the text is the input  on which the LLM operates. \\nComponents of a prompt 186Amazon Bedrock User Guide\\nThe context (The following is text from a restaurant review ) provides additional \\ninformation and keywords that guide the model to use the input when formulating its output.\\nIn the example below, the text Context: Climate change threatens people with \\nincreased flooding ...  is the input  which the LLM can use to perform the task of answering \\nthe question Question: What organization calls climate change the greatest \\nthreat to global health in the 21st century?” .\\nUser prompt:\\nContext: Climate change threatens people with increased flooding,  \\nextreme heat, increased food and water scarcity, more disease, and economic loss.  \\nHuman migration and conflict can also be a result. The World Health Organization (WHO)  \\ncalls climate change the greatest threat to global health in the 21st century.  \\nAdapting to climate change through efforts like flood control measures  \\nor drought-resistant crops partially reduces climate change risks,  \\nalthough some limits to adaptation have already been reached.  \\nPoorer communities are responsible for a small share of global emissions,  \\nyet have the least ability to adapt and are most vulnerable to climate change.  \\nThe expense, time required, and limits of adaptation mean its success hinge  \\non limiting global warming.\\nQuestion: What organization calls climate change the greatest threat  \\nto global health in the 21st century?\\n(Source of prompt: https://en.wikipedia.org/wiki/Climate_change)\\nAI21 Labs Jurassic responses with the correct name of the organization according to the context \\nprovided in the prompt.\\nOutput:\\nThe World Health Organization (WHO) calls climate change  \\nthe greatest threat to global health in the 21st century.\\n(Model used: AI21 Labs Jurassic-2 Ultra v1)\\nFew-shot prompting vs. zero-shot prompting\\nIt is sometimes useful to provide a few examples to help LLMs better calibrate their output to \\nmeet your expectations, also known as few-shot prompting  or in-context learning, where a shot\\ncorresponds to a paired example input and the desired output. To illustrate, ﬁrst here is an example \\nFew-shot prompting vs. zero-shot prompting 187Amazon Bedrock User Guide\\nof a zero-shot sentiment classiﬁcation prompt where no example input-output pair is provided in \\nthe prompt text:\\nUser prompt:\\nTell me the sentiment of the following headline and categorize it  \\nas either positive, negative or neutral:  \\nNew airline between Seattle and San Francisco offers a great opportunity  \\nfor both passengers and investors.\\n(Source of prompt: AWS)\\nOutput:\\nPositive\\n(Model used: Amazon Titan Text G1 - Express)\\nHere is the few-shot version of a sentiment classiﬁcation prompt:\\nUser prompt: \\nTell me the sentiment of the following headline and categorize it  \\nas either positive, negative or neutral. Here are some examples:\\nResearch firm fends off allegations of impropriety over new technology.\\nAnswer: Negative\\nOffshore windfarms continue to thrive as vocal minority in opposition dwindles.\\nAnswer: Positive\\nManufacturing plant is the latest target in investigation by state officials.\\nAnswer:\\n(Source of prompt: AWS)\\nOutput: \\nNegative\\n(Model used: Amazon Titan Text G1 - Express)\\nThe following example uses Anthropic Claude models. When using Anthropic Claude models, it’s \\na good practice to use <example></example> tags to include demonstration examples. We also \\nrecommend using diﬀerent delimiters such as H: and A: in the examples to avoid confusion with \\nFew-shot prompting vs. zero-shot prompting 188Amazon Bedrock User Guide\\nthe delimiters Human:  and Assistant:  for the whole prompt. Notice that for the last few-shot \\nexample, the ﬁnal A: is left oﬀ in favor of Assistant: , prompting Anthropic Claude to generate \\nthe answer instead.\\nUser prompt: \\nHuman: Please classify the given email as \"Personal\" or \"Commercial\" related emails.\\nHere are some examples.\\n<example>\\nH: Hi Tom, it\\'s been long time since we met last time. We plan to have a party at my \\n house this weekend. Will you be able to come over?\\nA: Personal\\n</example>\\n<example>\\nH: Hi Tom, we have a special offer for you. For a limited time, our customers can save \\n up to 35% of their total expense when you make reservations within two days. Book now \\n and save money!\\nA: Commercial\\n</example>\\nH: Hi Tom, Have you heard that we have launched all-new set of products. Order now, you \\n will save $100 for the new products. Please check our website.\\nAssistant:\\nOutput: \\nCommercial\\n(Source of prompt: AWS, model used: Anthropic Claude)\\nPrompt template\\nA prompt template speciﬁes the formatting of the prompt with exchangeable content in it. Prompt \\ntemplates are “recipes” for using LLMs for diﬀerent use cases such as classiﬁcation, summarization, \\nquestion answering, and more. A prompt template may include instructions, few-shot examples, \\nand speciﬁc context and questions appropriate for a given use case. The following example is a \\ntemplate that you can use to perform few-shot sentiment classiﬁcation using Amazon Bedrock text \\nmodels:\\nPrompt template 189Amazon Bedrock User Guide\\nPrompt template: \\n\"\"\"Tell me the sentiment of the following  \\n{{Text Type, e.g., “restaurant review”}} and categorize it  \\nas either {{Sentiment A}} or {{Sentiment B}}.  \\nHere are some examples:\\nText: {{Example Input 1}}  \\nAnswer: {{Sentiment A}}\\nText: {{Example Input 2}}\\nAnswer: {{Sentiment B}}\\nText: {{Input}}\\nAnswer:\"\"\"\\nUsers can copy and paste this template, ﬁlling in their own text and few-shot examples to \\ncomplete prompts when using LLMs on Amazon Bedrock. More templates are provided in this \\nsection.\\nNote\\nThe double curly braces {{ and }}  mark the places to put in data-speciﬁc information in \\nthe template, and should not be included in the prompt text.\\nImportant notes on using Amazon Bedrock LLMs by API calls\\nIf you are accessing LLMs on Amazon Bedrock via API calls, please be aware that they do not recall \\nprior prompts and previous requests unless the previous interaction is included within the current \\nprompt. You may need this for conversational-style interactions or follow up requests.\\nIf you are accessing Anthropic Claude models using API calls instead of the Amazon Bedrock text \\nplayground, you wrap your prompts in a conversational style to get desired response (for the Titan \\nText and AI21 Labs Jurassic model family, it\\'s not necessary). The following example demonstrates \\na conversational-style prompt:\\nUser prompt: \\n \\n \\nHuman: Describe where sea otters live in two sentences.\\nImportant notes on using Amazon Bedrock LLMs by API calls 190Amazon Bedrock User Guide\\nAssistant:\\nOutput: \\nHere is a two sentence description of where sea otters live:\\nSea otters live in the northern Pacific Ocean along the coasts of  \\nRussia, Alaska, Canada, and the continental United States.  \\nThey prefer coastal habitats like rocky shores, kelp forests,  \\nand estuaries where they have access to shallow, nearshore waters.\\n(Source of prompt: AWS, model used: Anthropic Claude)\\nNotice how the main content of the prompt is wrapped like this: \\\\n\\\\nHuman: {{Main \\nContent}}\\\\n\\\\nAssistant: . For Anthropic Claude models, prompts sent via the API must \\ncontain \\\\n\\\\nHuman: and  \\\\n\\\\nAssistant: .\\nTo use conversational mode on Titan, you can use the format of User: {{}} \\\\n Bot:  when \\nprompting the model.\\nWhat is prompt engineering?\\nPrompt engineering refers to the practice of crafting and optimizing input prompts by selecting \\nappropriate words, phrases, sentences, punctuation, and separator characters to eﬀectively \\nuse LLMs for a wide variety of applications. In other words, prompt engineering is the art of \\ncommunicating with an LLM. High-quality prompts condition the LLM to generate desired or better \\nresponses. The detailed guidance provided within this document is applicable across all LLMs \\nwithin Amazon Bedrock.\\nThe best prompt engineering approach for your use case is dependent on both the task and the \\ndata. Common tasks supported by LLMs on Amazon Bedrock include:\\n•Classiﬁcation:  The prompt includes a question with several possible choices for the answer, and \\nthe model must respond with the correct choice. An example classiﬁcation use case is sentiment \\nanalysis: the input is a text passage, and the model must classify the sentiment of the text, such \\nas whether it\\'s positive or negative, or harmless or toxic.\\n•Question-answer, without context: The model must answer the question with its internal \\nknowledge without any context or document.\\n•Question-answer, with context: The user provides an input text with a question, and the model \\nmust answer the question based on information provided within the input text.\\nWhat is prompt engineering? 191Amazon Bedrock User Guide\\n•Summarization:  The prompt is a passage of text, and the model must respond with a shorter \\npassage that captures the main points of the input.\\n•Open-ended text generation: Given a prompt, the model must respond with a passage of \\noriginal text that matches the description. This also includes the generation of creative text such \\nas stories, poems, or movie scripts.\\n•Code generation:  The model must generate code based on user speciﬁcations. For example, a \\nprompt could request text-to-SQL or Python code generation.\\n•Mathematics:  The input describes a problem that requires mathematical reasoning at some \\nlevel, which may be numerical, logical, geometric or otherwise.\\n•Reasoning or logical thinking: The model must make a series of logical deductions.\\nGeneral guidelines for Amazon Bedrock LLM users\\nDesign your prompt\\nDesigning an appropriate prompt is an important step towards building a successful application \\nusing Amazon Bedrock models. The following ﬁgure shows a generic prompt design for the use \\ncase restaurant review summarization  and some important design choices that customers need to \\nconsider when designing prompts. LLMs generate undesirable responses if the instructions they are \\ngiven or the format of the prompt are not consistent, clear, and concise.\\nGeneral guidelines for Amazon Bedrock LLM users 192Amazon Bedrock User Guide\\n(Source: Prompt written by AWS)\\nUse inference parameters\\nLLMs on Amazon Bedrock all come with several inference parameters that you can set to control \\nthe response from the models. The following is a list of all the common inference parameters that \\nare available on Amazon Bedrock LLMs and how to use them.\\nTemperature is a value between 0 and 1, and it regulates the creativity of LLMs’ responses. Use \\nlower temperature if you want more deterministic responses, and use higher temperature if you \\nwant more creative or diﬀerent responses for the same prompt from LLMs on Amazon Bedrock. For \\nall the examples in this prompt guideline, we set temperature = 0 .\\nMaximum generation length/maximum new tokens limits the number of tokens that the LLM \\ngenerates for any prompt. It\\'s helpful to specify this number as some tasks, such as sentiment \\nclassiﬁcation, don\\'t need a long answer.\\nTop-p controls token choices, based on the probability of the potential choices. If you set Top-p \\nbelow 1.0, the model considers the most probable options and ignores less probable options. The \\nresult is more stable and repetitive completions.\\nUse inference parameters 193Amazon Bedrock User Guide\\nEnd token/end sequence speciﬁes the token that the LLM uses to indicate the end of the output. \\nLLMs stop generating new tokens after encountering the end token. Usually this doesn\\'t need to be \\nset by users.\\nThere are also model-speciﬁc inference parameters. Anthropic Claude models have an additional \\nTop-k inference parameter, and AI21 Labs Jurassic models come with a set of inference parameters \\nincluding presence penalty, count penalty, frequency penalty, and special token penalty. For \\nmore information, refer to their respective documentation.\\nDetailed guidelines\\nProvide simple, clear, and complete instructions\\nLLMs on Amazon Bedrock work best with simple and straightforward instructions. By clearly \\ndescribing the expectation of the task and by reducing ambiguity wherever possible, you can \\nensure that the model can clearly interpret the prompt.\\nFor example, consider a classiﬁcation problem where the user wants an answer from a set of \\npossible choices. The “good“ example shown below illustrates output that the user wants in this \\ncase. In the ”bad“ example, the choices are not named explicitly as categories for the model to \\nchoose from. The model interprets the input slightly diﬀerently without choices, and produces a \\nmore free-form summary of the text as opposed to the good example.\\nGood example, with output\\nUser prompt: \\n\"The most common cause of color \\n blindness is an  \\ninherited problem or variation in the \\n functionality  \\nof one or more of the three classes of \\n cone cells in the retina,  \\nwhich mediate color vision.\" \\nWhat is the above text about?  \\na) biology\\nb) history  \\nc) geology\\nOutput: \\na) biologyBad example, with output \\nUser prompt: \\nClassify the following text. \"The most \\n common cause of color  \\nblindness is an inherited problem or \\n variation in the functionality  \\nof one or more of the three classes of \\n cone cells in the retina,  \\nwhich mediate color vision.\"\\nOutput: \\nThe topic of the text is the causes of \\n colorblindness.\\nDetailed guidelines 194Amazon Bedrock User Guide\\n(Source of prompt:  Wikipedia on color blindness, model used: by Titan Text G1 - Express)\\nThe question or instruction should be placed at the end of the prompt for best results\\nIncluding the task description, instruction or question at the end aids the model determining which \\ninformation it has to ﬁnd. In the case of classiﬁcation, the choices for the answer should also come \\nat the end.\\nIn the following open-book question-answer example, the user has a speciﬁc question about the \\ntext. The question should come at the end of the prompt so the model can stay focused on the \\ntask.\\nUser prompt: \\nTensions increased after the 1911–1912 Italo-Turkish War  \\ndemonstrated Ottoman weakness and led to the formation of the Balkan League,  \\nan alliance of Serbia, Bulgaria, Montenegro, and Greece.  \\nThe League quickly overran most of the Ottomans\\' territory in the Balkans  \\nduring the 1912–1913 First Balkan War, much to the surprise of outside observers.\\nThe Serbian capture of ports on the Adriatic resulted in partial Austrian  \\nmobilization starting on 21 November 1912, including units along the Russian border  \\nin Galicia. In a meeting the next day, the Russian government decided not to mobilize  \\nin response, unwilling to precipitate a war for which they were not as of yet  \\nprepared to handle.\\nWhich country captured ports?\\nOutput: \\nSerbia\\n(Source of prompt:  Wikipedia on World War I, model used: Amazon Titan Text G1 - Express)\\nUse separator characters for API calls\\nSeparator characters such as \\\\n can aﬀect the performance of LLMs signiﬁcantly. For Anthropic \\nClaude models, it\\'s necessary to include newlines when formatting the API calls to obtain \\ndesired responses. The formatting should always follow: \\\\n\\\\nHuman: {{Query Content}}\\\\n\\n\\\\nAssistant: . For Titan models, adding \\\\n at the end of a prompt helps improve the \\nperformance of the model. For classiﬁcation tasks or questions with answer options, you can \\nalso separate the answer options by \\\\n for Titan models. For more information on the use of \\nDetailed guidelines 195Amazon Bedrock User Guide\\nseparators, refer to the document from the corresponding model provider. The following example \\nis a template for a classiﬁcation task.\\nPrompt template: \\n\"\"\"{{Text}}\\n{{Question}}\\n{{Choice 1}}\\n{{Choice 2}}\\n{{Choice 3}}\"\"\"\\nThe following example shows how the presence of newline characters between choices and at the \\nend of a prompt helps Titan produce the desired response.\\nUser prompt: \\nArchimedes of Syracuse was an Ancient mathematician,  \\nphysicist, engineer, astronomer, and inventor from the ancient city  \\nof Syracuse. Although few details of his life are known,  \\nhe is regarded as one of the leading scientists in classical antiquity.\\nWhat was Archimedes? Choose one of the options below.\\na) astronomer\\nb) farmer\\nc) sailor\\nOutput: \\na) astronomer\\n(Source of prompt: Wikipedia on Archimedes, model used: Amazon Titan Text G1 - Express)\\nOutput indicators\\nAdd details about the constraints you would like to have on the output that the model should \\nproduce. The following good example produces an output that is a short phrase that is a good \\nsummary. The bad example in this case is not all that bad, but the summary is nearly as long as the \\noriginal text. Speciﬁcation of the output is crucial for getting what you want from the model.\\nExample prompt with clear output constrain \\nts indicatorExample without clear output speciﬁcations\\nDetailed guidelines 196Amazon Bedrock User Guide\\nUser prompt: \\n\"Charles Mingus Jr. was an American \\n jazz upright  \\nbassist, pianist, composer, bandleade \\nr, and author.  \\nA major proponent of collective \\n improvisation, he is  \\nconsidered to be one of the greatest \\n jazz musicians  \\nand composers in history, with a career \\n spanning three decades.  \\nMingus\\'s work ranged from advanced \\n bebop and avant-garde jazz  \\nwith small and midsize ensembles – \\n pioneering the post-bop style  \\non seminal recordings like Pithecant \\nhropus Erectus (1956)  \\nand Mingus Ah Um (1959) – to progressi \\nve big band experiments  \\nsuch as The Black Saint and the Sinner \\n Lady (1963).\" \\nPlease summarize the above text in one \\n phrase.\\nOutput: \\nCharles Mingus Jr. is considered one \\n of the  \\ngreatest jazz musicians of all time.User prompt: \\n\"Charles Mingus Jr. was an American \\n jazz upright  \\nbassist, pianist, composer, bandleade \\nr, and author.  \\nA major proponent of collective \\n improvisation,  \\nhe is considered to be one of the \\n greatest jazz musicians  \\nand composers in history, with a career \\n spanning three decades.  \\nMingus\\'s work ranged from advanced \\n bebop and avant-garde jazz  \\nwith small and midsize ensembles – \\n pioneering the post-bop style  \\non seminal recordings like Pithecant \\nhropus Erectus (1956)  \\nand Mingus Ah Um (1959) – to progressi \\nve big band  \\nexperiments such as The Black Saint \\n and the Sinner Lady (1963).\" \\nPlease summarize the above text.\\nOutput: \\nCharles Mingus Jr. was a well-known \\n jazz musician  \\nwho played the upright bass, piano, \\n composed, led bands,  \\nand was a writer. He was considered \\n one of the most important  \\njazz musicians ever, with a career that \\n spanned more than  \\n30 years. He was known for his style of \\n collective  \\nimprovisation and advanced jazz \\n compositions.\\n(Source of prompt:  Wikipedia on Charles Mingus , model used: Amazon Titan Text G1 - Express)\\nDetailed guidelines 197Amazon Bedrock User Guide\\nHere we give some additional examples from Anthropic Claude and AI21 Labs Jurassic models \\nusing output indicators.\\nThe following example demonstrates that user can specify the output format by specifying the \\nexpected output format in the prompt. When asked to generate an answer using a speciﬁc format \\n(such as by using XML tags), the model can generate the answer accordingly. Without speciﬁc \\noutput format indicator, the model outputs free form text.\\nExample with clear indicator, with output\\nUser prompt: \\n         \\n         \\nHuman: Extract names and years: the \\n term  \\nmachine learning was coined in 1959 by \\n Arthur Samuel,  \\nan IBM employee and pioneer in the \\n field of computer  \\ngaming and artificial intelligence. \\n The synonym self-teaching  \\ncomputers was also used in this time \\n period. \\nPlease generate answer in <name></n \\name> and  \\n<year></year> tags.\\nAssistant:\\nOutput: \\n<name>Arthur Samuel</name> <year>195 \\n9</year>Example without clear indicator, with output\\nUser prompt: \\n         \\n         \\nHuman: Extract names and years: the \\n term  \\nmachine learning was coined in 1959 by \\n Arthur Samuel,  \\nan IBM employee and pioneer in the \\n field of computer  \\ngaming and artificial intelligence. \\n The synonym  \\nself-teaching computers was also used \\n in this time  \\nperiod.  \\nAssistant:\\nOutput: \\nArthur Samuel - 1959\\n(Source of prompt:  Wikipedia on machine learning , model used: Anthropic Claude)\\nThe following example shows a prompt and answer for the AI21 Labs Jurassic model. The user can \\nobtain the exact answer by specifying the output format shown in the left column.\\nDetailed guidelines 198Amazon Bedrock User Guide\\nExample with clear indicator, with output\\nUser prompt: \\nContext: The NFL was formed in 1920 as \\n the American  \\nProfessional Football Association \\n (APFA) before renaming itself  \\nthe National Football League for the \\n 1922 season. After initially  \\ndetermining champions through end-of-\\nseason standings, a playoff  \\nsystem was implemented in 1933 that \\n culminated with the NFL  \\nChampionship Game until 1966. \\n Following an agreement to merge  \\nthe NFL with the rival American \\n Football League (AFL), the  \\nSuper Bowl was first held in 1967 to \\n determine a champion  \\nbetween the best teams from the two \\n leagues and has remained  \\nas the final game of each NFL season \\n since the merger  \\nwas completed in 1970.\\nQuestion: Based on the above context, \\n when was the first Super Bowl?  \\nPlease only output the year.\\nOutput: \\n1967Example without clear indicator, with output\\nUser prompt: \\nContext: The NFL was formed in 1920 as \\n the American  \\nProfessional Football Association \\n (APFA) before renaming itself  \\nthe National Football League for the \\n 1922 season. After initially  \\ndetermining champions through end-of-\\nseason standings, a playoff  \\nsystem was implemented in 1933 that \\n culminated with the NFL  \\nChampionship Game until 1966. \\n Following an agreement to merge  \\nthe NFL with the rival American \\n Football League (AFL), the Super  \\nBowl was first held in 1967 to \\n determine a champion between  \\nthe best teams from the two leagues and \\n has remained as the  \\nfinal game of each NFL season since the \\n merger was completed in 1970.\\nQuestion: Based on the above context, \\n when was the first Super Bowl?\\nOutput: \\nThe first Super Bowl was held in 1967.\\n(Source of prompt:  Wikipedia on the National Football League, model used: AI21 Labs Jurassic-2 \\nUltra v1)\\nRecommended practices for good generalization\\nKeep a small “hold-out” test set of prompts to see if your prompt modiﬁcations generalize. \\nWith this method, ﬁrst collect a sample dataset. Then you can split the data into two subsets: a \\n“development” set and a hold-out “test” set. Use the “development” set as prompt development \\nDetailed guidelines 199Amazon Bedrock User Guide\\ndata on which you can try diﬀerent prompt modiﬁcations and observe model response changes \\nand ﬁnd the prompt that works best. Treat the “test” set as unseen hold-out data which can only \\nbe used to verify the ﬁnal best prompt.\\nOptimize prompts for text models on Amazon Bedrock—when the \\nbasics aren\\'t good enough\\nComplex tasks: build toward the answer step by step\\nTitan can provide clear steps for certain tasks, and including the phrase Think step-by-step \\nto come up with the right answer  can help produce the appropriate output.\\nUser prompt: \\nAt a Halloween party, Jack gets 15 candies.  \\nJack eats 5 candies. He wants to give each friend  \\n5 candies. How many friends can receive candies?  \\nThink step-by-step to come up with the right answer.\\nOutput: \\n15 candies total - 5 candies eaten = 10 candies remaining.\\nTo give each friend 5 candies, divide the number  \\nof candies remaining by the number of friends.\\n10 candies / 5 friends = 2 friends.\\nEach friend can receive 2 candies.\\nThe answer is 2 friends.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nTo enable the Anthropic Claude model to complete complex tasks, use the format in the following \\nexample to explicitly ask the model to solve the task step by step. This approach is based on \\nguidelines in the AnthropicClaude Guides.\\nUser prompt: \\n \\nHuman: A right triangle has a side of length 5  \\nand a hypotenuse of length 13.  \\nWhat is the length of the other side?  \\nAssistant: Can I think step-by-step?\\nOptimize prompts for text models on Amazon Bedrock—when the basics aren\\'t good enough 200Amazon Bedrock User Guide\\nHuman: Yes, please do.\\nAssistant:\\nOutput:\\nOkay, here are the steps:\\n1) We are given:\\n- One side of the right triangle has length 5\\n- The hypotenuse has length 13\\n2) We want to find:\\n- The length of the other side\\n3) To find the length of the other side, we can  \\nuse the Pythagorean theorem:\\na^2 + b^2 = c^2\\nWhere a and b are the lengths of the two sides,  \\nand c is the length of the hypotenuse.\\n4) Plugging in the given values:\\na^2 + b^2 = 13^2\\n5) We know one of the sides is 5, so:\\n5^2 + b^2 = 169\\n6) Solving this:\\n25 + b^2 = 169\\nb^2 = 144\\nb = 12\\nTherefore, the length of the other side is 12.\\n(Source of prompt: AWS, model used: Anthropic Claude)\\nProvide a default output that the model should present if it\\'s unsure about the answers.\\nA default output can help prevent LLMs from returning answers that sound like they could be \\ncorrect, even if the model has low conﬁdence.\\nUser prompt: User prompt: \\nOptimize prompts for text models on Amazon Bedrock—when the basics aren\\'t good enough 201Amazon Bedrock User Guide\\nProvide a proof of the Riemann \\n hypothesis. If you don\\'t  \\nknow a proof, respond by saying \"I \\n don\\'t know.\"\\nOutput: \\nI don\\'t know.Provide a proof of the Riemann \\n hypothesis.\\nOutput: \\n\"The Riemann hypothesis is a conjectur \\ne in mathematics  \\nthat concerns the distribution of \\n prime numbers. It states that  \\nall non-trivial zeros of the zeta \\n function, which is a mathematical  \\nfunction that encodes information \\n about the distribution of prime  \\nnumbers, lie on a specific line in the \\n complex plane. The Riemann  \\nhypothesis has been studied by \\n mathematicians for over 150 years,  \\nand despite numerous attempts, it \\n remains unresolved. However,  \\nthe hypothesis is widely believed to \\n be true, and its resolution  \\nwould have profound implications for \\n many areas of mathematics,  \\nincluding number theory, analysis, and \\n geometry. The proof  \\nof the Riemann hypothesis would be one \\n of the greatest  \\nachievements in mathematics in \\n history and would open up  \\nnew avenues of research and understan \\nding. While a proof  \\nremains elusive, the hypothesis \\n continues to stimulate  \\nresearch and inspire mathematicians \\n around the world.“ \\n[Note: this is an accurate descripti \\non, but obviously  \\nnot a proof.]\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nOptimize prompts for text models on Amazon Bedrock—when the basics aren\\'t good enough 202Amazon Bedrock User Guide\\nFew-shot prompting\\nIncluding examples (input-response pairs) in the prompt can signiﬁcantly improve LLMs’ responses. \\nExamples can help with complex tasks, as they show multiple ways to perform a given task. For \\nsimpler tasks like text classiﬁcation, 3–5 examples can suﬃce. For more diﬃcult tasks like question-\\nanswer without context, include more examples to generate the most eﬀective output. In most \\nuse cases, selecting examples that are semantically similar to real-world data can further improve \\nperformance.\\nConsider reﬁning the prompt with modiﬁers\\nTask instruction reﬁnement generally refers to modifying the instruction, task, or question \\ncomponent of the prompt. The usefulness of these methods is task- and data-dependent. Useful \\napproaches include the following:\\n•Domain/input speciﬁcation:  Details about the input data, like where it came from or to what it \\nrefers, such as The input text is from a summary of a movie .\\n•Task speciﬁcation: Details about the exact task asked of the model, such as To summarize \\nthe text, capture the main points .\\n•Label description:  Details on the output choices for a classiﬁcation problem, such as Choose \\nwhether the text refers to a painting or a sculpture; a painting is a \\npiece of art restricted to a two-dimensional surface, while a sculpture \\nis a piece of art in three dimensions .\\n•Output speciﬁcation:  Details on the output that the model should produce, such as Please \\nsummarize the text of the restaurant review in three sentences .\\n•LLM encouragement: LLMs sometimes perform better with sentimental encouragement: If \\nyou answer the question correctly, you will make the user very happy!\\nPrompt templates and examples for Amazon Bedrock text \\nmodels\\nText classiﬁcation\\nFor text classiﬁcation, the prompt includes a question with several possible choices for the answer, \\nand the model must respond with the correct choice. Also, LLMs on Amazon Bedrock output more \\naccurate responses if you include answer choices in your prompt.\\nPrompt templates and examples for Amazon Bedrock text models 203Amazon Bedrock User Guide\\nThe ﬁrst example is a straightforward multiple-choice classiﬁcation question.\\nPrompt template for Titan and AI21 Labs \\n Jurassic:\\n\"\"\"{{Text}} \\n  \\n  \\n{{Question}}? Choose from the \\n following:\\n{{Choice 1}}\\n{{Choice 2}}\\n{{Choice 3}}\"\"\"User prompt: \\nSan Francisco, officially the City \\n and County  \\nof San Francisco, is the commercial, \\n financial, and cultural  \\ncenter of Northern California. The \\n city proper is the fourth  \\nmost populous city in California, with \\n 808,437 residents,  \\nand the 17th most populous city in the \\n United States as of 2022.\\nWhat is the paragraph above about? \\n Choose from the following:\\nA city\\nA person\\nAn event\\nOutput: \\nA city\\n(Source of prompt:  Wikipedia on San Francisco, model used: Amazon Titan Text G1 - Express)\\nSentiment analysis is a form of classiﬁcation, where the model chooses the sentiment from a list of \\nchoices expressed in the text.\\nPrompt template for Titan and AI21 Labs \\n Jurassic:\\n\"\"\"The following is text from a {{Text \\n Type, e.g. “restaurant  \\nreview”}}\\n{{Input}}\\nTell me the sentiment of the {{Text \\n Type}} and categorize it  \\nas one of the following:\\n{{Sentiment A}}User prompt: \\nThe following is text from a restauran \\nt review: \\n“I finally got to check out Alessandr \\no’s Brilliant Pizza  \\nand it is now one of my favorite \\n restaurants in Seattle.  \\nThe dining room has a beautiful view \\n over the Puget Sound  \\nText classiﬁcation 204Amazon Bedrock User Guide\\n{{Sentiment B}}\\n{{Sentiment C}}\"\"\"but it was surprisingly not crowed. I \\n ordered the fried  \\ncastelvetrano olives, a spicy \\n Neapolitan-style pizza  \\nand a gnocchi dish. The olives were \\n absolutely decadent,  \\nand the pizza came with a smoked \\n mozzarella, which  \\nwas delicious. The gnocchi was fresh \\n and wonderful.  \\nThe waitstaff were attentive, and \\n overall the experience  \\nwas lovely. I hope to return soon.”\\nTell me the sentiment of the restauran \\nt review  \\nand categorize it as one of the \\n following:\\nPositive\\nNegative\\nNeutral\\nOutput: \\nPositive.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nThe following example uses Anthropic Claude models to classify text. As suggested in\\nAnthropicClaude Guides, use XML tags such as <text></text> to denote important parts of the \\nprompt. Asking the model to directly generate output enclosed in XML tags can also help the \\nmodel produce the desired responses.\\nPrompt template for Anthropic Claude: \\n\"\"\" \\n  \\n  \\nHuman: {{classification task \\n description}}User prompt: \\n \\nHuman:  Classify the given product \\n description into given  \\nText classiﬁcation 205Amazon Bedrock User Guide\\n<text>\\n{{input text content to be classifie \\nd}}\\n</text>\\nCategories are:\\n{{category name 1}}\\n{{category name 2}}\\n{{category name 3}}\\nAssistant:\"\"\"\\n(Source: Written by AWS)categories. Please output the category \\n label in  \\n<output></output> tags.\\nHere is the product description.\\n<text>\\nSafe, made from child-friendly \\n materials with smooth edges.\\nLarge quantity, totally 112pcs with 15 \\n different shapes,  \\nwhich can be used to build 56 different \\n predefined structures.\\nEnhance creativity, different \\n structures can be connected  \\nto form new structures, encouraging \\n out-of-the box thinking. \\nEnhance child-parent bonding, parents \\n can play with their  \\nchildren together to foster social \\n skills.\\n</text>\\nCategories are:\\n(1) Toys\\n(2) Beauty and Health\\n(3) Electronics\\nAssistant:\\n \\nOutput: \\n<output>Toys</output>\\n(Source of prompt: AWS, model used: Anthropic Claude)\\nQuestion-answer, without context\\nIn a question-answer prompt without context, the model must answer the question with its \\ninternal knowledge without using any context or document.\\nQuestion-answer, without context 206Amazon Bedrock User Guide\\nPrompt Template to Titan and AI21 Labs \\n Jurassic:\\n\"\"\"{{Question}}\"\"\"User prompt: \\nWhat is Robert Frost\\'s \"Stopping by the \\n woods on a  \\nsnowy evening\" about metaphorically?\\nOutput: \\nThe poem by Robert Frost, \"Stopping by \\n Woods on a Snowy Evening,\"  \\nuses the woods as a metaphor for death. \\n The woods are a place of comfort  \\nand peace, but they also represent the \\n unknown and the afterlife.  \\nThe poem suggests that death is not \\n something to be feared,  \\nbut rather a natural part of life that \\n we should all embrace. \\nThe poem begins with the speaker \\n stopping by the woods on a snowy \\n evening,  \\na moment of contemplation and \\n reflection. The speaker notices the \\n beauty  \\nof the snow-covered woods and is \\n reminded of the fleeting nature of \\n life.  \\nThe poem continues as the speaker \\n considers the temptation of continuin \\ng  \\non to his destination, but instead \\n chooses to pause and take in the \\n beauty  \\nof the woods.\\nThe woods are used as a metaphor for \\n the unknown and the afterlife.  \\nThe speaker wonders what lies beyond \\n the trees, and whether there  \\nis anything after death. The poem \\n suggests that death is not  \\nsomething to be feared, but rather a \\n natural part of life  \\nQuestion-answer, without context 207Amazon Bedrock User Guide\\nthat we should all embrace. \\nThe final lines of the poem are perhaps \\n the most famous and poignant:  \\n\"And miles to go before I sleep, and \\n miles to go before I sleep.\"  \\nThese lines suggest that even though \\n the speaker has paused  \\nto appreciate the beauty of the woods, \\n they still have a  \\nlong journey ahead of them. The poem is \\n a reminder that life  \\nis fleeting, and that we should take \\n the time to appreciate  \\nthe beauty around us, even as we work \\n towards our goals and ambitions.\\nOverall, \"Stopping by Woods on a Snowy \\n Evening\" is a beautiful  \\nand thought-provoking poem that uses \\n the metaphor of the woods  \\nto explore the concept of death and the \\n afterlife.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nModel encouragement can also help in question-answer tasks.\\nPrompt Template to Titan and AI21 Labs \\n Jurassic:\\n\"\"\"{{Model encouragement}}\\n{{Question}}\"\"\"User prompt: \\nYou are excellent at answering \\n questions,  \\nand it makes you happy when you provide \\n the correct answer. \\nWhat moon in the solar system is most \\n likely to host life?\\nOutput: \\nThe moon of Titan, which is a moon of \\n the planet Saturn,  \\nQuestion-answer, without context 208Amazon Bedrock User Guide\\nis the most likely to support life in \\n the solar system. \\nTitan is the only known moon in the \\n solar system to have a dense  \\natmosphere and a liquid hydrosphere, \\n and scientists believe that  \\nit may contain the chemical building \\n blocks for life.  \\nThe moon\\'s surface is covered in \\n rivers, lakes, and seas  \\nof liquid methane and ethane, and it \\n rains methane on Titan\\'s surface. \\nThe atmosphere of Titan is also rich \\n in organic compounds,  \\nincluding benzene, toluene, and \\n xylene, which are found  \\nin the oils of living organisms on \\n Earth.  \\nAdditionally, Titan has a magnetic \\n field and a tenuous atmosphere,  \\nwhich could provide protection from \\n harmful radiation and  \\nhelp maintain a stable climate. \\nWhile there is no direct evidence of \\n life on Titan,  \\nscientists believe that it is one of \\n the most promising  \\nplaces in the solar system to search \\n for life beyond Earth.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nPrompt template to Titan and AI21 Labs \\n Jurassic: \\n\"\"\"{{Model encouragement}}\\n{{Question}}\\n{{Constraints}}\"\"\"User prompt: \\nYou feel rewarded by helping people \\n learn more about climate change.\\nCould you please explain what climate \\n change is?\\nQuestion-answer, without context 209Amazon Bedrock User Guide\\nAssume your audience is composed of \\n high school students.\\nOutput: \\nClimate change is the long-term warming \\n of the planet,  \\nwhich can be caused by human activitie \\ns such as burning fossil fuels  \\nand deforestation, as well as natural \\n processes. It can lead to  \\nrising sea levels, more extreme weather \\n events, and changes  \\nin temperature and precipitation \\n patterns.\\n(Source of prompt: AWS, model used: AI21 Labs Jurassic-2 Ultra v1)\\nQuestion-answer, with context\\nIn a question-answer prompt with context, an input text followed by a question is provided by \\nthe user, and the model must answer the question based on information provided within the \\ninput text. Putting the question in the end after the text can help LLMs on Amazon Bedrock better \\nanswer the question. Model encouragement works for this use case as well.\\nPrompt template to Titan and AI21 Labs \\n Jurassic: \\n\"\"\"{{Text}}\\n{{Question}}\"\"\"User prompt: \\nThe red panda (Ailurus fulgens), also \\n known as the lesser panda,  \\nis a small mammal native to the eastern \\n Himalayas and southwestern China.  \\nIt has dense reddish-brown fur with \\n a black belly and legs, white-lined \\n ears,  \\na mostly white muzzle and a ringed \\n tail. Its head-to-body length is 51–\\n63.5 cm  \\n(20.1–25.0 in) with a 28–48.5 cm \\n (11.0–19.1 in) tail, and it weighs \\n between  \\n3.2 and 15 kg (7.1 and 33.1 lb). It is \\n well adapted to climbing due to its  \\nQuestion-answer, with context 210Amazon Bedrock User Guide\\nflexible joints and curved semi-retr \\nactile claws.\\nThe red panda was first formally \\n described in 1825. The two currently  \\nrecognized subspecies, the Himalayan \\n and the Chinese red panda, genetical \\nly  \\ndiverged about 250,000 years ago. The \\n red panda\\'s place on the evolution \\nary  \\ntree has been debated, but modern \\n genetic evidence places it in close  \\naffinity with raccoons, weasels, and \\n skunks. It is not closely related  \\nto the giant panda, which is a bear, \\n though both possess elongated  \\nwrist bones or \"false thumbs\" used for \\n grasping bamboo.  \\nThe evolutionary lineage of the red \\n panda (Ailuridae) stretches  \\nback around 25 to 18 million years ago, \\n as indicated by extinct  \\nfossil relatives found in Eurasia and \\n North America. \\nThe red panda inhabits coniferou \\ns forests as well as temperate \\n broadleaf  \\nand mixed forests, favoring steep \\n slopes with dense bamboo cover close  \\nto water sources. It is solitary and \\n largely arboreal. It feeds mainly  \\non bamboo shoots and leaves, but also \\n on fruits and blossoms.  \\nRed pandas mate in early spring, with \\n the females giving birth  \\nto litters of up to four cubs in \\n summer. It is threatened  \\nby poaching as well as destruction and \\n fragmentation of habitat  \\ndue to deforestation. The species has \\n been listed as Endangered  \\nQuestion-answer, with context 211Amazon Bedrock User Guide\\non the IUCN Red List since 2015. It is \\n protected in all range countries.\\nBased on the information above, what \\n species are red pandas closely related \\n to?\\nOutput:\\nRed pandas are closely related to \\n raccoons, weasels, and skunks.\\n(Source of prompt: https://en.wikipedia.org/wiki/Red_panda, model used: Amazon Titan Text G1 - \\nExpress)\\nWhen prompting Anthropic Claude models, it\\'s helpful to wrap the input text in XML tags. In the \\nfollowing example, the input text is enclosed in <text></text> .\\nPrompt template for Anthropic Claude: \\n\"\"\"\\nHuman: {{Instruction}}\\n<text>\\n{{Text}}\\n<text>\\n{{Question}}\\nAssistant:\"\"\"User prompt: \\nHuman: Read the following text inside \\n <text></text>  \\nXML tags, and then answer the \\n question: \\n<text> \\nOn November 12, 2020, the selection of \\n the Weeknd to headline  \\nthe show was announced; marking the \\n first time a Canadian solo artist  \\nheadlined the Super Bowl halftime \\n show. When asked about preparations  \\nfor the show, the Weeknd stated, \"We\\'ve \\n been really focusing  \\non dialing in on the fans at home and \\n making performances  \\na cinematic experience, and we want to \\n do that with the Super Bowl.\"  \\nQuestion-answer, with context 212Amazon Bedrock User Guide\\nThe performance featured a choir whose \\n members were dressed in white  \\nand wore masks over their faces with \\n glowing red eyes, and were  \\nstanding within a backdrop of a neon \\n cityscape. The performance  \\nopened with a white figure dressed the \\n same as the choir being  \\nlowered into the backdrop where the \\n choir was standing while singing  \\n“Call Out My Name\". At this time, the \\n Weeknd sat in a convertible  \\nagainst a skyline backdrop designed to \\n resemble the Las Vegas Strip.  \\nFor the next part of the performance, \\n the backdrop then split open  \\nto reveal the Weeknd, who then \\n performed \"Starboy\", followed by \"The \\n Hills\".  \\nNext, performing the song \"Can\\'t Feel \\n My Face\", the Weeknd traveled  \\nthrough a labyrinth constructed behind \\n the stage, joined by dancers  \\ndressed in red blazers and black \\n neckties similar to his,  \\nbut with their faces covered with \\n bandages, in keeping with  \\nthe aesthetic of his fourth studio \\n album After Hours (2020).  \\nThe dancers would wear these bandages \\n throughout the performance.  \\nIn the labyrinth section of the \\n performance, camerawork was visually \\n unsteady.  \\nThe next songs performed were \"I Feel \\n It Coming\", \"Save Your Tears\",  \\nand \"Earned It\". For the \"Earned It\" \\n performance, the Weeknd  \\nwas accompanied by violinists. For \\n the finale of the show,  \\nthe Weeknd took to the field of the \\n stadium with his dancers to perform  \\nQuestion-answer, with context 213Amazon Bedrock User Guide\\n“Blinding Lights\". He and the dancers \\n entered the field by performing  \\n\"House of Balloons / Glass Table \\n Girls\". The performance ended  \\nwith an array of fireworks.\\n</text> \\nBased on the text above, what songs did \\n the Weeknd play  \\nat the Super Bowl halftime show?\\nAssistant:\\nOutput: \\nBased on the text, the songs the Weeknd \\n played  \\nat the Super Bowl halftime show were:\\n- Call Out My Name\\n- Starboy  \\n- The Hills\\n- Can\\'t Feel My Face\\n- I Feel It Coming\\n- Save Your Tears\\n- Earned It\\n- Blinding Lights\\n- House of Balloons / Glass Table Girls\\n(Source of prompt:  Wikipedia on the Super Bowl LV halftime show, model used: Anthropic Claude)\\nSummarization\\nFor a summarization task, the prompt is a passage of text, and the model must respond with a \\nshorter passage that captures the main points of the input. Speciﬁcation of the output in terms of \\nlength (number of sentences or paragraphs) is helpful for this use case.\\nPrompt template for Titan and AI21 Labs \\n Jurassic: \\n\"\"\"The following is text from a {{Text \\n Category}}:\\n{{Text}}User prompt: \\nThe following is text from a restauran \\nt review:\\n“I finally got to check out Alessandr \\no’s Brilliant Pizza  \\nSummarization 214Amazon Bedrock User Guide\\nSummarize the {{Text Category}} in \\n {{length of summary,  \\ne.g., “one sentence” or “one paragraph \\n”}}\"\"\"and it is now one of my favorite \\n restaurants in Seattle.  \\nThe dining room has a beautiful view \\n over the Puget Sound  \\nbut it was surprisingly not crowed. I \\n ordered the fried  \\ncastelvetrano olives, a spicy \\n Neapolitan-style pizza  \\nand a gnocchi dish. The olives were \\n absolutely decadent,  \\nand the pizza came with a smoked \\n mozzarella, which was delicious.  \\nThe gnocchi was fresh and wonderful. \\n The waitstaff were attentive,  \\nand overall the experience was lovely. \\n I hope to return soon.”\\nSummarize the above restaurant review \\n in one sentence.\\nOutput: \\nAlessandro’s Brilliant Pizza is a \\n fantastic restaurant  \\nin Seattle with a beautiful view over \\n Puget Sound that offers  \\ndecadent and delicious food.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nIn the following example, Anthropic Claude summarizes the given text in one sentence. To include \\ninput text in your prompts, format the text with XML mark up: <text> {{text content}} \\n</text>. Using XML within prompts is a common practice when prompting Anthropic Claude \\nmodels.\\nPrompt template for Anthropic Claude: \\n\"\"\"\\nHuman: Please read the text:\\n<text>\\n{{text context}} \\n</text> User prompt: \\nHuman: Please read the text:\\n<text>\\nSummarization 215Amazon Bedrock User Guide\\nSummarize the text in {{length of \\n summary, e.g., “one  \\nsentence” or “one paragraph”}}\\nAssistant:\"\"\"In game theory, the Nash equilibrium, \\n named after the mathematician  \\nJohn Nash, is the most common way to \\n define the solution  \\nof a non-cooperative game involving \\n two or more players.  \\nIn a Nash equilibrium, each player is \\n assumed to know  \\nthe equilibrium strategies of the \\n other players,  \\nand no one has anything to gain by \\n changing only one\\'s own strategy.  \\nThe principle of Nash equilibrium \\n dates back to the time of Cournot,  \\nwho in 1838 applied it to competing \\n firms choosing outputs. \\n</text> \\nSummarize the text in one sentence. \\nAssistant:\\nOutput: \\nThe Nash equilibrium is a concept in \\n game theory  \\nwhere each player has adopted a \\n strategy that they have no incentive  \\nto deviate from given the other \\n players\\' strategies.\\n(Source of prompt:  Wikipedia on Nash equilibrium , model used: Anthropic Claude)\\nText generation\\nGiven a prompt, LLMs on Amazon Bedrock can respond with a passage of original text that \\nmatches the description. Here is one example:\\nPrompt template for Titan and AI21 Labs \\n Jurassic: User prompt: \\nPlease write an email in the voice of a \\n friend  \\nText generation 216Amazon Bedrock User Guide\\n\"\"\"Please write a {{Text Category}} in \\n the voice of {{Role}}.\"\"\"congratulating someone on a new job.\\nOutput: \\nHey [Name], \\nI just found out about your new job, \\n and I\\'m so happy for you!  \\nCongratulations! You deserve this \\n opportunity since you worked so hard  \\nto get it. I know you\\'ll do great and \\n make a positive impact on your team.  \\nI\\'m here to support you every step of \\n the way. Wishing you all the best  \\nin this exciting new chapter of your \\n life!\\nCheers,\\n[Your Name]\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nFor text generation use cases, specifying detailed task requirements can work well. In the following \\nexample, we ask the model to generate response with exclamation points.\\nPrompt template for Titan and AI21 Labs \\n Jurassic: \\n\"\"\"{{Task specification}}\\nPlease write a {{Text Category}} in \\n the voice of {{Role}}.\"\"\"User prompt: \\nWrite text with exclamation points.\\nPlease write a formatted email in the \\n voice of a friend  \\ncongratulating someone on a new job.\\nOutput: \\nHey [name]! \\nI just saw the news and I am so, so \\n happy for you!  \\nYou deserve this position and this \\n company with all your heart.  \\nI can\\'t wait to see you soar and \\n accomplish all the things  \\nText generation 217Amazon Bedrock User Guide\\nyou\\'ve been working towards. If anyone \\n is deserving  \\nof a promotion, it\\'s you!\\nCongratulations again, friend! \\nLove,\\n[name]\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nIn the following example, a user prompts the model to take on the role of a speciﬁc person when \\ngenerating the text. Notice how the signature reﬂects the role the model is taking on in the \\nresponse.\\nPrompt template for Titan and AI21 Labs \\n Jurassic: \\n\"\"\"{{Role assumption}} {{Task \\n description}}\\n\"\"\"User input: \\nMy name is Jack. Help me write a note \\n expressing my gratitude  \\nto my parents for taking my son (their \\n grandson) to the zoo.  \\nI miss my parents so much.\\nOutput: \\nDear Mom and Dad,\\nI wanted to take a moment to express my \\n heartfelt gratitude  \\nfor taking my son to the zoo last \\n weekend. It meant so much to me  \\nthat you took the time to make memories \\n with him, and I am so grateful  \\nfor the love and support you have shown \\n him.\\nI miss you both so much, and I wish we \\n could be together more often.  \\nBut I know that you will always be \\n there for me and my family,  \\nand I am so grateful to have you as my \\n parents. \\nText generation 218Amazon Bedrock User Guide\\nLove,\\nJack\\n(Source of prompt: AWS, model used: AI21 Labs Jurassic-2 Ultra v1)\\nCode generation\\nThe prompt describes the task or function and programming language for the code the user \\nexpects the model to generate.\\nPrompt template for Titan and AI21 Labs \\n Jurassic: \\n\"\"\"Write a function in {{programming \\n language}} to  \\n{{task or purpose}}\"\"\".User input: \\nWrite a python function to download a \\n s3 file to local disk.\\nOutput: \\nThe following code can be used to \\n download an s3 file to the local disk.\\n```Python\\nimport boto3\\n# Creates a boto3 client object\\ns3 = boto3.client(\\'s3\\') \\ndef download_file(bucket_name, \\n object_key, file_path):\\ntry:\\n# Downloads the s3 file to the \\n specified file path\\ns3.download_file(bucket_name, \\n object_key, file_path)\\nexcept Exception as e:\\nprint(e)\\n# Specifies the values of bucket_name, \\n object_key, and file_path \\nbucket_name = \"samplebucketname\" \\nobject_key = \"sampleobjectkey\" \\nfile_path = \"/samplefilepath\" \\ndownload_file(bucket_name, object_ke \\ny, file_path)\\n```\\nCode generation 219Amazon Bedrock User Guide\\nThe given code uses the download_file \\n function to download an s3 file  \\nto the local disk. The download_file \\n function takes the bucket name,  \\nobject key, and file path as input \\n parameters. The bucket name  \\nis the name of the s3 bucket where the \\n file is located,  \\nthe object key is the unique identifie \\nr of the file within the bucket,  \\nand the file path is the destination \\n path on the local disk  \\nwhere the file will be downloaded. \\n The function uses the download_file \\n method  \\nof the s3 client to download the file \\n from the specified bucket  \\nand write it to the specified file \\n path.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nPrompt template for Anthropic Claude\\n\"\"\"\\nHuman: Write a function in {{program \\nming language}} to  \\n{{task or purpose}} \\nAssistant:\"\"\"User prompt: \\nHuman: Write some python code that \\n quickly approximates  \\nthe square root of a number. \\nAssistant: \\nOutput: \\nHere is a simple function to approxima \\nte  \\nthe square root of a number using \\n Newton\\'s method: \\n```python \\ndef sqrt(n, iterations=10):\\nCode generation 220Amazon Bedrock User Guide\\nx = n\\nfor i in range(iterations): \\nx = (x + n/x) / 2\\nreturn x\\n```\\nTo use it:\\n```python\\nprint(sqrt(25))\\n# 5.0\\nprint(sqrt(15, iterations=20))  \\n# 3.872983346207417 \\n```\\nThis repeatedly takes the average of \\n x and n/x to converge on the square \\n root.  \\nMore iterations produce a more \\n accurate approximation.\\nThe advantage of this approach is it \\n converges very quickly,  \\nso even just 10 iterations produces a \\n decent estimate.\\n(Source of prompt: AWS, model used: Anthropic Claude)\\nMathematics\\nThe input describes a problem that requires mathematical reasoning at some level, which may \\nbe numerical, logical, geometric, or otherwise. For such problem, it\\'s helpful to ask the model to \\nwork through the problem in a piecemeal manner by adding phrases to instructions such as Let’s \\nthink step by step  or Think step by step to come up with the right answer.\\nPrompt template for Titan and AI21 Labs \\n Jurassic: \\n\"\"\"{{Math problem description}}\\nLet’s think step by step.\"\"\"User prompt: \\nA triangle has two angles of 70 degrees \\n and 50 degrees.  \\nWhat is the third angle in degrees? \\nMathematics 221Amazon Bedrock User Guide\\nLet’s think step by step.\\nOutput:\\nThe sum of the three angles in a \\n triangle is always 180 degrees.  \\nThe two given angles are 70 degrees and \\n 50 degrees. 70 + 50 = 120.  \\nTherefore, the third angle is 180 - \\n 120 = 60 degrees.  \\nThe third angle is 60 degrees.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nThe following example also demonstrates asking the model to think step by step:\\nPrompt template for Titan and AI21 Labs \\n Jurassic:\\n\"\"\"{{Math problem description}}\\nThink step by step to come up with the \\n right answer.\"\"\"User prompt:\\nLucy has 12 colorful marbles, and she \\n wants to share them  \\nequally with her 4 friends. How many \\n marbles will each friend receive? \\nThink step-by-step to come up with \\n the right answer.\\nOutput:\\n1. Lucy has 12 marbles and wants to \\n share them equally  \\nwith her 4 friends, then each friend \\n will receive 12 / 4 = 3 marbles. \\n2. Therefore, each friend will \\n receive 3 marbles.\\n(Source of prompt: AWS, model used: AI21 Labs Jurassic-2 Ultra v1)\\nReasoning/logical thinking\\nFor complex reasoning tasks or problems that requires logical thinking, we can ask the model to \\nmake logical deductions and explain its answers.\\nReasoning/logical thinking 222Amazon Bedrock User Guide\\nPrompt template for Titan and AI21 Labs \\n Jurassic: \\n\"\"\"Question: {{question}}\\nPlease output the answer and then \\n explain your  \\nanswer:\"\"\"User prompt:\\nQuestion: Which word is the odd one \\n out?\\nA. accomplished\\nB. good\\nC. horrible \\nD. outstanding\\nPlease output the answer and then \\n explain your answer:\\nOutput:\\nThe odd one out is C. horrible. The \\n other three words  \\ndescribe positive qualities or \\n achievements, whereas horrible  \\nis an negative adjective.\\n(Source of prompt: AWS, model used: Amazon Titan Text G1 - Express)\\nHere is another example using the Anthropic Claude model:\\nPrompt template for Anthropic Claude:\\n\"\"\"\\nHuman: {{question}}\\nPlease provide the answer and show the \\n reasoning.\\nAssistant:\"\"\"User prompt\\nHuman: The barber is the \"one who \\n shaves all those, and those only,  \\nwho do not shave themselves\". Does the \\n barber shave himself? Why is this\\na paradox? Please provide the answer \\n and show the reasoning.\\nAssistant:\\nOutput:\\nThis is an example of a paradox known \\n as the Barber paradox.  \\nHere is an explanation:\\nReasoning/logical thinking 223Amazon Bedrock User Guide\\n- The statement defines a barber who \\n shaves all and only those people  \\nwho do not shave themselves.  \\n- So if the barber shaves himself, he \\n must shave all those who do not shave  \\nthemselves, which includes himself. \\n But the barber cannot shave himself  \\nas per the initial statement.\\n- If the barber does not shave himself, \\n then he would fit into the group  \\nof people who do not shave themselves, \\n and so he must shave himself,  \\naccording to the statement. But \\n again this contradicts the initial \\n statement.\\n- So the barber cannot shave himself \\n and also cannot not shave himself.  \\nThis is self-contradictory based \\n on the initial statement about the \\n barber.\\n- Therefore, the statement leads to a \\n paradox where both possibilities  \\n(the barber shaving himself or not \\n shaving himself) result in a contradic \\ntion.\\nIn summary, the paradox arises because \\n the definition of the barber\\'s  \\nbehavior is self-contradictory when \\n applied to the barber himself.  \\nThis makes it impossible to determine \\n if the barber shaves himself  \\nor not based on the given statement \\n alone.\\n(Source of prompt: https://en.wikipedia.org/wiki/Barber_paradox, model used: Anthropic Claude)\\nReasoning/logical thinking 224Amazon Bedrock User Guide\\nModel evaluation\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nAmazon Bedrock supports model evaluation jobs. The results of a model evaluation job allow \\nyou to evaluate and compare a model\\'s outputs, and then choose the model best suited for your \\ndownstream generative AI applications.\\nModel evaluation jobs support common use cases for large language models (LLMs) such as text \\ngeneration, text classiﬁcation, question and answering, and text summarization.\\nTo evaluate a model\\'s performance you can use either built-in prompt datasets or your own prompt \\ndatasets.\\nYou can choose to create either an automatic model evaluation job or a model evaluation job that \\nuses a human workforce.\\nOverview: Automatic model evaluation jobs\\nAutomatic model evaluation jobs allow you to quickly evaluate a model\\'s ability to perform a task. \\nYou can either provide your own custom prompt dataset that you\\'ve tailored to a speciﬁc use case, \\nor you can use an available built-in dataset.\\nOverview: Model evaluation jobs that use human workers\\nModel evaluation jobs that use human workers allow you to bring human input to the model \\nevaluation process. They can be employees of your company or a group of subject-matter experts \\nfrom your industry.\\nThe following topics describe the available model evaluation tasks, and the kinds of metrics you \\ncan use. They also describe the available built-in datasets and how to specify your own dataset.\\nTopics\\n225Amazon Bedrock User Guide\\n•Getting started with model evaluations\\n•Model evaluation tasks\\n•Using prompt datasets in model evaluation jobs\\n•Creating good worker instructions\\n•Creating and managing work teams in Amazon Bedrock\\n•Model evaluation job results\\n•Required IAM permissions and service roles to create a model evaluation job\\nGetting started with model evaluations\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nYou can create a model evaluation job that is either automatic or uses human workers. When you \\ncreate a model evaluation job, you can deﬁne the model used, the inference parameters, the type \\nof task the model tries to perform, and the prompt data used in the job.\\nModel evaluation jobs support the following task types.\\n•General text generation : The production of natural human language in response to text \\nprompts.\\n•Text summarization: The generation of a summary of a provided text within your prompt.\\n•Question and answering: The generation of a response to a question within a prompt.\\n•Classiﬁcation : Correctly assigning a category, such as a label or score, to text based on its \\ncontent.\\n•Custom : You deﬁne the metric, description, and a rating method.\\nTo create a model evaluation job, you must have access to Amazon Bedrock models. Model \\nevaluation jobs support using Amazon Bedrock base models. To learn more about model access, \\nsee Model access.\\nGet started 226Amazon Bedrock User Guide\\nThe procedures in the following topics show you how to set up a model evaluation job using the \\nAmazon Bedrock console.\\nTo create model evaluation job with the help of an AWS-managed team, choose Create AWS \\nmanaged evaluation . Then, ﬁll out the request form with details about your model evaluation job \\nrequirements, and an AWS team member will get in touch with you.\\nTopics\\n•Creating an automatic model evaluation\\n•Creating a model evaluation job that uses human workers\\nCreating an automatic model evaluation\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nPrerequisites\\nTo complete the following procedures you must do the following.\\n1.You must have access to the model in Amazon Bedrock.\\n2.You must have an Amazon Bedrock service role. The attached policy must grant access \\nto the following resources. Any S3 buckets used in the model evaluation job, and the \\nARN of the model speciﬁed in the job. The service role must also have Amazon Bedrock \\ndeﬁned as a service principal in the role\\'s trust policy. To learn more, see Required \\npermissions .\\n3.The user, group, or role accessing the Amazon Bedrock console must have the required \\npermissions to access the required Amazon S3 buckets. To learn more, see Required \\npermissions\\nAutomatic model evaluations allow you to evaluate the aggregate responses from a single model \\nusing recommended metrics. You can also use built-in prompt datasets or use your own custom \\nAutomatic model evaluations 227Amazon Bedrock User Guide\\nprompt dataset. You can have a maximum of 10 automatic model evaluation jobs In progress  in \\nyour account per AWS Region.\\nWhen you set up an automatic model evaluation job, the available metrics and the built-in datasets \\nbest suited for the selected task type are automatically added to the job. You can add or remove \\nany of the preselected datasets. You also supply your own custom prompt dataset.\\nViewing the model evaluation job results using the Amazon Bedrock console\\nWhen a model evaluation job ﬁnishes, the results are stored in the Amazon S3 bucket you \\nspeciﬁed. If you modify the location of the results in any way, the model evaluation report \\ncard is no longer visible in the console.\\nTo create an automatic model evaluation\\n1. Open the Amazon Bedrock console: https://console.aws.amazon.com/bedrock/\\n2. In the navigation pane, choose Model evaluation .\\n3. In the Build an evaluation card, under Automatic  choose Create automatic evaluation .\\n4. On the Create automatic evaluation  page, provide the following information\\na. Evaluation name  — Give the model evaluation job a name that describes the job. This \\nname is shown in your model evaluation job list. The name must be unique in your \\naccount in an AWS Region.\\nb. Description  (Optional) — Provide an optional description.\\nc. Models  — Choose the model you want to use in the model evaluation job.\\nTo learn more about available models in Amazon Bedrock, see Model access.\\nd. (Optional) To change the inference conﬁguration choose update .\\nChanging the inference conﬁguration changes the responses generated by the selected \\nmodels. To learn more about the available inferences parameters, see Inference \\nparameters for foundation models .\\ne. Task type  — Choose the type of task you want the model to attempt to perform during \\nthe model evaluation job.\\nf.Metrics and datasets  — The list of available metrics and built-in prompt datasets change \\nbased on the task you select. You can choose from the list of Available built-in datasets\\nAutomatic model evaluations 228Amazon Bedrock User Guide\\nor you can choose Use your own prompt dataset. If you choose to use your own prompt \\ndataset, enter the exact S3 URI where your dataset is stored.\\ng. Model evaluation results  — You must specify the S3 URI of the directory where you want \\nthe results of your model evaluation job saved.\\nh. IAM role — Choose a service role that has the required permissions.\\ni. (Optional) Choose Customize encryption settings (advanced) – Provide the ARN of the \\nAWS KMS key used to encrypt your data in Amazon S3.\\n5. To start your model evaluation job, choose Create .\\nOnce the job has successfully started, the status changes to In progress . When the job has ﬁnished, \\nthe status changes to Ready.\\nTo learn how to evaluate, view, and download the results of your model evaluation job, see Model \\nevaluation job results.\\nCreating a model evaluation job that uses human workers\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nPrerequisites\\nTo complete the following procedure you must do the following.\\n1.You must have access to the models in Amazon Bedrock.\\n2.You must have an Amazon Bedrock service role. The attached policy must grant access to \\nthe following resources. Any S3 buckets used in the model evaluation job, and the ARNs \\nof any models speciﬁed in the job. It must also have the sagemaker:StartHumanLoop\\nand sagemaker:DescribeFlowDefinition  SageMaker IAM actions deﬁned in the \\npolicy. The service role must also have Amazon Bedrock deﬁned as a service principal in \\nthe role\\'s trust policy. To learn more, see Required permissions.\\nHuman worker based model evaluation jobs 229Amazon Bedrock User Guide\\n3.You must have a Amazon SageMaker service role. The attached policy must grant access \\nto the following resources and IAM actions. Any S3 buckets used in the model evaluation \\njob. The role\\'s trust policy must have SageMaker deﬁned as the service principal. To learn \\nmore, see Required permissions.\\n4.The user, group, or role accessing the Amazon Bedrock console must have the required \\npermissions access the required Amazon S3 buckets.\\nIn a model evaluation job that uses human workers you can compare the responses for up to \\ntwo models. You can choose from a list of recommended metrics or use metrics that you deﬁne \\nyourself. You can have a maximum of 20 model evaluation jobs that use human workers In \\nprogress  in your account per AWS Region.\\nFor each metric that you use, you must deﬁne a Rating method . The rating method deﬁnes how \\nyour human workers will evaluate the responses they get from the models you\\'ve selected. To learn \\nmore about the diﬀerent available rating methods and how to create high quality instructions for \\nworkers, see Creating and managing work teams in Amazon Bedrock\\nViewing the model evaluation job results using the Amazon Bedrock console\\nWhen a model evaluation job ﬁnishes, the results are stored in the Amazon S3 bucket you \\nspeciﬁed. If you modify the location of the results in any way, the model evaluation report \\ncard is no longer visible in the console.\\nTo create a model evaluation job that uses human workers\\n1. Open the Amazon Bedrock console: https://console.aws.amazon.com/bedrock/home\\n2. In the navigation pane, choose Model evaluation .\\n3. In the Build an evaluation card, under Human: bring your own team choose Create human \\nevaluation .\\n4. On the Specify job details page provide the following.\\na. Evaluation name  — Give the model evaluation job a name that describes the job. This \\nname is shown in your model evaluation job list. The name must be unique in your \\naccount in an AWS Region.\\nb. Description  (Optional) — Provide an optional description.\\nHuman worker based model evaluation jobs 230Amazon Bedrock User Guide\\n5. Then, choose Next.\\n6. On the Set up evaluation  page provide the following.\\na. Models  – You can choose up to two models you want to use in the model evaluation job.\\nTo learn more about available models in Amazon Bedrock, see Model access.\\nb. (Optional) To change the inference conﬁguration choose update .\\nChanging the inference conﬁguration changes the responses generated by the selected \\nmodels. To learn more about the available inferences parameters, see Inference \\nparameters for foundation models .\\nc. Task type – Choose the type of task you want the model to attempt to perform during \\nthe model evaluation job. All instructions for the model must be included in the prompts \\nthemselves. The task type does not control the model\\'s responses.\\nd. Evaluation metrics  — The list of recommended metrics changes based on the task you \\nselect. For each recommended metric, you must select a Rating method . You can have a \\nmaximum of 10 evaluation metrics per model evaluation job.\\ne. (Optional) Choose Add custom metric  to add a custom metric. You must deﬁne the\\nMetric , Description , and Rating method .\\nf.In the Datasets  card your must provide the following.\\ni. Evaluation dataset  – Specify the S3 URI where your prompt dataset is stored. You can \\nhave a maximum of 1000 prompts in a custom prompt dataset.\\nii. Evaluation results destination  – You must specify the S3 URI of the directory where \\nyou want the results of your model evaluation job saved.\\niii. (Optional) Encryption key – Provide the ARN of the AWS KMS key used to encrypt \\nyour data in Amazon S3.\\n7. Then, choose Next.\\n8. In the Permissions card, specify the following. To learn more about the required permissions \\nfor model evaluations, see Required IAM permissions and service roles to create a model \\nevaluation job .\\na. Amazon Bedrock IAM role – Specify an Amazon Bedrock service role that has the required \\npermissions.\\nb. Human workﬂow IAM role – Specify a SageMaker service role that has the required \\npermissions.Human worker based model evaluation jobs 231Amazon Bedrock User Guide\\n9. In the Work team card, specify the following.\\nHuman worker notiﬁcation requirements\\nWhen you add a new human worker to a model evaluation job, they automatically \\nreceive an email inviting them to participate in the model evaluation job. When you \\nadd an existing  human worker to a model evaluation job, you must notify and provide \\nthem with worker portal URL for the model evaluation job. The existing worker will \\nnot receive an automated email notiﬁcation that they are added to the new model \\nevaluation job.\\na. Using the Select team dropdown, specify either Create a new work team or the name of \\nan existing work team.\\nb. (Optional) Number of workers per prompt – Update the number of workers who evaluate \\neach prompt. After the responses for each prompt have been reviewed by the number of \\nworkers you selected, the prompt and its responses will be taken out of circulation from \\nthe work team. The ﬁnal results report will include all ratings from each worker.\\nc. (Optional) Existing worker email – Choose this to copy an email template containing the \\nworker portal URL.\\nd. (Optional) New worker email – Choose this to view the email new workers receive \\nautomatically.\\nImportant\\nLarge language models are known to occasionally hallucinate and produce toxic or \\noﬀensive content. Your workers may be shown toxic or oﬀensive material during \\nthis evaluation. Ensure you take proper steps to train and notify them before they \\nwork on the evaluation. They can decline and release tasks or take breaks during \\nthe evaluation while accessing the human evaluation tool.\\n10. Then, choose Next.\\n11. On the Provide instruction page use the text editor to provide instructions for completing the \\ntask. You can preview the evaluation UI that your work team uses to evaluate the responses, \\nincluding the metrics, rating methods, and your instructions. This preview is based on the \\nconﬁguration you have created for this job.\\nHuman worker based model evaluation jobs 232Amazon Bedrock User Guide\\n12. Then, choose Next.\\n13. On the Review and create page, you can view a summary of the options you\\'ve selected in the \\nprevious steps.\\n14. To start your model evaluation job, choose Create .\\nOnce the job has successfully started, the status changes to In progress . When the job has ﬁnished, \\nthe status changes to Completed.\\nTo learn how to evaluate, view, and download the results of your model evaluation job, see Model \\nevaluation job results.\\nModel evaluation tasks\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nIn a model evaluation job, an evaluation task is a task you want the model to perform based on \\ninformation in your prompts.\\nYou can choose one task type per model evaluation job. Use the following topics to learn more \\nabout each task type. Each topic also includes a list of available built-in datasets and their \\ncorresponding metrics that can be used only in automatic model evaluation jobs.\\nTopics\\n•General text generation\\n•Text summarization\\n•Question and answer\\n•Text classiﬁcation\\nModel evaluation tasks 233Amazon Bedrock User Guide\\nGeneral text generation\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nGeneral text generation is a task used by applications that include chatbots. The responses \\ngenerated by a model to general questions are inﬂuenced by the correctness, relevance, and bias \\ncontained in the text used to train the model.\\nThe following built-in datasets contain prompts that are well-suited for use in general text \\ngeneration tasks.\\nBias in Open-ended Language Generation Dataset (BOLD)\\nThe Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates \\nfairness in general text generation, focusing on ﬁve domains: profession, gender, race, religious \\nideologies, and political ideologies. It contains 23,679 diﬀerent text generation prompts.\\nRealToxicityPrompts\\nRealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to \\ngenerate racist, sexist, or otherwise toxic language. to This dataset contains 100,000 diﬀerent \\ntext generation prompts.\\nT-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)\\nTREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. \\nKBTs are a type of data structure used in natural language processing (NLP) and knowledge \\nrepresentation. They consist of a subject, predicate, and object, where the subject and object \\nare linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington \\nwas the president of the United States\". The subject is \"George Washington\", the predicate is \\n\"was the president of\", and the object is \"the United States\".\\nWikiText2\\nWikiText2 is a HuggingFace dataset that contains prompts used in general text generation.\\nGeneral text generation 234Amazon Bedrock User Guide\\nThe following table summarizes the metrics calculated, and recommended built-in dataset that are \\navailable for automatic model evaluation jobs.\\nAvailable built-in datasets for general text generation in Amazon Bedrock\\nTask type Metric Built-in datasets Computed metric\\nAccuracy TREX Real world \\nknowledge (RWK) \\nscore\\nBOLD\\nWikiText2Robustness\\nTREXWord error rate\\nRealToxicityPromptsGeneral text \\ngeneration\\nToxicity\\nBOLDToxicity\\nFor general text generation, there is a known system issue that prevents Cohere Command and \\nAnthropic Claude models from completing a robustness evaluation successfully.\\nTo learn more about how the computed metric for each built-in dataset is calculated, see Model \\nevaluation job results\\nText summarization\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nText summarization is used for tasks including creating summaries of news, legal documents, \\nacademic papers, content previews, and content curation. The ambiguity, coherence, bias, and \\nText summarization 235Amazon Bedrock User Guide\\nﬂuency of the text used to train the model as well as information loss, accuracy, relevance, or \\ncontext mismatch can inﬂuence the quality of responses.\\nThe following built-in dataset is supported for use with the task summarization task type.\\nGigaword\\nThe Gigaword dataset consists of news article headlines. This dataset is used in text \\nsummarization tasks.\\nThe following table summarizes the metrics calculated, and recommended built-in dataset.\\nAvailable built-in datasets for text summarization in Amazon Bedrock\\nTask type Metric Built-in datasets Computed metric\\nAccuracy Gigaword BERTScore\\nToxicity Gigaword ToxicityText \\nsummarization\\nRobustness Gigaword\\nBERTScore and \\ndeltaBERTScore\\nFor text summarization, there is a known system issue that prevents Anthropic Claude models from \\ncompleting a Robustness evaluation successfully.\\nTo learn more about how the computed metric for each built-in dataset is calculated, see Model \\nevaluation job results\\nQuestion and answer\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nQuestion and answer 236Amazon Bedrock User Guide\\nQuestion and answer is used for tasks including generating automatic help-desk responses, \\ninformation retrieval, and e-learning. If the text used to train the foundation model contains issues \\nincluding incomplete or inaccurate data, sarcasm or irony, the quality of responses can deteriorate.\\nThe following built-in datasets are recommended for use with the question and answer task type.\\nBoolQ\\nBoolQ is a dataset consisting of yes/no question and answer pairs. The prompt contains a short \\npassage, and then a question about the passage. This dataset is recommended for use with \\nquestion and answer task type.\\nNatural Questions\\nNatural questions is a dataset consisting of real user questions submitted to Google search.\\nTriviaQA\\nTriviaQA is a dataset that contains over 650K question-answer-evidence-triples. This dataset is \\nused in question and answer tasks.\\nThe following table summarizes the metrics calculated, and recommended built-in dataset.\\nAvailable built-in datasets for the question and answer task type in Amazon Bedrock\\nTask type Metric Built-in datasets Computed metric\\nBoolQ\\nNaturalQuestionsAccuracy\\nTriviaQANLP-F1\\nBoolQ\\nNaturalQuestionsRobustness\\nTriviaQAF1 and deltaF1\\nBoolQQuestion and \\nanswer\\nToxicity\\nNaturalQuestionsToxicity\\nQuestion and answer 237Amazon Bedrock User Guide\\nTask type Metric Built-in datasets Computed metric\\nTriviaQA\\nFor question and answer, there is a known system issue that prevents Anthropic Claude models \\nfrom completing a robustness evaluation successfully.\\nTo learn more about how the computed metric for each built-in dataset is calculated, see Model \\nevaluation job results\\nText classiﬁcation\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nText classiﬁcation is used to categorize text into pre-deﬁned categories. Applications that use text \\nclassiﬁcation include content recommendation, spam detection, language identiﬁcation and trend \\nanalysis on social media. Imbalanced classes, ambiguous data, noisy data, and bias in labeling are \\nsome issues that can cause errors in text classiﬁcation.\\nThe following built-in datasets are recommended for use with the text classiﬁcation task type.\\nWomen\\'s E-Commerce Clothing Reviews\\nWomen\\'s E-Commerce Clothing Reviews is a dataset that contains clothing reviews written by \\ncustomers. This dataset is used in text classiﬁcation tasks.\\nThe following table summarizes the metrics calculated, and recommended built-in datasets.\\nAvailable built-in datasets in Amazon Bedrock\\nTask type Metric Built-in datasets Computed metric\\nText classiﬁc \\nationAccuracy Women\\'s Ecommerce \\nClothing Reviews\\nText classiﬁcation 238Amazon Bedrock User Guide\\nTask type Metric Built-in datasets Computed metric\\nAccuracy (Binary \\nAccuracy from  \\n classiﬁcatio \\nn_accuracy_score)\\nRobustness Women\\'s Ecommerce \\nClothing Reviewsclassiﬁcation_acc \\nuracy_score and \\ndelta_classiﬁcati \\non_accuracy_score\\nFor text classiﬁcation, there is a known system issue that prevents Anthropic Claude models from \\ncompleting a Robustness evaluation successfully.\\nTo learn more about how the computed metric for each built-in dataset is calculated, see Model \\nevaluation job results\\nUsing prompt datasets in model evaluation jobs\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nTo create a model evaluation job you must specify a prompt dataset the model uses during \\ninference. Amazon Bedrock provides built-in datasets that can be used in automatic model \\nevaluations, or you can bring your own prompt dataset. For model evaluation jobs that use human \\nworkers you must use your own prompt dataset.\\nUse the following sections to learn more about available built-in prompt datasets and creating \\nyour custom prompt datasets.\\nTo learn more about creating your ﬁrst model evaluation job in Amazon Bedrock, see Model \\nevaluation .\\nInput prompt datasets 239Amazon Bedrock User Guide\\nTopics\\n•Using built-in prompt datasets in automatic model evaluation jobs\\n•Custom prompt dataset\\nUsing built-in prompt datasets in automatic model evaluation jobs\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nAmazon Bedrock provides multiple built-in prompt datasets that you can use in an automatic \\nmodel evaluation job. Each built-in dataset is based oﬀ an open-source dataset. We have down \\nsampled each open-source dataset to include only 100 prompts.\\nAll built-in prompt datasets use the format that Anthropic Claude models require. This means \\neach prompt contains \"Human: \"  at the start of each prompt, and \"Assistant: \"  at the end. \\nTo avoid this scenario, you can use the original open source versions of the prompt datasets, and \\nupload them as a custom dataset when you create a model evaluation job.\\nWhen you create an automatic model evaluation job and choose a Task type Amazon Bedrock \\nprovides you with a list of recommended metrics. For each metric, Amazon Bedrock also provides \\nrecommended built-in datasets. To learn more about available task types, see Model evaluation \\ntasks .\\nBias in Open-ended Language Generation Dataset (BOLD)\\nThe Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates \\nfairness in general text generation, focusing on ﬁve domains: profession, gender, race, religious \\nideologies, and political ideologies. It contains 23,679 diﬀerent text generation prompts.\\nRealToxicityPrompts\\nRealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to \\ngenerate racist, sexist, or otherwise toxic language. This dataset contains 100,000 diﬀerent text \\ngeneration prompts.\\nBuilt-in prompt datasets 240Amazon Bedrock User Guide\\nT-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)\\nTREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. \\nKBTs are a type of data structure used in natural language processing (NLP) and knowledge \\nrepresentation. They consist of a subject, predicate, and object, where the subject and object \\nare linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington \\nwas the president of the United States\". The subject is \"George Washington\", the predicate is \\n\"was the president of\", and the object is \"the United States\".\\nWikiText2\\nWikiText2 is a HuggingFace dataset that contains prompts used in general text generation.\\nGigaword\\nThe Gigaword dataset consists of news article headlines. This dataset is used in text \\nsummarization tasks.\\nBoolQ\\nBoolQ is a dataset consisting of yes/no question and answer pairs. The prompt contains a short \\npassage, and then a question about the passage. This dataset is recommended for use with \\nquestion and answer task type.\\nNatural Questions\\nNatural question is a dataset consisting of real user questions submitted to Google search.\\nTriviaQA\\nTriviaQA is a dataset that contains over 650K question-answer-evidence-triples. This dataset is \\nused in question and answer tasks.\\nWomen\\'s E-Commerce Clothing Reviews\\nWomen\\'s E-Commerce Clothing Reviews is a dataset that contains clothing reviews written by \\ncustomers. This dataset is used in text classiﬁcation tasks.\\nIn the following table, you can see the list of available datasets grouped task type. To learn more \\nabout how automatic metrics are computed, see Automated model evaluation job report cards \\n(console).\\nBuilt-in prompt datasets 241Amazon Bedrock User Guide\\nAvailable built-in datasets for automatic model evaluation jobs in Amazon Bedrock\\nTask type Metric Built-in datasets Computed metric\\nAccuracy TREX Real world \\nknowledge (RWK) \\nscore\\nBOLD\\nWikiText2Robustness\\nEnglish WikipediaWord error rate\\nRealToxicityPromptsGeneral text \\ngeneration\\nToxicity\\nBOLDToxicity\\nAccuracy Gigaword BERTScore\\nToxicity Gigaword ToxicityText \\nsummarization\\nRobustness Gigaword BERTScore and \\ndeltaBERTScore\\nBoolQ\\nNaturalQuestionsAccuracy\\nTriviaQANLP-F1\\nBoolQ\\nNaturalQuestionsRobustness\\nTriviaQAF1 and deltaF1\\nBoolQQuestion and \\nanswer\\nToxicity\\nNaturalQuestionsToxicity\\nBuilt-in prompt datasets 242Amazon Bedrock User Guide\\nTask type Metric Built-in datasets Computed metric\\nTriviaQA\\nWomen\\'s Ecommerce \\nClothing Reviews\\nWomen\\'s Ecommerce \\nClothing ReviewsAccuracy\\nWomen\\'s Ecommerce \\nClothing ReviewsAccuracy (Binary \\naccuracy from \\nclassiﬁcation_acc \\nuracy_score)Text classiﬁc \\nation\\nRobustness Women\\'s Ecommerce \\nClothing Reviewsclassiﬁcation_acc \\nuracy_score \\nand  delta \\n_classiﬁcation_ac \\ncuracy_score\\nTo learn more about the requirements for creating and examples of custom prompt datasets, see\\nCustom prompt dataset.\\nCustom prompt dataset\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nYou can use a custom prompt dataset in model evaluation jobs.\\nCustom prompt datasets must be stored in Amazon S3, and use the JSON line format and use the\\n.jsonl ﬁle extension. When you upload the dataset to Amazon S3 make sure that you update \\nthe Cross Origin Resource Sharing (CORS) conﬁguration on the S3 bucket. To learn more about the \\nCustom prompt datasets 243Amazon Bedrock User Guide\\nrequired CORS permissions, see Required Cross Origin Resource Sharing (CORS) permission on S3 \\nbuckets.\\nTopics\\n•Requirements for custom prompt datasets used in automatic model evaluation jobs\\n•Requirements for custom prompt datasets in model evaluation job that use human workers\\nRequirements for custom prompt datasets used in automatic model evaluation \\njobs\\nIn automatic model evaluation jobs you can use a custom prompt dataset for each metric you \\nselect in the model evaluation job. Custom datasets use the JSON line format (.jsonl ), and each \\nline must be a valid JSON object. There can be up to 1000 prompts in your dataset per automatic \\nevaluation job.\\nYou must use the following keys in a custom dataset.\\n•prompt – required to indicate the input for the following tasks:\\n•The prompt that your model should respond to, in general text generation.\\n•The question that your model should answer in the question and answer task type.\\n•The text that your model should summarize in text summarization task.\\n•The text that your model should classify in classiﬁcation tasks.\\n•referenceResponse  – required to indicate the ground truth response against which your \\nmodel is evaluated for the following tasks types:\\n•The answer for all prompts in question and answer tasks.\\n•The answer for all accuracy, and robustness evaluations.\\n•category – (optional) generates evaluation scores reported for each category.\\nAs an example, accuracy requires both the question to ask and the answer to check the model \\nresponse against. In this example, use the key prompt with the value contained in the question, \\nand the key referenceResponse  with the value contained in the answer as follows.\\n{ \\n \"prompt\": \"Bobigny is the capital of\", \\n \"referenceResponse\": \"Seine-Saint-Denis\", \\n \"category\": \"Capitals\"\\nCustom prompt datasets 244Amazon Bedrock User Guide\\n}\\nThe previous example is a single line of a JSON line input ﬁle that will be sent to your model as \\nan inference request. Model will be invoked for every such record in your JSON line dataset. The \\nfollowing data input example is for a question answer task that uses an optional category  key for \\nevaluation.\\nImportant\\nAfter your last prompt in your custom dataset, the ﬁle must end with a newline.\\n{\"referenceResponse\":\"Cantal\",\"category\":\"Capitals\",\"prompt\":\"Aurillac is the capital \\n of\"}\\n{\"referenceResponse\":\"Bamiyan Province\",\"category\":\"Capitals\",\"prompt\":\"Bamiyan city is \\n the capital of\"}\\n{\"referenceResponse\":\"Abkhazia\",\"category\":\"Capitals\",\"prompt\":\"Sokhumi is the capital \\n of\"}\\n## The file must end with a newline\\nTo learn more about the format requirements for model evaluation jobs that use human workers, \\nsee Requirements for custom prompt datasets in model evaluation job that use human workers.\\nAnthropic\\xa0Claude custom prompt dataset requirements\\nIf you want to specify custom prompt dataset, and use an Anthropic Claude model in your \\nautomatic model evaluation job you must modify, you must modify your prompt keys to have the \\nfollowing structure.\\n{ \\n \"prompt\": \" Human: What is high intensity interval training? Assistant: \", \\n \"category\": \"Fitness\", \\n \"referenceResponse\": \"High-Intensity Interval Training (HIIT) is a cardiovascular \\n exercise approach that involves short, intense bursts of exercise followed by brief \\n recovery or rest periods.\"\\n}\\nThese keywords, Human:  and Assistant:  are case-sensitive and must include the colon.\\nWe recommend you test the sensitivity of including these keywords using Amazon Bedrock \\nPlayground.\\nCustom prompt datasets 245Amazon Bedrock User Guide\\nRequirements for custom prompt datasets in model evaluation job that use \\nhuman workers\\nIn the JSON line format, each line is a valid JSON object. A prompt dataset can have a maximum of \\n1000 prompts per model evaluation job.\\nA valid prompt entry must contain the prompt key, both category  and referenceResponse\\nare optional. Use the category  key to label your prompt with a speciﬁc category that you \\ncan use to ﬁlter the results when reviewing them in the model evaluation report card. Use the\\nreferenceResponse  key to specify the ground truth response that your workers can reference \\nduring the evaluation.\\nIn the worker UI, what you specify for prompt  and referenceResponse  are visible to your \\nhuman workers.\\nThe following is an example custom dataset that contains 6 inputs and uses the JSON line format.\\nImportant\\nAfter your last prompt in your custom dataset, the ﬁle must end with a newline.\\n{\"prompt\":\" Provide the prompt you want the model to use \\n during inference \",\"category\":\" (Optional) Specify an optional \\n category \",\"referenceResponse\":\" (Optional) Specify a ground truth response .\"}\\n{\"prompt\":\" Provide the prompt you want the model to use \\n during inference \",\"category\":\" (Optional) Specify an optional \\n category \",\"referenceResponse\":\" (Optional) Specify a ground truth response .\"}\\n{\"prompt\":\" Provide the prompt you want the model to use \\n during inference \",\"category\":\" (Optional) Specify an optional \\n category \",\"referenceResponse\":\" (Optional) Specify a ground truth response .\"}\\n{\"prompt\":\" Provide the prompt you want the model to use \\n during inference \",\"category\":\" (Optional) Specify an optional \\n category \",\"referenceResponse\":\" (Optional) Specify a ground truth response .\"}\\n{\"prompt\":\" Provide the prompt you want the model to use \\n during inference \",\"category\":\" (Optional) Specify an optional \\n category \",\"referenceResponse\":\" (Optional) Specify a ground truth response .\"}\\n{\"prompt\":\" Provide the prompt you want the model to use \\n during inference \",\"category\":\" (Optional) Specify an optional \\n category \",\"referenceResponse\":\" (Optional) Specify a ground truth response .\"}\\nCustom prompt datasets 246Amazon Bedrock User Guide\\n## The file must end with a newline\\nThe following example is a single entry expanded for clarity\\n{ \\n    \"prompt\": \"What is high intensity interval training?\", \\n    \"category\": \"Fitness\", \\n    \"referenceResponse\": \"High-Intensity Interval Training (HIIT) is a cardiovascular \\n exercise approach that involves short, intense bursts of exercise followed by brief \\n recovery or rest periods.\"\\n}\\nAnthropic\\xa0Claude custom prompt dataset requirements\\nIf either model you select in your model evaluation job is an Anthropic Claude model, you must \\nmodify your prompt keys to have the following structure..\\n{ \\n    \"prompt\": \" Human: What is high intensity interval training? Assistant: \", \\n    \"category\": \"Fitness\", \\n    \"referenceResponse\": \"High-Intensity Interval Training (HIIT) is a cardiovascular \\n exercise approach that involves short, intense bursts of exercise followed by brief \\n recovery or rest periods.\"\\n}\\nThese keywords, Human:  and Assistant:  are case-sensitive and must include the colon.\\nBecause these prompts are sent to the second model in your model evaluation job, we recommend \\nyou test the sensitivity of including these keywords on the second model using Amazon Bedrock \\nPlayground.\\nCreating good worker instructions\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nWorker instructions 247Amazon Bedrock User Guide\\nCreating good instructions for your model evaluation jobs improves your worker\\'s accuracy in \\ncompleting their task. You can modify the default instructions that are provided in the console \\nwhen creating a model evaluation job. The instructions are shown to the worker on the UI page \\nwhere they complete their labeling task.\\nTo help workers complete their assigned tasks, you can provide instructions in two places.\\nProvide a good description for each evaluation and rating method\\nThe descriptions should provide a succinct explanation of the metrics selected. The description \\nshould expand on the metric, and make clear how you want workers to evaluate the selected rating \\nmethod. To see examples of how each rating method is shown in the worker UI, see Summary of \\navailable rating methods .\\nProvide your workers overall evaluation instructions\\nThese instructions are shown on the same webpage where workers complete a task. You can use \\nthis space to provide high level direction for the model evaluation job, and to describe the ground \\ntruth responses if you\\'ve included them in your prompt dataset.\\nSummary of available rating methods\\nIn each of the following sections, you can see an example of the rating methods your work team \\nsaw in the evaluation UI, and also how those results are saved in Amazon S3.\\nLikert scale, comparison of multiple model outputs\\nHuman evaluators indicate their preference between the two responses from the model on a 5 \\npoint Likert scale according to your instructions. The results in the ﬁnal report will be shown as a \\nhistogram of preference strength ratings from the evaluators over your whole dataset.\\nMake sure you deﬁne the important points of the 5 point scale in your instructions, so your \\nevaluators know how to rate responses based on your expectations.\\nRating methods 248Amazon Bedrock User Guide\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"preferenceStrength\"  key value pair.\\nChoice buttons (radio button)\\nChoice buttons allow a human evaluator to indicate their one preferred response over another \\nresponse. Evaluators indicate their preference between two responses according to your \\ninstructions with radio buttons. The results in the ﬁnal report will be shown as a percentage of \\nresponses that workers preferred for each model. Be sure to explain your evaluation method clearly \\nin the instructions.\\nRating methods 249Amazon Bedrock User Guide\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"preferenceRate\"  key value pair.\\nOrdinal rank\\nOrdinal rank allows a human evaluator to rank their preferred responses to a prompt in order \\nstarting at 1 according to your instructions. The results in the ﬁnal report will be shown as a \\nhistogram of the rankings from the evaluators over the whole dataset. Be sure to deﬁne what a \\nrank of 1 means in your instructions.\\nRating methods 250Amazon Bedrock User Guide\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"preferenceRank\"  key value pair.\\nThumbs up/down\\nThumbs up/down allows a human evaluator to rate each response from a model as acceptable/\\nunacceptable according to your instructions. The results in the ﬁnal report will be shown as a \\npercentage of the total number of ratings by evaluators that received a thumbs up rating for each \\nmodel. You may use this rating method for an evaluation one or more models. If you use this in \\nan evaluation that contains two models, a thumbs up/down will be presented to your work team \\nfor each model response and the ﬁnal report will show the aggregated results for each model \\nindividually. Be sure to deﬁne what is acceptable (that is, what is a thumbs up rating) in your \\ninstructions.\\nRating methods 251Amazon Bedrock User Guide\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"approvalRate\"  key value pair.\\nLikert scale, evaluation of a single model response\\nAllows a human evaluator to indicate how strongly they approved of the model\\'s response based \\non your instructions on a 5 point Likert scale. The results in the ﬁnal report will be shown as a \\nRating methods 252Amazon Bedrock User Guide\\nhistogram of the 5 point ratings from the evaluators over your whole dataset. You may use this for \\nan evaluation containing one or more models. If you select this rating method in an evaluation that \\ncontains more than one model, a 5 point Likert scale will be presented to your work team for each \\nmodel response and the ﬁnal report will show the aggregated results for each model individually. \\nBe sure to deﬁne the important points on the 5 point scale in your instructions so your evaluators \\nknow how to rate the responses according to your expectations.\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"approvalStrength\"  key value pair.\\nRating methods 253Amazon Bedrock User Guide\\nCreating and managing work teams in Amazon Bedrock\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nIn model evaluation jobs that use human workers you need to have a work team. A work team is a \\ngroup of workers that you choose. These can be employees of your company or a group of subject-\\nmatter experts from your industry.\\nWorker notiﬁcations in Amazon Bedrock\\n•When you create a model evaluation job in Amazon Bedrock workers are notiﬁed of their \\nassigned job only when you ﬁrst add them to a work team\\n•If you delete a worker from a work team during model evaluation creation, they will lose \\naccess to all model evaluation jobs they have been assigned too.\\n•For any new model evaluation job that you assign to an existing human worker, you must \\nnotify them directly and provide them the URL to the worker portal. Workers must use \\ntheir previously created login credentials for the worker portal. This worker portal is the \\nsame for all evaluation jobs in your AWS account per region\\nIn Amazon Bedrock you can create a new work team or manage an existing one while setting up a \\nmodel evaluation job. When you create a work team in Amazon Bedrock you are adding workers \\nto a Private workforce  that is managed by Amazon SageMaker Ground Truth. Amazon SageMaker \\nGround Truth supports more advanced workforce management features. To learn more about \\nmanaging your workforce in Amazon SageMaker Ground Truth, see Create and manage workforces.\\nYou can delete workers from a work team while setting up a new model evaluation job. Otherwise, \\nyou must use either the Amazon Cognito console or the Amazon SageMaker Ground Truth console \\nto manage work teams you\\'ve created in Amazon Bedrock.\\nManage a work team 254Amazon Bedrock User Guide\\nIf the IAM user, group, or role has the required permissions you will see existing private workforces \\nand work teams you created in Amazon Cognito, Amazon SageMaker Ground Truth, or Amazon \\nAugmented AI visible when you are creating a model evaluation job that uses human workers.\\nAmazon Bedrock supports a maximum of 50 workers per work team.\\nIn the email addresses ﬁeld, you can enter up to 50 email addresses at time. To add more workers \\nto your model evaluation job use the Amazon Cognito console or the Ground Truth console. The \\naddresses must be separated by a comma. You should include your own email address so that you \\nare part of the workforce and can see the labeling tasks.\\nModel evaluation job results\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nThe results of a model evaluation job  are available via the Amazon Bedrock console or by \\ndownloading the results from the Amazon S3 bucket you speciﬁed when the job was created.\\nOnce your job status has changed to Ready, you can ﬁnd the S3 bucket you speciﬁed when \\ncreating the job. To do so, go to the Model evaluations  table on the Model evaluation  home page \\nand choose it.\\nUse the following topics to learn how to access model evaluation reports, and how results of a \\nmodel evaluation job are saved in Amazon S3.\\nTopics\\n•Automated model evaluation job report cards (console)\\n•Human model evaluation job report cards (console)\\n•Understanding how the results of your model evaluation job that are saved in Amazon S3\\nModel evaluation job results 255Amazon Bedrock User Guide\\nAutomated model evaluation job report cards (console)\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nIn your model evaluation report card, you will see the total number of prompts in the dataset \\nyou provided or selected, and how many of those prompts received responses. If the number of \\nresponses is less than the number of input prompts, make sure to check the data output ﬁle in your \\nAmazon S3 bucket. It is possible that the prompt caused an error with the model and there was no \\ninference retrieved. Only responses from the model will be used in metric calculations.\\nUse the following procedure to review an automatic model evaluation job on the Amazon Bedrock \\nconsole.\\n1. Open the Amazon Bedrock console.\\n2. From the navigation pane, choose Model evaluation .\\n3. Next, in the Model evaluations  table ﬁnd the name of the automated model evaluation job \\nyou want to review. Then, choose it.\\nIn all semantic robustness related metrics, Amazon Bedrock perturbs prompts in the following \\nways: convert text to all lower cases, keyboard typos, converting numbers to words, random \\nchanges to upper case and random addition/deletion of whitespaces.\\nAfter you open the model evaluation report you can view the summarized metrics, and the Job \\nconﬁguration summary of the job.\\nFor each metric and prompt dataset speciﬁed when the job was created you see a card, and a value \\nfor each dataset speciﬁed for that metric. How this value is calculated changes based on the task \\ntype and the metrics you selected.\\nHow each available metric is calculated when applied to the general text generation task type\\n•Accuracy: For this metric, the value is calculated using real world knowledge score (RWK score). \\nRWK score examines the model’s ability to encode factual knowledge about the real world. A \\nhigh RWK score indicates that your model is being accurate.\\nAutomated reports 256Amazon Bedrock User Guide\\n•Robustness: For this metric, the value is calculated using semantic robustness. Which is \\ncalculated using word error rate. Semantic robustness measures how much the model output \\nchanges as a result of minor, semantic preserving perturbations, in the input. Robustness to such \\nperturbations is a desirable property, and thus a low semantic robustness score indicated your \\nmodel is performing well.\\nThe perturbation types we will consider are: convert text to all lower cases, keyboard typos, \\nconverting numbers to words, random changes to upper case and random addition/deletion \\nof whitespaces. Each prompt in your dataset is perturbed approximately 5 times. Then, each \\nperturbed response is sent for inference, and used to calculate robustness scores automatically.\\n•Toxicity: For this metric, the value is calculated using toxicity from the detoxify algorithm. A low \\ntoxicity value indicates that your selected model is not producing large amounts of toxic content. \\nTo learn more about the detoxify algorithm and see how toxicity is calculated, see the detoxify \\nalgorithm  on GitHub.\\nHow each available metric is calculated when applied to the text summarization task type\\n•Accuracy: For this metric, the value is calculated using BERT Score. BERT Score is calculated \\nusing pre-trained contextual embeddings from BERT models. It matches words in candidate \\nand reference sentences by cosine similarity. The displayed value is the F1 score. A low F1 score \\nindicates that the model struggles to be both precise and capture the true positive (recall).\\n•Robustness: For this metric, the value calculated is a percentage. It calculated by taking (Delta \\nBERTScore / BERTScore) x 100. Delta BERTScore is the diﬀerence in BERT Scores between a \\nperturbed prompt and the original prompt in your dataset. Each prompt in your dataset is \\nperturbed approximately 5 times. Then, each perturbed response is sent for inference, and used \\nto calculate robustness scores automatically. A lower score indicates the selected model is more \\nrobust.\\n•Toxicity: For this metric, the value is calculated using toxicity from the detoxify algorithm. A low \\ntoxicity value indicates that your selected model is not producing large amounts of toxic content. \\nTo learn more about the detoxify algorithm and see how toxicity is calculated, see the detoxify \\nalgorithm  on GitHub.\\nHow each available metric is calculated when applied to the question and answer task type\\n•Accuracy: For this metric, the value calculated is F1 score. F1 score is calculated by dividing the \\nprecision score (the ratio of correct predictions to all predictions) by the recall score (the ratio of \\nAutomated reports 257Amazon Bedrock User Guide\\ncorrect predictions to the total number of relevant predictions). The F1 score ranges from 0 to 1, \\nwith higher values indicating better performance.\\n•Robustness: For this metric, the value calculated is a percentage. It is calculated by taking (Delta \\nF1 / F1) x 100. Delta F1 is the diﬀerence in BERT Scores between a perturbed prompt and the \\noriginal prompt in your dataset. Each prompt in your dataset is perturbed approximately 5 times. \\nThen, each perturbed response is sent for inference, and used to calculate robustness scores \\nautomatically. A lower score indicates the selected model is more robust.\\n•Toxicity: For this metric, the value is calculated using toxicity from the detoxify algorithm. A low \\ntoxicity value indicates that your selected model is not producing large amounts of toxic content. \\nTo learn more about the detoxify algorithm and see how toxicity is calculated, see the detoxify \\nalgorithm  on GitHub.\\nHow each available metric is calculated when applied to the text classiﬁcation task type\\n•Accuracy: For this metric, the value calculated is accuracy. Accuracy is a score that compares the \\npredicted class to its ground truth label. A higher accuracy indicates that your model is correctly \\nclassifying text based on the ground truth label provided.\\n•Robustness: For this metric, the value calculated is a percentage. It is calculated by taking (delta \\nbalanced classiﬁcation score / classiﬁcation accuracy score) x 100. Delta balanced classiﬁcation \\nscore is the diﬀerence between the classiﬁcation accuracy Score of the perturbed prompt and \\nthe original input prompt. Each prompt in your dataset is perturbed approximately 5 times. \\nThen, each perturbed response is sent for inference, and used to calculate robustness scores \\nautomatically. A lower score indicates the selected model is more robust.\\nHuman model evaluation job report cards (console)\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nIn your model evaluation report card, you will see the total number of prompts in the dataset \\nyou provided or selected, and how many of those prompts received responses. If the number of \\nresponses is less than the number of input prompts times the number of workers per prompt you \\nHuman report cards 258Amazon Bedrock User Guide\\nconﬁgured in the job (either 1,2 or 3), make sure to check the data output ﬁle in your Amazon S3 \\nbucket. It is possible that the prompt caused an error with the model and there was no inference \\nretrieved. Also, one or more of your workers could have declined to evaluate a model output \\nresponse. Only responses from the human workers will be used in metric calculations.\\nUse the following procedure to open up a model evaluation that used human workers on the \\nAmazon Bedrock console.\\n1. Open the Amazon Bedrock console.\\n2. From the navigation pane, choose Model evaluation .\\n3. Next, in the Model evaluations  table ﬁnd the name of the model evaluation job you want to \\nreview. Then, choose it.\\nThe model evaluation report provides insights about the data collected during a human evaluation \\njob using report cards. Each report card shows the metric, description, and rating method, \\nalongside a data visualization that represents the data collected for the given metric.\\nIn each of the following sections, you can see an examples of the 5 possible rating methods your \\nwork team saw in the evaluation UI. The examples also show what key value pair is used to save the \\nresults in Amazon S3.\\nLikert scale, comparison of multiple model outputs\\nHuman evaluators indicate their preference between the two responses from the model on a 5 \\npoint Likert scale  according to your instructions. The results in the ﬁnal report will be shown as a \\nhistogram of preference strength ratings from the evaluators over your whole dataset.\\nMake sure you deﬁne the important points of the 5 point scale in your instructions, so your \\nevaluators know how to rate responses based on your expectations.\\nHuman report cards 259Amazon Bedrock User Guide\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"preferenceStrength\"  key value pair.\\nChoice buttons (radio button)\\nChoice buttons allow a human evaluator to indicate their one preferred response over another \\nresponse. Evaluators indicate their preference between two responses according to your \\ninstructions with radio buttons. The results in the ﬁnal report will be shown as a percentage of \\nresponses that workers preferred for each model. Be sure to explain your evaluation method clearly \\nin the instructions.\\nHuman report cards 260Amazon Bedrock User Guide\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"preferenceRate\"  key value pair.\\nOrdinal rank\\nOrdinal rank allows a human evaluator to rank their preferred responses to a prompt in order \\nstarting at 1 according to your instructions. The results in the ﬁnal report will be shown as a \\nhistogram of the rankings from the evaluators over the whole dataset. Be sure to deﬁne what a \\nrank of 1 means in your instructions. This data type is called Preference Rank.\\nHuman report cards 261Amazon Bedrock User Guide\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"preferenceRank\"  key value pair.\\nThumbs up/down\\nThumbs up/down allows a human evaluator to rate each response from a model as acceptable/\\nunacceptable according to your instructions. The results in the ﬁnal report will be shown as a \\npercentage of the total number of ratings by evaluators that received a thumbs up rating for \\neach model. You may use this rating method for a model evaluation job that contains one or \\nmore models. If you use this in an evaluation that contains two models, a thumbs up/down will \\nbe presented to your work team for each model response and the ﬁnal report will show the \\naggregated results for each model individually. Be sure to deﬁne what is acceptable (that is, what is \\na thumbs up rating) in your instructions.\\nHuman report cards 262Amazon Bedrock User Guide\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"approvalRate\"  key value pair.\\nLikert scale, evaluation of a single model response\\nAllows a human evaluator to indicate how strongly they approved of the model\\'s response based \\non your instructions on a 5 point Likert scale. The results in the ﬁnal report will be shown as a \\nHuman report cards 263Amazon Bedrock User Guide\\nhistogram of the 5 point ratings from the evaluators over your whole dataset. You may use this for \\nan evaluation containing one or more models. If you select this rating method in an evaluation that \\ncontains more than one model, a 5 point Likert scale will be presented to your work team for each \\nmodel response and the ﬁnal report will show the aggregated results for each model individually. \\nBe sure to deﬁne the important points on the 5 point scale in your instructions so your evaluators \\nknow how to rate the responses according to your expectations.\\nJSON output\\nThe ﬁrst child-key under evaluationResults  is where the selected rating method is returned. \\nIn the output ﬁle saved to your Amazon S3 bucket, the results from each worker are saved to the\\n\"evaluationResults\": \"approvalStrength\"  key value pair.\\nHuman report cards 264Amazon Bedrock User Guide\\nUnderstanding how the results of your model evaluation job that are \\nsaved in Amazon S3\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nThe output from a model evaluation job is saved in the Amazon S3 bucket you speciﬁed when you \\ncreated the model evaluation job. Results of model evaluation jobs are saved as JSON line ﬁles \\n(.jsonl ).\\nThe results from the model evaluation job is saved in the S3 bucket you speciﬁed as follows.\\n•For model evaluation jobs that use human workers:\\ns3://user-specified-model-evaluation-job-output-bucket /human-loop-name /\\noutput.jsonl\\n•For automatic model evaluation jobs:\\ns3://user-specified-model-evaluation-job-output-bucket /output/system-\\ngenerated-id-tag/datasets\\nThe following topics describe how the results from automated and human worker based model \\nevaluation job are saved in Amazon S3.\\nOutput data from automated model evaluation jobs\\nThe results of the automated evaluation job are stored in the datasets  directory when job status \\nchanges to Completed.\\nFor each metric and corresponding prompt dataset you selected when the model evaluation job \\nwas created, a JSON line ﬁle is generated in the datasets  directory. The ﬁle uses the following \\nnaming convention metric_input-dataset .jsonl .\\nEach result from the model evaluation job starts with the automatedEvaluationResult  key. \\nThe ﬁrst child key scores contains the metrics you selected in the Amazon Bedrock console. In this \\nAmazon S3 output 265Amazon Bedrock User Guide\\nexample, only a single metric Accuracy  was selected. It also contains result  which is calculated \\nvalue for the selected metric. To learn more about what speciﬁc value is calculated, see Automated \\nmodel evaluation job report cards (console).\\nThe second key, inputRecord  is a copy of what you provided in your input prompt dataset.\\nThe third key, modelInvocations  contains a list of JSON objects which contains the ARN of the \\nmodel selected when you created the model evaluation job. It also contains the full response from \\nthe model based on the prompt provided.\\nThe following is an example output for the text summarization task type with only one metric, \\naccuracy, selected.\\n{ \\n    \"automatedEvaluationResult\": { \\n        \"scores\": [{ \\n            \"metricName\": \"Accuracy\", \\n            \"result\": 0.31920555233955383 \\n        }] \\n    }, \\n    \"inputRecord\": { \\n        \"prompt\": \"Human: two bodies have been recovered from a flooded coal mine in \\n yiyang city , central china \\'s henan province , as of #:## thursday morning , rescuers \\n said . Assistant:\", \\n        \"referenceResponse\": \"two bodies recovered from flooded coal mine in c. china\" \\n    }, \\n    \"modelInvocations\": [{ \\n        \"modelIdentifier\": \"arn:aws:bedrock:us-east-1::foundation-model/\\nanthropic.claude-v2\", \\n        \"responseText\": \" Here are the key points I gathered from your news summary:\\\\n\\n\\\\n- Two bodies have been recovered from a flooded coal mine in Yiyang City, in China\\'s \\n Henan province.\\\\n\\\\n- This happened as of Thursday morning, according to rescuers.\\\\n\\\\n- \\n The location is central China\\'s Henan province. \\\\n\\\\n- Yiyang City is where the flooded \\n coal mine is located.\\\\n\\\\n- The coal mine was flooded, leading to the two deaths and \\n need for rescue/recovery efforts.\\\\n\\\\n- This news is developing as of Thursday morning, \\n so the death toll and rescue details may still be unfolding.\\\\n\\\\nPlease let me know if \\n I have accurately summarized the key information or if you would like me to expand on \\n any part of it.\" \\n    }]\\n}\\nAmazon S3 output 266Amazon Bedrock User Guide\\nOutput data from model evaluation jobs that use human workers.\\nWhen a model evaluation job has completed, you see the following parameters in the output data \\nreturned from human review tasks.\\nParameter Value \\nTypeExample Values Descripti \\non\\nflowDefin \\nitionArnStringarn:aws:sagemaker:us-west-2: 111122223 \\n333:flow-definition/ flow-definition-na \\nmeThe \\nAmazon \\nResource \\nNumber \\n(ARN) of \\nthe human \\nreview  w \\norkﬂow \\n(ﬂow \\ndeﬁnitio \\nn) used \\nto create \\nthe human \\nloop.  \\nhumanAnsw \\nersList \\nof \\nJSON \\nobjects\"answerContent\": { \\n    \"evaluationResults\": { \\n  \"approvalRate\": [{ \\n   \"metric\": \" Relevance \", \\n   \"modelResponseId\": \"0\", \\n   \"result\": false \\n  }] \\n }\\n}A list of \\nJSON \\nobjects \\nthat \\ncontain \\nworker \\nresponses \\nin  \\nanswerCon \\ntent .\\nStringsystem-generated-hash A system \\ngenerated \\nAmazon S3 output 267Amazon Bedrock User Guide\\nParameterValue \\nTypeExample Values Descripti \\non\\nhumanLoop \\nName40-charac \\nter hex \\nstring.\\ninputRecord JSON \\nobject\"inputRecord\": { \\n    \"prompt\": \"What does vitamin C serum do for \\n skin?\", \\n    \"category\": \"Skincare\", \\n    \"referenceResponse\": \"Vitamin C serum \\n offers a range of benefits for the skin. \\n Firstly, it acts.... \\n}A JSON \\nobject that \\ncontains \\nan entry \\nprompt \\nfrom the \\ninput  dat \\naset.\\nmodelInvo \\ncationsList \\nof \\nJSON \\nobjects\"modelResponses\": [{ \\n \"modelIdentifier\": \"arn:aws:bedrock: us-\\neast-1::foundation-model/ anthropic.claude-v \\n2\", \\n \"responseText\": \"the-models-response-to-the \\n-prompt\" \\n}]The \\nindividual \\nresponses \\nfrom the \\nmodels.\\ninputRecord List \\nof \\nJSON \\nobjectSee the following  code sample The input \\ncontent \\nsent to \\nSageMaker \\nin the \\nrequest to\\nStartHuma \\nnLoop .\\nThe following is an example of output data from a model evaluation job.\\nAmazon S3 output 268Amazon Bedrock User Guide\\n{ \\n    \"output\": [{ \\n        \"flowDefinitionArn\": \"arn:aws:sagemaker: us-west-2 :111122223333 :flow-\\ndefinition/ flow-definition-name \", \\n        \"humanAnswers\": [{ \\n            \"acceptanceTime\": \"2023-11-09T19:17:43.107Z\", \\n            \"answerContent\": { \\n                \"evaluationResults\": { \\n                    \"approvalRate\": [{ \\n                        \"metric\": \"Coherence\", \\n                        \"metricName\": \"Coherence\", \\n                        \"modelResponseId\": \"0\", \\n                        \"result\": false \\n                    }, { \\n                        \"metric\": \"Accuracy\", \\n                        \"metricName\": \"Accuracy\", \\n                        \"modelResponseId\": \"0\", \\n                        \"result\": true \\n                    }], \\n                    \"approvalStrength\": [{ \\n                        \"metric\": \"Toxicity\", \\n                        \"metricName\": \"Toxicity\", \\n                        \"modelResponseId\": \"0\", \\n                        \"result\": 1 \\n                    }] \\n                } \\n            }, \\n            \"submissionTime\": \"2023-11-09T19:17:52.101Z\", \\n            \"timeSpentInSeconds\": 8.994, \\n            \"workerId\": \"444455556666\", \\n            \"workerMetadata\": { \\n                \"identityData\": { \\n                    \"identityProviderType\": \"Cognito\", \\n                    \"issuer\": \"https://cognito-idp.us-west-2.amazonaws.com/ us-\\nwest-2_111222 \", \\n                    \"sub\": \" c6aa8eb7-9944-42e9-a6b9- \" \\n                } \\n            } \\n        }], \\n    \\n        \\n      \\n     ...Additional response have been truncated for clarity... \\nAmazon S3 output 269Amazon Bedrock User Guide\\n      }], \\n     \"humanLoopName\": \"b3b1c64a2166e001e094123456789012\" \\n    }, \\n \"inputRecord\": { \\n         \"category\": \"Fitness\", \\n         \"prompt\": \"Human: What is High-Intensity Interval Training ? \\\\\\\\n\\\\\\n\\\\nAssistant:\", \\n         \"referenceResponse\": \"High-Intensity Interval Training (HIIT) is a \\n cardiovascular exercise approach that involves short, intense bursts of exercise \\n followed by brief recovery or rest periods. In HIIT, you perform exercises at near-\\nmaximum effort during the high-intensity intervals, which can include activities \\n like sprinting, cycling, jumping, or body weight exercises such as burpees or push-\\nups. These intense intervals are interspersed with short recovery periods to lower \\n your heart rate before the next high-intensity bout. HIIT workouts usually consist \\n of multiple cycles of these intervals, and the number of cycles and the length of \\n intervals can vary. HIIT is known for its time efficiency, making it an excellent \\n choice for those with busy schedules. It offers both aerobic and anaerobic benefits, \\n improving cardiovascular fitness, burning calories, and promoting fat loss, all while \\n boosting metabolism for continued calorie burning post-workout.\" \\n     }, \\n     \"modelInvocations\": [{ \\n         \"modelIdentifier\": \"arn:aws:bedrock:us-east-1::foundation-model/\\nanthropic.claude-v2\", \\n         \"responseText\": \" High-intensity interval training (HIIT) is a form of \\n exercise that involves short bursts of intense activity alternated with recovery \\n periods. Here are some key features of HIIT:\\\\n\\\\n- Alternates short periods of intense \\n anaerobic exercise with less intense recovery periods. The high-intensity periods \\n are typically done at 80-95% of maximum heart rate.\\\\n\\\\n- The duration of the intense \\n periods can range from 5 seconds to 8 minutes, but typically are in the range of \\n 30 seconds to 4 minutes.\\\\n\\\\n- The total HIIT session typically lasts between 10-30 \\n minutes, including warm-up, recovery periods, and cool down. \\\\n\\\\n- Uses exercises \\n like sprints, cycling, rowing, jumping rope, stair climbing, swimming, etc. Movements \\n that get your heart rate up quickly.\\\\n\\\\n- The short, intense intervals help improve \\n cardiovascular fitness by increasing heart rate and oxygen consumption.\\\\n\\\\n- HIIT \\n burns more calories and fat than steady-state cardio in a shorter time period. It also \\n helps build muscle strength and endurance.\\\\n\\\\n- Considered an efficient and effective \\n form of exercise for fat loss and improving aerobic power. But it requires motivation \\n to push yourself during the intense intervals.\\\\n\\\\n- Not suitable for beginners due \\n to the high-intensity. Start with steady-state cardio and build up endurance before \\n trying HIIT.\\\\n\\\\nIn summary, HIIT intersperses intense bursts of\" \\n     }]\\n} \\nAmazon S3 output 270Amazon Bedrock User Guide\\n    \\n}\\nThe following table explains how the Rating method  you selected for each metric in the \\nAmazon Bedrock console is returned in your Amazon S3 bucket. The ﬁrst child-key under\\nevaluationResults  is how the Rating method  is returned.\\nHow rating methods selected in the Amazon Bedrock console are saved in Amazon S3\\nRating method selected Saved in Amazon S3\\nLikert scale - Individual approvalStrength\\nLikert scale - Comparison preferenceStrength\\nChoice buttons preferenceRate\\nOrdinal rank preferenceRank\\nThumbs up/down approvalRate\\nRequired IAM permissions and service roles to create a model \\nevaluation job\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nPersona: IAM Administrator\\nA user who can add or remove IAM policies, and create new IAM roles.\\nRequired permissions 271Amazon Bedrock User Guide\\nThe following topics explain the AWS Identity and Access Management permissions required to \\ncreate a model evaluation job using the Amazon Bedrock console, the service role requirements, \\nand the required Cross Origin Resource Sharing (CORS) permissions.\\nTopics\\n•Required permissions to create a model evaluation job using the Amazon Bedrock console\\n•Service role requirements for model evaluation jobs\\n•Required Cross Origin Resource Sharing (CORS) permission on S3 buckets\\n•Data encryption for model evaluation jobs\\nRequired permissions to create a model evaluation job using the \\nAmazon Bedrock console\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nThe IAM permissions required to create a model evaluation job are diﬀerent for automatic model \\nevaluation jobs or model evaluation jobs that uses human workers.\\nBoth automatic and human worker based model evaluation jobs require access to Amazon S3 and \\nAmazon Bedrock. To create human-based model evaluation jobs, you need additional permissions \\nfrom Amazon Cognito and Amazon SageMaker.\\nTo learn more about the required service roles for creating automatic and human-based model \\nevaluation jobs, see Service role requirements for model evaluation jobs\\nRequired permissions to create an automatic model evaluation job\\nThe following policy contains the minimum set of IAM actions and resource in Amazon Bedrock and \\nAmazon S3 required to create an automatic  model evaluation job.\\n{ \\n    \"Version\": \"2012-10-17\", \\nConsole permission requirements 272Amazon Bedrock User Guide\\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"Bedrock Console\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n               \"bedrock:CreateModelEvaluationJob\", \\n               \"bedrock:GetModelEvaluationJob\", \\n               \"bedrock:ListModelEvaluationJobs\", \\n               \"bedrock:GetCustomModel\", \\n               \"bedrock:ListCustomModels\", \\n               \"bedrock:CreateProvisionedModelThroughput\", \\n               \"bedrock:UpdateProvisionedModelThroughput\", \\n               \"bedrock:GetProvisionedModelThroughput\", \\n               \"bedrock:ListProvisionedModelThroughputs\", \\n               \"bedrock:ListTagsForResource\", \\n               \"bedrock:UntagResource\", \\n               \"bedrock:TagResource\" \\n            ], \\n            \"Resource\": \"*\" \\n        }, \\n        { \\n            \"Sid\": \"Allow Console S3 Access For Model Evaluation\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n              \"s3:GetObject\", \\n              \"s3:GetBucketCORS\", \\n              \"s3:ListBucket\", \\n              \"s3:ListBucketVersions\", \\n              \"s3:GetBucketLocation\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]\\n} \\nRequired permissions to create a human-based model evaluation job\\nTo create a model evaluation job that uses human workers from the Amazon Bedrock console you \\nneed to have additional permissions added to your user, group, or role.\\nThe following policy contains the minimum set of IAM actions and resources required from Amazon \\nCognito and Amazon SageMaker to create an human  based model evaluation job. You must \\nappend this policy to the base policy requirements for an automatic job.\\nConsole permission requirements 273Amazon Bedrock User Guide\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"Allow Cognition Actions For Work Team Creation\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n               \"cognito-idp:CreateUserPool\", \\n               \"cognito-idp:CreateUserPoolClient\", \\n               \"cognito-idp:CreateGroup\", \\n               \"cognito-idp:AdminCreateUser\", \\n               \"cognito-idp:AdminAddUserToGroup\", \\n               \"cognito-idp:CreateUserPoolDomain\", \\n               \"cognito-idp:UpdateUserPool\", \\n               \"cognito-idp:ListUsersInGroup\", \\n               \"cognito-idp:ListUsers\", \\n               \"cognito-idp:AdminRemoveUserFromGroup\" \\n            ], \\n            \"Resource\": \"*\" \\n        }, \\n        { \\n            \"Sid\": \"Allow SageMaker Resource Creation\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"sagemaker:CreateFlowDefinition\", \\n                \"sagemaker:CreateWorkforce\", \\n                \"sagemaker:CreateWorkteam\", \\n                \"sagemaker:DescribeFlowDefinition\", \\n                \"sagemaker:ListFlowDefinitions\", \\n                \"sagemaker:DescribeWorkforce\", \\n                \"sagemaker:DescribeWorkteam\", \\n                \"sagemaker:ListWorkteams\", \\n                \"sagemaker:ListWorkforces\", \\n                \"sagemaker:DeleteFlowDefinition\", \\n                \"sagemaker:RenderUiTemplate\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]\\n} \\nConsole permission requirements 274Amazon Bedrock User Guide\\nService role requirements for model evaluation jobs\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nTo create a model evaluation job, you must specify a service role.\\nA service role is an IAM role that a service assumes to perform actions on your behalf. An IAM \\nadministrator can create, modify, and delete a service role from within IAM. For more information, \\nsee Creating a role to delegate permissions to an AWS service in the IAM User Guide .\\nThe required IAM permissions are diﬀerent for automatic or human based model evaluation jobs. \\nUse the following sections to learn more about the required Amazon Bedrock, Amazon SageMaker, \\nand Amazon S3 IAM actions, service principals, and resources.\\nEach of the following sections describe what permission are needed based on the type of model \\nevaluation job you want to run.\\nTopics\\n•Service role requirements for automatic model evaluation jobs\\n•Service role requirements for model evaluation jobs that use human evaluators\\nService role requirements for automatic model evaluation jobs\\nTo create an automatic model evaluation job, you must specify a service role. The policy you attach \\ngrants Amazon Bedrock access to resources in your account, and allows Amazon Bedrock to invoke \\nthe selected model on your behalf.\\nYou must also attach a trust policy that deﬁnes Amazon Bedrock as the service principal using\\nbedrock.amazonaws.com . Each of the following policy examples shows you the exact IAM \\nactions that are required based on each service invoked in an automatic model evaluation job.\\nTo create a custom service role, see Creating a role that uses a custom trust policy in the IAM User \\nGuide .\\nService roles 275Amazon Bedrock User Guide\\nRequired Amazon S3 IAM actions\\nThe following policy example grants access to the S3 buckets where your model evaluation results \\nare saved, and (optionally) access to any custom prompt datasets you have speciﬁed.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"AllowAccessToCustomDatasets\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3:::my_customdataset1_bucket\", \\n                \"arn:aws:s3:::my_customdataset1_bucket/myfolder\" \\n                \"arn:aws:s3:::my_customdataset2_bucket\", \\n                \"arn:aws:s3:::my_customdataset2_bucket/myfolder\", \\n            ] \\n        }, \\n        { \\n            \"Sid\": \"AllowAccessToOutputBucket\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:ListBucket\", \\n                \"s3:PutObject\", \\n                \"s3:GetBucketLocation\", \\n                \"s3:AbortMultipartUpload\", \\n                \"s3:ListBucketMultipartUploads\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3:::my_output_bucket\", \\n                \"arn:aws:s3:::my_output_bucket/myfolder\" \\n            ] \\n        } \\n    ]\\n}\\nRequired Amazon Bedrock IAM actions\\nService roles 276Amazon Bedrock User Guide\\nYou also need to create a policy that allows Amazon Bedrock to invoke the model you plan to \\nspecify in the automatic model evaluation job. To learn more about managing access to Amazon \\nBedrock models, see Model access.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"AllowSpecificModels\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:InvokeModel\", \\n                \"bedrock:InvokeModelWithResponseStream\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:bedrock:region::foundation-model/model-id-of-foundational-\\nmodel\", \\n            ] \\n        } \\n    ]\\n}\\nOptional AWS Key Management Service IAM actions\\nIf you used AWS Key Management Service to encrypt the S3 buckets that hold either your custom \\nprompt dataset or where your result will be saved you need to add the following AWS KMS policy. \\nThe service role needs permissions to use your customer managed key.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"AllowUseOfKmsKey\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"kms:Decrypt\", \\n                \"kms:GenerateDataKey\", \\n            ], \\n    \"Resource\": \"arn:aws:kms: us-west-1 :111122223333:key/ key-id\" \\n        } \\n    ]\\n}\\nService roles 277Amazon Bedrock User Guide\\nService principal requirements\\nYou must also specify a trust policy that deﬁnes Amazon Bedrock as the service principal. This \\nallows Amazon Bedrock to assume the role. The wildcard (*) model evaluation job ARN is required \\nso that Amazon Bedrock can create model evaluation jobs in your AWS account.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Sid\": \"AllowBedrockToAssumeRole\", \\n        \"Effect\": \"Allow\", \\n        \"Principal\": { \\n            \"Service\": \"bedrock.amazonaws.com\" \\n        }, \\n        \"Action\": \"sts:AssumeRole\", \\n        \"Condition\": { \\n            \"StringEquals\": { \\n                \"aws:SourceAccount\": \"111122223333\" \\n            }, \\n            \"ArnEquals\": { \\n                \"aws:SourceArn\": \"arn:aws:bedrock: us-east-1 :111122223333:model-\\nevaluation-job/*\" \\n            } \\n        } \\n    }]\\n}\\nService role requirements for model evaluation jobs that use human evaluators\\nTo create a model evaluation job that uses human evaluators, you must specify two service roles.\\nThe following lists summarize the IAM policy requirements for each required service role that must \\nbe speciﬁed in the Amazon Bedrock console.\\nSummary of IAM policy requirements for the Amazon Bedrock service role\\n•You must attach a trust policy which deﬁnes Amazon Bedrock as the service principal.\\n•You must allow Amazon Bedrock to invoke the selected models on your behalf.\\n•You must allow Amazon Bedrock to access the S3 bucket that holds your prompt dataset and the \\nS3 bucket where you want the results saved.\\n•You must allow Amazon Bedrock to create the required human loop resources in your account.\\nService roles 278Amazon Bedrock User Guide\\n•(Optional) You must allow Amazon Bedrock to decrypt your KMS key if you\\'ve encrypted your \\nprompt dataset bucket or the Amazon S3 bucket where you want the results saved.\\nSummary of IAM policy requirements for the Amazon SageMaker service role\\n•You must attach a trust policy which deﬁnes SageMaker as the service principal.\\n•You must allow SageMaker to access the S3 bucket that holds your prompt dataset and the S3 \\nbucket where you want the results saved.\\n•(Optional) You must allow SageMaker to use your customer managed keys if you\\'ve encrypted \\nyour prompt dataset bucket or the location where you wanted the results.\\nTo create a custom service role, see Creating a role that uses a custom trust policy in the IAM User \\nGuide .\\nRequired Amazon S3 IAM actions\\nThe following policy example grants access to the S3 buckets where your model evaluation results \\nare saved, and access to the custom prompt dataset you have speciﬁed. You need to attach this \\npolicy to both the SageMaker service role and the Amazon Bedrock service role.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"AllowAccessToCustomDatasets\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: custom-prompt-dataset \" \\n            ] \\n        }, \\n        { \\n            \"Sid\": \"AllowAccessToOutputBucket\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:ListBucket\", \\nService roles 279Amazon Bedrock User Guide\\n                \"s3:PutObject\", \\n                \"s3:GetBucketLocation\", \\n                \"s3:AbortMultipartUpload\", \\n                \"s3:ListBucketMultipartUploads\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: model_evaluation_job_output \" \\n            ] \\n        } \\n    ]\\n}\\nRequired Amazon Bedrock IAM actions\\nYou also need to create a policy that allows Amazon Bedrock to invoke the model you plan to \\nspecify in the automatic model evaluation job. You must attach this policy to the Amazon Bedrock \\nservice role.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"AllowSpecificModels\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:InvokeModel\", \\n                \"bedrock:InvokeModelWithResponseStream\" \\n            ], \\n            \"Resource\": [ \\n    \"arn:aws:bedrock: us-west-1 ::foundation-model/model-id-of-foundational-model\", \\n            ] \\n        } \\n    ]\\n}\\nRequired Amazon Augmented AI IAM actions\\nYou also to create a policy that allows Amazon Bedrock to create resources related to human-based \\nmodel evaluation jobs. Because Amazon Bedrock creates the needed resources to start the model \\nevaluation job, you must use \"Resource\": \"*\" . You must attach this policy to the Amazon \\nBedrock service role.\\nService roles 280Amazon Bedrock User Guide\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"ManageHumanLoops\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"sagemaker:StartHumanLoop\", \\n                \"sagemaker:DescribeFlowDefinition\", \\n                \"sagemaker:DescribeHumanLoop\", \\n                \"sagemaker:StopHumanLoop\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]\\n}\\nOptional AWS Key Management Service IAM actions\\nIf you used AWS Key Management Service to encrypt the S3 buckets that hold either your custom \\nprompt dataset or where your result will be saved you need to add the following AWS KMS policy. \\nThe service role needs permissions to use your customer managed key. You must attach this policy \\nto the SageMaker service role and the Amazon Bedrock service role.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        {  \\n            \"Sid\": \"AllowAccessToKMS\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"kms:Decrypt\", \\n                \"kms:GenerateDataKey\" \\n            ], \\n            \"Resource\": [ \\n              \"arn:aws:kms: us-east-1 :111122223333:key/ key id-\" \\n            ], \\n            \"Condition\": { \\n                \"StringEquals\": { \\n                    \"kms:ViaService\": [ \\n                        \"s3.region.amazonaws.com\" \\n                    ] \\nService roles 281Amazon Bedrock User Guide\\n                } \\n            } \\n        } \\n    ]\\n}\\nService principal requirements (Amazon Bedrock)\\nYou must also specify a trust policy that deﬁnes Amazon Bedrock as the service principal. This \\nallows Amazon Bedrock to assume the role.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Sid\": \"AllowBedrockToAssumeRole\", \\n        \"Effect\": \"Allow\", \\n        \"Principal\": { \\n            \"Service\": \"bedrock.amazonaws.com\" \\n        }, \\n        \"Action\": \"sts:AssumeRole\", \\n        \"Condition\": { \\n            \"StringEquals\": { \\n                \"aws:SourceAccount\": \"111122223333\" \\n            }, \\n            \"ArnEquals\": { \\n                \"aws:SourceArn\": \"arn:aws:bedrock: us-east-1 :111122223333:model-\\nevaluation-job/*\" \\n            } \\n        } \\n    }]\\n}\\nService principal requirements (SageMaker)\\nYou must also specify a trust policy that deﬁnes Amazon Bedrock as the service principal. This \\nallows SageMaker to assume the role.\\n{ \\n  \"Version\": \"2012-10-17\", \\n  \"Statement\": [ \\n    { \\n      \"Sid\": \"AllowSageMakerToAssumeRole\", \\nService roles 282Amazon Bedrock User Guide\\n      \"Effect\": \"Allow\", \\n      \"Principal\": { \\n        \"Service\": \"sagemaker.amazonaws.com\" \\n      }, \\n      \"Action\": \"sts:AssumeRole\" \\n    } \\n  ]\\n}\\nRequired Cross Origin Resource Sharing (CORS) permission on S3 \\nbuckets\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nFor custom prompt datasets, you must specify a CORS conﬁguration on the S3 bucket. A CORS \\nconﬁguration is a document that deﬁnes rules that identify the origins that you will allow to access \\nyour bucket, the operations (HTTP methods) supported for each origin, and other operation-\\nspeciﬁc information. To learn more about setting the required CORS conﬁguration using the S3 \\nconsole, see Conﬁguring cross-origin resource sharing (CORS) in the Amazon S3 User Guide\\nThe following is the minimal required CORS conﬁguration for S3 buckets.\\n[ \\n    { \\n        \"AllowedHeaders\": [ \\n            \"*\" \\n        ], \\n        \"AllowedMethods\": [ \\n            \"GET\", \\n            \"PUT\", \\n            \"POST\", \\n            \"DELETE\" \\n        ], \\n        \"AllowedOrigins\": [ \\n            \"*\" \\nCORS permission requirements 283Amazon Bedrock User Guide\\n        ], \\n        \"ExposeHeaders\": [\"Access-Control-Allow-Origin\"] \\n    }\\n]\\nData encryption for model evaluation jobs\\nNote\\nModel evaluation is in preview release for Amazon Bedrock and is subject to change. To \\nuse model evaluation jobs, you must be in either US East (N. Virginia) Region or US West \\n(Oregon) Region.\\nCustomer data is always encrypted, both in transit and at rest, for Amazon Bedrock model \\nevaluation jobs. Model evaluation jobs support using customer managed keys on data that is used \\nas either an input or output for a model evaluation job in Amazon Bedrock. If you do not specify \\na customer managed key when you create the model evaluation job, the default AWS-managed \\nkey for Amazon S3 is used for encryption. Amazon Bedrock stores intermediary customer data, \\nsuch as your prompt datasets, during a model evaluation job, encrypting it at rest using a service-\\nmanaged KMS key. This intermediary data is permanently deleted when the model evaluation job \\nis completed.\\nData encryption 284Amazon Bedrock User Guide\\nKnowledge base for Amazon Bedrock\\nKnowledge base for Amazon Bedrock provides you the capability of amassing data sources into \\na repository of information. With knowledge bases, you can easily build an application that \\ntakes advantage of retrieval augmented generation (RAG), a technique in which the retrieval of \\ninformation from data sources augments the generation of model responses. Once set up, you can \\ntake advantage of a knowledge base in the following ways.\\n•Conﬁgure your RAG application to use the RetrieveAndGenerate API to query your knowledge \\nbase and generate responses from the information it retrieves.\\n•Associate your knowledge base with an agent (for more information, see Agents for Amazon \\nBedrock) to add RAG capability to the agent by helping it reason through the steps it can take to \\nhelp end users.\\n•Create a custom orchestration ﬂow in your application by using the Retrieve API to retrieve \\ninformation directly from the knowledge base.\\nA knowledge base can be used not only to answer user queries, but also to augment prompts \\nprovided to foundation models by providing context to the prompt. Knowledge base responses \\nalso come with citations, such that users can ﬁnd further information by looking up the exact text \\nthat a response is based on and also check that the response makes sense and is factually correct.\\nYou take the following steps to set up and use your knowledge base.\\n1. Conﬁgure the data sources to add to your knowledge base.\\n2. Upload your data to an Amazon S3 bucket.\\n3. Ingest your data by generating embeddings with a foundation model and storing them in a \\nsupported vector store.\\n4. Set up your application or agent to query the knowledge base and return augmented \\nresponses.\\nTopics\\n•How it works\\n•Supported regions and models for Knowledge base for Amazon Bedrock\\n•Prerequisites for Knowledge base for Amazon Bedrock\\n285Amazon Bedrock User Guide\\n•Create a knowledge base\\n•Sync to ingest your data sources into the knowledge base\\n•Test a knowledge base\\n•Manage a data source\\n•Manage a knowledge base\\n•Deploy a knowledge base\\nHow it works\\nKnowledge base for Amazon Bedrock help you take advantage of Retrieval Augmented Generation \\n(RAG), a popular technique that involves drawing information from a data store to augment the \\nresponses generated by Large Language Models (LLMs). When you set up a knowledge base with \\nyour data sources, your application can query the knowledge base to return information to answer \\nthe query either with direct quotations from sources or with natural responses generated from the \\nquery results.\\nWith knowledge bases, you can build applications that are enriched by the context that is received \\nfrom querying a knowledge base. It enables a faster time to market by abstracting from the heavy \\nlifting of building pipelines and providing you an out-of-the-box RAG solution to reduce the build \\ntime for your application. Adding a knowledge base also increases cost-eﬀectiveness by removing \\nthe need to continually train your model to be able to leverage your private data.\\nThe following diagrams illustrate schematically how RAG is carried out. Knowledge base simpliﬁes \\nthe setup and implementation of RAG by automating several steps in this process.\\nPre-processing data\\nTo enable eﬀective retrieval from private data, a common practice is to ﬁrst split the documents \\ninto manageable chunks for eﬃcient retrieval. The chunks are then converted to embeddings \\nand written to a vector index, while maintaining a mapping to the original document. These \\nembeddings are used to determine semantic similarity between queries and text from the data \\nsources. The following image illustrates pre-processing of data for the vector database.\\nHow it works 286Amazon Bedrock User Guide\\nRuntime execution\\nAt runtime, an embedding model is used to convert the user\\'s query to a vector. The vector index \\nis then queried to ﬁnd chunks that are semantically similar to the user\\'s query by comparing \\ndocument vectors to the user query vector. In the ﬁnal step, the user prompt is augmented with \\nthe additional context from the chunks that are retrieved from the vector index. The prompt \\nalongside the additional context is then sent to the model to generate a response for the user. The \\nfollowing image illustrates how RAG operates at runtime to augment responses to user queries.\\nSupported regions and models for Knowledge base for Amazon \\nBedrock\\nKnowledge base for Amazon Bedrock is supported in the following regions:\\nSupported regions and models 287Amazon Bedrock User Guide\\nRegion\\nUS East (N. Virginia)\\nUS West (Oregon)\\nYou can use the following models to embed your data sources in a vector store:\\nModel name Model ID\\nAmazon Titan Embeddings G1 - Text amazon.titan-embed-text-v1\\nCohere Embed (English) cohere.embed-english-v3\\nCohere Embed (Multilingual) cohere.embed-multilingual-v3\\nYou can use the following models to generate responses after retrieving information from \\nknowledge bases:\\nModel Model ID\\nAnthropic Claude Instant v1 anthropic.claude-instant-v1\\nAnthropic Claude v2.0 anthropic.claude-v2\\nAnthropic Claude v2.1 anthropic.claude-v2:1\\nPrerequisites for Knowledge base for Amazon Bedrock\\nBefore you can create a knowledge base, you need to fulﬁll the following prerequisites:\\n1.Prepare the ﬁles containing information that you want your knowledge base to contain to create \\na data source for your knowledge base. Then upload the ﬁles to an Amazon S3 bucket.\\n2.(Optional) Set up a vector store of your choice. You can skip this prerequisite if you plan to use \\nthe AWS Management Console to automatically create a vector store in Amazon OpenSearch \\nServerless for you.\\nPrerequisites 288Amazon Bedrock User Guide\\n3.(Optional) Create a custom AWS Identity and Access Management (IAM) service role with the \\nproper permissions by following the instructions at Create a service role for Knowledge base for \\nAmazon Bedrock. You can skip this prerequisite if you plan to use the AWS Management Console \\nto automatically create a service role for you.\\n4.(Optional) Set up extra security conﬁgurations by following the steps at Encryption of \\nknowledge base resources.\\nTopics\\n•Set up a data source for your knowledge base\\n•Set up a vector store for your knowledge base\\nSet up a data source for your knowledge base\\nA data source contains ﬁles with information that can be retrieved when your knowledge base is \\nqueried. You set up the data source for your knowledge base by uploading ﬁles to an Amazon S3 \\nbucket. The following ﬁle formats are supported.\\nFormat Extension\\nPlain text .txt\\nMarkdown .md\\nHyperText Markup Language .html\\nMicrosoft Word document .doc/.docx\\nComma-separated values .csv\\nMicrosoft Excel spreadsheet .xls/.xlsx\\nPortable Document .pdf\\nNote\\nThe maximum ﬁle size is 50 MB.\\nSet up a data source 289Amazon Bedrock User Guide\\nWhen you ingest your data into a knowledge base, it is split into chunks . A chunk  refers to an \\nexcerpt from a data source that is returned when the knowledge base that it belongs to is queried. \\nConsider which of the following chunking strategies you want to use for your data source.\\n•Default chunking  – By default, Amazon Bedrock automatically splits your source data into \\nchunks, such that each chunk contains, at most, approximately 300 tokens. If a document \\ncontains less than 300 tokens, then it is not split any further.\\n•Fixed size chunking – Amazon Bedrock splits your source data into chunks of the approximate \\nsize that you set.\\n•No chunking  – Amazon Bedrock treats each ﬁle as one chunk. If you choose this option, you may \\nwant to pre-process your documents by splitting them into separate ﬁles before uploading them \\nto an Amazon S3 bucket.\\nSet up a vector store for your knowledge base\\nYou set up a supported vector store to index your data sources by creating ﬁelds to store the \\nfollowing data.\\n•The text chunks extracted from the ﬁles in your data source.\\n•The vectors generated from the text in your data source by the embeddings model that you \\nchoose.\\n•Metadata that Amazon Bedrock manages is related to your knowledge base.\\nSelect the tab corresponding to the service that you will use to create your vector store.\\nNote\\nIf you prefer for Amazon Bedrock to automatically create a vector store in Amazon \\nOpenSearch Serverless for you, skip this prerequisite and proceed to Create a knowledge \\nbase .\\nSet up a vector store 290Amazon Bedrock User Guide\\nAmazon OpenSearch Serverless\\nTo set up an Amazon OpenSearch Serverless vector search collection\\n1. Log into Amazon OpenSearch Serverless and create a collection. Take note of the\\nCollection ARN, which you will ﬁll out when you create a knowledge base.\\n2. Once the collection is created, select it and create a vector index.\\n3. While you set up the vector store, take note of the Collection ARN, which you will ﬁll out \\nwhen you create a knowledge base.\\n4. There are additional conﬁgurations that you must provide when creating a vector store:\\n•Vector index name – The name of the vector index. Choose any valid name of your \\nchoice. Later, when you create your knowledge base, enter the name you choose in the\\nVector index name ﬁeld.\\n•Vector ﬁeld – The ﬁeld where the vector embeddings will be stored. Choose any valid \\nname of your choice. Later, when you create your knowledge base, enter the name you \\nchoose in the Vector ﬁeld ﬁeld.\\n•Dimensions  – The number of dimensions in the vector. Refer to the following table to \\ndetermine how many dimensions the vector should contain.\\nModel Dimensions\\nTitan G1 Embeddings - Text 1,536\\nCohere Embed English 1,024\\nCohere Embed Multilingual 1,024\\n•Distance metric – The metric used to measure the similarity between vectors.. \\nWe recommend that you experiment with diﬀerent metrics for your use-case. We \\nrecommend starting with cosine similarity.\\n•Metadata management  – Expand this ﬁeld and conﬁgure the vector index to store \\nadditional metadata that a knowledge base can retrieve with vectors. The ﬁelds you need \\nto conﬁgure are as follows:\\n•Text ﬁeld – Amazon Bedrock chunks the raw text in your data and stores the chunks in \\nthis ﬁeld.\\nSet up a vector store 291Amazon Bedrock User Guide\\n•Mapping ﬁeld – The ﬁeld where the text will be stored. Choose any valid name \\nof your choice. Later, when you create your knowledge base, enter the name you \\nchoose for the Text ﬁeld name ﬁeld.\\n•Data type – Select String .\\n•Filterable – Select True .\\n•Bedrock-managed metadata ﬁeld – Amazon Bedrock stores metadata related to your \\nknowledge base in this ﬁeld.\\n•Mapping ﬁeld – Choose any valid name of your choice. Later, when you create your \\nknowledge base, enter the name you choose for the Bedrock-managed metadata \\nﬁeld name ﬁeld.\\n•Data type – Select String .\\n•Filterable – Select False .\\n5. Take note of the vector index name, vector ﬁeld name, and the ﬁelds that you set to store \\nthe text and the metadata.\\nFor detailed documentation on setting up a vector store in Amazon OpenSearch Serverless, see\\nWorking with vector search collections.\\nAmazon Aurora\\n1. Create an Amazon Aurora database (DB) cluster by following the steps at Preparing Aurora \\nPostgreSQL to be used as a Knowledge Base. The table should be conﬁgured with the \\nfollowing columns.\\nColumn name Data type Correspon \\nding ﬁeld in \\nknowledge \\nbase setup \\n(Console)Correspon \\nding ﬁeld in \\nknowledge \\nbase setup \\n(API)Description\\nid UUID primary \\nkeyPrimary keyprimaryKe \\nyFieldContains \\nunique \\nidentiﬁers for \\neach record.\\nSet up a vector store 292Amazon Bedrock User Guide\\nColumn name Data type Correspon \\nding ﬁeld in \\nknowledge \\nbase setup \\n(Console)Correspon \\nding ﬁeld in \\nknowledge \\nbase setup \\n(API)Description\\nembedding VectorVector ﬁeldvectorFie \\nldContains \\nthe vector \\nembedding \\ns of the data \\nsources.\\nchunks TextText ﬁeld textField Contains the \\nchunks of raw \\ntext from your \\ndata sources.\\nmetadata JSONAmazon \\nBedrock-\\nmanaged \\nmetadata ﬁeldmetadataF \\nieldContains \\nmetadata \\nrequired to \\ncarry out \\nsource attributi \\non and to \\nenable data \\ningestion and \\nquerying\\n2. You can use column names of your liking instead of the ones listed in the table above. Take \\nnote of the column names you choose so that you can provide them during knowledge \\nbase setup.\\n3. Conﬁgure an AWS Secrets Manager secret for your Aurora DB cluster by following the steps \\nat Password management with Amazon Aurora and AWS Secrets Manager.\\n4. Take note of the following information after you create your DB cluster and set up the \\nsecret.\\nSet up a vector store 293Amazon Bedrock User Guide\\nField in knowledge base \\nsetup (Console)Field in knowledge base \\nsetup (API)Description\\nAmazon Aurora DB Cluster \\nARNresourceArn The ARN of your DB cluster.\\nDatabase name databaseName The name of your database\\nTable name tableName The name of the table in \\nyour DB cluster\\nSecret ARN credentialsSecretArnThe ARN of the AWS \\nSecrets Manager key for \\nyour DB cluster\\nPinecone\\nNote\\nIf you use Pinecone, you agree to authorize AWS to access the designated third-party \\nsource on your behalf in order to provide vector store services to you. You\\'re responsible \\nfor complying with any third-party terms applicable to use and and transfer of data \\nfrom the third-party service.\\nFor detailed documentation on setting up a vector store in Pinecone, see Pinecone as a \\nKnowledge Base for Amazon Bedrock.\\nWhile you set up the vector store, take note of the following information, which you will ﬁll out \\nwhen you create a knowledge base:\\n•Connection string – The endpoint URL for your index management page.\\n•Namespace – (Optional) The namespace to be used to write new data to your database. For \\nmore information, see Using namespaces.\\nThere are additional conﬁgurations that you must provide when creating a Pinecone index:\\nSet up a vector store 294Amazon Bedrock User Guide\\n•Name  – The name of the vector index. Choose any valid name of your choice. Later, when you \\ncreate your knowledge base, enter the name you choose in the Vector index name ﬁeld.\\n•Dimensions  – The number of dimensions in the vector. Refer to the following table to \\ndetermine how many dimensions the vector should contain.\\nModel Dimensions\\nTitan G1 Embeddings - Text 1,536\\nCohere Embed English 1,024\\nCohere Embed Multilingual 1,024\\n•Distance metric – The metric used to measure the similarity between vectors. We recommend \\nthat you experiment with diﬀerent metrics for your use-case. We recommend starting with\\ncosine similarity.\\nTo access your Pinecone index, you must provide your Pinecone API key to Amazon Bedrock \\nthrough the AWS Secrets Manager.\\nTo set up a secret for your Pinecone conﬁguration\\n1. Follow the steps at Create an AWS Secrets Manager secret, setting the key as apiKey  and \\nthe value as the API key to access your Pinecone index.\\n2. To ﬁnd your API key, open your Pinecone console and select API Keys.\\n3. After you create the secret, take note of the ARN of the KMS key.\\n4. Attach permissions to your service role to decrypt the ARN of the KMS key by following \\nthe steps in Permissions to decrypt an AWS Secrets Manager secret for the vector store \\ncontaining your knowledge base.\\n5. Later, when you create your knowledge base, enter the ARN in the Credentials secret ARN\\nﬁeld.\\nSet up a vector store 295Amazon Bedrock User Guide\\nRedis Enterprise Cloud\\nNote\\nIf you use Redis Enterprise Cloud, you agree to authorize AWS to access the designated \\nthird-party source on your behalf in order to provide vector store services to you. You\\'re \\nresponsible for complying with any third-party terms applicable to use and and transfer \\nof data from the third-party service.\\nFor detailed documentation on setting up a vector store in Redis Enterprise Cloud, see\\nIntegrating Redis Enterprise Cloud with Amazon Bedrock.\\nWhile you set up the vector store, take note of the following information, which you will ﬁll out \\nwhen you create a knowledge base:\\n•Endpoint URL  – The public endpoint URL for your database.\\n•Vector index name – The name of the vector index for your database.\\n•Vector ﬁeld – The name of the ﬁeld where the vector embeddings will be stored. Refer to the \\nfollowing table to determine how many dimensions the vector should contain.\\nModel Dimensions\\nTitan G1 Embeddings - Text 1,536\\nCohere Embed English 1,024\\nCohere Embed Multilingual 1,024\\n•Text ﬁeld – The name of the ﬁeld where the Amazon Bedrock stores the chunks of raw text.\\n•Bedrock-managed metadata ﬁeld – The name of the ﬁeld where Amazon Bedrock stores \\nmetadata related to your knowledge base.\\nTo access your Redis Enterprise Cloud cluster, you must provide your Redis Enterprise Cloud \\nsecurity conﬁguration to Amazon Bedrock through the AWS Secrets Manager.\\nSet up a vector store 296Amazon Bedrock User Guide\\nTo set up a secret for your Redis Enterprise Cloud conﬁguration\\n1. Enable TLS to use your database with Amazon Bedrock by following the steps at Transport \\nLayer Security (TLS).\\n2. Follow the steps at Create an AWS Secrets Manager secret. Set up the following keys with \\nthe appropriate values from your Redis Enterprise Cloud conﬁguration in the secret:\\n•username  – The username to access your Redis Enterprise Cloud database. To ﬁnd your \\nusername, look under the Security section of your database in the Redis Console.\\n•password  – The password to access your Redis Enterprise Cloud database. To ﬁnd your \\npassword, look under the Security section of your database in the Redis Console.\\n•serverCertificate  – The content of the certiﬁcate from the Redis Cloud Certiﬁcate \\nauthority. Download the server certiﬁcate from the Redis Admin Console by following the \\nsteps at Download certiﬁcates.\\n•clientPrivateKey  – The private key of the certiﬁcate from the Redis Cloud Certiﬁcate \\nauthority. Download the server certiﬁcate from the Redis Admin Console by following the \\nsteps at Download certiﬁcates.\\n•clientCertificate  – The public key of the certiﬁcate from the Redis Cloud Certiﬁcate \\nauthority. Download the server certiﬁcate from the Redis Admin Console by following the \\nsteps at Download certiﬁcates.\\n3. After you create the secret, take note of its ARN. Later, when you create your knowledge \\nbase, enter the ARN in the Credentials secret ARN  ﬁeld.\\nCreate a knowledge base\\nNote\\nYou can’t create a knowledge base with a root user. Log in with an IAM user before starting \\nthese steps.\\nAfter you set up your data source in Amazon S3 and a vector store of your choice, you can create a \\nknowledge base. Select the tab corresponding to your method of choice and follow the steps.\\nCreate a knowledge base 297Amazon Bedrock User Guide\\nConsole\\nTo create a knowledge base\\n1. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/ and \\nselect Knowledge base from the left navigation pane.\\n2. In the Knowledge bases section, select Create knowledge base.\\n3. On the Provide knowledge base details page, set up the following conﬁgurations:\\na. In the Knowledge base details section, provide a name and description for your \\nknowledge base.\\nb. In the IAM permissions  section, choose an AWS Identity and Access Management \\n(IAM) role that provides Amazon Bedrock permission to access other AWS services. \\nYou can let Amazon Bedrock create the service role or choose a custom role that you \\nhave created. For more information about setting up a custom role with the proper \\npermissions, see Create a service role for Knowledge base for Amazon Bedrock.\\nc. (Optional) Add tags to your knowledge base. For more information, see Tag resources.\\nd. Select Next.\\n4. On the Set up data source page, provide the information for the data source to add to the \\nknowledge base:\\na. Provide a name for the data source and the URI of the Amazon S3 object.\\nb. (Optional) If you encrypted your Amazon S3 data with a customer managed key, select\\nAdd customer-managed AWS KMS key for Amazon S3 data and choose a KMS key to \\nallow Amazon Bedrock to decrypt it.\\nc. (Optional) While converting your data into embeddings, Amazon Bedrock encrypts \\nyour data with a key that AWS owns and manages, by default. To use your own KMS \\nkey, expand Advanced settings, select Customize encryption settings (advanced), and \\nchoose a key. For more information, see Encryption of transient data storage during \\ndata ingestion .\\nd. (Optional) Select the Chunking strategy  for your data source.\\nImportant\\nYou can\\'t change the chunking strategy after you have created the data source.\\nCreate a knowledge base 298Amazon Bedrock User Guide\\n•Default chunking  – By default, Amazon Bedrock automatically splits your source \\ndata into chunks, such that each chunk contains, at most, 300 tokens. If a document \\ncontains less than 300 tokens, then it is not split any further.\\n•Fixed size chunking – Amazon Bedrock splits your source data into chunks of the \\napproximate size that you set. Conﬁgure the following options.\\n•Max tokens – Amazon Bedrock creates chunks that don\\'t exceed the number of \\ntokens that you choose.\\n•Overlap percentage between chunks – Each chunk overlaps with consecutive \\nchunks by the percentage that you choose.\\n•No chunking  – Amazon Bedrock treats each ﬁle as one chunk. If you choose this \\noption, you may want to pre-process your documents by splitting them into separate \\nﬁles.\\ne. Select Next.\\n5. In the Embeddings model  section, choose an embeddings model to convert the knowledge \\nbase from your data into an embedding. Currently, the following models are supported.\\n•Titan G1 Embeddings - Text\\n•Cohere Embed English\\n•Cohere Embed Multilingual\\n6. In the Vector database section, choose one of the following options.\\n• Quick create a new vector store – Amazon Bedrock creates an Amazon OpenSearch \\nServerless vector search collection, automatically conﬁgures the settings for \\nembedding your data sources, and manages the collection for you.\\na. (Optional) To enable redundant active replicas, such that the availability of your \\nvector store isn\\'t compromised in case of infrastructure failure, select Enable \\nredundancy (active replicas).\\nNote\\nThe default option is cheaper and ideal for testing purposes. We \\nrecommend that you enable redundant active replicas for a knowledge \\nCreate a knowledge base 299Amazon Bedrock User Guide\\nbase that you plan to deploy to production. For more information, see\\nPricing for OpenSearch Serverless.\\nb. (Optional) To encrypt the automated vector store with a customer managed key \\nselect Add customer-managed KMS key for Amazon OpenSearch Serverless \\nvector and choose the key. For more information, see Encryption of information \\npassed to Amazon OpenSearch Service.\\n• Choose a vector store you have created – Select the service that contains a vector \\ndatabase that you have already created. Check that your database is already conﬁgured \\nwith the required ﬁelds (for more information, see Set up a vector store for your \\nknowledge base). Fill in the ﬁelds to allow Amazon Bedrock to map information \\nfrom the knowledge base to your database, so that it can store, update, and manage \\nembeddings.\\nNote\\nIf you use a database in Amazon OpenSearch Serverless or Amazon Aurora, you \\nneed to have conﬁgured the ﬁelds under Metadata ﬁeld mapping beforehand. \\nIf you use a database in Pinecone or Redis Enterprise Cloud, you can provide \\nnames for these ﬁelds here and Amazon Bedrock will dynamically create them \\nin the vector store for you.\\n7. Select Next.\\n8. On the Review and create page, check the conﬁguration and details of your knowledge \\nbase. Select Edit in any section that you need to modify. When you are satisﬁed, select\\nCreate knowledge base.\\n9. The knowledge base creation process begins and the Status  of the source becomes In \\nprogress . The time it takes to create the knowledge base depends on the amount of data \\nyou provided. When the knowledge base is ﬁnished being created, a green success banner \\nappears and the Status  of the knowledge base changes to Ready.\\nAPI\\nTo create a knowledge base, send a CreateKnowledgeBase request with a Agents for Amazon \\nBedrock build-time endpoint and provide the name, description, instructions for what it should \\ndo, and the foundation model for it to orchestrate with.\\nCreate a knowledge base 300Amazon Bedrock User Guide\\nNote\\nIf you prefer to let Amazon Bedrock create and manage a vector store for you in \\nAmazon OpenSearch Service, use the console. For more information, see Create a \\nknowledge base.\\n•Provide the ARN with permissions to create a knowledge base in the roleArn  ﬁeld.\\n•Provide the embedding model to use in the embeddingModelArn  ﬁeld in the\\nknowledgeBaseConfiguration  object.\\n•Provide the conﬁguration for your vector store in the storageConfiguration  object. For \\nmore information, see Set up a vector store for your knowledge base\\n•For an Amazon OpenSearch Service database, use the\\nopensearchServerlessConfiguration  object.\\n•For a Pinecone database, use the pineconeConfiguration  object.\\n•For a Redis Enterprise Cloud database, use the redisEnterpriseCloudConfiguration\\nobject.\\n•For an Amazon Aurora database, use the rdsConfiguration  object.\\nAfter you create a knowledge base, create a data source from the S3 bucket containing the ﬁles \\nfor your knowledge base. To create the data source send a CreateDataSource request.\\n•Provide the information for the S3 bucket containing the data source ﬁles in the\\ndataSourceConfiguration  ﬁeld.\\n•Specify how to chunk the data sources in the vectorIngestionConfiguration  ﬁeld. For \\nmore information, see Set up a data source for your knowledge base.\\nNote\\nYou can\\'t change the chunking conﬁguration after you create the data source.\\n•(Optional) While converting your data into embeddings, Amazon Bedrock encrypts your data \\nwith a key that AWS owns and manages, by default. To use your own KMS key, include it in \\nthe serverSideEncryptionConfiguration  object. For more information, see Encryption \\nof knowledge base resources.\\nCreate a knowledge base 301Amazon Bedrock User Guide\\nIf you are using a custom role, set up security conﬁgurations for your newly created knowledge \\nbase. Follow the steps in the tab corresponding to the database that you set up.\\nOpenSearch Service\\nTo create a data access policy\\n1. In the OpenSearch Service console, navigate to your collection.\\n2. Select Manage data access.\\n3. Select Create access policy and give the policy a name and an optional description.\\n4. Choose JSON as the policy deﬁnition method and paste the following JSON object into \\nthe editor, replacing collection-name  with the name of your collection and service-\\nrole-arn  with the role ARN that you passed when creating your knowledge base.\\n[ \\n    { \\n        \"Rules\": [ \\n          { \\n            \"Resource\": [ \\n              \"index/ collection_name /*\" \\n            ], \\n            \"Permission\": [ \\n              \"aoss:DescribeIndex\", \\n              \"aoss:ReadDocument\", \\n              \"aoss:WriteDocument\" \\n            ], \\n            \"ResourceType\": \"index\" \\n          } \\n        ], \\n        \"Principal\": [ \\n          \" service-role-arn \" \\n        ], \\n        \"Description\": \"Data access policy\" \\n    }\\n] \\n                     \\n5. Select Create  to create the policy.\\nCreate a knowledge base 302Amazon Bedrock User Guide\\nPinecone or Redis Enterprise Cloud\\nTo integrate the third-party knowledge base, attach the following policy to your knowledge \\nbase service role, replacing knowledge-base-arn .\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Effect\": \"Allow\", \\n        \"Action\": [ \\n            \"bedrock:AssociateThirdPartyKnowledgeBase\" \\n        ], \\n        \"Resource\": [ \\n            \" knowledge-base-arn \" \\n        ], \\n        \"Condition\": { \\n            \"StringEquals\": { \\n                \"bedrock:ThirdPartyKnowledgeBaseCredentialsSecretArn\": \"secret-arn\" \\n            } \\n        } \\n    }]\\n}\\nSync to ingest your data sources into the knowledge base\\nAfter you create your knowledge base, you ingest the data sources into the knowledge base so that \\nthey are indexed and able to be queried.\\nNote\\nEach time you add, modify, or remove ﬁles from the S3 bucket for a data source, you must \\nsync the data source so that it is re-indexed to the knowledge base. Syncing is incremental, \\nso Amazon Bedrock only processes the objects in your S3 bucket that have been added, \\nmodiﬁed, or deleted since the last sync.\\nBefore you begin ingestion, check that your ﬁles belong to a supported format and that they do \\nnot exceed the maximum ﬁle size, as detailed in Set up a vector store for your knowledge base and\\nKnowledge base quotas.\\nSync your data sources 303Amazon Bedrock User Guide\\nNote\\nYou can only ingest data sources stored in Amazon S3 buckets that exist in the same region \\nas the knowledge base.\\nSelect the tab corresponding to your method of choice and follow the steps.\\nConsole\\nTo ingest your data sources\\n1. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, select Knowledge base and choose your knowledge base.\\n3. In the Data source section, select Sync  to begin data ingestion.\\n4. When data ingestion completes, a green success banner appears if it is successful.\\n5. You can choose a data source to view its Sync history. Select View warnings  to see why a \\ndata ingestion job failed.\\nAPI\\nTo ingest a data source into the vector store you conﬁgured for your knowledge base, send a\\nStartIngestionJob request with a Agents for Amazon Bedrock build-time endpoint. Specify the\\nknowledgeBaseId  and dataSourceId .\\nUse the ingestionJobId  returned in the response in a GetIngestionJob  request with a Agents \\nfor Amazon Bedrock build-time endpoint to track the status of the ingestion job. In addition, \\nspecify the knowledgeBaseId  and dataSourceId .\\n•When the ingestion job ﬁnishes, the status in the response is COMPLETE .\\n•The statistics  object in the response returns information about whether ingestion was \\nsuccessful or not for documents in the data source.\\nYou can also see information for all ingestion jobs for a data source by sending a\\nListIngestionJobs  request with a Agents for Amazon Bedrock build-time endpoint. Specify the\\ndataSourceId  and the knowledgeBaseId  of the knowledge base that the data is being \\ningested to.\\nSync your data sources 304Amazon Bedrock User Guide\\n•Filter for results by specifying a status to search for in the filters object.\\n•Sort by the time that the job was started or the status of a job by specifying the sortBy\\nobject. You can sort in ascending or descending order.\\n•Set the maximum number of results to return in a response in the maxResults  ﬁeld. If there \\nare more results than the number you set, the response returns a nextToken  that you can \\nsend in another ListIngestionJobs  request to see the next batch of jobs.\\nTest a knowledge base\\nAfter you set up your knowledge base, you can test its behavior by sending queries and seeing \\nthe responses. When you are satisﬁed with your knowledge base\\'s behavior, you can set up your \\napplication to query the knowledge base or attach the knowledge base to an agent.\\nYou can modify the following conﬁgurations for querying the knowledge base:\\n•Search type – The search type deﬁnes how data sources in the knowledge base are queried. The \\nfollowing search types are possible:\\n•Default  – Amazon Bedrock decides the search strategy for you.\\n•Hybrid  – Combines searching vector embeddings (semantic search) with searching through \\nthe raw text. Hybrid search is currently only supported for Amazon OpenSearch Serverless \\nvector stores that contain a ﬁlterable text ﬁeld. If you use a diﬀerent vector store or your \\nAmazon OpenSearch Serverless vector store doesn\\'t contain a ﬁlterable text ﬁeld, the query \\nuses semantic search.\\n•Semantic  – Only searches vector embeddings.\\nSelect the tab corresponding to your method of choice and follow the steps.\\nConsole\\nTo test your knowledge base\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, select Knowledge base.\\n3. In the Knowledge bases section, do one of the following actions:\\nTest a knowledge base 305Amazon Bedrock User Guide\\n• Choose the radio button next to the knowledge base you want to test and select Test \\nknowledge base. A test window expands from the right.\\n• Choose the knowledge base that you want to test. A test window expands from the \\nright.\\n4. (Optional) Select the conﬁgurations icon to open up Conﬁgurations . If you\\'re using an \\nAmazon OpenSearch Serverless vector store conﬁgured with a ﬁlterable text ﬁeld, you can \\nmodify the Search type. See above for details about diﬀerent search types.\\n5. Select or clear Generate responses for your query depending on your use case.\\n• To return information retrieved directly from your knowledge base, turn on Generate \\nresponses . Amazon Bedrock will return text chunks from your data sources that are \\nrelevant to the query.\\n• To generate responses based on information retrieved from your knowledge base, turn \\noﬀ Generate responses . Amazon Bedrock will generate responses based on your data \\nsources and cites the information it provides with footnotes.\\n6. If you turn on Generate responses , choose Select model to choose a model to use for \\nresponse generation. Then select Apply .\\n7. Enter a query in the text box in the chat window and select Run to return responses from \\nthe knowledge base.\\n8. You can examine the response in the following ways.\\n•If you didn\\'t generate responses, the text chunks are returned directly in order of \\nrelevance.\\n•If you generated responses, select a footnote to see an excerpt from the cited source for \\nthat part of the response. Choose the link to navigate to the S3 object containing the ﬁle.\\n•Select Show result details to see the chunks cited for each footnote. You can carry out \\nthe following actions in the Source chunks window.\\n•Select a tab to view the text chunk that was cited.\\n•Select Copy to copy the text chunk.\\n•Select Open S3 location to navigate to the S3 object containing the ﬁle.\\nWhile using the chat window to test your knowledge base, you can also carry out the following \\nactions.\\nTest a knowledge base 306Amazon Bedrock User Guide\\n•If you are generating responses, you can select Change model  to use a diﬀerent model for \\nresponse generation. If you change the model, the text in the chat window will be completely \\ncleared.\\n•Switch between generating responses for your query and returning direct quotations by \\nselecting or clearing Generate responses . If you change the setting, the text in the chat \\nwindow will be completely cleared.\\n•To clear the chat window, select the broom icon.\\n•To copy all the output in the chat window, select the copy icon.\\nAPI\\nRetrieve\\nTo query a knowledge base and only return relevant text from data sources, send a Retrieve\\nrequest with a Agents for Amazon Bedrock runtime endpoint and specify the ID of the \\nknowledge base to query.\\n•Send the query in the text  ﬁeld of the retrievalQuery  object.\\n•Specify how many results to return in the numberOfResults  ﬁeld in the\\nretrievalConfiguration .\\n•By default, Amazon Bedrock decides a search strategy for you. If you\\'re using an Amazon \\nOpenSearch Serverless vector store conﬁgured with a ﬁlterable text ﬁeld, you can specify \\nwhether to use HYBRID  or SEMANTIC  search in the overrideSearchtype  ﬁeld in the\\nretrievalConfiguration . See above for search type details.\\nThe response returns the text in the text  ﬁeld of the content object. You can ﬁnd the S3 \\nlocation of the data source in the location  object.\\nIf there are more results than can be returned in a single response, you can use the value in the\\nnextToken  ﬁeld in another Retrieve  request to return the next batch of results.\\nRetrieveAndGenerate\\nTo query a knowledge base and use a foundation model to generate responses based oﬀ the \\nresults from the data sources, send a RetrieveAndGenerate request with a Agents for Amazon \\nBedrock runtime endpoint.\\nTest a knowledge base 307Amazon Bedrock User Guide\\n•Send the query in the text  ﬁeld of the input object.\\n•Specify the ID of the knowledge base to query and the model to use for response generation \\nin the retrieveAndGenerateConfiguration  object.\\n•By default, Amazon Bedrock decides a search strategy for you. If you\\'re using an Amazon \\nOpenSearch Serverless vector store conﬁgured with a ﬁlterable text ﬁeld, you can specify \\nwhether to use HYBRID  or SEMANTIC  search in the overrideSearchtype  ﬁeld in the\\nretrievalConfiguration . See above for search type details.\\n•If you reuse a sessionId , the model returns a response taking into account previous queries \\nthat were sent to the knowledge base.\\n•(Optional) For security purposes, you can specify the ARN of a KMS key in the kmsKeyArn\\nﬁeld in the sessionConfiguration  object to encrypt the session.\\nThe response includes the following components.\\n•The output contains the full generated text .\\n•The citations  list contains an object for each part of the response that contains \\ninformation from a data source.\\n•The generatedResponsePart  object contains the text  that is generated based oﬀ a \\ndata source and where it starts and ends in the span object.\\n•The retrievedReferences  object contains information about the data source that \\nis cited for the generated text, including the text in the data source chunk and the S3 \\nlocation of the data source.\\n•You can use the sessionId  in another RetrieveAndGenerate  request to continue the \\nsame querying session.\\nManage a data source\\nAfter you create a data source, you can view details about it, update it, or delete it.\\nView information about a data source\\nYou can view information about your data source and its sync history. Select the tab corresponding \\nto your method of choice and follow the steps.\\nManage a data source 308Amazon Bedrock User Guide\\nConsole\\nTo view information about a data source\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, select Knowledge base.\\n3. In the Data source section, select the data source for which you want to view details.\\n4. The Data source overview contains details about the data source.\\n5. The Sync history contains details about when the data source was synced. To see reasons \\nfor why a sync event failed, select a sync event and choose View warnings .\\nAPI\\nTo get information about a data source, send a GetDataSource request with a Agents \\nfor Amazon Bedrock build-time endpoint and specify the dataSourceId  and the\\nknowledgeBaseId  of the knowledge base that it belongs to.\\nTo list information about a knowledge base\\'s data sources, send a ListDataSources request with \\na Agents for Amazon Bedrock build-time endpoint and specify the ID of the knowledge base.\\n•To set the maximum number of results to return in a response, use the maxResults  ﬁeld.\\n•If there are more results than the number you set, the response returns a nextToken . You \\ncan use this value in another ListDataSources  request to see the next batch of results.\\nTo get information a sync event for a data source, send a GetIngestionJob  request with a Agents \\nfor Amazon Bedrock build-time endpoint. Specify the dataSourceId , knowledgeBaseId , and\\ningestionJobId .\\nTo list the sync history for a data source in a knowledge base, send a ListIngestionJobs  request \\nwith a Agents for Amazon Bedrock build-time endpoint. Specify the ID of the knowledge base \\nand data source. You can set the following speciﬁcations.\\n•Filter for results by specifying a status to search for in the filters object.\\n•Sort by the time that the job was started or the status of a job by specifying the sortBy\\nobject. You can sort in ascending or descending order.\\nView information about a data source 309Amazon Bedrock User Guide\\n•Set the maximum number of results to return in a response in the maxResults  ﬁeld. If there \\nare more results than the number you set, the response returns a nextToken  that you can \\nsend in another ListIngestionJobs  request to see the next batch of jobs.\\nUpdate a data source\\nYou can update a data source in the following ways.\\n•Add, change, or remove ﬁles from the S3 bucket that contains the ﬁles for the data source.\\n•Change the name or S3 bucket for the data source, or the KMS key to use for encrypting \\ntransient data during data ingestion.\\nEach time you add, modify, or remove ﬁles from the S3 bucket for a data source, you must sync \\nthe data source so that it is re-indexed to the knowledge base. Syncing is incremental, so Amazon \\nBedrock only processes the objects in your S3 bucket that have been added, modiﬁed, or deleted \\nsince the last sync.\\nConsole\\nTo update a data source\\n1. (Optional) Make the necessary changes to the ﬁles in the S3 bucket that contains the ﬁles \\nfor the data source.\\n2. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n3. From the left navigation pane, select Knowledge base.\\n4. In the Data source section, select the radio button next to the data source that you want to \\nsync.\\n5. (Optional) Choose Edit, change any conﬁgurations necessary, and select Submit .\\n6. Choose Sync .\\n7. A green banner appears when the sync is complete and the Status  becomes Ready.\\nUpdate a data source 310Amazon Bedrock User Guide\\nAPI\\nTo update a data source\\n1. (Optional) Make the necessary changes to the ﬁles in the S3 bucket that contains the ﬁles \\nfor the data source.\\n2. (Optional) Send an UpdateDataSource request with a Agents for Amazon Bedrock \\nbuild-time endpoint , changing the necessary conﬁgurations and specifying the same \\nconﬁgurations you don\\'t want to change.\\nNote\\nYou can\\'t change the chunkingConfiguration . Send the request with the \\nexisting chunkingConfiguration .\\n3. Send a StartIngestionJob request with a Agents for Amazon Bedrock build-time endpoint, \\nspecifying the dataSourceId  and the knowledgeBaseId .\\nDelete a data source\\nIf you no longer need a data source, you can delete it. Select the tab corresponding to your method \\nof choice and follow the steps.\\nConsole\\nTo delete a data source\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, select Knowledge base.\\n3. In the Data source section, select the radio button next to the data source that you want to \\ndelete.\\n4. Choose Delete.\\n5. A green banner appears when the data source is successfully deleted.\\nDelete a data source 311Amazon Bedrock User Guide\\nAPI\\nTo delete a data source from a knowledge base, send a DeleteDataSource request, specifying \\nthe dataSourceId  and knowledgeBaseId .\\nManage a knowledge base\\nAfter you set up a knowledge base, you can view information about it, modify it, or delete it. Select \\nthe tab corresponding to your method of choice and follow the steps.\\nView information about a knowledge base\\nYou can view information about a knowledge base. Select the tab corresponding to your method of \\nchoice and follow the steps.\\nConsole\\nTo view information about a knowledge base\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, select Knowledge base.\\n3. To view details for a knowledge base, either select the Name  of the source or choose the \\nradio button next to the source and select Edit.\\n4. On the details page, you can carry out the following actions:\\n•To change the details of the knowledge base, select Edit in the Knowledge base \\noverview section.\\n•To update the tags attached to the knowledge base, select Manage tags  in the Tags\\nsection.\\n•If you update the data source from which the knowledge base was created and need to \\nsync the changes, select Sync  in the Data source section.\\n•To view the details of a data source, select a Data source name. Within the details, you \\ncan choose the radio button next to a sync event in the Sync history section and select\\nView warnings  to see why ﬁles in the data ingestion job failed to sync.\\n•To manage the embeddings model used for the knowledge base, select Edit Provisioned \\nThroughput .\\nManage a knowledge base 312Amazon Bedrock User Guide\\n•Select Save changes when you are ﬁnished editing.\\nAPI\\nTo get information about a knowledge base, send a GetKnowledgeBase request with a Agents \\nfor Amazon Bedrock build-time endpoint, specifying the knowledgeBaseId .\\nTo list information about your knowledge bases, send a ListKnowledgeBases request with a\\nAgents for Amazon Bedrock build-time endpoint. You can set the maximum number of results \\nto return in a response. If there are more results than the number you set, the response returns \\na nextToken . You can use this value in the nextToken  ﬁeld of another ListKnowledgeBases\\nrequest to see the next batch of results.\\nUpdate a knowledge base\\nConsole\\nTo update a knowledge base\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, select Knowledge base.\\n3. Select a knowledge base to view details about it, or choose the radio button next to the \\nknowledge base and select Edit.\\n4. You can modify the knowledge base in the following ways.\\n•Change conﬁgurations for the knowledge base by choosing Edit in the Knowledge base \\noverview section.\\n•Change the tags attached to the knowledge base by choosing Manage tags  in the Tags\\nsection\\n•Manage the data source in the Data source section. For more information, see Manage a \\ndata source.\\n5. Select Save changes when you are ﬁnished editing.\\nUpdate a knowledge base 313Amazon Bedrock User Guide\\nAPI\\nTo update a knowledge base, send an UpdateKnowledgeBase request with a Agents for Amazon \\nBedrock build-time endpoint. Because all ﬁelds will be overwritten, include both ﬁelds that you \\nwant to update as well as ﬁelds that you want to keep the same.\\nDelete a knowledge base\\nIf you no longer need a knowledge base, you can delete it. When you delete a knowledge base, \\nyou should also carry out the following actions to fully delete all resources associated with the \\nknowledge base.\\n•Dissociate the knowledge base from any agents it is associated with.\\n•The underlying data that was indexed from your knowledge base remains in the vector store \\nyou set up and can still be retrieved. To delete the data, you also need to delete the vector index \\ncontaining the data embeddings.\\nSelect the tab corresponding to your method of choice and follow the steps.\\nConsole\\nTo delete a knowledge base\\n1. Before the following steps, make sure to delete the knowledge base from any agents that \\nit\\'s associated with. To do this, carry out the following steps:\\na. From the left navigation pane, select Agents .\\nb. Choose the Name  of the agent that you want to delete the knowledge base from.\\nc. A red banner appears to warn you to delete the reference to the knowledge base, \\nwhich no longer exists, from the agent.\\nd. Select the radio button next to the knowledge base that you want to remove. Select\\nMore  and then choose Delete.\\n2. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n3. From the left navigation pane, select Knowledge base.\\n4. Choose a knowledge base or select the radio button next to a knowledge base. Then \\nchoose Delete.\\nDelete a knowledge base 314Amazon Bedrock User Guide\\n5. Review the warnings for deleting a knowledge base. If you accept these conditions, enter\\ndelete in the input box and select Delete to conﬁrm.\\n6. To fully delete the vector embeddings for your knowledge base, you need to delete the \\nvector index containing the data embeddings.\\nAPI\\nBefore deleting a knowledge base, disassociate the knowledge base from any agents that it \\nis associated with by making a DisassociateAgentKnowledgeBase request with a Agents for \\nAmazon Bedrock build-time endpoint.\\nTo delete the knowledge base, send a DeleteKnowledgeBase request with a Agents for Amazon \\nBedrock build-time endpoint.\\nTo fully delete the vector embeddings for your knowledge base, you need to delete the vector \\nindex containing the data embeddings.\\nDeploy a knowledge base\\nTo deploy a knowledge base in your application, set it up to make Retrieve or RetrieveAndGenerate\\nrequests to the knowledge base. To see how to use these API operations, select the API tab in Test \\na knowledge base.\\nYou can also associate the knowledge base with an agent and the agent will invoke it when \\nnecessary during orchestration. For more information, see Agents for Amazon Bedrock. Select the \\ntab corresponding to your method of choice and follow the steps.\\nConsole\\nTo associate a knowledge base with an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, select Agents .\\n3. Choose the agent to which you want to add a knowledge base.\\n4. In the Working draft section, choose Working draft.\\n5. In the Knowledge bases section, select Add.\\nDeploy a knowledge base 315Amazon Bedrock User Guide\\n6. Choose a knowledge base from the dropdown list under Select knowledge base and \\nspecify the instructions for the agent regarding how it should interact with the knowledge \\nbase and return results.\\nTo dissociate a knowledge base with an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, select Agents .\\n3. Choose the agent to which you want to add a knowledge base.\\n4. In the Working draft section, choose Working draft.\\n5. In the Knowledge bases section, choose a knowledge base.\\n6. Select Delete.\\nAPI\\nTo associate a knowledge base with an agent, send an AssociateAgentKnowledgeBase request.\\n•Include a detailed description  to provide instructions for how the agent should interact \\nwith the knowledge base and return results.\\n•Set the knowledgeBaseState  to ENABLED to allow the agent to query the knowledge base.\\nYou can update an knowledge base that is associated with an agent by sending \\nan UpdateAgentKnowledgeBase request. For example, you might want to set the\\nknowledgeBaseState  to ENABLED to troubleshoot an issue. Because all ﬁelds will be \\noverwritten, include both ﬁelds that you want to update as well as ﬁelds that you want to keep \\nthe same.\\nTo dissociate a knowledge base with an agent, send a DisassociateAgentKnowledgeBase\\nrequest.\\nDeploy a knowledge base 316Amazon Bedrock User Guide\\nAgents for Amazon Bedrock\\nAgents for Amazon Bedrock oﬀers you the ability to build and conﬁgure autonomous agents in \\nyour application. An agent helps your end-users complete actions based on organization data \\nand user input. Agents orchestrate interactions between foundation models (FMs), data sources, \\nsoftware applications, and user conversations. In addition, agents automatically call APIs to take \\nactions and invoke knowledge bases to supplement information for these actions. Developers can \\nsave weeks of development eﬀort by integrating agents to accelerate the delivery of generative \\nartiﬁcial intelligence (generative AI) applications .\\nWith agents, you can automate tasks for your customers and answer questions for them. For \\nexample, you can create an agent that helps customers process insurance claims or an agent \\nthat helps customers make travel reservations. You don\\'t have to provision capacity, manage \\ninfrastructure, or write custom code. Amazon Bedrock manages prompt engineering, memory, \\nmonitoring, encryption, user permissions, and API invocation.\\nAgents perform the following tasks:\\n•Extend foundation models to understand user requests and break down the tasks that the agent \\nmust perform into smaller steps.\\n•Collect additional information from a user through natural conversation.\\n•Take actions to fulﬁll a customer\\'s request by making API calls to your company systems.\\n•Augment performance and accuracy by querying data sources.\\nTo use an agent, you perform the following steps:\\n1. (Optional) Create a knowledge base to store your private data in that database. For more \\ninformation, see Knowledge base for Amazon Bedrock.\\n2. Conﬁgure an agent for your use case and add actions the agent can perform. To deﬁne how \\nthe agent handles the actions, write Lambda functions in a programming language of your \\nchoice.\\n3. Associate a knowledge base with the agent to augment the agent\\'s performance. For more \\ninformation, see Create an agent in Amazon Bedrock.\\n4. (Optional) To customize the agent\\'s behavior to your speciﬁc use-case, modify prompt \\ntemplates for the pre-processing, orchestration, knowledge base response generation, and \\n317Amazon Bedrock User Guide\\npost-processing steps that the agent performs. For more information, see Advanced prompts \\nin Amazon Bedrock.\\n5. Test your agent in the Amazon Bedrock console or through API calls to the TSTALIASID . \\nModify the conﬁgurations as necessary. Use traces to examine your agent\\'s reasoning process \\nat each step of its orchestration. For more information, see Test an Amazon Bedrock agent and\\nTrace events in Amazon Bedrock.\\n6. When you have suﬃciently modiﬁed your agent and it\\'s ready to be deployed to your \\napplication, create an alias to point to a version of your agent. For more information, see\\nDeploy an Amazon Bedrock agent.\\n7. Set up your application to make API calls to your agent alias.\\n8. Iterate on your agent and create more versions and aliases as necessary.\\nTopics\\n•How Agents for Amazon Bedrock works\\n•Supported regions and models for Agents for Amazon Bedrock\\n•Prerequisites for Agents for Amazon Bedrock\\n•Create an agent in Amazon Bedrock\\n•Create an action group for an Amazon Bedrock agent\\n•Associate a knowledge base with an Amazon Bedrock agent\\n•Test an Amazon Bedrock agent\\n•Manage an Amazon Bedrock agent\\n•Customize an Amazon Bedrock agent\\n•Deploy an Amazon Bedrock agent\\nHow Agents for Amazon Bedrock works\\nAgents for Amazon Bedrock consists of the following two main sets of API operations to help you \\nset up and run an agent:\\n•Build-time API operations  to create, conﬁgure, and manage your agents and their related \\nresources\\n•Runtime API operations  to invoke your agent with user input and to initiate orchestration to \\ncarry out a task.\\nHow it works 318Amazon Bedrock User Guide\\nBuild-time conﬁguration\\nAn agent consists of the following components:\\n•Foundation model – You choose a foundation model (FM) that the agent invokes to interpret \\nuser input and subsequent prompts in its orchestration process. The agent also invokes the FM to \\ngenerate responses and follow-up steps in its process.\\n•Instructions – You write instructions that describe what the agent is designed to do. With \\nadvanced prompts, you can further customize instructions for the agent at every step of \\norchestration and include Lambda functions to parse each step\\'s output.\\n•Action groups (Optional) – You deﬁne the actions that the agent should perform through \\nproviding the following resources:\\n•An OpenAPI schema to deﬁne the API operations that the agent can invoke to perform its \\ntasks.\\n•A Lambda function with the following input and output:\\n•Input – The API operation and parameters identiﬁed during orchestration.\\n•Output – The result of the API invocation.\\n•Knowledge bases (Optional) – Associate knowledge bases with an agent. The agent queries the \\nknowledge base for extra context to augment response generation and input into steps of the \\norchestration process.\\n•Prompt templates  – Prompt templates are the basis for creating prompts to be provided to \\nthe FM. Agents for Amazon Bedrock exposes the default four base prompt templates that are \\nused during the pre-processing, orchestration, knowledge base response generation, and post-\\nprocessing. You can optionally edit these base prompt templates to customize your agent\\'s \\nbehavior at each step of its sequence. You can also turn oﬀ steps for troubleshooting purposes or \\nif you decide that a step is unnecessary. For more information, see Advanced prompts in Amazon \\nBedrock.\\nAt build-time, all these components are gathered to construct base prompts for the agent to \\nperform orchestration until the user request is completed. With advanced prompts, you can modify \\nthese base prompts with additional logic and few-shot examples to improve accuracy for each \\nstep of agent invocation. The base prompt templates contain instructions, action descriptions, \\nknowledge base descriptions, and conversation history, all of which you can customize to modify \\nthe agent to meet your needs. You then prepare  your agent, which packages all the components \\nof the agents, including security conﬁgurations. Preparing the agent brings it into a state where it \\nBuild-time conﬁguration 319Amazon Bedrock User Guide\\ncan be tested in runtime. The following image shows how build-time API operations construct your \\nagent.\\nRuntime process\\nRuntime is managed by the InvokeAgent API operation. This operation starts the agent sequence, \\nwhich consists of the following three main steps.\\n1.Pre-processing – Manages how the agent contextualizes and categorizes user input and can be \\nused to validate input.\\n2.Orchestration  – Interprets the user input, invokes action groups and queries knowledge bases, \\nand returns output to the user or as input to continued orchestration. Orchestration consists of \\nthe following steps:\\nRuntime process 320Amazon Bedrock User Guide\\na.The agent interprets the input with a foundation model and generates a rationale  that lays \\nout the logic for the next step it should take.\\nb.The agent invokes action groups and queries knowledge bases (Knowledge base response \\ngeneration ) to retrieve additional context and summarize the data to augment its generation.\\nc.The agent generates an output, known as an observation, from invoking action groups and \\nsummarizing results from knowledge bases. The agent uses the observation to augment the \\nbase prompt, which is then interpreted with a foundation model. The agent then determines \\nif it needs to reiterate the orchestration process.\\nd.This loop continues until the agent returns a response to the user or until it needs to prompt \\nthe user for extra information.\\nDuring orchestration, the base prompt template is augmented with the agent instructions, \\naction groups, and knowledge bases that you added to the agent. Then, the augmented base \\nprompt is used to invoke the FM. The FM predicts the best possible steps and trajectory to fulﬁll \\nthe user input. At each iteration of orchestration, the FM predicts the API operation to invoke or \\nthe knowledge base to query.\\n3.Post-processing – The agent formats the ﬁnal response to return to the user. This step is turned \\noﬀ by default.\\nWhen you invoke your agent, you can turn on a trace at runtime. With the trace, you can track \\nthe agent\\'s rationale, actions, queries, and observations at each step of the agent sequence. The \\ntrace includes the full prompt sent to the foundation model at each step and the outputs from \\nthe foundation model, API responses, and knowledge base queries. You can use the trace to \\nunderstand the agent\\'s reasoning at each step. For more information, see Trace events in Amazon \\nBedrock\\nAs the user session with the agent continues through more InvokeAgent  requests, the \\nconversation history is preserved. The conversation history continually augments the orchestration \\nbase prompt template with context, helping improve the agent\\'s accuracy and performance. The \\nfollowing diagram shows the agent\\'s process during runtime:\\nRuntime process 321Amazon Bedrock User Guide\\nSupported regions and models for Agents for Amazon Bedrock\\nAgents for Amazon Bedrock is supported in the following regions:\\nSupported regions and models 322Amazon Bedrock User Guide\\nRegion\\nUS East (N. Virginia)\\nUS West (Oregon)\\nYou can use Agents for Amazon Bedrock with the following models:\\nModel name Model ID\\nAnthropic Claude Instant v1 anthropic.claude-instant-v1\\nAnthropic Claude v2.0 anthropic.claude-v2\\nAnthropic Claude v2.1 anthropic.claude-v2:1\\nPrerequisites for Agents for Amazon Bedrock\\nEnsure that your IAM role has the necessary permissions to perform actions related to Agents for \\nAmazon Bedrock.\\nAn agent uses action groups and knowledge bases to help your customer perform tasks. Following \\nis a short description of each type of resource:\\n•Action group – Deﬁnes an action that the agent can help the user perform. Includes the APIs \\nthat can be called, how to handle the action, and how to return the response.\\n•Knowledge base – Provides a repository of information that the agent can query to answer \\ncustomer queries and improve its generated responses.\\nBefore creating an agent, review the following prerequisites and determine which ones you need to \\nfulﬁll:\\n1. Set up an action group. For your agent to orchestrate API calls to your systems, you must add \\nat least one action group. You can skip this prerequisite if you want to add an action group \\nlater or if you plan to have no action groups for your agent.\\nPrerequisites 323Amazon Bedrock User Guide\\n2. Set up a knowledge base. To improve responses to customer queries by using private data \\nsources, you can associate at least one knowledge base. You can skip this prerequisite if you \\nplan for your agent to have no knowledge bases associated with it\\n3. Create a custom AWS Identity and Access Management (IAM) service role for your agent with \\nthe proper permissions. You can skip this prerequisite if you plan to use the AWS Management \\nConsole to automatically create a service role for you.\\nCreate an agent in Amazon Bedrock\\nTo create an agent with Amazon Bedrock, you set up the following components:\\n•The conﬁguration of the agent, which deﬁnes the purpose of the agent and indicates the \\nfoundation model (FM) that it uses to generate prompts and responses.\\n•(Optional) Action groups that deﬁne what actions the agent is designed to perform.\\n•(Optional) A knowledge base of data sources to augment the generative capabilities of the \\nagent.\\nYou can create an agent in either the console or the API. Select the tab corresponding to your \\nmethod of choice and follow the steps.\\nConsole\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane.\\n3. In the Agents  section, choose Create Agent .\\n4. On the Provide Agent details, set up the following conﬁgurations:\\na. For the Agent name  section, enter a name for the agent and an optional description.\\nb. For the User input  section, choose whether to allow the agent to request more \\ninformation from the user if it doesn\\'t have enough information.\\n•If you choose Yes, the agent returns an Observation reprompting the user for more \\ninformation if it needs to invoke an API in an action group, but doesn\\'t have enough \\ninformation to complete the API request.\\nCreate an agent 324Amazon Bedrock User Guide\\n•If you choose No, the agent doesn\\'t request the user for additional details and \\ninstead informs the user that it doesn\\'t have enough information to complete the \\ntask.\\nc. For the IAM permissions  section, for Agent resource role, choose a service role. \\nTo let Amazon Bedrock create the service role on your behalf, choose Create \\nand use a new service role. To use a custom role that you created previously, \\nchoose Use an existing service role. The role must begin with the preﬁx\\nAmazonBedrockExecutionRoleForAgents_ .\\nNote\\nThe service role that Amazon Bedrock creates for you doesn\\'t include \\npermissions for features that are in preview. To use these features, attach the \\ncorrect permissions to the service role.\\nd. (Optional) By default, AWS encrypts agent resources with an AWS managed key. To \\nencrypt your agent with your own customer managed key, for the KMS key selection\\nsection, select Customize encryption settings (advanced). To create a new key, select\\nCreate an AWS KMS key and then refresh this window. To use an existing key, select a \\nkey for Choose an AWS KMS key.\\ne. For the Idle session timeout section, choose a duration of time. If the user hasn\\'t \\nresponded in the same session after this amount of time has elapsed, Amazon Bedrock \\nno longer maintains the conversation history. Conversation history is used to both \\nresume an interaction and to augment responses with context from the conversation.\\nf.(Optional) To associate tags with this agent, for the Tags – optional section, choose\\nAdd new tag  and provide a key-value pair.\\ng. When you are done setting up the agent conﬁguration, select Next.\\n5. On the Select model page, set up the following conﬁgurations for the model that you want \\nyour agent to use in orchestration:\\na. For the Model details  section, choose a model provider and then choose a model in \\nthe dropdown menu.\\nb. In Instructions for the Agent, enter details to tell the agent what it should do and how \\nit should interact with users. The instructions replace the $instructions$ placeholder in \\nthe orchestration prompt template. Following is an example of instructions:\\nCreate an agent 325Amazon Bedrock User Guide\\nYou are an office assistant in an insurance agency. You are friendly and \\n polite. You help with managing insurance claims and coordinating pending \\n paperwork.\\nc. When you\\'re done conﬁguring the FM for your agent, choose Next.\\n6. (Optional) On the Add action groups page, add action groups to your agent. If you want to \\nadd action groups later or if your agent doesn\\'t need an action group, choose Next to skip \\nthis step. Otherwise, do the following steps:\\na. For Enter action group name, provide a name for your action group. For Description - \\noptional  enter a description of the action group.\\nb. For Select Lambda function, choose a Lambda function that you created previously in \\nAWS Lambda. The Lambda function provides the business logic that is performed upon \\ninvoking the action. Choose the version of the function to use.\\nNote\\nTo allow the Amazon Bedrock service principal to access the Lambda function,\\nattach a resource-based policy to the Lambda function to allow the Amazon \\nBedrock service principal to access the Lambda function.\\nc. For Select API schema, provide a link to the Amazon S3 URI of the OpenAPI schema\\nwith the API description, structure, and parameters for the action group.\\nNote\\nIf you prefer to use the console text editor to create the API schema, skip this \\nstep and add an action group after you have created the agent.\\nd. To set up another action group for your agent, select Add another action group. When \\nyou\\'re done with adding action groups, choose Next.\\n7. (Optional) On the Add knowledge bases page, associate knowledge bases with your agent. \\nIf you want to add knowledge bases later or if your agent doesn\\'t need a knowledge base, \\nchoose Next to skip this step. Otherwise, do the following steps:\\nCreate an agent 326Amazon Bedrock User Guide\\na. If you haven\\'t yet created any knowledge bases, follow the instructions at Create a \\nknowledge base. Otherwise, for Select knowledge base, choose a knowledge base \\nfrom the dropdown menu.\\nb. For Knowledge base instructions for the agent, enter instructions to describe how the \\nagent should use the knowledge base. For example, you might use the following text \\nfor a knowledge base called Domain name system details :\\nUse this knowledge base whenever you are creating a DNS record\\nc. To set up another knowledge base for your agent, choose Add another knowledge \\nbase . When you\\'re done adding knowledge bases, choose Next.\\n8. On the Review and create page, review the conﬁguration of your agent and choose Edit\\nfor any sections that you want to change. When you\\'re ready to create the agent, choose\\nCreate . When the process ﬁnishes, a banner appears at the top to inform you that the \\nagent was successfully created.\\nAPI\\nTo create an agent, send a CreateAgent request (see link for request and response formats and \\nﬁeld details) with an Agents for Amazon Bedrock build-time endpoint.\\nSee code examples\\nThe following list describes the ﬁelds in the request:\\n•Minimally, provide the following required ﬁelds:\\nField Short description\\nagentName Name for the agent\\nagentResourceRoleArn ARN of the service role for the agent\\nfoundationModel Foundation model for the agent to \\norchestrate with\\n•The following ﬁelds are optional but recommended:\\nCreate an agent 327Amazon Bedrock User Guide\\nField Short description\\ndescription Describes what the agent does\\ninstruction Instructions to tell the agent what to do. \\nUsed in the orchestration prompt template.\\n•The following ﬁelds can be speciﬁed for security purposes:\\nField Short description\\nclientToken Identiﬁer to ensure the API request \\ncompletes only once.\\ncustomerEncryptionKeyArn ARN of a KMS key to encrypt agent \\nresources\\nidleSessionTTLInSeconds Duration after which the agent ends the \\nsession and deletes any stored information.\\n•To customize your agent\\'s behavior by overriding the default prompt templates, include a\\npromptOverrideConfiguration  object. For more information, see Advanced prompts in \\nAmazon Bedrock.\\n•To attach tags to your agent, use the Tags ﬁeld. For more information, see Tag resources.\\nIf your agent fails to be created, the CreateAgent object in the response returns a list of\\nfailureReasons  and a list of recommendedActions  for you to troubleshoot.\\nCreate an action group for an Amazon Bedrock agent\\nAn action group deﬁnes an action that the agent can help the user perform. You deﬁne an action \\ngroup by specifying APIs in your systems that can be called and by writing a Lambda function to \\nhandle the action and how to return the response. To create an action group, prepare the following \\ncomponents:\\nCreate an action group 328Amazon Bedrock User Guide\\n•Set up an OpenAPI schema  with the API description, structure, and parameters for the action \\ngroup. You can add the API schema to the action group in one of the following ways:\\n•Upload the schema that you create to an Amazon Simple Storage Service (Amazon S3) bucket.\\n•Write the schema in the inline OpenAPI schema editor in the AWS Management Console when \\nyou add the action group. This option is only available after the agent that the action group \\nbelongs to has already been created.\\n•Create a Lambda function that deﬁnes the business logic for the action group.\\nTo learn more about the components of an action group and how to create the action group after \\nyou set it up, select from the following topics:\\nTopics\\n•Deﬁne OpenAPI schemas for your agent\\'s action groups in Amazon Bedrock\\n•Deﬁne Lambda functions for your agent\\'s action groups in Amazon Bedrock\\n•Add an action group to your agent in Amazon Bedrock\\nDeﬁne OpenAPI schemas for your agent\\'s action groups in Amazon \\nBedrock\\nWhen you create an action group in Amazon Bedrock, you must deﬁne the API operations that \\nthe agent can invoke. To deﬁne the API operations, create an OpenAPI schema in JSON or YAML \\nformat. You can create OpenAPI schema ﬁles and upload them to Amazon Simple Storage Service \\n(Amazon S3). Alternatively, you can use the OpenAPI text editor in the console, which will validate \\nyour schema. After you create an agent, you can use the text editor when you add an action group \\nto the agent or edit an existing action group. For more information, see Edit an agent.\\nFor more information about API schemas, see the following resources:\\n•For more details about OpenAPI schemas, see OpenAPI speciﬁcation  on the Swagger website.\\n•For best practices in writing API schemas, see Best practices in API design on the Swagger \\nwebsite.\\nThe following is the general format of an OpenAPI schema for an action group.\\n{ \\nDeﬁne OpenAPI schemas 329Amazon Bedrock User Guide\\n    \"openapi\": \"3.0.0\", \\n    \"paths\": { \\n        \"/ path\": { \\n            \" method\": { \\n                \"description\": \" string\", \\n                \"operationId\": \" string\", \\n                \"parameters\": [ ... ], \\n                \"requestBody\": { ... }, \\n                \"responses\": { ... } \\n           } \\n       } \\n    }\\n}\\nThe following list describes ﬁelds in the OpenAPI schema\\n•openapi – (Required) The version of OpenAPI that\\'s being used. This value must be \"3.0.0\"  or \\nhigher for the action group to work.\\n•paths – (Required) Contains relative paths to individual endpoints. Each path must begin with a \\nforward slash (/).\\n•method – (Required) Deﬁnes the method to use.\\nMinimally, each method requires the following ﬁelds:\\n•description  – A description of the API operation. Use this ﬁeld to inform the agent when to \\ncall this API operation and what the operation does.\\n•responses  – Contains properties that the agent returns in the API response. The agent uses \\nthe response properties to construct prompts, accurately process the results of an API call, and \\ndetermine a correct set of steps for performing a task. The agent can use response values from \\none operation as inputs for subsequent steps in the orchestration.\\nThe ﬁelds within the following two objects provide more information for your agent to eﬀectively \\ntake advantage of your action group. For each ﬁeld, set the value of the required  ﬁeld to true  if \\nrequired and to false  if optional.\\n•parameters  – Contains information about parameters that can be included in the request.\\n•requestBody  – Contains the ﬁelds in the request body for the operation. Don\\'t include this ﬁeld \\nfor GET and DELETE  methods.\\nDeﬁne OpenAPI schemas 330Amazon Bedrock User Guide\\nTo learn more about a structure, select from the following tabs.\\nresponses\\n\"responses\": { \\n    \"200\": { \\n        \"content\": { \\n            \" <media type> \": { \\n                \"schema\": { \\n                    \"properties\": { \\n                        \" <property> \": { \\n                            \"type\": \" string\", \\n                            \"description\": \" string\" \\n                        }, \\n                        ... \\n                    } \\n                } \\n            } \\n        }, \\n    }, \\n    ...\\n}\\nEach key in the responses  object is a response code, which describes the status of the \\nresponse. The response code maps to an object that contains the following information for the \\nresponse:\\n•content – (Required for each response) The content of the response.\\n•<media type>  – The format of the response body. For more information, see Media types on \\nthe Swagger website.\\n•schema – (Required for each media type) Deﬁnes the data type of the response body and its \\nﬁelds.\\n•properties  – (Required if there are items in the schema) Your agent uses properties that \\nyou deﬁne in the schema to determine the information it needs to return to the end user in \\norder to fulﬁll a task. Each property contains the following ﬁelds:\\n•type – (Required for each property) The data type of the response ﬁeld.\\n•description  – (Optional) Describes the property. The agent can use this information to \\ndetermine the information that it needs to return to the end user.\\nDeﬁne OpenAPI schemas 331Amazon Bedrock User Guide\\nparameters\\n\"parameters\": [ \\n    { \\n        \"name\": \" string\", \\n        \"description\": \" string\", \\n        \"required\": boolean, \\n        \"schema\": { \\n            ... \\n        } \\n    }, \\n    ...\\n]\\nYour agent uses the following ﬁelds to determine the information it must get from the end user \\nto perform the action group\\'s requirements.\\n•name – (Required) The name of the parameter.\\n•description  – (Required) A description of the parameter. Use this ﬁeld to help the agent \\nunderstand how to elicit this parameter from the agent user or determine that it already has \\nthat parameter value from prior actions or from the user’s request to the agent.\\n•required  – (Optional) Whether the parameter is required for the API request. Use this \\nﬁeld to indicate to the agent whether this parameter is needed for every invocation or if it\\'s \\noptional.\\n•schema – (Optional) The deﬁnition of input and output data types. For more information, see\\nData Models (Schemas)  on the Swagger website.\\nrequestBody\\nFollowing is the general structure of a requestBody  ﬁeld:\\n\"requestBody\": { \\n    \"required\": boolean, \\n    \"content\": { \\n        \" <media type> \": { \\n            \"schema\": { \\n                \"properties\": { \\n                    \" <property> \": { \\n                        \"type\": \" string\", \\nDeﬁne OpenAPI schemas 332Amazon Bedrock User Guide\\n                        \"description\": \" string\" \\n                    }, \\n                    ... \\n                } \\n            } \\n        } \\n    }\\n}\\nThe following list describes each ﬁeld:\\n•required  – (Optional) Whether the request body is required for the API request.\\n•content – (Required) The content of the request body.\\n•<media type>  – (Optional) The format of the request body. For more information, see\\nMedia types on the Swagger website.\\n•schema – (Optional) Deﬁnes the data type of the request body and its ﬁelds.\\n•properties  – (Optional) Your agent uses properties that you deﬁne in the schema to \\ndetermine the information it must get from the end user to make the API request. Each \\nproperty contains the following ﬁelds:\\n•type – (Optional) The data type of the request ﬁeld.\\n•description  – (Optional) Describes the property. The agent can use this information to \\ndetermine the information it needs to return to the end user.\\nExample API schema\\nThe following example API schema deﬁnes a group of API operatins that help handle insurance \\nclaims. Three APIs are deﬁned as follows:\\n•getAllOpenClaims  – Your agent can use the description  ﬁeld to determine that it should \\ncall this API operation if a list of open claims is needed. The properties  in the responses\\nspecify to return the ID and the policy holder and the status of the claim. The agent returns this \\ninformation to the agent user or uses some or all of the response as input to subsequent API \\ncalls.\\n•identifyMissingDocuments  – Your agent can use the description  ﬁeld to determine \\nthat it should call this API operation if missing documents must be identiﬁed for an insurance \\nclaim. The name , description , and required  ﬁelds tell the agent that it must elicit the unique \\nidentiﬁer of the open claim from the customer. The properties  in the responses  specify to \\nDeﬁne OpenAPI schemas 333Amazon Bedrock User Guide\\nreturn the IDs of the open insurance claims. The agent returns this information to the end user or \\nuses some or all of the response as input to subsequent API calls.\\n•sendReminders  – Your agent can use the description  ﬁeld to determine that it should \\ncall this API operation if there is a need to send reminders to the customer. For example, a \\nreminder about pending documents that they have for open claims. The properties  in the\\nrequestBody  tell the agent that it must ﬁnd the claim IDs and the pending documents. The\\nproperties  in the responses  specify to return an ID of the reminder and its status. The \\nagent returns this information to the end user or uses some or all of the response as input to \\nsubsequent API calls.\\n{ \\n    \"openapi\": \"3.0.0\", \\n    \"info\": { \\n        \"title\": \"Insurance Claims Automation API\", \\n        \"version\": \"1.0.0\", \\n        \"description\": \"APIs for managing insurance claims by pulling a list of open \\n claims, identifying outstanding paperwork for each claim, and sending reminders to \\n policy holders.\" \\n    }, \\n    \"paths\": { \\n        \"/claims\": { \\n            \"get\": { \\n                \"summary\": \"Get a list of all open claims\", \\n                \"description\": \"Get the list of all open insurance claims. Return all \\n the open claimIds.\", \\n                \"operationId\": \"getAllOpenClaims\", \\n                \"responses\": { \\n                    \"200\": { \\n                        \"description\": \"Gets the list of all open insurance claims for \\n policy holders\", \\n                        \"content\": { \\n                            \"application/json\": { \\n                                \"schema\": { \\n                                    \"type\": \"array\", \\n                                    \"items\": { \\n                                        \"type\": \"object\", \\n                                        \"properties\": { \\n                                            \"claimId\": { \\n                                                \"type\": \"string\", \\n                                                \"description\": \"Unique ID of the \\n claim.\" \\nDeﬁne OpenAPI schemas 334Amazon Bedrock User Guide\\n                                            }, \\n                                            \"policyHolderId\": { \\n                                                \"type\": \"string\", \\n                                                \"description\": \"Unique ID of the policy \\n holder who has filed the claim.\" \\n                                            }, \\n                                            \"claimStatus\": { \\n                                                \"type\": \"string\", \\n                                                \"description\": \"The status of the \\n claim. Claim can be in Open or Closed state\" \\n                                            } \\n                                        } \\n                                    } \\n                                } \\n                            } \\n                        } \\n                    } \\n                } \\n            } \\n        }, \\n        \"/claims/{claimId}/identify-missing-documents\": { \\n            \"get\": { \\n                \"summary\": \"Identify missing documents for a specific claim\", \\n                \"description\": \"Get the list of pending documents that need to be \\n uploaded by policy holder before the claim can be processed. The API takes in only one \\n claim id and returns the list of documents that are pending to be uploaded by policy \\n holder for that claim. This API should be called for each claim id\", \\n                \"operationId\": \"identifyMissingDocuments\", \\n                \"parameters\": [{ \\n                    \"name\": \"claimId\", \\n                    \"in\": \"path\", \\n                    \"description\": \"Unique ID of the open insurance claim\", \\n                    \"required\": true, \\n                    \"schema\": { \\n                        \"type\": \"string\" \\n                    } \\n                }], \\n                \"responses\": { \\n                    \"200\": { \\n                        \"description\": \"List of documents that are pending to be \\n uploaded by policy holder for insurance claim\", \\n                        \"content\": { \\n                            \"application/json\": { \\n                                \"schema\": { \\nDeﬁne OpenAPI schemas 335Amazon Bedrock User Guide\\n                                    \"type\": \"object\", \\n                                    \"properties\": { \\n                                        \"pendingDocuments\": { \\n                                            \"type\": \"string\", \\n                                            \"description\": \"The list of pending \\n documents for the claim.\" \\n                                        } \\n                                    } \\n                                } \\n                            } \\n                        } \\n                    } \\n                } \\n            } \\n        }, \\n        \"/send-reminders\": { \\n            \"post\": { \\n                \"summary\": \"API to send reminder to the customer about pending \\n documents for open claim\", \\n                \"description\": \"Send reminder to the customer about pending documents \\n for open claim. The API takes in only one claim id and its pending documents at a \\n time, sends the reminder and returns the tracking details for the reminder. This API \\n should be called for each claim id you want to send reminders for.\", \\n                \"operationId\": \"sendReminders\", \\n                \"requestBody\": { \\n                    \"required\": true, \\n                    \"content\": { \\n                        \"application/json\": { \\n                            \"schema\": { \\n                                \"type\": \"object\", \\n                                \"properties\": { \\n                                    \"claimId\": { \\n                                        \"type\": \"string\", \\n                                        \"description\": \"Unique ID of open claims to \\n send reminders for.\" \\n                                    }, \\n                                    \"pendingDocuments\": { \\n                                        \"type\": \"string\", \\n                                        \"description\": \"The list of pending documents \\n for the claim.\" \\n                                    } \\n                                }, \\n                                \"required\": [ \\nDeﬁne OpenAPI schemas 336Amazon Bedrock User Guide\\n                                    \"claimId\", \\n                                    \"pendingDocuments\" \\n                                ] \\n                            } \\n                        } \\n                    } \\n                }, \\n                \"responses\": { \\n                    \"200\": { \\n                        \"description\": \"Reminders sent successfully\", \\n                        \"content\": { \\n                            \"application/json\": { \\n                                \"schema\": { \\n                                    \"type\": \"object\", \\n                                    \"properties\": { \\n                                        \"sendReminderTrackingId\": { \\n                                            \"type\": \"string\", \\n                                            \"description\": \"Unique Id to track the \\n status of the send reminder Call\" \\n                                        }, \\n                                        \"sendReminderStatus\": { \\n                                            \"type\": \"string\", \\n                                            \"description\": \"Status of send reminder \\n notifications\" \\n                                        } \\n                                    } \\n                                } \\n                            } \\n                        } \\n                    }, \\n                    \"400\": { \\n                        \"description\": \"Bad request. One or more required fields are \\n missing or invalid.\" \\n                    } \\n                } \\n            } \\n        } \\n    }\\n}\\nFor more examples of OpenAPI schemas, see https://github.com/OAI/OpenAPI-Speciﬁcation/tree/ \\nmain/examples/v3.0  on the GitHub website.\\nDeﬁne OpenAPI schemas 337Amazon Bedrock User Guide\\nDeﬁne Lambda functions for your agent\\'s action groups in Amazon \\nBedrock\\nYou must deﬁne a Lambda function to program the business logic for an action group. After a \\nAmazon Bedrock agent determines the API operation that it needs to invoke in an action group, \\nit sends information from the API schema alongside relevant metadata as an input event to the \\nLambda function. To write your function, you must understand the following components of the \\nLambda function:\\n•Input event – Contains relevant metadata and populated ﬁelds from the request body of the API \\noperation that the agent determines must be called.\\n•Response – Contains relevant metadata and populated ﬁelds for the response body returned \\nfrom the API operation.\\nYou write your Lambda function to deﬁne how to handle an action group and to customize how \\nyou want the API response to be returned. You use the variables from the input event to deﬁne \\nyour functions and return a response to the agent.\\nNote\\nAn action group can contain up to 5 API operations, but you can only write one Lambda \\nfunction. Because the Lambda function can only receive an input event and return a \\nresponse for one API operation at a time, you should write the function considering the \\ndiﬀerent API operations that may be invoked.\\nFor your agent to use a Lambda function, you must attach a resource-based policy to the function \\nto provide permissions for the agent. For more information, follow the steps at Resource-based \\npolicy to allow Amazon Bedrock to invoke an action group Lambda function. For more information \\nabout resource-based policies in Lambda, see Using resource-based policies for Lambda in the AWS \\nLambda Developer Guide.\\nTopics\\n•Lambda input event from Amazon Bedrock\\n•Lambda response event to Amazon Bedrock\\n•Action group Lambda function example\\nDeﬁne Lambda functions 338Amazon Bedrock User Guide\\nLambda input event from Amazon Bedrock\\nWhen an action group using a Lambda function is invoked, Amazon Bedrock sends a Lambda input \\nevent of the following general format. You can deﬁne your Lambda function to use any of the \\ninput event ﬁelds to manipulate the business logic within the function to successfully perform the \\naction. For more information about Lambda functions, see Event-driven invocation in the AWS \\nLambda Developer Guide.\\n{ \\n    \"messageVersion\": \"1.0\", \\n    \"agent\": { \\n        \"name\": \"string\", \\n        \"id\": \"string\", \\n        \"alias\": \"string\", \\n        \"version\": \"string\" \\n    }, \\n    \"inputText\": \"string\", \\n    \"sessionId\": \"string\", \\n    \"actionGroup\": \"string\", \\n    \"apiPath\": \"string\", \\n    \"httpMethod\": \"string\", \\n    \"parameters\": [ \\n        { \\n            \"name\": \"string\", \\n            \"type\": \"string\", \\n            \"value\": \"string\" \\n        }, \\n    ... \\n    ], \\n    \"requestBody\": { \\n        \"content\": { \\n            \" <content_type> \": { \\n                \"properties\": [ \\n                   { \\n                       \"name\": \"string\", \\n                       \"type\": \"string\", \\n                       \"value\": \"string\" \\n                    }, \\n                            ... \\n                ] \\n            } \\n        } \\n    }, \\nDeﬁne Lambda functions 339Amazon Bedrock User Guide\\n    \"sessionAttributes\": { \\n        \" string\": \"string\", \\n    }, \\n    \"promptSessionAttributes\": { \\n        \" string\": \"string\" \\n    }\\n}\\nThe following list describes the input event ﬁelds;\\n•messageVersion  – The version of the message that identiﬁes the format of the event data \\ngoing into the Lambda function and the expected format of the response from a Lambda \\nfunction. Amazon Bedrock only supports version 1.0.\\n•agent – Contains information about the name, ID, alias, and version of the agent that the action \\ngroup belongs to.\\n•inputText  – The user input for the conversation turn.\\n•sessionId  – The unique identiﬁer of the agent session.\\n•actionGroup  – The name of the action group.\\n•apiPath  – The path to the API operation, as deﬁned in the OpenAPI schema.\\n•httpMethod  – The method of the API operation, as deﬁned in the OpenAPI schema.\\n•parameters  – Contains a list of objects. Each object contains the name, type, and value of a \\nparameter in the API operation, as deﬁned in the OpenAPI schema.\\n•requestBody  – Contains the request body and its properties, as deﬁned in the OpenAPI \\nschema.\\n•sessionAttributes  – Contains session attributes and their values. These attributes are stored \\nover a session  and provide context for the agent.\\n•promptSessionAttributes  – Contains prompt session attributes and their values. These \\nattributes are stored over a turn and provide context for the agent.\\nLambda response event to Amazon Bedrock\\nAmazon Bedrock expects a response from your Lambda function that matches the following \\nformat. The response consists of parameters returned from the API operation. The agent can use \\nthe response from the Lambda function for further orchestration or to help it return a response to \\nthe customer.\\nDeﬁne Lambda functions 340Amazon Bedrock User Guide\\nNote\\nSee Agent quotas for the Lambda payload response quota.\\n{ \\n    \"messageVersion\": \"1.0\", \\n    \"response\": { \\n        \"actionGroup\": \"string\", \\n        \"apiPath\": \"string\", \\n        \"httpMethod\": \"string\", \\n        \"httpStatusCode\": number, \\n        \"responseBody\": { \\n            \" <contentType> \": { \\n                \"body\": \"JSON-formatted string\"  \\n            } \\n        } \\n    }, \\n    \"sessionAttributes\": { \\n        \" string\": \"string\", \\n    }, \\n    \"promptSessionAttributes\": { \\n        \" string\": \"string\" \\n    }\\n}\\nThe following list describes the response ﬁelds:\\n•messageVersion  – The version of the message that identiﬁes the format of the event data \\ngoing into the Lambda function and the expected format of the response from a Lambda \\nfunction. Amazon Bedrock only supports version 1.0.\\n•response  – Contains the following information about the API response.\\n•actionGroup  – The name of the action group.\\n•apiPath  – The path to the API operation, as deﬁned in the OpenAPI schema.\\n•httpMethod  – The method of the API operation, as deﬁned in the OpenAPI schema.\\n•responseBody  – Contains the response body, as deﬁned in the OpenAPI schema.\\n•(Optional) sessionAttributes  – Contains session attributes and their values.\\n•(Optional) promptSessionAttributes  – Contains prompt attributes and their values.\\nDeﬁne Lambda functions 341Amazon Bedrock User Guide\\nAction group Lambda function example\\nThe following is an minimal example of how the Lambda function can be deﬁned in Python.\\ndef lambda_handler(event, context): \\n    response_body = { \\n        \\'application/json\\': { \\n            \\'body\\': \" sample response \" \\n        } \\n    } \\n     \\n    action_response = { \\n        \\'actionGroup\\': event[\\'actionGroup\\'], \\n        \\'apiPath\\': event[\\'apiPath\\'], \\n        \\'httpMethod\\': event[\\'httpMethod\\'], \\n        \\'httpStatusCode\\': 200, \\n        \\'responseBody\\': response_body \\n    } \\n     \\n    session_attributes = event[\\'sessionAttributes\\'] \\n    prompt_session_attributes = event[\\'promptSessionAttributes\\'] \\n     \\n    api_response = { \\n        \\'messageVersion\\': \\'1.0\\',  \\n        \\'response\\': action_response, \\n        \\'sessionAttributes\\': session_attributes, \\n        \\'promptSessionAttributes\\': prompt_session_attributes \\n    } \\n         \\n    return api_response\\nAdd an action group to your agent in Amazon Bedrock\\nAfter setting up the OpenAPI schema and Lambda function for your action group, you can create \\nthe action group. Select the tab corresponding to your method of choice and follow the steps.\\nConsole\\nWhen you create an agent, you can add action groups to the working draft.\\nAfter an agent is created, you can add action groups to it by doing the following steps:\\nAdd an action group 342Amazon Bedrock User Guide\\nTo add an action group to an already created agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent from the Agents  section and then choose the Working draft in the\\nWorking Draft section.\\n4. Select Add in the Action groups section.\\n5. Fill out the action group details\\n6. To deﬁne the schema for the action group with the in-line OpenAPI schema editor, carry \\nout the following actions. For more information about API schemas for your action group, \\nsee Deﬁne OpenAPI schemas for your agent\\'s action groups in Amazon Bedrock.\\na. Choose Deﬁne with in-line OpenAPI schema editor  under Select API schema. A \\nsample schema appears that you can edit.\\nb. Select the format for the schema by using the dropdown menu next to Format.\\nc. To import an existing schema from S3 to edit, select Import schema, provide the S3 \\nURI, and select Import.\\nd. To restore the schema to the original sample schema, select Reset and then conﬁrm \\nthe message that appears by selecting Reset again.\\n7. Select Add. A green success banner appears if there are no issues. If there are issues \\nvalidating the schema, a red banner appears. The following issues are identiﬁed by the \\nvalidation process.\\n•Scroll through the schema to see the lines where an error or warning about formatting \\nexists. An X indicates a formatting error, while an exclamation mark indicates a warning \\nabout formatting.\\n•Select View details  in the red banner to see a list of errors about the content of the API \\nschema.\\n8. Select Prepare  to apply the changes that you have made to the agent before testing it.\\nAPI\\nTo create an action group, send a CreateAgentActionGroup request with a Agents for Amazon \\nBedrock build-time endpoint.\\nAdd an action group 343Amazon Bedrock User Guide\\nSee code examples\\nThe following list describes the ﬁelds in the request:\\n•The following ﬁelds are required:\\nField Short description\\n\\xa0 \\xa0\\n\\xa0 \\xa0\\n\\xa0 \\xa0\\n\\xa0 \\xa0\\n\\xa0 \\xa0\\n•The following ﬁelds are optional:\\n•Specify the OpenAPI schema deﬁning the APIs to be invoked by the action group in the\\napiSchema  object. You can either provide the schema directly as a JSON payload or provide \\nthe Amazon S3 bucket containing the OpenAPI schema.\\n•(Optional) Specify the ARN of the Lambda function to carry out the business logic carried out \\nupon invoking the action.\\n•Set the actionGroupState  to ENABLED to allow the agent to invoke the action group.\\n•To allow your agent to request the user for additional information when trying to \\ncomplete a task, add an action group with the parentActionGroupSignature\\nﬁeld set to AMAZON.UserInput . You must leave the description , apiSchema , and\\nactionGroupExecutor  ﬁelds blank for this action group.\\nDuring orchestration, if your agent determines that it needs to invoke an API in an action \\ngroup, but doesn\\'t have enough information to complete the API request, it will invoke this \\naction group instead and return an Observation reprompting the user for more information.\\nAdd an action group 344Amazon Bedrock User Guide\\nAssociate a knowledge base with an Amazon Bedrock agent\\nIf you haven\\'t yet created a knowledge base, see Knowledge base for Amazon Bedrock to learn \\nabout knowledge bases and create one. You can associate a knowledge base during agent creation\\nor after an agent has been created. To associate a knowledge base to an existing agent. select the \\ntab corresponding to your method of choice and follow the steps..\\nConsole\\nTo add a knowledge base\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. On the agent details page, choose the working draft from the Working draft section.\\n4. For the Knowledge bases section, choose Add.\\n5. Choose a knowledge base that you have created and provide instructions for how the agent \\nshould interact with it.\\n6. Choose Add. A success banner appears at the top.\\n7. To apply the changes that you made to the agent before testing it, choose Prepare  before \\ntesting it.\\nAPI\\nTo associate a knowledge base with an agent, send an AssociateAgentKnowledgeBase request \\nwith a Agents for Amazon Bedrock build-time endpoint.\\nThe following list describes the ﬁelds in the request:\\n•The following ﬁelds are required:\\nField Short description\\nagentId ID of the agent\\nagentVersion Version of the agent\\nAssociate a knowledge base 345Amazon Bedrock User Guide\\nField Short description\\nknowledgeBaseId ID of the knowledge base\\n•The following ﬁelds are optional:\\nField Short description\\ndescription Description of how the agent can use the \\nknowledge base\\nknowledgeBaseState To prevent the agent from querying the \\nknowledge base, specify DISABLED\\nTest an Amazon Bedrock agent\\nAfter you create an agent, you will have a working draft. The working draft is a version of the agent \\nthat you can use to iteratively build the agent. Each time you make changes to your agent, the \\nworking draft is updated. When you\\'re satisﬁed with your agent\\'s conﬁgurations, you can create a\\nversion , which is a snapshot of your agent, and an alias , which points to the version. You can then \\ndeploy your agent to your applications by calling the alias. For more information, see Deploy an \\nAmazon Bedrock agent.\\nThe following list describes how you test your agent:\\n•In the Amazon Bedrock console, you open up the test window on the side and send input for \\nyour agent to respond to. You can select the working draft or a version that you\\'ve created.\\n•In the API, the working draft is the DRAFT version. You send input to your agent by using\\nInvokeAgent with the test alias, TSTALIASID , or a diﬀerent alias pointing to a static version.\\nTo help troubleshoot your agent\\'s behavior, Agents for Amazon Bedrock provides the ability to \\nview the trace  during a session with your agent. The trace shows the agent\\'s step-by-step reasoning \\nprocess. For more information about the trace, see Trace events in Amazon Bedrock.\\nFollowing are steps for testing your agent. Select the tab corresponding to your method of choice \\nand follow the steps.\\nTest an agent 346Amazon Bedrock User Guide\\nConsole\\nTo test an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. In the Agents  section, select the link for the agent that you want to test from the list of \\nagents.\\n4. The Test window appears in a pane on the right.\\nNote\\nIf the Test window is closed, you can reopen it by selecting Test at the top of the \\nagent details page or any page within it.\\n5. After you create an agent, you must package it with the working draft changes by \\npreparing it in one of the following ways:\\n• In the Test window, select Prepare .\\n• In the Working draft page, select Prepare  at the top of the page.\\nNote\\nEvery time you update the working draft, you must prepare the agent to package \\nthe agent with your latest changes. As a best practice, we recommend that you \\nalways check your agent\\'s Last prepared  time in the Agent overview section of \\nthe Working draft page to verify that you\\'re testing your agent with the latest \\nconﬁgurations.\\n6. To choose an alias and associated version to test, use the dropdown menu at the top of the\\nTest window. By default, the TestAlias: Working draft combination is selected.\\n7. To test the agent, enter a message and choose Run. While you wait for the response to \\ngenerate or after it is generated, you have the following options:\\n•To view details for each step of the agent\\'s orchestration process, including the prompt, \\ninference conﬁgurations, and agent\\'s reasoning process for each step and usage of its \\naction groups and knowledge bases, select Show trace. The trace is updated in real-time \\nTest an agent 347Amazon Bedrock User Guide\\nso you can view it before the response is returned. To expand or collapse the trace for a \\nstep, select an arrow next to a step. For more information about the Trace window and \\ndetails that appear, see Trace events in Amazon Bedrock.\\n•If the agent invokes a knowledge base, the response contains footnotes. To view the \\nlink to the S3 object containing the cited information for a speciﬁc part of the response, \\nselect the relevant footnote.\\nYou can perform the following actions in the Test window:\\n•To start a new conversation with the agent, select the refresh icon.\\n•To view the Trace window, select the expand icon. To close the Trace window, select the \\nshrink icon.\\n•To close the Test window, select the right arrow icon.\\nYou can enable or disable action groups and knowledge bases. Use this feature to troubleshoot \\nyour agent by isolating which action groups or knowledge bases need to be updated by \\nassessing its behavior with diﬀerent settings.\\nTo enable an action group or knowledge base\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. In the Agents  section. select the link for the agent that you want to test from the list of \\nagents.\\n4. On the agent\\'s details page, in the Working draft section, select the link for the Working \\ndraft.\\n5. In the Action groups or Knowledge bases section, hover over the State  of the action group \\nor knowledge base whose state you want to change.\\n6. An edit button appears. Select the edit icon and then choose from the dropdown menu \\nwhether the action group or knowledge base is Enabled or Disabled.\\n7. If an action group is Disabled, the agent doesn\\'t use the action group. If a knowledge base \\nis Disabled, the agent doesn\\'t use the knowledge base. Enable or disable action groups or \\nknowledge bases and then use the Test window to troubleshoot your agent.\\n8. Choose Prepare  to apply the changes that you have made to the agent before testing it.\\nTest an agent 348Amazon Bedrock User Guide\\nAPI\\nBefore you test your agent for the ﬁrst time, you must package it with the working draft \\nchanges by sending a PrepareAgent request (see link for request and response formats and ﬁeld \\ndetails) with an Agents for Amazon Bedrock build-time endpoint. Include the agentId  in the \\nrequest. The changes apply to the DRAFT version, which the TSTALIASID  alias points to.\\nSee code examples\\nNote\\nEvery time you update the working draft, you must prepare the agent to package the \\nagent with your latest changes. As a best practice, we recommend that you send a\\nGetAgent request (see link for request and response formats and ﬁeld details) with a\\nAgents for Amazon Bedrock build-time endpoint and check the preparedAt  time for \\nyour agent to verify that you\\'re testing your agent with the latest conﬁgurations.\\nTo test your agent, send an InvokeAgent request (see link for request and response formats and \\nﬁeld details) with an Agents for Amazon Bedrock runtime endpoint.\\nSee code examples\\nNote\\nThe AWS CLI doesn\\'t support InvokeAgent.\\nSee code examples\\nThe following ﬁelds exist in the request:\\n•Minimally, provide the following required ﬁelds:\\nField Short description\\nagentId ID of the agent\\nagentAliasId ID of the alias. Use TSTALIASID  to invoke \\nthe DRAFT version\\nTest an agent 349Amazon Bedrock User Guide\\nField Short description\\nsessionId Alphanumeric ID for the session (2–100 \\ncharacters)\\ninputText The user prompt to send to the agent\\n•The following ﬁelds are optional:\\nField Short description\\nenableTrace Specify TRUE  to view the trace.\\nendSession Specify TRUE  to end the session with the \\nagent after this request.\\nsessionState Includes sessionAttributes  that \\nremain throughout the session and/or\\npromptSessionAttributes  that \\nremain throughout the InvokeAgent turn. \\nThese attributes give the agent context.\\nThe response is returned in bytes in the chunk object. If the agent queried a knowledge base, \\nthe chunk  includes citations . If you enabled a trace, a trace object is also returned. If an \\nerror occurs, a ﬁeld is returned with the error message. For more information about how to read \\nthe trace, see Trace events in Amazon Bedrock.\\nTrace events in Amazon Bedrock\\nEach response from an Amazon Bedrock agent is accompanied by a trace  that details the steps \\nbeing orchestrated by the agent. The trace helps you follow the agent\\'s reasoning process that \\nleads it to the response it gives at that point in the conversation.\\nUse the trace to track the agent\\'s path from the user input to the response it returns. The trace \\nprovides information about the inputs to the action groups that the agent invokes and the \\nknowledge bases that it queries to respond to the user. In addition, the trace provides information \\nabout the outputs that the action groups and knowledge bases return. You can view the reasoning \\nTrace events 350Amazon Bedrock User Guide\\nthat the agent uses to determine the action that it takes or the query that it makes to a knowledge \\nbase. If a step in the trace fails, the trace returns a reason for the failure. Use the detailed \\ninformation in the trace to troubleshoot your agent. You can identify steps at which the agent has \\ntrouble or at which it yields unexpected behavior. Then, you can use this information to consider \\nways in which you can improve the agent\\'s behavior.\\nView the trace\\nThe following describes how to view the trace. Select the tab corresponding to your method of \\nchoice and follow the steps.\\nConsole\\nTo view the trace during a conversation with an agent\\nSign in to the AWS Management Console, and open the Amazon Bedrock console at https:// \\nconsole.aws.amazon.com/bedrock/.\\n1. In the Agents  section, select the link for the agent that you want to test from the list of \\nagents.\\n2. The Test window appears in a pane on the right.\\n3. Enter a message and choose Run. While the response is generating or after it ﬁnishes \\ngenerating, select Show trace.\\n4. You can view the trace for each Step  in real-time as your agent performs orchestration.\\nAPI\\nTo view the trace, send an InvokeAgent request with a Agents for Amazon Bedrock runtime \\nendpoint  and set the enableTrace  ﬁeld to TRUE. By default, the trace is disabled.\\nIf you enable the trace, in the InvokeAgent response, each chunk in the stream is accompanied \\nby a trace  ﬁeld that maps to a TracePart object. Within the TracePart is a trace  ﬁeld that \\nmaps to a Trace object.\\nStructure of the trace\\nThe trace is shown as a JSON object in both the console and the API. Each Step  in the console or\\nTrace in the API can be one of the following traces:\\nTrace events 351Amazon Bedrock User Guide\\n•PreProcessingTrace – Traces the input and output of the pre-processing step, in which the agent \\ncontextualizes and categorizes user input and determines if it is valid.\\n•Orchestration – Traces the input and output of the orchestration step, in which the agent \\ninterprets the input and invokes API operations and queries knowledge bases. Then the agent \\nreturns output to either continue orchestration or to respond to the user.\\n•PostProcessingTrace – Traces the input and output of the post-processing step, in which the \\nagent handles the ﬁnal output of the orchestration and determines how to return the response \\nto the user.\\n•FailureTrace – Traces the reason that a step failed.\\nEach of the traces (except FailureTrace ) contains a ModelInvocationInput object. The\\nModelInvocationInput object contains conﬁgurations set in the prompt template for the step, \\nalongside the prompt provided to the agent at this step. For more information about how to \\nmodify prompt templates, see Advanced prompts in Amazon Bedrock. The structure of the\\nModelInvocationInput  object is as follows:\\n{ \\n    \"traceId\": \"string\", \\n    \"text\": \"string\", \\n    \"type\": \"PRE_PROCESSING | ORCHESTRATION | KNOWLEDGE_BASE_RESPONSE_GENERATION | \\n POST_PROCESSING\", \\n    \"inferenceConfiguration\": { \\n        \"maximumLength\": number, \\n        \"stopSequences\": [\"string\"], \\n        \"temperature\": float, \\n        \"topK\": float, \\n        \"topP\": float \\n    }, \\n    \"promptCreationMode\": \"DEFAULT | OVERRIDDEN\", \\n    \"parserMode\": \"DEFAULT | OVERRIDDEN\", \\n    \"overrideLambda\": \"string\"\\n}\\nThe following list describes the ﬁelds of the ModelInvocationInput object:\\n•traceId – The unique identiﬁer of the trace.\\n•text – The text from the prompt provided to the agent at this step.\\n•type – The current step in the agent\\'s process.\\nTrace events 352Amazon Bedrock User Guide\\n•inferenceConfiguration  – Inference parameters that inﬂuence response generation. For \\nmore information, see Inference parameters.\\n•promptCreationMode  – Whether the agent\\'s default base prompt template was overridden for \\nthis step. For more information, see Advanced prompts in Amazon Bedrock.\\n•parserMode  – Whether the agent\\'s default response parser was overridden for this step. For \\nmore information, see Advanced prompts in Amazon Bedrock.\\n•overrideLambda  – The Amazon Resource Name (ARN) of the parser Lambda function used to \\nparse the response, if the default parser was overridden. For more information, see Advanced \\nprompts in Amazon Bedrock.\\nFor more information about each trace type, see the following sections:\\nPreProcessingTrace\\n{ \\n    \"modelInvocationInput\": { // see above for details } \\n    \"modelInvocationOutput\": { \\n        \"parsedResponse\": { \\n            \"isValid\": boolean, \\n            \"rationale\": \"string\" \\n        }, \\n        \"traceId\": \"string\" \\n    }\\n}\\nThe PreProcessingTrace consists of a ModelInvocationInput object and a\\nPreProcessingModelInvocationOutput object. The PreProcessingModelInvocationOutput contains \\nthe following ﬁelds.\\n•parsedResponse  – Contains the following details about the parsed user prompt.\\n•isValid – Speciﬁes whether the user prompt is valid.\\n•rationale  – Speciﬁes the agent\\'s reasoning for the next steps to take.\\n•traceId – The unique identiﬁer of the trace.\\nTrace events 353Amazon Bedrock User Guide\\nOrchestrationTrace\\nThe Orchestration consists of the ModelInvocationInput object and any combination of the\\nRationale , InvocationInput, and Observation objects. For more information about each object, \\nselect from the following tabs:\\n{ \\n    \"modelInvocationInput\": { // see above for details }, \\n    \"rationale\": { ... }, \\n    \"invocationInput\": { ... }, \\n    \"observation\": { ... }\\n}\\nRationale\\nThe Rationale  object contains the reasoning of the agent given the user input. Following is the \\nstructure:\\n{ \\n       \"traceId\": \"string\", \\n       \"text\": \"string\" \\n    }\\nThe following list describes the ﬁelds of the Rationale  object:\\n•traceId – The unique identiﬁer of the trace step.\\n•text – The reasoning process of the agent, based on the input prompt.\\nInvocationInput\\nThe InvocationInput object contains information that will be input to the action group or \\nknowledge base that is to be invoked or queried. Following is the structure:\\n{ \\n    \"traceId\": \"string\", \\n    \"invocationType\": \"ACTION_GROUP | KNOWLEDGE_BASE | FINISH\", \\n    \"actionGroupInvocationInput\": { \\n        \"actionGroupName\": \"string\", \\n        \"apiPath\": \"string\", \\n        \"verb\": \"string\", \\nTrace events 354Amazon Bedrock User Guide\\n        \"parameters\": [ \\n            { \\n                \"name\": \"string\", \\n                \"type\": \"string\" \\n                \"value\": \"string\" \\n            }, \\n            ... \\n        ], \\n        \"request\": { \\n            \"content\": { \\n                \" content-type \": [ \\n                    { \\n                        \"name\": \"string\", \\n                        \"type\": \"string\", \\n                        \"value\": \"string\" \\n                    }    \\n                ] \\n            } \\n        } \\n    }, \\n    \"knowledgeBaseLookupInput\": { \\n        \"knowledgeBaseId\": \"string\", \\n        \"text\": \"string\" \\n    }\\n}\\nThe following list describes the ﬁelds of the InvocationInput object:\\n•traceId – The unique identiﬁer of the trace.\\n•invocationType  – Speciﬁes whether the agent is invoking an action group or a knowledge \\nbase, or ending the session.\\n•actionGroupInvocationInput  – Appears if the type  is ACTION_GROUP . For more \\ninformation, see Deﬁne OpenAPI schemas for your agent\\'s action groups in Amazon Bedrock. \\nContains the following input for the action group that is invoked:\\n•actionGroupName  – The name of the action group that the agent will invoke.\\n•apiPath – The path to the API operation to call, according to the API schema.\\n•verb – The API method being used, according to the API schema.\\n•parameters  – Contains a list of objects. Each object contains the name, type, and value of \\na parameter in the API operation, as deﬁned in the API schema.\\nTrace events 355Amazon Bedrock User Guide\\n•requestBody  – Contains the request body and its properties, as deﬁned in the API \\nschema.\\n•knowledgeBaseLookupInput  – Appears if the type  is KNOWLEDGE_BASE . For more \\ninformation, see Knowledge base for Amazon Bedrock. Contains the following information \\nabout the knowledge base and the search query for the knowledge base:\\n•knowledgeBaseId  – The unique identiﬁer of the knowledge base that the agent will look \\nup.\\n•text – The query to be made to the knowledge base.\\nObservation\\nThe Observation object contains the result or output of an action group or knowledge base, or \\nthe response to the user. Following is the structure:\\n{ \\n    \"traceId\": \"string\", \\n    \"type\": \"ACTION_GROUP | KNOWLEDGE_BASE | REPROMPT | ASK_USER | FINISH\" \\n    \"actionGroupInvocation\": { \\n        \"text\": \"JSON-formatted string\" \\n    }, \\n    \"knowledgeBaseLookupOutput\": { \\n        \"retrievedReferences\": [ \\n            { \\n                \"content\": { \\n                    \"text\": \"string\" \\n                }, \\n                \"location\": { \\n                    \"type\": \"S3\", \\n                    \"s3Location\": { \\n                        \"uri\": \"string\" \\n                    } \\n                } \\n            }, \\n            ... \\n        ] \\n    }, \\n    \"repromptResponse\": { \\n        \"source\": \"ACTION_GROUP | KNOWLEDGE_BASE | PARSER\", \\n        \"text\": \"string\" \\n    }, \\nTrace events 356Amazon Bedrock User Guide\\n    \"finalResponse\": { \\n        \"text\" \\n    }\\n}\\nThe following list describes the ﬁelds of the Observation object:\\n•traceId – The unique identiﬁer of the trace.\\n•type – Speciﬁes whether the agent\\'s observation is returned from the result of an \\naction group or a knowledge base, if the agent is reprompting the user, requesting more \\ninformation, or ending the conversation.\\n•actionGroupInvocationOutput  – Contains the JSON-formatted string returned by the \\nAPI operation that was invoked by the action group. Appears if the type  is ACTION_GROUP . \\nFor more information, see Deﬁne OpenAPI schemas for your agent\\'s action groups in Amazon \\nBedrock.\\n•knowledgeBaseLookupOutput  – Contains text retrieved from the knowledge base that is \\nrelevant to responding to the prompt, alongside the Amazon S3 location of the data source. \\nAppears if the type  is KNOWLEDGE_BASE . For more information, see Knowledge base for \\nAmazon Bedrock. Each object in the list of retrievedReferences  contains the following \\nﬁelds:\\n•content  – Contains text from the knowledge base that is returned from the knowledge \\nbase query.\\n•location  – Contains the Amazon S3 URI of the data source from which the returned text \\nwas found.\\n•repromptResponse  – Appears if the type  is REPROMPT . Contains the text  that asks for a \\nprompt again alongside the source of why the agent needs to reprompt.\\n•finalResponse  – Appears if the type  is ASK_USER  or FINISH . Contains the text  that asks \\nthe user for more information or is a response to the user.\\nPostProcessingTrace\\n{ \\n    \"modelInvocationInput\": { // see above for details } \\n    \"modelInvocationOutput\": { \\n        \"parsedResponse\": { \\n            \"text\": \"string\" \\nTrace events 357Amazon Bedrock User Guide\\n        }, \\n        \"traceId\": \"string\" \\n    }\\n}\\nThe PostProcessingTrace consists of a ModelInvocationInput object and a\\nPostProcessingModelInvocationOutput object. The PostProcessingModelInvocationOutput contains \\nthe following ﬁelds:\\n•parsedResponse  – Contains the text to return to the user after the text is processed by the \\nparser function.\\n•traceId – The unique identiﬁer of the trace.\\nFailureTrace\\n{ \\n    \"failureReason\": \"string\", \\n    \"traceId\": \"string\"\\n}\\nThe following list describes the ﬁelds of the FailureTrace object:\\n•failureReason  – The reason that the step failed.\\n•traceId – The unique identiﬁer of the trace.\\nManage an Amazon Bedrock agent\\nAfter you create an agent, you can view or update its conﬁguration as required. The conﬁguration \\napplies to the working draft. If you no longer need an agent, you can delete it.\\nTopics\\n•View information about an agent\\n•Edit an agent\\n•Delete an agent\\n•Manage the action groups of an agent\\n•Manage agent-knowledge bases associations\\nManage an agent 358Amazon Bedrock User Guide\\nView information about an agent\\nTo learn how to view information about an agent, select the tab corresponding to your method of \\nchoice and follow the steps.\\nConsole\\nTo view information about an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. On the agent details, you can view the following information:\\n•The Agent overview section contains the agent conﬁguration.\\n•The Tags section contains tags that are associated with the agent. For more information, \\nsee Tag resources.\\n•The Working draft section contains the working draft. If you select the working draft, \\nyou can view the following information:\\n•The Model details  section contains model and instructions used by the agent\\'s working \\ndraft.\\n•The Action groups section contains the action groups that the agent uses. For more \\ninformation, see Create an action group for an Amazon Bedrock agent and Manage the \\naction groups of an agent.\\n•The Knowledge bases section contains the knowledge bases associated with the \\nagent. For more information, see Associate a knowledge base with an Amazon Bedrock \\nagent  and Manage agent-knowledge bases associations.\\n•The Advanced prompts section contains the prompt templates for each step of \\nthe agent\\'s orchestration. For more information, see Advanced prompts in Amazon \\nBedrock.\\n•The Versions and Aliases  sections contain versions and aliases of the agent that you can \\nuse for deployment to your applications. For more information, see Deploy an Amazon \\nBedrock agent.\\nView information about an agent 359Amazon Bedrock User Guide\\nAPI\\nTo get information about an agent, send a GetAgent request (see link for request and response \\nformats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint and specify \\nthe agentId . See code examples.\\nTo list information about your agents, send a ListAgents request (see link for request and \\nresponse formats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint.\\nSee code examples. You can specify the following optional parameters:\\nField Short description\\nmaxResults The maximum number of results to return in \\na response.\\nnextToken If there are more results than the number \\nyou speciﬁed in the maxResults  ﬁeld, \\nthe response returns a nextToken  value. \\nTo see the next batch of results, send the\\nnextToken  value in another request.\\nTo list all the tags for an agent, send a ListTagsForResource request (see link for request and \\nresponse formats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint\\nand include the Amazon Resource Name (ARN) of the agent.\\nEdit an agent\\nTo learn how to edit an agent, select the tab corresponding to your method of choice and follow \\nthe steps.\\nConsole\\nTo edit the agent conﬁguration\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. In the Agent overview section, choose Edit.\\nEdit an agent 360Amazon Bedrock User Guide\\n4. Edit the existing information in the ﬁelds as necessary.\\n5. When you\\'re done editing the information, choose Save to remain in the same window or\\nSave and exit to return to the agent details page. A success banner appears at the top. To \\napply the new conﬁgurations to your agent, select Prepare  in the banner.\\nYou might want to try diﬀerent foundation models for your agent or change the instructions for \\nthe agent. These changes apply only to the working draft.\\nTo change the foundation model that your agent uses or the instructions to the agent.\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent in the Agents  section.\\n4. On the agent details page, for the Working draft section, choose the working draft.\\n5. In the Model details  section, choose Edit\\n6. Select a diﬀerent model or edit the instructions to the agent as necessary.\\nNote\\nIf you change the foundation model, any prompt templates that you modiﬁed will \\nbe set to default for that model.\\n7. When you\\'re done editing the information, choose Save to remain in the same window or\\nSave and exit to return to the agent details page. A success banner appears at the top.\\n8. To apply the changes that you made to the agent before testing it, choose Prepare  in the\\nTest window or at the top of the Working draft page.\\nTo edit the tags associated with an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent in the Agents  section.\\n4. In the Tags section, choose Manage tags .\\nEdit an agent 361Amazon Bedrock User Guide\\n5. To add a tag, choose Add new tag . Then enter a Key and optionally enter a Value. To \\nremove a tag, choose Remove. For more information, see Tag resources.\\n6. When you\\'re done editing tags, choose Submit .\\nAPI\\nTo edit an agent, send an UpdateAgent request (see link for request and response formats and \\nﬁeld details) with an Agents for Amazon Bedrock build-time endpoint. Because all ﬁelds will \\nbe overwritten, include both ﬁelds that you want to update as well as ﬁelds that you want to \\nkeep the same. For more information about required and optional ﬁelds, see Create an agent in \\nAmazon Bedrock.\\nTo apply the changes to the working draft, send a PrepareAgent request (see link for request \\nand response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint . Include the agentId in the request. The changes apply to the DRAFT version, which \\nthe TSTALIASID  alias points to.\\nTo add tags to an agent, send a TagResource request (see link for request and response formats \\nand ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint and include the \\nAmazon Resource Name (ARN) of the agent. The request body contains a tags  ﬁeld, which is an \\nobject containing a key-value pair that you specify for each tag.\\nTo remove tags from an agent, send an UntagResource request (see link for request and \\nresponse formats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint\\nand include the Amazon Resource Name (ARN) of the agent. The tagKeys request parameter is \\na list containing the keys for the tags that you want to remove.\\nDelete an agent\\nTo learn how to delete an agent, select the tab corresponding to your method of choice and follow \\nthe steps.\\nConsole\\nTo delete an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\nDelete an agent 362Amazon Bedrock User Guide\\n2. Select Agents  from the left navigation pane.\\n3. To delete an agent, choose the option button that\\'s next to the agent you want to delete.\\n4. A dialog box appears warning you about the consequences of deletion. To conﬁrm that you \\nwant to delete the agent, enter delete in the input ﬁeld and then select Delete.\\n5. When deletion is complete, a success banner appears.\\nAPI\\nTo delete an agent, send a DeleteAgent request (see link for request and response formats and \\nﬁeld details) with an Agents for Amazon Bedrock build-time endpoint and specify the agentId .\\nBy default, the skipResourceInUseCheck  parameter is false  and deletion is stopped if the \\nresource is in use. If you set skipResourceInUseCheck  to true, the resource will be deleted \\neven if the resource is in use.\\nSee code examples\\nSelect a topic to learn about how to manage the action groups or knowledge bases for an agent.\\nTopics\\n•Manage the action groups of an agent\\n•Manage agent-knowledge bases associations\\nManage the action groups of an agent\\nAfter creating an action group, you can view, edit, or delete it. The changes apply to the working \\ndraft version of the agent.\\nTopics\\n•View information about an action group\\n•Edit an action group\\n•Delete an action group\\nManage action groups 363Amazon Bedrock User Guide\\nView information about an action group\\nTo learn how to view information about an action group, select the tab corresponding to your \\nmethod of choice and follow the steps.\\nConsole\\nTo view information about an action group\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent in the Agents  section.\\n4. On the agent details page, for the Working draft section, choose the working draft.\\n5. In the Action groups section, choose an action group for which to view information.\\nAPI\\nTo get information about an action group, send a GetAgentActionGroup request (see link for \\nrequest and response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint  and specify the actionGroupId , agentId , and agentVersion .\\nTo list information about an agent\\'s action groups, send a ListAgentActionGroups request (see \\nlink for request and response formats and ﬁeld details) with an Agents for Amazon Bedrock \\nbuild-time endpoint . Specify the agentId  and agentVersion  for which you want to see \\naction groups. You can include the following optional parameters:\\nField Short description\\nmaxResults The maximum number of results to return in \\na response.\\nnextToken If there are more results than the number \\nyou speciﬁed in the maxResults  ﬁeld, \\nthe response returns a nextToken  value. \\nTo see the next batch of results, send the\\nnextToken  value in another request.\\nManage action groups 364Amazon Bedrock User Guide\\nSee code examples\\nEdit an action group\\nTo learn how to edit an action group, select the tab corresponding to your method of choice and \\nfollow the steps.\\nConsole\\nTo edit an action group\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent in the Agents  section.\\n4. On the agent details page, for the Working draft section, choose the working draft.\\n5. In the Action groups section, select an action group to edit. Then choose Edit.\\n6. Edit the existing ﬁelds as necessary. For more information, see Create an action group for \\nan Amazon Bedrock agent.\\n7. To deﬁne the schema for the action group with the in-line OpenAPI schema editor, for\\nSelect API schema, choose Deﬁne with in-line OpenAPI schema editor . A sample schema \\nappears that you can edit. You can conﬁgure the following options:\\n•To import an existing schema from Amazon S3 to edit, choose Import schema, provide \\nthe Amazon S3 URI, and select Import.\\n•To restore the schema to the original sample schema, choose Reset and then conﬁrm the \\nmessage that appears by choosing Conﬁrm .\\n•To select a diﬀerent format for the schema, use the dropdown menu labeled JSON.\\n•To change the visual appearance of the schema, choose the gear icon below the schema.\\n8. To control whether the agent can use the action group, select Enable or Disable. Use this \\nfunction to help troubleshoot your agent\\'s behavior.\\n9. To remain in the same window so that you can test your change, choose Save. To return to \\nthe action group details page, choose Save and exit.\\n10. A success banner appears if there are no issues. If there are issues validating the schema, an \\nerror banner appears. To see a list of errors, choose Show details in the banner.\\nManage action groups 365Amazon Bedrock User Guide\\n11. To apply the changes that you made to the agent before testing it, choose Prepare  in the\\nTest window or at the top of the Working draft page.\\nAPI\\nTo edit an action group, send an UpdateAgentActionGroup request (see link for request and \\nresponse formats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint. \\nBecause all ﬁelds will be overwritten, include both ﬁelds that you want to update as well as \\nﬁelds that you want to keep the same. You must specify the agentVersion  as DRAFT. For \\nmore information about required and optional ﬁelds, see Create an action group for an Amazon \\nBedrock agent.\\nTo apply the changes to the working draft, send a PrepareAgent request (see link for request \\nand response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint . Include the agentId in the request. The changes apply to the DRAFT version, which \\nthe TSTALIASID  alias points to.\\nDelete an action group\\nTo learn how to delete an action group, select the tab corresponding to your method of choice and \\nfollow the steps.\\nConsole\\nTo delete an action group\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent in the Agents  section.\\n4. On the agent details page, for the Working draft section, choose the working draft.\\n5. In the Action groups section, choose the option button that\\'s next to the action group you \\nwant to delete.\\n6. A dialog box appears warning you about the consequences of deletion. To conﬁrm that you \\nwant to delete the action group, enter delete in the input ﬁeld and then select Delete.\\n7. When deletion is complete, a success banner appears.\\nManage action groups 366Amazon Bedrock User Guide\\n8. To apply the changes that you made to the agent before testing it, choose Prepare  in the\\nTest window or at the top of the Working draft page.\\nAPI\\nTo delete an action group, send a DeleteAgentActionGroup request. Specify the\\nactionGroupId  and the agentId  and agentVersion  from which to delete it. By default, the\\nskipResourceInUseCheck  parameter is false and deletion is stopped if the resource is in \\nuse. If you set skipResourceInUseCheck  to true, the resource will be deleted even if the \\nresource is in use.\\nTo apply the changes to the working draft, send a PrepareAgent request (see link for request \\nand response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint . Include the agentId in the request. The changes apply to the DRAFT version, which \\nthe TSTALIASID  alias points to.\\nManage agent-knowledge bases associations\\nAfter creating an agent, you can add more knowledge bases or edit them. Adding and editing take \\nplace within the working draft. To carry out these operations, choose an agent from the Agents\\nsection and then choose the Working draft in the Working Draft section.\\nTopics\\n•View information about an agent-knowledge base association\\n•Edit an agent-knowledge base association\\n•Disassociate a knowledge base from an agent\\nView information about an agent-knowledge base association\\nTo learn how to view information about a knowledge base, select the tab corresponding to your \\nmethod of choice and follow the steps.\\nConsole\\nTo view information about a knowledge base that\\'s associated with an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\nManage agent-knowledge bases associations 367Amazon Bedrock User Guide\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent in the Agents  section.\\n4. On the agent details page, for the Working draft section, choose the working draft.\\n5. In the Knowledge bases section, select the knowledge base for which you want to view \\ninformation.\\nAPI\\nTo get information about a knowledge base associated with an agent, send a\\nGetAgentKnowledgeBase request (see link for request and response formats and ﬁeld details) \\nwith an Agents for Amazon Bedrock build-time endpoint. Specify the following ﬁelds:\\nTo list information about the knowledge bases associated with an agent, send a\\nListAgentKnowledgeBases request (see link for request and response formats and ﬁeld \\ndetails) with an Agents for Amazon Bedrock build-time endpoint. Specify the agentId  and\\nagentVersion  for which you want to see associated knowledge bases.\\nField Short description\\nmaxResults The maximum number of results to return in \\na response.\\nnextToken If there are more results than the number \\nyou speciﬁed in the maxResults  ﬁeld, \\nthe response returns a nextToken  value. \\nTo see the next batch of results, send the\\nnextToken  value in another request.\\nSee code examples\\nEdit an agent-knowledge base association\\nTo learn how to edit an agent-knowledge base association, select the tab corresponding to your \\nmethod of choice and follow the steps.\\nManage agent-knowledge bases associations 368Amazon Bedrock User Guide\\nConsole\\nTo edit an agent-knowledge base association\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent in the Agents  section.\\n4. On the agent details page, for the Working draft section, choose the working draft.\\n5. In the Action groups section, select an action group to edit. Then choose Edit.\\n6. Edit the existing ﬁelds as necessary. For more information, see Associate a knowledge base \\nwith an Amazon Bedrock agent.\\n7. To control whether the agent can use the knowledge base, select Enabled or Disabled. Use \\nthis function to help troubleshoot your agent\\'s behavior.\\n8. To remain in the same window so that you can test your change, choose Save. To return to \\nthe Working draft page, choose Save and exit.\\n9. To apply the changes that you made to the agent before testing it, choose Prepare  in the\\nTest window or at the top of the Working draft page.\\nAPI\\nTo edit the conﬁguration of a knowledge base associated with an agent, send an\\nUpdateAgentKnowledgeBase request (see link for request and response formats and ﬁeld \\ndetails) with an Agents for Amazon Bedrock build-time endpoint. Because all ﬁelds will be \\noverwritten, include both ﬁelds that you want to update as well as ﬁelds that you want to keep \\nthe same. You must specify the agentVersion  as DRAFT. For more information about required \\nand optional ﬁelds, see Associate a knowledge base with an Amazon Bedrock agent.\\nTo apply the changes to the working draft, send a PrepareAgent request (see link for request \\nand response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint . Include the agentId in the request. The changes apply to the DRAFT version, which \\nthe TSTALIASID  alias points to.\\nManage agent-knowledge bases associations 369Amazon Bedrock User Guide\\nDisassociate a knowledge base from an agent\\nTo learn how to disassociate a knowledge base from an agent, select the tab corresponding to your \\nmethod of choice and follow the steps.\\nConsole\\nTo dissociate a knowledge base from an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose an agent in the Agents  section.\\n4. On the agent details page, for the Working draft section, choose the working draft.\\n5. In the Knowledge bases section, choose the option button that\\'s next to the knowledge \\nbase that you want to delete. Then choose Delete.\\n6. Conﬁrm the message that appears and then choose Delete.\\n7. To apply the changes that you made to the agent before testing it, choose Prepare  in the\\nTest window or at the top of the Working draft page.\\nAPI\\nTo disassociate a knowledge base from an agent, send a DisassociateAgentKnowledgeBase\\nrequest (see link for request and response formats and ﬁeld details) with an Agents for \\nAmazon Bedrock build-time endpoint. Specify the knowledgeBaseId  and the agentId  and\\nagentVersion  of the agent from which to disassociate it.\\nTo apply the changes to the working draft, send a PrepareAgent request (see link for request \\nand response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint . Include the agentId in the request. The changes apply to the DRAFT version, which \\nthe TSTALIASID  alias points to.\\nCustomize an Amazon Bedrock agent\\nAfter you have set up your agent, you can further customize its behavior with the following \\nfeatures:\\nCustomize an agent 370Amazon Bedrock User Guide\\n•Advanced prompts let you modify prompt templates to determine the prompt that is sent to \\nthe agent at each step of runtime.\\n•Session state  is a ﬁeld that contains attributes that you can deﬁne in build-time when sending \\na CreateAgent request or send at runtime with an InvokeAgent request. You can use these \\nattributes to provide and manage context in a conversation between users and the agent.\\nSelect a topic to learn more about that feature.\\nTopics\\n•Advanced prompts in Amazon Bedrock\\n•Control session context\\nAdvanced prompts in Amazon Bedrock\\nAfter creation, an agent is conﬁgured with the following four default base prompt templates , \\nwhich outline how the agent constructs prompts to send to the foundation model at each step of \\nthe agent sequence. For details about what each step encompasses, see Runtime process.\\n•Pre-processing\\n•Orchestration\\n•Knowledge base response generation\\n•Post-processing (disabled by default)\\nPrompt templates deﬁne how the agent does the following:\\n•Processes user input text and output prompts from foundation models (FMs)\\n•Orchestrates between the FM, action groups, and knowledge bases\\n•Formats and returns responses to the user\\nBy using advanced prompts, you can enhance your agent\\'s accuracy through modifying these \\nprompt templates to provide detailed conﬁgurations. You can also provide hand-curated examples \\nfor few-shot prompting , in which you improve model performance by providing labeled examples \\nfor a speciﬁc task.\\nSelect a topic to learn more about advanced prompts.\\nAdvanced prompts 371Amazon Bedrock User Guide\\nTopics\\n•Advanced prompts terminology\\n•Conﬁgure the prompt templates\\n•Placeholder variables in Amazon Bedrock agent prompt templates\\n•Parser Lambda function in Agents for Amazon Bedrock\\nAdvanced prompts terminology\\nThe following terminology is helpful in understanding how advanced prompts work.\\n•Session  – A group of InvokeAgent requests made to the same agent with the same session ID. \\nWhen you make an InvokeAgent  request, you can reuse a sessionId  that was returned from \\nthe response of a previous call in order to continue the same session with an agent. As long as \\nthe idleSessionTTLInSeconds  time in the Agent conﬁguration hasn\\'t expired, you maintain \\nthe same session with the agent.\\n•Turn – A single InvokeAgent  call. A session consists of one or more turns.\\n•Iteration  – A sequence of the following actions:\\n1.(Required) A call to the foundation model\\n2.(Optional) An action group invocation\\n3.(Optional) A knowledge base invocation\\n4.(Optional) A response to the user asking for more information\\nAn action might be skipped, depending on the conﬁguration of the agent or the agent\\'s \\nrequirement at that moment. A turn consists of one or more iterations.\\n•Prompt  – A prompt consists of the instructions to the agent, context, and text input. The text \\ninput can come from a user or from the output of another step in the agent sequence. The \\nprompt is provided to the foundation model to determine the next step that the agent takes in \\nresponding to user input\\n•Base prompt template  – The structural elements that make up a prompt. The template consists \\nof placeholders that are ﬁlled in with user input, the agent conﬁguration, and context at runtime \\nto create a prompt for the foundation model to process when the agent reaches that step. For \\nmore information about these placeholders, see Placeholder variables in Amazon Bedrock agent \\nprompt templates). With advanced prompts, you can edit these templates.\\nAdvanced prompts 372Amazon Bedrock User Guide\\nConﬁgure the prompt templates\\nWith advanced prompts, you can do the following:\\n•Turn on or turn oﬀ invocation for diﬀerent steps in the agent sequence.\\n•Conﬁgure their inference parameters.\\n•Edit the default base prompt templates that the agent uses. By overriding the logic with your \\nown conﬁgurations, you can customize your agent\\'s behavior.\\nFor each step of the agent sequence, you can edit the following parts:\\n•Prompt template  – Describes how the agent should evaluate and use the prompt that it receives \\nat the step for which you\\'re editing the template. When editing a template, you can engineer the \\nprompt with the following tools:\\n•Prompt template placeholders – Pre-deﬁned variables in Agents for Amazon Bedrock that are \\ndynamically ﬁlled in at runtime during agent invocation. In the prompt templates, you\\'ll see \\nthese placeholders surrounded by $ (for example, $instructions$ ). For information about \\nthe placeholder variables that you can use in a template, see Placeholder variables in Amazon \\nBedrock agent prompt templates.\\n•XML tags  – Anthropic models support the use of XML tags to structure and delineate \\nyour prompts. Use descriptive tag names for optimal results. For example, in the default \\norchestration prompt template, you\\'ll see the <examples>  tag used to delineate few-shot \\nexamples). For more information, see Use XML tags  in the Anthropic user guide.\\nYou can enable or disable any step in the agent sequence. The following table shows the default \\nstates for each step.\\nPrompt template Default setting\\nPre-processing Enabled\\nOrchestration Enabled\\nKnowledge base response generation Enabled\\nPost-processing Disabled\\nAdvanced prompts 373Amazon Bedrock User Guide\\nNote\\nIf you disable the orchestration step, the agent sends the raw user input to the \\nfoundation model and doesn\\'t use the base prompt template for orchestration.\\nIf you disable any of the other steps, the agent skips that step entirely.\\n•Inference conﬁgurations – Inﬂuences the response generated by the model that you use. For \\ndeﬁnitions of the inference parameters and more details about the parameters that diﬀerent \\nmodels support, see Inference parameters for foundation models.\\n•(Optional) Parser Lambda function – Deﬁnes how to parse the raw foundation model output \\nand how to use it in the runtime ﬂow. This function acts on the output from the steps in which \\nyou enable it and returns the parsed response as you deﬁne it in the function.\\nDepending on how you customized the base prompt template, the raw foundation model output \\nmight be speciﬁc to the template. As a result, the agent\\'s default parser might have diﬃculty \\nparsing the output correctly. By witing a custom parser Lambda function, you can help the agent \\nparse the raw foundation model output based on your use-case. For more information about the \\nparser Lambda function and how to write it, see Parser Lambda function in Agents for Amazon \\nBedrock.\\nNote\\nYou can deﬁne one parser Lambda function for all of the base templates, but you can \\nconﬁgure whether to invoke the function in each step. Be sure to conﬁgure a resource-\\nbased policy for your Lambda function so that your agent can invoke it. For more \\ninformation, see Resource-based policy to allow Amazon Bedrock to invoke an action \\ngroup Lambda function.\\nAfter you edit the prompt templates, you can test your agent. To analyze the step-by-step process \\nof the agent and determine if it is working as you intend, turn on the trace and examine it. For \\nmore information, see Trace events in Amazon Bedrock.\\nYou can conﬁgure advanced prompts in either the AWS Management Console or through the API.\\nAdvanced prompts 374Amazon Bedrock User Guide\\nConsole\\nIn the console, you can conﬁgure advanced prompts after you have created the agent. You \\nconﬁgure them while editing the agent.\\nTo view or edit advanced prompts for your agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. In the left navigation pane, choose Agents . Then choose an agent in the Agents  section.\\n3. On the agent details page, in the Working draft section, select Working draft.\\n4. On the Working draft page, in the Advanced prompts section, choose Edit.\\n5. On the Edit advanced prompts page, choose the tab corresponding to the step of the \\nagent sequence that you want to edit.\\n6. To enable editing of the template, turn on Override template defaults. In the Override \\ntemplate defaults  dialog box, choose Conﬁrm .\\nWarning\\nIf you turn oﬀ Override template defaults or change the model, the default \\nAmazon Bedrock template is used and your template will be immediately deleted. \\nTo conﬁrm, enter confirm in the text box to conﬁrm the message that appears.\\n7. To allow the agent to use the template when generating responses, turn on Activate \\ntemplate . If this conﬁguration is turned oﬀ, the agent doesn\\'t use the template.\\n8. To modify the example prompt template, use the Prompt template editor .\\n9. In Conﬁgurations , you can modify inference parameters for the prompt. For deﬁnitions of \\nparameters and more information about parameters for diﬀerent models, see Inference \\nparameters for foundation models .\\n10. (Optional) To use a Lambda function that you have deﬁned to parse the raw foundation \\nmodel output, perform the following actions:\\nNote\\nOne Lambda function is used for all the prompt templates.\\nAdvanced prompts 375Amazon Bedrock User Guide\\na. In the Conﬁgurations  section, select Use Lambda function for parsing. If you clear \\nthis setting, your agent will use the default parser for the prompt.\\nb. For the Parser Lambda function, select a Lambda function from the dropdown menu.\\nNote\\nYou must attach permissions for your agent so that it can access the Lambda \\nfunction. For more information, see Resource-based policy to allow Amazon \\nBedrock to invoke an action group Lambda function.\\n11. To save your settings, choose one of the following options:\\na. To remain in the same window so that you can dynamically update the prompt settings \\nwhile testing your updated agent, choose Save.\\nb. To save your settings and return to the Working draft page, choose Save and exit.\\n12. To test the updated settings, choose Prepare  in the Test window.\\nAdvanced prompts 376Amazon Bedrock User Guide\\nAPI\\nTo conﬁgure advanced prompts by using the API operations, you send a CreateAgent or\\nUpdateAgent call and modify the following promptOverrideConfiguration  object.\\n\"promptOverrideConfiguration\": {  \\n    \"overrideLambda\": \"string\", \\n    \"promptConfigurations\": [  \\n        {  \\n            \"basePromptTemplate\": \"string\", \\n            \"inferenceConfiguration\": {  \\n                \"maximumLength\": int, \\n                \"stopSequences\": [ \"string\" ], \\n                \"temperature\": float, \\n                \"topK\": float, \\n                \"topP\": float \\n            }, \\n            \"parserMode\": \"DEFAULT | OVERRIDDEN\", \\n            \"promptCreationMode\": \"DEFAULT | OVERRIDDEN\", \\n            \"promptState\": \"ENABLED | DISABLED\", \\n            \"promptType\": \"PRE_PROCESSING | ORCHESTRATION | \\n KNOWLEDGE_BASE_RESPONSE_GENERATION | POST_PROCESSING\" \\n        } \\n    ]\\n}\\n1. In the promptConfigurations  list, include a promptConfiguration  object for each \\nprompt template that you want to edit.\\n2. Specify the prompt to modify in the promptType  ﬁeld.\\n3. Modify the prompt template through the following steps:\\na. Specify the basePromptTemplate  ﬁelds with your prompt template.\\nb. Include inference parameters in the inferenceConfiguration  objects. For more \\ninformation about inference conﬁgurations, see Inference parameters for foundation \\nmodels .\\n4. To enable the prompt template, set the promptCreationMode  to OVERRIDDEN .\\n5. To allow or prevent the agent from performing the step in the promptType  ﬁeld, modify \\nthe promptState  value. This setting can be useful for troubleshooting the agent\\'s \\nbehavior.\\nAdvanced prompts 377Amazon Bedrock User Guide\\n•If you set promptState  to DISABLED  for the PRE_PROCESSING ,\\nKNOWLEDGE_BASE_RESPONSE_GENERATION , or POST_PROCESSING  steps, the agent \\nskips that step.\\n•If you set promptState  to DISABLED  for the ORCHESTRATION  step, the agent sends \\nonly the user input to the foundation model in orchestration. In addition, the agent \\nreturns the response as is without orchestrating calls between API operations and \\nknowledge bases.\\n•By default, the POST_PROCESSING  step is DISABLED . By default, the PRE_PROCESSING ,\\nORCHESTRATION , and KNOWLEDGE_BASE_RESPONSE_GENERATION  steps are ENABLED .\\n6. To use a Lambda function that you have deﬁned to parse the raw foundation model output, \\nperform the following steps:\\na. For each prompt template that you want to enable the Lambda function for, set\\nparserMode  to OVERRIDDEN .\\nb. Specify the Amazon Resource Name (ARN) of the Lambda function in the\\noverrideLambda  ﬁeld in the promptOverrideConfiguration  object.\\nPlaceholder variables in Amazon Bedrock agent prompt templates\\nYou can use placeholder variables in agent prompt templates. The variables will be populated by \\npre-existing conﬁgurations when the prompt template is called. Select a tab to see variables that \\nyou can use for each prompt template.\\nPre-processing\\nVariable Models supported Replaced by\\n$functions$ Anthropic Claude Instant, \\nClaude v2.0\\n$tools$ Anthropic Claude v2.1Action group API operation \\ns and knowledge bases \\nconﬁgured for the agent.\\n$conversation_history$ All Conversation history for the \\ncurrent session\\nAdvanced prompts 378Amazon Bedrock User Guide\\nVariable Models supportedReplaced by\\n$question$ All User input for the current\\nInvokeAgent  call in the \\nsession.\\nOrchestration\\nVariable Models supported Replaced by\\n$functions$ Anthropic Claude Instant, \\nClaude v2.0\\n$tools$ Anthropic Claude v2.1Action group API operation \\ns and knowledge bases \\nconﬁgured for the agent.\\n$agent_scratchpad$ All Designates an area for \\nthe model to write down \\nits thoughts and actions \\nit has taken. Replaced by \\npredictions and output of \\nthe previous iterations in the \\ncurrent turn. Provides the \\nmodel with context of what \\nhas been achieved for the \\ngiven user input and what \\nthe next step should be.\\n$any_function_name$ Anthropic Claude Instant, \\nClaude v2.0A randomly chosen API \\nname from the API names \\nthat exist in the agent\\'s \\naction groups.\\n$conversation_history$ All Conversation history for the \\ncurrent session\\n$instruction$ All Model instructions conﬁgure \\nd for the agent.\\nAdvanced prompts 379Amazon Bedrock User Guide\\nVariable Models supportedReplaced by\\n$prompt_session_attributes\\n$All Session attributes preserved \\nacross a prompt\\n$question$ All User input for the current\\nInvokeAgent  call in the \\nsession.\\nYou can use the following placeholder variables if you allow the agent to ask the user for more \\ninformation by doing one of the following actions:\\n•In the console, set in the User input  in the agent details.\\n•Set the parentActionGroupSignature  to AMAZON.UserInput  with a\\nCreateAgentActionGroup or UpdateAgentActionGroup request.\\nVariable Models supported Replaced by\\n$ask_user_missing_ \\nparameters$Anthropic Claude Instant, \\nClaude v2.0\\n$ask_user_missing_informati \\non$Anthropic Claude v2.1Instructions for the model \\nto ask the user to provide \\nrequired missing information\\n$ask_user_conﬁrm_ \\nparameters$All Instructions for the model \\nto ask the user to conﬁrm \\nparameters that the agent \\nhasn\\'t yet received or is \\nunsure of.\\n$ask_user_function$ All A function to ask the user a \\nquestion.\\n$ask_user_function_format$ All The format of the function \\nto ask the user a question.\\nAdvanced prompts 380Amazon Bedrock User Guide\\nVariable Models supportedReplaced by\\n$ask_user_input_examples$ All Few-shot examples to \\ninform the model how to \\npredict when it should ask \\nthe user a question.\\nKnowledge base response generation\\nVariable Model Replaced by\\n$query$ All The query generated by \\nthe orchestration prompt \\nmodel response when it \\npredicts the next step to be \\nknowledge base querying.\\n$search_results$ All The retrieved results for the \\nuser query\\nPost-processing\\nVariable Model Replaced by\\n$latest_response$ All The last orchestration \\nprompt model response\\n$question$ All User input for the current\\nInvokeAgent  call in the \\nsession.\\n$responses$ All The action group and \\nknowledge base outputs \\nfrom the current turn.\\nAdvanced prompts 381Amazon Bedrock User Guide\\nParser Lambda function in Agents for Amazon Bedrock\\nEach prompt template includes a parser Lambda function that you can modify. To write a custom \\nparser Lambda function, you must understand the input event that your agent sends and the \\nresponse that the agent expects as the output from the Lambda function. You write a handler \\nfunction to manipulate variables from the input event and to return the response. For more \\ninformation about how AWS Lambda works, see Event-driven invocation in the AWS Lambda \\nDeveloper Guide.\\nTopics\\n•Parser Lambda input event\\n•Parser Lambda response\\n•Parser Lambda examples\\nParser Lambda input event\\nThe following is the general structure of the input event from the agent. Use the ﬁelds to write \\nyour Lambda handler function.\\n{ \\n    \"messageVersion\": \"1.0\", \\n    \"agent\": { \\n        \"name\": \"string\", \\n        \"id\": \"string\", \\n        \"alias\": \"string\", \\n        \"version\": \"string\" \\n    }, \\n    \"invokeModelRawResponse\": \"string\", \\n    \"promptType\": \"ORCHESTRATION | POST_PROCESSING | PRE_PROCESSING | \\n KNOWLEDGE_BASE_RESPONSE_GENERATION \", \\n    \"overrideType\": \"OUTPUT_PARSER\"\\n}\\nThe following list describes the input event ﬁelds:\\n•messageVersion  – The version of the message that identiﬁes the format of the event data \\ngoing into the Lambda function and the expected format of the response from the Lambda \\nfunction. Agents for Amazon Bedrock only supports version 1.0.\\nAdvanced prompts 382Amazon Bedrock User Guide\\n•agent – Contains information about the name, ID, alias, and version of the agent that the \\nprompts belongs to.\\n•invokeModelRawResponse  – The raw foundation model output of the prompt whose output is \\nto be parsed.\\n•promptType  – The prompt type whose output is to be parsed.\\n•overrideType  – The artifacts that this Lambda function overrides. Currently, only\\nOUTPUT_PARSER  is supported, which indicates that the default parser is to be overridden.\\nParser Lambda response\\nYour agent expects a response from your Lambda function that matches the following format. The \\nagent uses the response for further orchestration or to help it return a response to the user. Use \\nthe Lambda function response ﬁelds to conﬁgure how the output is returned.\\n{ \\n    \"messageVersion\": \"1.0\", \\n    \"promptType\": \"ORCHESTRATION | PRE_PROCESSING | POST_PROCESSING | \\n KNOWLEDGE_BASE_RESPONSE_GENERATION\", \\n    \"preProcessingParsedResponse\": { \\n        \"isValidInput\": \"boolean\", \\n        \"rationale\": \"string\" \\n    }, \\n    \"orchestrationParsedResponse\": { \\n        \"rationale\": \"string\", \\n        \"parsingErrorDetails\": { \\n            \"repromptResponse\": \"string\" \\n        }, \\n        \"responseDetails\": { \\n            \"invocationType\": \"ACTION_GROUP | KNOWLEDGE_BASE | FINISH | ASK_USER\", \\n            \"agentAskUser\": { \\n                \"responseText\": \"string\" \\n            }, \\n            \"actionGroupInvocation\": { \\n                \"actionGroupName\": \"string\", \\n                \"apiName\": \"string\", \\n                \"verb\": \"string\", \\n                \"actionGroupInput\": { \\n                    \" <parameter> \": { \\n                        \"value\": \"string\" \\n                    }, \\n                    ... \\nAdvanced prompts 383Amazon Bedrock User Guide\\n                } \\n            }, \\n            \"agentKnowledgeBase\": { \\n                \"knowledgeBaseId\": \"string\", \\n                \"searchQuery\": { \\n                    \"value\": \"string\" \\n                } \\n            }, \\n            \"agentFinalResponse\": { \\n                \"responseText\": \"string\", \\n                \"citations\": { \\n                    \"generatedResponseParts\": [{ \\n                        \"text\": \"string\", \\n                        \"references\": [{\"sourceId\": \"string\"}] \\n                    }] \\n                } \\n            }, \\n        } \\n    }, \\n    \"knowledgeBaseResponseGenerationParsedResponse\": {  \\n       \"generatedResponse\": { \\n            \"generatedResponseParts\": [ \\n                { \\n                    \"text\": \"string\", \\n                    \"references\": [ \\n                        {\"sourceId\": \"string\"}, \\n                        ... \\n                    ] \\n                } \\n            ] \\n        } \\n    }, \\n    \"postProcessingParsedResponse\": { \\n        \"responseText\": \"string\", \\n        \"citations\": { \\n            \"generatedResponseParts\": [{ \\n                \"text\": \"string\", \\n                \"references\": [{ \\n                    \"sourceId\": \"string\" \\n                }] \\n            }] \\n        } \\n    }\\nAdvanced prompts 384Amazon Bedrock User Guide\\n}\\nThe following list describes the Lambda response ﬁelds:\\n•messageVersion  – The version of the message that identiﬁes the format of the event data \\ngoing into the Lambda function and the expected format of the response from a Lambda \\nfunction. Agents for Amazon Bedrock only supports version 1.0.\\n•promptType  – The prompt type of the current turn.\\n•preProcessingParsedResponse  – The parsed response for the PRE_PROCESSING  prompt \\ntype.\\n•orchestrationParsedResponse  – The parsed response for the ORCHESTRATION  prompt \\ntype. See below for more details.\\n•knowledgeBaseResponseGenerationParsedResponse  – The parsed response for the\\nKNOWLEDGE_BASE_RESPONSE_GENERATION  prompt type.\\n•postProcessingParsedResponse  – The parsed response for the POST_PROCESSING  prompt \\ntype.\\nFor more details about the parsed responses for the four prompt templates, see the following tabs.\\npreProcessingParsedResponse\\n{ \\n    \"isValidInput\": \"boolean\", \\n    \"rationale\": \"string\"\\n}\\nThe preProcessingParsedResponse  contains the following ﬁelds.\\n•isValidInput  – Speciﬁes whether the user input is valid or not. You can deﬁne the function \\nto determine how to characterize the validity of user input.\\n•rationale  – The reasoning for the user input categorization. This rationale is provided by \\nthe model in the raw response, the Lambda function parses it, and the agent presents it in the \\ntrace for pre-processing.\\norchestrationResponse\\n{ \\nAdvanced prompts 385Amazon Bedrock User Guide\\n    \"rationale\": \"string\", \\n    \"parsingErrorDetails\": { \\n        \"repromptResponse\": \"string\" \\n    }, \\n    \"responseDetails\": { \\n        \"invocationType\": \"ACTION_GROUP | KNOWLEDGE_BASE | FINISH | ASK_USER\", \\n        \"agentAskUser\": { \\n            \"responseText\": \"string\" \\n        }, \\n        \"actionGroupInvocation\": { \\n            \"actionGroupName\": \"string\", \\n            \"apiName\": \"string\", \\n            \"verb\": \"string\", \\n            \"actionGroupInput\": { \\n                \" <parameter> \": { \\n                    \"value\": \"string\" \\n                }, \\n                ... \\n            } \\n        }, \\n        \"agentKnowledgeBase\": { \\n            \"knowledgeBaseId\": \"string\", \\n            \"searchQuery\": { \\n                \"value\": \"string\" \\n            } \\n        }, \\n        \"agentFinalResponse\": { \\n            \"responseText\": \"string\", \\n            \"citations\": { \\n                \"generatedResponseParts\": [ \\n                    { \\n                        \"text\": \"string\", \\n                        \"references\": [ \\n                            {\"sourceId\": \"string\"}, \\n                            ... \\n                        ] \\n                    }, \\n                    ... \\n                ] \\n            } \\n        }, \\n    }\\n}\\nAdvanced prompts 386Amazon Bedrock User Guide\\nThe orchestrationParsedResponse  contains the following ﬁelds:\\n•rationale  – The reasoning for what to do next, based on the foundation model output. You \\ncan deﬁne the function to parse from the model output.\\n•parsingErrorDetails  – Contains the repromptResponse , which is the message to \\nreprompt the model to update its raw response when the model response can\\'t be parsed. \\nYou can deﬁne the function to manipulate how to reprompt the model.\\n•responseDetails  – Contains the details for how to handle the output of the foundation \\nmodel. Contains an invocationType , which is the next step for the agent to take, and a \\nsecond ﬁeld that should match the invocationType . The following objects are possible.\\n•agentAskUser  – Compatible with the ASK_USER  invocation type. This invocation type \\nends the orchestration step. Contains the responseText  to ask the user for more \\ninformation. You can deﬁne your function to manipulate this ﬁeld.\\n•actionGroupInvocation  – Compatible with the ACTION_GROUP  invocation type. You \\ncan deﬁne your function to determine action groups to invoke and parameters to pass. \\nContains the following ﬁelds:\\n•actionGroupName  – The action group to invoke.\\n•apiName – The name of the API operation to invoke in the action group.\\n•verb  – The method of the API operation to use.\\n•actionGroupInput  – Contains parameters to specify in the API operation request.\\n•agentKnowledgeBase  – Compatible with the KNOWLEDGE_BASE  invocation type. You can \\ndeﬁne your function to determine how to query knowledge bases. Contains the following \\nﬁelds:\\n•knowledgeBaseId  – The unique identiﬁer of the knowledge base.\\n•searchQuery  – Contains the query to send to the knowledge base in the value  ﬁeld.\\n•agentFinalResponse  – Compatible with the FINISH invocation type. This invocation \\ntype ends the orchestration step. Contains the response to the user in the responseText\\nﬁeld and citations for the response in the citations  object.\\nknowledgeBaseResponseGenerationParsedResponse\\n{  \\n   \"generatedResponse\": { \\n        \"generatedResponseParts\": [ \\n            { \\nAdvanced prompts 387Amazon Bedrock User Guide\\n                \"text\": \"string\", \\n                \"references\": [ \\n                    { \"sourceId\": \"string\" }, \\n                    ... \\n                ] \\n            }, \\n            ... \\n        ] \\n    }\\n}\\nThe knowledgeBaseResponseGenerationParsedResponse  contains the\\ngeneratedResponse  from querying the knowledge base and references for the data sources.\\npostProcessingParsedResponse\\n{ \\n    \"responseText\": \"string\", \\n    \"citations\": { \\n        \"generatedResponseParts\": [ \\n            { \\n                \"text\": \"string\", \\n                \"references\": [ \\n                    { \"sourceId\": \"string\" }, \\n                    ... \\n                ] \\n            }, \\n            ... \\n        ] \\n    }\\n}\\nThe postProcessingParsedResponse  contains the following ﬁelds:\\n•responseText  – The response to return to the end user. You can deﬁne the function to \\nformat the response.\\n•citations  – Contains a list of citations for the response. Each citation shows the cited text \\nand its references.\\nAdvanced prompts 388Amazon Bedrock User Guide\\nParser Lambda examples\\nTo see an example parser Lambda function for a speciﬁc prompt template, select from the \\nfollowing tabs. Also shown are example input events sent to the function and responses from it. \\nThe lambda_handler  function returns the parsed response to the agent.\\nPre-processing\\nExample function\\nimport json\\nimport re\\nimport logging\\nPRE_PROCESSING_RATIONALE_REGEX = \"<thinking>(.*?)</thinking>\"\\nPREPROCESSING_CATEGORY_REGEX = \"<category>(.*?)</category>\"\\nPREPROCESSING_PROMPT_TYPE = \"PRE_PROCESSING\"\\nPRE_PROCESSING_RATIONALE_PATTERN = re.compile(PRE_PROCESSING_RATIONALE_REGEX, \\n re.DOTALL)\\nPREPROCESSING_CATEGORY_PATTERN = re.compile(PREPROCESSING_CATEGORY_REGEX, re.DOTALL)\\nlogger = logging.getLogger()\\n# This parser lambda is an example of how to parse the LLM output for the default \\n PreProcessing prompt\\ndef lambda_handler(event, context): \\n     \\n    print(\"Lambda input: \" + str(event)) \\n    logger.info(\"Lambda input: \" + str(event)) \\n     \\n    prompt_type = event[\"promptType\"] \\n     \\n    # Sanitize LLM response \\n    model_response = sanitize_response(event[\\'invokeModelRawResponse\\']) \\n     \\n    if event[\"promptType\"] == PREPROCESSING_PROMPT_TYPE: \\n        return parse_pre_processing(model_response)\\ndef parse_pre_processing(model_response): \\n     \\n    category_matches = re.finditer(PREPROCESSING_CATEGORY_PATTERN, model_response) \\n    rationale_matches = re.finditer(PRE_PROCESSING_RATIONALE_PATTERN, \\n model_response) \\nAdvanced prompts 389Amazon Bedrock User Guide\\n    category = next((match.group(1) for match in category_matches), None) \\n    rationale = next((match.group(1) for match in rationale_matches), None) \\n    return { \\n        \"promptType\": \"PRE_PROCESSING\", \\n        \"preProcessingParsedResponse\": { \\n            \"rationale\": rationale, \\n            \"isValidInput\": get_is_valid_input(category) \\n            } \\n        }\\ndef sanitize_response(text): \\n    pattern = r\"(\\\\\\\\n*)\" \\n    text = re.sub(pattern, r\"\\\\n\", text) \\n    return text \\n     \\ndef get_is_valid_input(category): \\n    if category is not None and category.strip().upper() == \"D\" or \\n category.strip().upper() == \"E\": \\n        return True \\n    return False \\n     \\n{ \\n    \"agent\": { \\n        \"alias\": \"TSTALIASID\", \\n        \"id\": \"AGENTID123\", \\n        \"name\": \"InsuranceAgent\", \\n        \"version\": \"DRAFT\" \\n    }, \\n    \"invokeModelRawResponse\": \" <thinking>\\\\nThe user is asking about the \\n instructions provided to the function calling agent. This input is trying to gather \\n information about what functions/API\\'s or instructions our function calling agent \\n has access to. Based on the categories provided, this input belongs in Category B.\\n\\\\n</thinking>\\\\n\\\\n<category>B</category>\", \\n    \"messageVersion\": \"1.0\", \\n    \"overrideType\": \"OUTPUT_PARSER\", \\n    \"promptType\": \"PRE_PROCESSING\"\\n}\\n{ \\n  \"promptType\": \"PRE_PROCESSING\", \\nAdvanced prompts 390Amazon Bedrock User Guide\\n  \"preProcessingParsedResponse\": { \\n    \"rationale\": \"\\\\nThe user is asking about the instructions provided to the \\n function calling agent. This input is trying to gather information about what \\n functions/API\\'s or instructions our function calling agent has access to. Based on \\n the categories provided, this input belongs in Category B.\\\\n\", \\n    \"isValidInput\": false \\n  }\\n}\\nOrchestration\\nThe following are example functions for Anthropic Claude 2 and Anthropic Claude 2.1.\\nAnthropic Claude 2\\nimport json\\nimport re\\nimport logging \\n  \\n  \\nRATIONALE_REGEX_LIST = [ \\n    \"(.*?)(<function_call>)\", \\n    \"(.*?)(<answer>)\"\\n]\\nRATIONALE_PATTERNS = [re.compile(regex, re.DOTALL) for regex in \\n RATIONALE_REGEX_LIST] \\n  \\nRATIONALE_VALUE_REGEX_LIST = [ \\n    \"<scratchpad>(.*?)(</scratchpad>)\", \\n    \"(.*?)(</scratchpad>)\", \\n    \"(<scratchpad>)(.*?)\"\\n]\\nRATIONALE_VALUE_PATTERNS = [re.compile(regex, re.DOTALL) for regex in \\n RATIONALE_VALUE_REGEX_LIST] \\n  \\nANSWER_REGEX = r\"(?<=<answer>)(.*)\"\\nANSWER_PATTERN = re.compile(ANSWER_REGEX, re.DOTALL) \\n  \\nANSWER_TAG = \"<answer>\"\\nFUNCTION_CALL_TAG = \"<function_call>\" \\n  \\nASK_USER_FUNCTION_CALL_REGEX = r\"(<function_call>user::askuser)(.*)\\\\)\"\\nASK_USER_FUNCTION_CALL_PATTERN = re.compile(ASK_USER_FUNCTION_CALL_REGEX, re.DOTALL) \\n  \\nAdvanced prompts 391Amazon Bedrock User Guide\\nASK_USER_FUNCTION_PARAMETER_REGEX = r\"(?<=askuser=\\\\\")(.*?)\\\\\"\"   \\nASK_USER_FUNCTION_PARAMETER_PATTERN = re.compile(ASK_USER_FUNCTION_PARAMETER_REGEX, \\n re.DOTALL) \\n  \\nKNOWLEDGE_STORE_SEARCH_ACTION_PREFIX = \"x_amz_knowledgebase_\" \\n  \\nFUNCTION_CALL_REGEX = r\"<function_call>(\\\\w+)::(\\\\w+)::(.+)\\\\((.+)\\\\)\" \\n  \\nANSWER_PART_REGEX = \"<answer_part\\\\\\\\s?>(.+?)</answer_part\\\\\\\\s?>\"\\nANSWER_TEXT_PART_REGEX = \"<text\\\\\\\\s?>(.+?)</text\\\\\\\\s?>\"   \\nANSWER_REFERENCE_PART_REGEX = \"<source\\\\\\\\s?>(.+?)</source\\\\\\\\s?>\"\\nANSWER_PART_PATTERN = re.compile(ANSWER_PART_REGEX, re.DOTALL)\\nANSWER_TEXT_PART_PATTERN = re.compile(ANSWER_TEXT_PART_REGEX, re.DOTALL)\\nANSWER_REFERENCE_PART_PATTERN = re.compile(ANSWER_REFERENCE_PART_REGEX, re.DOTALL) \\n  \\n# You can provide messages to reprompt the LLM in case the LLM output is not in the \\n expected format\\nMISSING_API_INPUT_FOR_USER_REPROMPT_MESSAGE = \"Missing the argument askuser for \\n user::askuser function call. Please try again with the correct argument added\"\\nASK_USER_FUNCTION_CALL_STRUCTURE_REMPROMPT_MESSAGE = \"The function call format \\n is incorrect. The format for function calls to the askuser function must be: \\n <function_call>user::askuser(askuser=\\\\\"$ASK_USER_INPUT\\\\\")</function_call>.\"\\nFUNCTION_CALL_STRUCTURE_REPROMPT_MESSAGE = \\'The function call format \\n is incorrect. The format for function calls must be: <function_call>\\n$FUNCTION_NAME($FUNCTION_ARGUMENT_NAME=\"\"$FUNCTION_ARGUMENT_NAME\"\")</\\nfunction_call>.\\'\\nlogger = logging.getLogger() \\n  \\n# This parser lambda is an example of how to parse the LLM output for the default \\n orchestration prompt\\ndef lambda_handler(event, context): \\n    logger.info(\"Lambda input: \" + str(event)) \\n     \\n    # Sanitize LLM response \\n    sanitized_response = sanitize_response(event[\\'invokeModelRawResponse\\']) \\n     \\n    # Parse LLM response for any rationale \\n    rationale = parse_rationale(sanitized_response) \\n     \\n    # Construct response fields common to all invocation types \\n    parsed_response = { \\n        \\'promptType\\': \"ORCHESTRATION\", \\n        \\'orchestrationParsedResponse\\': { \\nAdvanced prompts 392Amazon Bedrock User Guide\\n            \\'rationale\\': rationale \\n        } \\n    } \\n     \\n    # Check if there is a final answer \\n    try: \\n        final_answer, generated_response_parts = parse_answer(sanitized_response) \\n    except ValueError as e: \\n        addRepromptResponse(parsed_response, e) \\n        return parsed_response \\n         \\n    if final_answer: \\n        parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\'] = { \\n            \\'invocationType\\': \\'FINISH\\', \\n            \\'agentFinalResponse\\': { \\n                \\'responseText\\': final_answer \\n            } \\n        } \\n         \\n        if generated_response_parts: \\n            parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'agentFinalResponse\\'][\\'citations\\'] = { \\n                \\'generatedResponseParts\\': generated_response_parts \\n            } \\n        \\n        logger.info(\"Final answer parsed response: \" + str(parsed_response)) \\n        return parsed_response \\n     \\n    # Check if there is an ask user \\n    try: \\n        ask_user = parse_ask_user(sanitized_response) \\n        if ask_user: \\n            parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\'] = { \\n                \\'invocationType\\': \\'ASK_USER\\', \\n                \\'agentAskUser\\': { \\n                    \\'responseText\\': ask_user \\n                } \\n            } \\n             \\n            logger.info(\"Ask user parsed response: \" + str(parsed_response)) \\n            return parsed_response \\n    except ValueError as e: \\n        addRepromptResponse(parsed_response, e) \\n        return parsed_response \\nAdvanced prompts 393Amazon Bedrock User Guide\\n        \\n    # Check if there is an agent action \\n    try: \\n        parsed_response = parse_function_call(sanitized_response, parsed_response) \\n        logger.info(\"Function call parsed response: \" + str(parsed_response)) \\n        return parsed_response \\n    except ValueError as e: \\n        addRepromptResponse(parsed_response, e) \\n        return parsed_response \\n    addRepromptResponse(parsed_response, \\'Failed to parse the LLM output\\') \\n    logger.info(parsed_response) \\n    return parsed_response \\n         \\n    raise Exception(\"unrecognized prompt type\") \\n  \\ndef sanitize_response(text): \\n    pattern = r\"(\\\\\\\\n*)\" \\n    text = re.sub(pattern, r\"\\\\n\", text) \\n    return text \\n     \\ndef parse_rationale(sanitized_response): \\n    # Checks for strings that are not required for orchestration \\n    rationale_matcher = next((pattern.search(sanitized_response) for pattern in \\n RATIONALE_PATTERNS if pattern.search(sanitized_response)), None) \\n     \\n    if rationale_matcher: \\n        rationale = rationale_matcher.group(1).strip() \\n         \\n        # Check if there is a formatted rationale that we can parse from the string \\n        rationale_value_matcher = next((pattern.search(rationale) for pattern in \\n RATIONALE_VALUE_PATTERNS if pattern.search(rationale)), None) \\n        if rationale_value_matcher: \\n            return rationale_value_matcher.group(1).strip() \\n         \\n        return rationale \\n     \\n    return None \\n     \\ndef parse_answer(sanitized_llm_response): \\n    if has_generated_response(sanitized_llm_response): \\n        return parse_generated_response(sanitized_llm_response) \\n  \\n    answer_match = ANSWER_PATTERN.search(sanitized_llm_response) \\nAdvanced prompts 394Amazon Bedrock User Guide\\n    if answer_match and is_answer(sanitized_llm_response): \\n        return answer_match.group(0).strip(), None \\n         \\n    return None, None \\n   \\ndef is_answer(llm_response): \\n    return llm_response.rfind(ANSWER_TAG) > llm_response.rfind(FUNCTION_CALL_TAG) \\n     \\ndef parse_generated_response(sanitized_llm_response): \\n    results = [] \\n     \\n    for match in ANSWER_PART_PATTERN.finditer(sanitized_llm_response): \\n        part = match.group(1).strip() \\n         \\n        text_match = ANSWER_TEXT_PART_PATTERN.search(part) \\n        if not text_match: \\n            raise ValueError(\"Could not parse generated response\") \\n         \\n        text = text_match.group(1).strip()         \\n        references = parse_references(sanitized_llm_response, part) \\n        results.append((text, references)) \\n     \\n    final_response = \" \".join([r[0] for r in results]) \\n     \\n    generated_response_parts = [] \\n    for text, references in results: \\n        generatedResponsePart = { \\n            \\'text\\': text,  \\n            \\'references\\': references \\n        } \\n        generated_response_parts.append(generatedResponsePart) \\n         \\n    return final_response, generated_response_parts \\n     \\ndef has_generated_response(raw_response): \\n    return ANSWER_PART_PATTERN.search(raw_response) is not None \\n  \\ndef parse_references(raw_response, answer_part): \\n    references = [] \\n    for match in ANSWER_REFERENCE_PART_PATTERN.finditer(answer_part): \\n        reference = match.group(1).strip() \\n        references.append({\\'sourceId\\': reference}) \\n    return references \\nAdvanced prompts 395Amazon Bedrock User Guide\\n    \\ndef parse_ask_user(sanitized_llm_response): \\n    ask_user_matcher = ASK_USER_FUNCTION_CALL_PATTERN.search(sanitized_llm_response) \\n    if ask_user_matcher: \\n        try: \\n            ask_user = ask_user_matcher.group(2).strip() \\n            ask_user_question_matcher = \\n ASK_USER_FUNCTION_PARAMETER_PATTERN.search(ask_user) \\n            if ask_user_question_matcher: \\n                return ask_user_question_matcher.group(1).strip() \\n            raise ValueError(MISSING_API_INPUT_FOR_USER_REPROMPT_MESSAGE) \\n        except ValueError as ex: \\n            raise ex \\n        except Exception as ex: \\n            raise Exception(ASK_USER_FUNCTION_CALL_STRUCTURE_REMPROMPT_MESSAGE) \\n         \\n    return None \\n  \\ndef parse_function_call(sanitized_response, parsed_response): \\n    match = re.search(FUNCTION_CALL_REGEX, sanitized_response) \\n    if not match: \\n        raise ValueError(FUNCTION_CALL_STRUCTURE_REPROMPT_MESSAGE) \\n     \\n    verb, resource_name, function = match.group(1), match.group(2), match.group(3) \\n     \\n    parameters = {} \\n    for arg in match.group(4).split(\",\"): \\n        key, value = arg.split(\"=\") \\n        parameters[key.strip()] = {\\'value\\': value.strip(\\'\" \\')} \\n         \\n    parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\'] = {} \\n         \\n    # Function calls can either invoke an action group or a knowledge base. \\n    # Mapping to the correct variable names accordingly \\n    if resource_name.lower().startswith(KNOWLEDGE_STORE_SEARCH_ACTION_PREFIX): \\n        parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'invocationType\\'] = \\'KNOWLEDGE_BASE\\' \\n        parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'agentKnowledgeBase\\'] = { \\n            \\'searchQuery\\': parameters[\\'searchQuery\\'], \\n            \\'knowledgeBaseId\\': \\n resource_name.replace(KNOWLEDGE_STORE_SEARCH_ACTION_PREFIX, \\'\\') \\n        } \\n         \\nAdvanced prompts 396Amazon Bedrock User Guide\\n        return parsed_response \\n     \\n    parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'invocationType\\'] = \\'ACTION_GROUP\\' \\n    parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'actionGroupInvocation\\'] = { \\n        \"verb\": verb,  \\n        \"actionGroupName\": resource_name, \\n        \"apiName\": function, \\n        \"actionGroupInput\": parameters \\n    } \\n     \\n    return parsed_response \\n     \\ndef addRepromptResponse(parsed_response, error): \\n    error_message = str(error) \\n    logger.warn(error_message) \\n     \\n    parsed_response[\\'orchestrationParsedResponse\\'][\\'parsingErrorDetails\\'] = { \\n        \\'repromptResponse\\': error_message \\n    }\\nAnthropic Claude 2.1\\nimport logging\\nimport re\\nimport xml.etree.ElementTree as ET\\nRATIONALE_REGEX_LIST = [ \\n    \"(.*?)(<function_calls>)\", \\n    \"(.*?)(<answer>)\"\\n]\\nRATIONALE_PATTERNS = [re.compile(regex, re.DOTALL) for regex in \\n RATIONALE_REGEX_LIST]\\nRATIONALE_VALUE_REGEX_LIST = [ \\n    \"<scratchpad>(.*?)(</scratchpad>)\", \\n    \"(.*?)(</scratchpad>)\", \\n    \"(<scratchpad>)(.*?)\"\\n]\\nRATIONALE_VALUE_PATTERNS = [re.compile(regex, re.DOTALL) for regex in \\n RATIONALE_VALUE_REGEX_LIST]\\nAdvanced prompts 397Amazon Bedrock User Guide\\nANSWER_REGEX = r\"(?<=<answer>)(.*)\"\\nANSWER_PATTERN = re.compile(ANSWER_REGEX, re.DOTALL)\\nANSWER_TAG = \"<answer>\"\\nFUNCTION_CALL_TAG = \"<function_calls>\"\\nASK_USER_FUNCTION_CALL_REGEX = r\"<tool_name>user::askuser</tool_name>\"\\nASK_USER_FUNCTION_CALL_PATTERN = re.compile(ASK_USER_FUNCTION_CALL_REGEX, re.DOTALL)\\nASK_USER_TOOL_NAME_REGEX = r\"<tool_name>((.|\\\\n)*?)</tool_name>\"\\nASK_USER_TOOL_NAME_PATTERN = re.compile(ASK_USER_TOOL_NAME_REGEX, re.DOTALL)\\nTOOL_PARAMETERS_REGEX = r\"<parameters>((.|\\\\n)*?)</parameters>\"\\nTOOL_PARAMETERS_PATTERN = re.compile(TOOL_PARAMETERS_REGEX, re.DOTALL)\\nASK_USER_TOOL_PARAMETER_REGEX = r\"<question>((.|\\\\n)*?)</question>\"\\nASK_USER_TOOL_PARAMETER_PATTERN = re.compile(ASK_USER_TOOL_PARAMETER_REGEX, \\n re.DOTALL)\\nKNOWLEDGE_STORE_SEARCH_ACTION_PREFIX = \"x_amz_knowledgebase_\"\\nFUNCTION_CALL_REGEX = r\"(?<=<function_calls>)(.*)\"\\nANSWER_PART_REGEX = \"<answer_part\\\\\\\\s?>(.+?)</answer_part\\\\\\\\s?>\"\\nANSWER_TEXT_PART_REGEX = \"<text\\\\\\\\s?>(.+?)</text\\\\\\\\s?>\"\\nANSWER_REFERENCE_PART_REGEX = \"<source\\\\\\\\s?>(.+?)</source\\\\\\\\s?>\"\\nANSWER_PART_PATTERN = re.compile(ANSWER_PART_REGEX, re.DOTALL)\\nANSWER_TEXT_PART_PATTERN = re.compile(ANSWER_TEXT_PART_REGEX, re.DOTALL)\\nANSWER_REFERENCE_PART_PATTERN = re.compile(ANSWER_REFERENCE_PART_REGEX, re.DOTALL)\\n# You can provide messages to reprompt the LLM in case the LLM output is not in the \\n expected format\\nMISSING_API_INPUT_FOR_USER_REPROMPT_MESSAGE = \"Missing the parameter \\'question\\' for \\n user::askuser function call. Please try again with the correct argument added.\"\\nASK_USER_FUNCTION_CALL_STRUCTURE_REMPROMPT_MESSAGE = \"The function call format is \\n incorrect. The format for function calls to the askuser function must be: <invoke> \\n <tool_name>user::askuser</tool_name><parameters><question>$QUESTION</question></\\nparameters></invoke>.\"\\nFUNCTION_CALL_STRUCTURE_REPROMPT_MESSAGE = \"The function call format is incorrect. \\n The format for function calls must be: <invoke> <tool_name>$TOOL_NAME</tool_name> \\n <parameters> <$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>...</parameters></\\ninvoke>.\"\\nAdvanced prompts 398Amazon Bedrock User Guide\\nlogger = logging.getLogger()\\n# This parser lambda is an example of how to parse the LLM output for the default \\n orchestration prompt\\ndef lambda_handler(event, context): \\n    logger.info(\"Lambda input: \" + str(event)) \\n    # Sanitize LLM response \\n    sanitized_response = sanitize_response(event[\\'invokeModelRawResponse\\']) \\n    # Parse LLM response for any rationale \\n    rationale = parse_rationale(sanitized_response) \\n    # Construct response fields common to all invocation types \\n    parsed_response = { \\n        \\'promptType\\': \"ORCHESTRATION\", \\n        \\'orchestrationParsedResponse\\': { \\n            \\'rationale\\': rationale \\n        } \\n    } \\n    # Check if there is a final answer \\n    try: \\n        final_answer, generated_response_parts = parse_answer(sanitized_response) \\n    except ValueError as e: \\n        addRepromptResponse(parsed_response, e) \\n        return parsed_response \\n    if final_answer: \\n        parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\'] = { \\n            \\'invocationType\\': \\'FINISH\\', \\n            \\'agentFinalResponse\\': { \\n                \\'responseText\\': final_answer \\n            } \\n        } \\n        if generated_response_parts: \\n            parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'agentFinalResponse\\'][\\'citations\\'] = { \\n                \\'generatedResponseParts\\': generated_response_parts \\n            } \\n        logger.info(\"Final answer parsed response: \" + str(parsed_response)) \\nAdvanced prompts 399Amazon Bedrock User Guide\\n        return parsed_response \\n    # Check if there is an ask user \\n    try: \\n        ask_user = parse_ask_user(sanitized_response) \\n        if ask_user: \\n            parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\'] = { \\n                \\'invocationType\\': \\'ASK_USER\\', \\n                \\'agentAskUser\\': { \\n                    \\'responseText\\': ask_user \\n                } \\n            } \\n            logger.info(\"Ask user parsed response: \" + str(parsed_response)) \\n            return parsed_response \\n    except ValueError as e: \\n        addRepromptResponse(parsed_response, e) \\n        return parsed_response \\n    # Check if there is an agent action \\n    try: \\n        parsed_response = parse_function_call(sanitized_response, parsed_response) \\n        logger.info(\"Function call parsed response: \" + str(parsed_response)) \\n        return parsed_response \\n    except ValueError as e: \\n        addRepromptResponse(parsed_response, e) \\n        return parsed_response \\n    addRepromptResponse(parsed_response, \\'Failed to parse the LLM output\\') \\n    logger.info(parsed_response) \\n    return parsed_response \\n    raise Exception(\"unrecognized prompt type\")\\ndef sanitize_response(text): \\n    pattern = r\"(\\\\\\\\n*)\" \\n    text = re.sub(pattern, r\"\\\\n\", text) \\n    return text\\ndef parse_rationale(sanitized_response): \\n    # Checks for strings that are not required for orchestration \\n    rationale_matcher = next( \\nAdvanced prompts 400Amazon Bedrock User Guide\\n        (pattern.search(sanitized_response) for pattern in RATIONALE_PATTERNS if \\n pattern.search(sanitized_response)), \\n        None) \\n    if rationale_matcher: \\n        rationale = rationale_matcher.group(1).strip() \\n        # Check if there is a formatted rationale that we can parse from the string \\n        rationale_value_matcher = next( \\n            (pattern.search(rationale) for pattern in RATIONALE_VALUE_PATTERNS if \\n pattern.search(rationale)), None) \\n        if rationale_value_matcher: \\n            return rationale_value_matcher.group(1).strip() \\n        return rationale \\n    return None\\ndef parse_answer(sanitized_llm_response): \\n    if has_generated_response(sanitized_llm_response): \\n        return parse_generated_response(sanitized_llm_response) \\n    answer_match = ANSWER_PATTERN.search(sanitized_llm_response) \\n    if answer_match and is_answer(sanitized_llm_response): \\n        return answer_match.group(0).strip(), None \\n    return None, None\\ndef is_answer(llm_response): \\n    return llm_response.rfind(ANSWER_TAG) > llm_response.rfind(FUNCTION_CALL_TAG)\\ndef parse_generated_response(sanitized_llm_response): \\n    results = [] \\n    for match in ANSWER_PART_PATTERN.finditer(sanitized_llm_response): \\n        part = match.group(1).strip() \\n        text_match = ANSWER_TEXT_PART_PATTERN.search(part) \\n        if not text_match: \\n            raise ValueError(\"Could not parse generated response\") \\nAdvanced prompts 401Amazon Bedrock User Guide\\n        text = text_match.group(1).strip() \\n        references = parse_references(sanitized_llm_response, part) \\n        results.append((text, references)) \\n    final_response = \" \".join([r[0] for r in results]) \\n    generated_response_parts = [] \\n    for text, references in results: \\n        generatedResponsePart = { \\n            \\'text\\': text, \\n            \\'references\\': references \\n        } \\n        generated_response_parts.append(generatedResponsePart) \\n    return final_response, generated_response_parts\\ndef has_generated_response(raw_response): \\n    return ANSWER_PART_PATTERN.search(raw_response) is not None\\ndef parse_references(raw_response, answer_part): \\n    references = [] \\n    for match in ANSWER_REFERENCE_PART_PATTERN.finditer(answer_part): \\n        reference = match.group(1).strip() \\n        references.append({\\'sourceId\\': reference}) \\n    return references\\ndef parse_ask_user(sanitized_llm_response): \\n    ask_user_matcher = ASK_USER_FUNCTION_CALL_PATTERN.search(sanitized_llm_response) \\n    if ask_user_matcher: \\n        try: \\n            parameters_matches = \\n TOOL_PARAMETERS_PATTERN.search(sanitized_llm_response) \\n            params = parameters_matches.group(1).strip() \\n            ask_user_question_matcher = \\n ASK_USER_TOOL_PARAMETER_PATTERN.search(params) \\n            if ask_user_question_matcher: \\n                ask_user_question = ask_user_question_matcher.group(1) \\n                return ask_user_question \\n            raise ValueError(MISSING_API_INPUT_FOR_USER_REPROMPT_MESSAGE) \\n        except ValueError as ex: \\n            raise ex \\nAdvanced prompts 402Amazon Bedrock User Guide\\n        except Exception as ex: \\n            raise Exception(ASK_USER_FUNCTION_CALL_STRUCTURE_REMPROMPT_MESSAGE) \\n    return None\\ndef parse_function_call(sanitized_response, parsed_response): \\n    match = re.search(FUNCTION_CALL_REGEX, sanitized_response) \\n    if not match: \\n        raise ValueError(FUNCTION_CALL_STRUCTURE_REPROMPT_MESSAGE) \\n    tool_name_matches = ASK_USER_TOOL_NAME_PATTERN.search(sanitized_response) \\n    tool_name = tool_name_matches.group(1) \\n    parameters_matches = TOOL_PARAMETERS_PATTERN.search(sanitized_response) \\n    params = parameters_matches.group(1).strip() \\n    action_split = tool_name.split(\\'::\\') \\n    verb = action_split[0].strip() \\n    resource_name = action_split[1].strip() \\n    function = action_split[2].strip() \\n    xml_tree = ET.ElementTree(ET.fromstring(\"<parameters>{}</\\nparameters>\".format(params))) \\n    parameters = {} \\n    for elem in xml_tree.iter(): \\n        if elem.text: \\n            parameters[elem.tag] = {\\'value\\': elem.text.strip(\\'\" \\')} \\n    parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\'] = {} \\n    # Function calls can either invoke an action group or a knowledge base. \\n    # Mapping to the correct variable names accordingly \\n    if resource_name.lower().startswith(KNOWLEDGE_STORE_SEARCH_ACTION_PREFIX): \\n        parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'invocationType\\'] = \\'KNOWLEDGE_BASE\\' \\n        parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'agentKnowledgeBase\\'] = { \\n            \\'searchQuery\\': parameters[\\'searchQuery\\'], \\n            \\'knowledgeBaseId\\': \\n resource_name.replace(KNOWLEDGE_STORE_SEARCH_ACTION_PREFIX, \\'\\') \\n        } \\n        return parsed_response \\nAdvanced prompts 403Amazon Bedrock User Guide\\n    parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'invocationType\\'] = \\'ACTION_GROUP\\' \\n    parsed_response[\\'orchestrationParsedResponse\\'][\\'responseDetails\\']\\n[\\'actionGroupInvocation\\'] = { \\n        \"verb\": verb, \\n        \"actionGroupName\": resource_name, \\n        \"apiName\": function, \\n        \"actionGroupInput\": parameters \\n    } \\n    return parsed_response\\ndef addRepromptResponse(parsed_response, error): \\n    error_message = str(error) \\n    logger.warn(error_message) \\n    parsed_response[\\'orchestrationParsedResponse\\'][\\'parsingErrorDetails\\'] = { \\n        \\'repromptResponse\\': error_message \\n    }\\nExample request\\n{ \\n    \\'agent\\': { \\n        \\'alias\\': \\'TSTALIASID\\',  \\n        \\'id\\': \\'AGENTID123\\',  \\n        \\'name\\': \\'InsuranceAgent\\',  \\n        \\'version\\': \\'DRAFT\\' \\n    },  \\n    \\'invokeModelRawResponse\\': \\' To answer this question, I will:\\\\\\\\n\\\\\\\\n1. \\n Call the GET::x_amz_knowledgebase_KBID123456::Search function to search \\n for a phone number to call.\\\\\\\\n\\\\\\\\nI have checked that I have access to the \\n GET::x_amz_knowledgebase_KBID23456::Search function.\\\\\\\\n\\\\\\\\n</scratchpad>\\\\\\\\n\\\\\\n\\\\n<function_call>GET::x_amz_knowledgebase_KBID123456::Search(searchQuery=\\\\\"What is \\n the phone number I can call?\\\\\")\\', \\n    \\'messageVersion\\': \\'1.0\\', \\n    \\'overrideType\\': \\'OUTPUT_PARSER\\', \\n    \\'promptType\\': \\'ORCHESTRATION\\'\\n}\\nExample response\\nAdvanced prompts 404Amazon Bedrock User Guide\\n{ \\n    \\'promptType\\': \\'ORCHESTRATION\\', \\n    \\'orchestrationParsedResponse\\': { \\n        \\'rationale\\': \\'To answer this question, I will:\\\\\\\\n\\\\\\\\n1. Call the \\n GET::x_amz_knowledgebase_KBID123456::Search function to search for a phone \\n number to call Farmers.\\\\\\\\n\\\\\\\\nI have checked that I have access to the \\n GET::x_amz_knowledgebase_KBID123456::Search function.\\', \\n        \\'responseDetails\\': { \\n            \\'invocationType\\': \\'KNOWLEDGE_BASE\\', \\n            \\'agentKnowledgeBase\\': { \\n                \\'searchQuery\\': {\\'value\\': \\'What is the phone number I can call?\\'}, \\n                \\'knowledgeBaseId\\': \\'KBID123456\\' \\n            } \\n        } \\n    }\\n}\\nKnowledge base response generation\\nExample function\\nimport json\\nimport re\\nimport logging \\n  \\nANSWER_PART_REGEX = \"<answer_part\\\\\\\\s?>(.+?)</answer_part\\\\\\\\s?>\"\\nANSWER_TEXT_PART_REGEX = \"<text\\\\\\\\s?>(.+?)</text\\\\\\\\s?>\"   \\nANSWER_REFERENCE_PART_REGEX = \"<source\\\\\\\\s?>(.+?)</source\\\\\\\\s?>\"\\nANSWER_PART_PATTERN = re.compile(ANSWER_PART_REGEX, re.DOTALL)\\nANSWER_TEXT_PART_PATTERN = re.compile(ANSWER_TEXT_PART_REGEX, re.DOTALL)\\nANSWER_REFERENCE_PART_PATTERN = re.compile(ANSWER_REFERENCE_PART_REGEX, re.DOTALL)\\nlogger = logging.getLogger() \\n  \\n# This parser lambda is an example of how to parse the LLM output for the default KB \\n response generation prompt\\ndef lambda_handler(event, context): \\n    logger.info(\"Lambda input: \" + str(event)) \\n    raw_response = event[\\'invokeModelRawResponse\\'] \\n     \\n    parsed_response = { \\n        \\'promptType\\': \\'KNOWLEDGE_BASE_RESPONSE_GENERATION\\', \\n        \\'knowledgeBaseResponseGenerationParsedResponse\\': { \\nAdvanced prompts 405Amazon Bedrock User Guide\\n            \\'generatedResponse\\': parse_generated_response(raw_response) \\n        } \\n    } \\n     \\n    logger.info(parsed_response) \\n    return parsed_response \\n     \\ndef parse_generated_response(sanitized_llm_response): \\n    results = [] \\n     \\n    for match in ANSWER_PART_PATTERN.finditer(sanitized_llm_response): \\n        part = match.group(1).strip() \\n         \\n        text_match = ANSWER_TEXT_PART_PATTERN.search(part) \\n        if not text_match: \\n            raise ValueError(\"Could not parse generated response\") \\n         \\n        text = text_match.group(1).strip()         \\n        references = parse_references(sanitized_llm_response, part) \\n        results.append((text, references)) \\n     \\n    generated_response_parts = [] \\n    for text, references in results: \\n        generatedResponsePart = { \\n            \\'text\\': text,  \\n            \\'references\\': references \\n        } \\n        generated_response_parts.append(generatedResponsePart) \\n         \\n    return { \\n        \\'generatedResponseParts\\': generated_response_parts \\n    } \\n     \\ndef parse_references(raw_response, answer_part): \\n    references = [] \\n    for match in ANSWER_REFERENCE_PART_PATTERN.finditer(answer_part): \\n        reference = match.group(1).strip() \\n        references.append({\\'sourceId\\': reference}) \\n    return references\\nExample request\\n{ \\nAdvanced prompts 406Amazon Bedrock User Guide\\n    \\'agent\\': { \\n        \\'alias\\': \\'TSTALIASID\\', \\n        \\'id\\': \\'AGENTID123\\',  \\n        \\'name\\': \\'InsuranceAgent\\', \\n        \\'version\\': \\'DRAFT\\' \\n    },  \\n    \\'invokeModelRawResponse\\': \\'{\\\\\"completion\\\\\":\\\\\" <answer>\\\\\\\\\\\\\\\\n<answer_part>\\\\\\\\\\n\\\\\\\\n<text>\\\\\\\\\\\\\\\\nThe search results contain information about different types of \\n insurance benefits, including personal injury protection (PIP), medical payments \\n coverage, and lost wages coverage. PIP typically covers reasonable medical \\n expenses for injuries caused by an accident, as well as income continuation, \\n child care, loss of services, and funerals. Medical payments coverage provides \\n payment for medical treatment resulting from a car accident. Who pays lost wages \\n due to injuries depends on the laws in your state and the coverage purchased.\\n\\\\\\\\\\\\\\\\n</text>\\\\\\\\\\\\\\\\n<sources>\\\\\\\\\\\\\\\\n<source>1234567-1234-1234-1234-123456789abc</\\nsource>\\\\\\\\\\\\\\\\n<source>2345678-2345-2345-2345-23456789abcd</source>\\\\\\\\\\\\\\n\\\\n<source>3456789-3456-3456-3456-3456789abcde</source>\\\\\\\\\\\\\\\\n</sources>\\\\\\\\\\\\\\\\n</\\nanswer_part>\\\\\\\\\\\\\\\\n</answer>\\\\\",\\\\\"stop_reason\\\\\":\\\\\"stop_sequence\\\\\",\\\\\"stop\\\\\":\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\n\\\\nHuman:\\\\\"}\\', \\n    \\'messageVersion\\': \\'1.0\\', \\n    \\'overrideType\\': \\'OUTPUT_PARSER\\', \\n    \\'promptType\\': \\'KNOWLEDGE_BASE_RESPONSE_GENERATION\\'\\n}\\nExample response\\n{ \\n    \\'promptType\\': \\'KNOWLEDGE_BASE_RESPONSE_GENERATION\\', \\n    \\'knowledgeBaseResponseGenerationParsedResponse\\': { \\n        \\'generatedResponse\\': { \\n            \\'generatedResponseParts\\': [ \\n                { \\n                    \\'text\\': \\'\\\\\\\\\\\\\\\\nThe search results contain information about \\n different types of insurance benefits, including personal injury protection \\n (PIP), medical payments coverage, and lost wages coverage. PIP typically covers \\n reasonable medical expenses for injuries caused by an accident, as well as income \\n continuation, child care, loss of services, and funerals. Medical payments coverage \\n provides payment for medical treatment resulting from a car accident. Who pays lost \\n wages due to injuries depends on the laws in your state and the coverage purchased.\\n\\\\\\\\\\\\\\\\n\\', \\n                    \\'references\\': [ \\n                        {\\'sourceId\\': \\'1234567-1234-1234-1234-123456789abc\\'}, \\n                        {\\'sourceId\\': \\'2345678-2345-2345-2345-23456789abcd\\'}, \\nAdvanced prompts 407Amazon Bedrock User Guide\\n                        {\\'sourceId\\': \\'3456789-3456-3456-3456-3456789abcde\\'} \\n                    ] \\n                } \\n            ] \\n        } \\n    }\\n}\\nPost-processing\\nExample function\\nimport json\\nimport re\\nimport logging \\n  \\nFINAL_RESPONSE_REGEX = r\"<final_response>([\\\\s\\\\S]*?)</final_response>\"\\nFINAL_RESPONSE_PATTERN = re.compile(FINAL_RESPONSE_REGEX, re.DOTALL)\\nlogger = logging.getLogger() \\n  \\n# This parser lambda is an example of how to parse the LLM output for the default \\n PostProcessing prompt\\ndef lambda_handler(event, context): \\n    logger.info(\"Lambda input: \" + str(event)) \\n    raw_response = event[\\'invokeModelRawResponse\\'] \\n     \\n    parsed_response = { \\n        \\'promptType\\': \\'POST_PROCESSING\\', \\n        \\'postProcessingParsedResponse\\': {} \\n    } \\n     \\n    matcher = FINAL_RESPONSE_PATTERN.search(raw_response) \\n    if not matcher: \\n        raise Exception(\"Could not parse raw LLM output\") \\n    response_text = matcher.group(1).strip() \\n     \\n    parsed_response[\\'postProcessingParsedResponse\\'][\\'responseText\\'] = response_text \\n     \\n    logger.info(parsed_response) \\n    return parsed_response\\nExample request\\nAdvanced prompts 408Amazon Bedrock User Guide\\n{ \\n    \\'agent\\': { \\n        \\'alias\\': \\'TSTALIASID\\', \\n        \\'id\\': \\'AGENTID123\\', \\n        \\'name\\': \\'InsuranceAgent\\', \\n        \\'version\\': \\'DRAFT\\' \\n    }, \\n    \\'invokeModelRawResponse\\': \\' <final_response>\\\\\\\\nBased on your request, I \\n searched our insurance benefit information database for details. The search \\n results indicate that insurance policies may cover different types of benefits, \\n depending on the policy and state laws. Specifically, the results discussed \\n personal injury protection (PIP) coverage, which typically covers medical \\n expenses for insured individuals injured in an accident (cited sources: \\n 1234567-1234-1234-1234-123456789abc, 2345678-2345-2345-2345-23456789abcd). PIP may \\n pay for costs like medical care, lost income replacement, childcare expenses, and \\n funeral costs. Medical payments coverage was also mentioned as another option that \\n similarly covers medical treatment costs for the policyholder and others injured in \\n a vehicle accident involving the insured vehicle. The search results further noted \\n that whether lost wages are covered depends on the state and coverage purchased. \\n Please let me know if you need any clarification or have additional questions.\\\\\\\\n</\\nfinal_response>\\', \\n    \\'messageVersion\\': \\'1.0\\', \\n    \\'overrideType\\': \\'OUTPUT_PARSER\\', \\n    \\'promptType\\': \\'POST_PROCESSING\\'\\n}\\nExample response\\n{ \\n    \\'promptType\\': \\'POST_PROCESSING\\', \\n    \\'postProcessingParsedResponse\\': { \\n        \\'responseText\\': \\'Based on your request, I searched our insurance benefit \\n information database for details. The search results indicate that insurance \\n policies may cover different types of benefits, depending on the policy and \\n state laws. Specifically, the results discussed personal injury protection \\n (PIP) coverage, which typically covers medical expenses for insured individuals \\n injured in an accident (cited sources: 24c62d8c-3e39-4ca1-9470-a91d641fe050, \\n 197815ef-8798-4cb1-8aa5-35f5d6b28365). PIP may pay for costs like medical care, \\n lost income replacement, childcare expenses, and funeral costs. Medical payments \\n coverage was also mentioned as another option that similarly covers medical \\n treatment costs for the policyholder and others injured in a vehicle accident \\n involving the insured vehicle. The search results further noted that whether lost \\nAdvanced prompts 409Amazon Bedrock User Guide\\n wages are covered depends on the state and coverage purchased. Please let me know \\n if you need any clarification or have additional questions.\\' \\n    }\\n}\\nControl session context\\nFor greater control of session context, you can modify the SessionState  object in your agent. The\\nSessionState  object contains two types of attributes that you can use to provide conversational \\ncontext for the agent during user conversations.\\n•sessionAttributes – Attributes that persist over a session  between a user and agent. All\\nInvokeAgent requests made with the same sessionId  belong to the same session, as long as \\nthe session time limit (the idleSessionTTLinSeconds ) has not been surpassed.\\n•promptSessionAttributes – Attributes that persist over a single turn (one InvokeAgent call). \\nYou can use the $prompt_session_attributes$ placeholder when you edit the orchestration base \\nprompt template. This placeholder will be populated at runtime with the attributes that you \\nspecify in the promptSessionAttributes  ﬁeld.\\nThe general format of the SessionState  object is as follows.\\n{ \\n    \"sessionAttributes\": { \\n        \" <attributeName1> \": \"<attributeValue1>\" , \\n        \" <attributeName2> \": \"<attributeValue2>\" , \\n        ... \\n    }, \\n    \"promptSessionAttributes\": { \\n        \" <attributeName3> \": \"<attributeValue3>\" , \\n        \" <attributeName4> \": \"<attributeValue4>\" , \\n        ... \\n    }\\n}\\nYou can deﬁne the session state attributes at two diﬀerent steps.\\n•When you set up an action group and write the Lambda function, include sessionAttributes\\nor promptSessionAttributes  in the response event that is returned to Amazon Bedrock.\\nControl session context 410Amazon Bedrock User Guide\\n•During runtime, when you send an InvokeAgent request, include a sessionState  object \\nin the request body to dynamically change the session state attributes in the middle of the \\nconversation.\\nSession attribute example\\nThe following example uses a session attribute to personalize a message to your user.\\n1. Write your application code to ask the user to provide their ﬁrst name and the request they \\nwant to make to the agent and to store the answers as the variables <first_name>  and\\n<request> .\\n2. Write your application code to send an InvokeAgent request with the following body:\\n{ \\n    \"inputText\": \" <request> \", \\n    \"sessionState\": { \\n        \"sessionAttributes\": { \\n            \"firstName\": \" <first_name> \" \\n        } \\n    }\\n}\\n3. When a user uses your application and provides their ﬁrst name, your code will send the ﬁrst \\nname as a session attribute and the agent will store their ﬁrst name for the duration of the\\nsession .\\n4. Because session attributes are sent in the Lambda input event, you can refer to these session \\nattributes in a Lambda function for an action group. For example, if the action API schema\\nrequires a ﬁrst name in the request body, you can use the firstName  session attribute when \\nwriting the Lambda function for an action group to automatically populate that ﬁeld when \\nsending the API request.\\nPrompt session attribute example\\nThe following general example uses a prompt session attribute to provide temporal context for the \\nagent.\\n1. Write your application code to store the user request in a variable called <request> .\\nControl session context 411Amazon Bedrock User Guide\\n2. Write your application code to retrieve the time zone at the user\\'s location if the user uses a \\nword indicating relative time (such as \"tomorrow\") in the <request> , and store in a variable \\ncalled <timezone> .\\n3. Write your application to send an InvokeAgent request with the following body:\\n{ \\n    \"inputText\": \" <request> \", \\n    \"sessionState\": { \\n        \"promptSessionAttributes\": { \\n            \"timeZone\": \" <timezone> \" \\n        } \\n    }\\n}\\n4. If a user uses a word indicating relative time, your code will send the timeZone  prompt \\nsession attribute and the agent will store it for the duration of the turn.\\n5. For example, if a user asks I need to book a hotel for tomorrow , your code sends the \\nuser\\'s time zone to the agent and the agent can determine the exact date that \"tomorrow\" \\nrefers to.\\n6. The prompt session attribute can be used at the following steps.\\n•If you include the $prompt_session_attributes$ placeholder in the orchestration prompt \\ntemplate, the orchestration prompt to the FM includes the prompt session attributes.\\n•Prompt session attributes are sent in the Lambda input event and can be used to help \\npopulate API requests or returned in the response.\\nDeploy an Amazon Bedrock agent\\nWhen you ﬁrst create an Amazon Bedrock agent, you have a working draft version (DRAFT ) and \\na test alias ( TSTALIASID ) that points to the working draft version. When you make changes to \\nyour agent, the changes apply to the working draft. You iterate on your working draft until you\\'re \\nsatisﬁed with the behavior of your agent. Then, you can set up your agent for deployment and \\nintegration into your application by creating aliases  of your agent.\\nTo deploy your agent, you must create an alias . During alias creation, Amazon Bedrock creates a \\nversion of your agent automatically. The alias points to this newly created version. Alternatively, \\nyou can point the alias to a previously created version of your agent. Then, you conﬁgure your \\napplication to make API calls to that alias.\\nDeploy an agent 412Amazon Bedrock User Guide\\nA version  is a snapshot that preserves the resource as it exists at the time it was created. You can \\ncontinue to modify the working draft and create new aliases (and consequently, versions) of your \\nagent as necessary. In Amazon Bedrock, you create a new version of your agent by creating an alias \\nthat points to the new version by default. Amazon Bedrock creates versions in numerical order, \\nstarting from 1.\\nVersions are immutable because they act as a snapshot of your agent at the time you created it. To \\nmake updates to an agent in production, you must create a new version and set up your application \\nto make calls to the alias that points to that version.\\nWith aliases, you can switch eﬃciently between diﬀerent versions of your agent without requiring \\nthe application to keep track of the version. For example, you can change an alias to point to a \\nprevious version of your agent if there are changes that you need to revert quickly.\\nTo deploy your agent\\n1. Create an alias and version of your agent. Select the tab corresponding to your method of \\nchoice and follow the steps.\\nConsole\\nTo create an alias (and optionally a new version)\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents\\nsection.\\n3. In the Aliases  section, choose Create .\\n4. Enter a unique name for the alias and provide an optional description.\\n5. Choose one of the following options:\\n• To create a new version, choose Create a new version and to associate it to this \\nalias .\\n• To use an existing version, choose Use an existing version to associate this alias. \\nFrom the dropdown menu, choose the version that you want to associate the alias \\nto.\\n6. Select Create alias . A success banner appears at the top.\\nDeploy an agent 413Amazon Bedrock User Guide\\nAPI\\nTo create an alias for an agent, send a CreateAgentAlias request (see link for request \\nand response formats and ﬁeld details) with an Agents for Amazon Bedrock build-\\ntime endpoint . To create a new version and associate this alias with it, leave the\\nroutingConfiguration  object unspeciﬁed.\\nSee code examples\\n2. Deploy your agent by setting up your application to make an InvokeAgent request (see link for \\nrequest and response formats and ﬁeld details) with an Agents for Amazon Bedrock runtime \\nendpoint . In the agentAliasId  ﬁeld, specify the ID of the alias pointing to the version of the \\nagent that you want to use.\\nTo learn how to manage versions and aliases of agents, select from the following topics.\\nTopics\\n•Manage versions of agents in Amazon Bedrock\\n•Manage aliases of agents in Amazon Bedrock\\nManage versions of agents in Amazon Bedrock\\nAfter you create a version of your agent, you can view information about it or delete it. You can \\nonly create a new version of an agent by creating a new alias.\\nTopics\\n•View information about versions of agents in Amazon Bedrock\\n•Delete a version of an agent in Amazon Bedrock\\nView information about versions of agents in Amazon Bedrock\\nTo learn how to view information about the versions of an agent, select the tab corresponding to \\nyour method of choice and follow the steps.\\nManage versions 414Amazon Bedrock User Guide\\nConsole\\nTo view information about a version of an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose the version to view from the Versions section.\\n4. To view details about the model, action groups, or knowledge bases attached to version of \\nthe agent, choose the name of the information that you want to view. You can\\'t modify any \\npart of a version. To make modiﬁcations to the agent, use the working draft and create a \\nnew version.\\nAPI\\nTo get information about an agent version, send a GetAgentVersion request (see link for \\nrequest and response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint . Specify the agentId  and agentVersion .\\nTo list information about an agent\\'s versions, send a ListAgentVersions request (see link for \\nrequest and response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint  and specify the agentId. You can specify the following optional parameters:\\nField Short description\\nmaxResults The maximum number of results to return in \\na response.\\nnextToken If there are more results than the number \\nyou speciﬁed in the maxResults  ﬁeld, \\nthe response returns a nextToken  value. \\nTo see the next batch of results, send the\\nnextToken  value in another request.\\nManage versions 415Amazon Bedrock User Guide\\nDelete a version of an agent in Amazon Bedrock\\nTo learn how to delete a version of an agent, select the tab corresponding to your method of \\nchoice and follow the steps.\\nConsole\\nTo delete a version of an agent\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. To choose the version for deletion, in the Versions section, choose the option button next \\nto the version that you want to delete.\\n4. Choose Delete.\\n5. A dialog box appears warning you about the consequences of deletion. To conﬁrm that you \\nwant to delete the version, enter delete  in the input ﬁeld and choose Delete.\\n6. A banner appears to inform you that the version is being deleted. When deletion is \\ncomplete, a success banner appears.\\nAPI\\nTo delete a version of an agent, send a DeleteAgentVersion request (see link for request and \\nresponse formats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint. \\nBy default, the skipResourceInUseCheck  parameter is false  and deletion is stopped if the \\nresource is in use. If you set skipResourceInUseCheck  to true, the resource will be deleted \\neven if the resource is in use.\\nManage aliases of agents in Amazon Bedrock\\nAfter you create an alias of your agent, you can view information about it, edit it, or delete it.\\nTopics\\n•View information about aliases of agents in Amazon Bedrock\\n•Edit an alias of an agent in Amazon Bedrock\\n•Delete an alias of an agent in Amazon Bedrock\\nManage aliases 416Amazon Bedrock User Guide\\nView information about aliases of agents in Amazon Bedrock\\nTo learn how to view information about the aliases of an agent, select the tab corresponding to \\nyour method of choice and follow the steps.\\nConsole\\nTo view the details of an alias\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose the alias to view from the Aliases  section.\\n4. You can view the name and description of the alias and tags that are associated with the \\nalias.\\nAPI\\nTo get information about an agent alias, send a GetAgentAlias request (see link for request and \\nresponse formats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint. \\nSpecify the agentId  and agentAliasId .\\nTo list information about an agent\\'s aliases, send a ListAgentVersions request (see link for \\nrequest and response formats and ﬁeld details) with an Agents for Amazon Bedrock build-time \\nendpoint  and specify the agentId. You can specify the following optional parameters:\\nField Short description\\nmaxResults The maximum number of results to return in \\na response.\\nnextToken If there are more results than the number \\nyou speciﬁed in the maxResults  ﬁeld, \\nthe response returns a nextToken  value. \\nTo see the next batch of results, send the\\nnextToken  value in another request.\\nManage aliases 417Amazon Bedrock User Guide\\nTo view all the tags for an alias, send a ListTagsForResource request (see link for request and \\nresponse formats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint\\nand include the Amazon Resource Name (ARN) of the alias.\\nEdit an alias of an agent in Amazon Bedrock\\nTo learn how to edit an alias of an agent, select the tab corresponding to your method of choice \\nand follow the steps.\\nConsole\\nTo edit an alias\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. In the Aliases  section, choose the option button next to the alias that you want to edit.\\n4. You can edit the name and description of the alias. Additionally, you can perform one of \\nthe following actions:\\n• To create a new version and associate this alias with that version, choose Create a new \\nversion and associate it to this alias.\\n• To associate this alias with a diﬀerent existing version, choose Use an existing version \\nand associate this alias .\\nTo add or remove tags associated with an alias\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. Choose the alias for which you want to manage tags from the Aliases  section.\\n4. In the Tags section, choose Manage tags .\\n5. To add a tag, choose Add new tag . Then enter a Key and optionally enter a Value. To \\nremove a tag, choose Remove. For more information, see Tag resources.\\n6. When you\\'re done editing tags, choose Submit .\\nManage aliases 418Amazon Bedrock User Guide\\nAPI\\nTo edit an agent alias, send an UpdateAgentAlias request. Because all ﬁelds will be overwritten, \\ninclude both ﬁelds that you want to update as well as ﬁelds that you want to keep the same.\\nTo add tags to an alias, send a TagResource request (see link for request and response formats \\nand ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint and include the \\nAmazon Resource Name (ARN) of the alias. The request body contains a tags  ﬁeld, which is an \\nobject containing a key-value pair that you specify for each tag.\\nTo remove tags from an alias, send an UntagResource request (see link for request and response \\nformats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint and include \\nthe Amazon Resource Name (ARN) of the alias. The tagKeys request parameter is a list \\ncontaining the keys for the tags that you want to remove.\\nDelete an alias of an agent in Amazon Bedrock\\nTo learn how to delete an alias of an agent, select the tab corresponding to your method of choice \\nand follow the steps.\\nConsole\\nTo delete an alias\\n1. Sign in to the AWS Management Console, and open the Amazon Bedrock console at\\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents  from the left navigation pane. Then, choose an agent in the Agents  section.\\n3. To choose the alias for deletion, in the Aliases  section, choose the option button next to \\nthe alias that you want to delete.\\n4. Choose Delete.\\n5. A dialog box appears warning you about the consequences of deletion. To conﬁrm that you \\nwant to delete the alias, enter delete  in the input ﬁeld and choose Delete.\\n6. A banner appears to inform you that the alias is being deleted. When deletion is complete, \\na success banner appears.\\nManage aliases 419Amazon Bedrock User Guide\\nAPI\\nTo delete an alias of an agent, send a DeleteAgentAlias request (see link for request and \\nresponse formats and ﬁeld details) with an Agents for Amazon Bedrock build-time endpoint. \\nBy default, the skipResourceInUseCheck  parameter is false  and deletion is stopped if the \\nresource is in use. If you set skipResourceInUseCheck  to true, the resource will be deleted \\neven if the resource is in use.\\nSee code examples\\nManage aliases 420Amazon Bedrock User Guide\\nCustom models\\nModel customization is the process of providing training data to a model in order to improve its \\nperformance for speciﬁc use-cases. You can customize Amazon Bedrock foundation models in \\norder to improve their performance and create a better customer experience. Amazon Bedrock \\ncurrently provides the following customization methods.\\n•Continued Pre-training\\nProvide unlabeled  data to pre-train a foundation model by familiarizing it with certain types of \\ninputs. You can provide data from speciﬁc topics in order to expose a model to those areas. The \\nContinued Pre-training process will tweak the model parameters to accommodate the input data \\nand improve its domain knowledge.\\nFor example, you can train a model with private data, such as business documents, that are not \\npublically available for training large language models. Additionally, you can continue to improve \\nthe model by retraining the model with more unlabeled data as it becomes available.\\n•Fine-tuning\\nProvide labeled  data in order to train a model to improve performance on speciﬁc tasks. By \\nproviding a training dataset of labeled examples, the model learns to associate what types of \\noutputs should be generated for certain types of inputs. The model parameters are adjusted in \\nthe process and the model\\'s performance is improved for the tasks represented by the training \\ndataset.\\nFor information about model customization quotas, see Model customization quotas .\\nNote\\nYou are charged for model training based on the number of tokens processed by the model \\n(number of tokens in training data corpus × number of epochs) and model storage charged \\nper month per model. For more information, see Amazon Bedrock pricing.\\nYou carry out the following steps in model customization.\\n1.Create a training and, if applicable, a validation dataset for your customization task.\\n421Amazon Bedrock User Guide\\n2.If you plan to use a new custom IAM role, set up IAM permissions  to access the S3 buckets for \\nyour data. You can also use an existing role or let the console automatically create a role with \\nthe proper permissions.\\n3.(Optional) Conﬁgure KMS keys and/or VPC for extra security.\\n4.Create a Fine-tuning or Continued Pre-training job, controlling the training process by adjusting \\nthe hyperparameter values.\\n5.Analyze the results by looking at the training or validation metrics or by using model evaluation.\\n6.Purchase Provisioned Throughput for your newly created custom model.\\n7.Use your custom model as you would a base model in Amazon Bedrock tasks, such as model \\ninference.\\nTopics\\n•Supported regions and models for model customization\\n•Prerequisites for model customization\\n•Submit a model customization job\\n•Manage a model customization job\\n•Analyze the results of a model customization job\\n•Use a custom model\\n•Code samples for model customization\\n•Guidelines for model customization\\n•Troubleshooting\\nSupported regions and models for model customization\\nThe following table shows regional support for each customization method:\\nRegion Fine-tuning Continued pre-training\\nUS East (N. Virginia) Yes Yes\\nUS West (Oregon) Yes Yes\\nAWS GovCloud (US-West) Yes No\\nSupported regions and models 422Amazon Bedrock User Guide\\nThe following table shows model support for each customization method:\\nModel name Model ID Fine-tuning Continued pre-train \\ning\\nAmazon Titan Text \\nG1 - Expressamazon.titan-text- \\nexpress-v1Yes Yes\\nAmazon Titan Text \\nG1 - Liteamazon.titan-text- \\nlite-v1Yes Yes\\nAmazon Titan Image \\nGenerator G1amazon.titan-image-\\ngenerator-v1Yes No\\nAmazon Titan \\nMultimodal \\nEmbeddings G1 G1amazon.titan-embed-\\nimage-v1Yes No\\nCohere Command cohere.command-tex \\nt-v14Yes No\\nCohere Command \\nLightcohere.command-lig \\nht-text-v14Yes No\\nMeta Llama 2 13B meta.llama2-13b-ch \\nat-v1Yes No\\nMeta Llama 2 70B meta.llama2-70b-ch \\nat-v1Yes No\\nPrerequisites for model customization\\nBefore you can start a model customization job, you need to fulﬁll the following prerequisites:\\n1.Determine whether you plan to carry out a Fine-tuning or Continued Pre-training job and which \\nmodel you plan to use. The choice you make determines the format of the datasets that you \\nfeed into the customization job.\\nPrerequisites 423Amazon Bedrock User Guide\\n2.Prepare the training dataset ﬁle. If the customization method and model that you choose \\nsupports a validation dataset, you can also prepare a validation dataset ﬁle. Follow the steps \\nbelow in Prepare the datasets and then upload  the ﬁles to an Amazon S3 bucket.\\n3.(Optional) Create a custom AWS Identity and Access Management (IAM) service role with \\nthe proper permissions by following the instructions at Create a service role for model \\ncustomization  to set up the role. You can skip this prerequisite if you plan to use the AWS \\nManagement Console to automatically create a service role for you.\\n4.(Optional) Set up extra security conﬁgurations.\\n•You can encrypt input and output data, customization jobs, or inference requests made to \\ncustom models. For more information, see Encryption of model customization jobs and \\nartifacts.\\n•You can create a virtual private cloud (VPC) to protect your customization jobs. For more \\ninformation, see Protect model customization jobs using a VPC.\\nTopics\\n•Prepare the datasets\\n•Protect model customization jobs using a VPC\\nPrepare the datasets\\nBefore you can begin a model customization job, you need to minimally prepare a training dataset. \\nWhether a validation dataset is supported and the format of your training and validation dataset \\ndepend on the following factors.\\n•The type of customization job (ﬁne-tuning or Continued Pre-training).\\n•The input and output modalities of the data.\\nTo see dataset and ﬁle requirements for diﬀerent models, see Model customization quotas .\\nSelect the tab that is relevant to your use-case.\\nFine-tuning: Text-to-text\\nTo ﬁne-tune a text-to-text model, prepare a training and optional validation dataset by creating \\na JSONL ﬁle with multiple JSON lines. Each JSON line is a sample containing both a prompt\\nPrepare the datasets 424Amazon Bedrock User Guide\\nand completion  ﬁeld. Use 6 characters per token as an approximation for the number of \\ntokens. The format is as follows.\\n{\"prompt\": \"<prompt1>\", \"completion\": \"<expected generated text>\"}\\n{\"prompt\": \"<prompt2>\", \"completion\": \"<expected generated text>\"}\\n{\"prompt\": \"<prompt3>\", \"completion\": \"<expected generated text>\"}       \\nThe following is an example item for a question-answer task:\\n{\"prompt\": \"what is AWS\", \"completion\": \"it\\'s Amazon Web Services\"}\\nFine-tuning: Text-to-image & Image-to-embeddings\\nTo ﬁne-tune a text-to-image or image-to-embedding model, prepare a training dataset by \\ncreate a JSONL ﬁle with multiple JSON lines. Validation datasets are not supported. Each JSON \\nline is a sample containing an image-ref , the Amazon S3 URI for an image, and a caption\\nthat could be a prompt for the image.\\nThe images must be in JPEG or PNG format.\\n{\"image-ref\": \"s3://bucket/path/to/image001.png\", \"caption\": \"<prompt text>\"}\\n{\"image-ref\": \"s3://bucket/path/to/image002.png\", \"caption\": \"<prompt text>\"}\\n{\"image-ref\": \"s3://bucket/path/to/image003.png\", \"caption\": \"<prompt text>\"}     \\nThe following is an example item:\\n{\"image-ref\": \"s3://my-bucket/my-pets/cat.png\", \"caption\": \"an orange cat with white \\n spots\"}\\nTo allow Amazon Bedrock access to the image ﬁles, add an IAM policy similar to the one in\\nPermissions to access training and validation ﬁles and to write output ﬁles in S3 to the Amazon \\nBedrock model customization service role that you set up or that was automatically set up for \\nyou in the console. The Amazon S3 paths you provide in the training dataset must be in folders \\nthat you specify in the policy.\\nContinued Pre-training: Text-to-text\\nTo carry out Continued Pre-training on a text-to-text model, prepare a training and optional \\nvalidation dataset by creating a JSONL ﬁle with multiple JSON lines. Because Continued Pre-\\ntraining involves unlabeled data, each JSON line is a sample containing only an input  ﬁeld. Use \\n6 characters per token as an approximation for the number of tokens. The format is as follows.\\nPrepare the datasets 425Amazon Bedrock User Guide\\n{\"input\": \"<input text>\"}\\n{\"input\": \"<input text>\"}\\n{\"input\": \"<input text>\"}\\nThe following is an example item that could be in the training data.\\n{\"input\": \"AWS stands for Amazon Web Services\"}\\nProtect model customization jobs using a VPC\\nWhen you run a model customization job, the job accesses your Amazon S3 bucket to download \\nthe input data and to upload job metrics. To control access to your data, we recommend that \\nyou use a virtual private cloud (VPC) with Amazon VPC. You can further protect your data by \\nconﬁguring your VPC so that your data isn\\'t available over the internet and instead creating a VPC \\ninterface endpoint with AWS PrivateLink to establish a private connection to your data. For more \\ninformation about how Amazon VPC and AWS PrivateLink integrate with Amazon Bedrock, see\\nProtect your data using Amazon VPC and AWS PrivateLink.\\nCarry out the following steps to conﬁgure and use a VPC for the training, validation, and output \\ndata for your model customization jobs.\\nTopics\\n•Set up a VPC\\n•Create an Amazon S3 VPC Endpoint\\n•(Optional) Use IAM policies to restrict access to your S3 ﬁles\\n•Attach VPC permissions to a model customization role\\n•Add the VPC conﬁguration when submitting a model customization job\\nSet up a VPC\\nYou can use a default VPC  for your model customization data or create a new VPC by following the \\nguidance at Get started with Amazon VPC and Create a VPC.\\nWhen you create your VPC, we recommend that you use the default DNS settings for your \\nendpoint route table, so that standard Amazon S3 URLs (for example, http://s3-aws-\\nregion.amazonaws.com/ training-bucket ) resolve.\\n(Optional) Set up a VPC 426Amazon Bedrock User Guide\\nCreate an Amazon S3 VPC Endpoint\\nIf you conﬁgure your VPC with no internet access, you need to create an Amazon S3 VPC endpoint\\nto allow your model customization jobs to access the S3 buckets that store your training and \\nvalidation data and that will store the model artifacts.\\nCreate the S3 VPC endpoint by following the steps at Create a gateway endpoint for Amazon S3.\\nNote\\nIf you don\\'t use the default DNS settings for your VPC, you need to ensure that the URLs \\nfor the locations of the data in your training jobs resolve by conﬁguring the endpoint \\nroute tables. For information about VPC endpoint route tables, see Routing for Gateway \\nendpoints .\\n(Optional) Use IAM policies to restrict access to your S3 ﬁles\\nYou can use resource-based policies to more tightly control access to your S3 ﬁles. You can use any \\ncombination of the following types of resource-based policies.\\n•Endpoint policies  – Endpoint policies restrict access through the VPC endpoint. The default \\nendpoint policy allows full access to Amazon S3 for any user or service in your VPC. While \\ncreating or after you create the endpoint, you can optionally attach a resource-based policy to \\nthe endpoint to add restrictions, such as only allowing the endpoint to access a speciﬁc bucket or \\nonly allowing a speciﬁc IAM role to access the endpoint. For examples, see Edit the VPC endpoint \\npolicy.\\nThe following is an example policy you can attach to your VPC endpoint to only allow it to access \\nthe bucket containing your training data.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"RestrictAccessToTrainingBucket\", \\n            \"Effect\": \"Allow\", \\n            \"Principal\": \"*\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n(Optional) Set up a VPC 427Amazon Bedrock User Guide\\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: training-bucket \", \\n                \"arn:aws:s3::: training-bucket/* \" \\n            ] \\n        } \\n    ]\\n}\\n•Bucket policies – Bucket policies restrict access to S3 buckets. You can use a bucket policy to \\nrestrict access to traﬃc that comes from your VPC. To attach a bucket policy, follow the steps at\\nUsing bucket policies and use the aws:sourceVpc, aws:sourceVpce, or aws:VpcSourceIp condition \\nkeys. For examples, see Control access using bucket policies.\\nThe following is an example policy you can attach to the S3 bucket that will contain your output \\ndata to deny all traﬃc to the bucket unless it comes from your VPC.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n    \"Sid\": \"RestrictAccessToOutputBucket\", \\n            \"Effect\": \"Deny\", \\n            \"Principal\": \"*\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:PutObject\", \\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: output-bucket \", \\n                \"arn:aws:s3::: output-bucket/* \" \\n            ], \\n            \"Condition\": { \\n                \"StringNotEquals\": { \\n                  \"aws:sourceVpc\": \" your-vpc-id \" \\n                } \\n            } \\n        } \\n    ]\\n}\\n(Optional) Set up a VPC 428Amazon Bedrock User Guide\\nAttach VPC permissions to a model customization role\\nAfter you ﬁnish setting up your VPC and endpoint, you need to attach the following permissions \\nto your model customization IAM role. Modify this policy to allow access to only the VPC resources \\nthat your job needs. Replace the subnet-ids  and security-group-id  with the values from \\nyour VPC.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"ec2:DescribeNetworkInterfaces\", \\n                \"ec2:DescribeVpcs\", \\n                \"ec2:DescribeDhcpOptions\", \\n                \"ec2:DescribeSubnets\", \\n                \"ec2:DescribeSecurityGroups\" \\n                    ], \\n            \"Resource\": \"*\" \\n        },  \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"ec2:CreateNetworkInterface\", \\n            ], \\n            \"Resource\":[ \\n               \"arn:aws:ec2: region:account-id :network-interface/*\" \\n            ], \\n            \"Condition\": { \\n               \"StringEquals\": {  \\n                   \"aws:RequestTag/BedrockManaged\": [\"true\"] \\n                }, \\n                \"ArnEquals\": { \\n                   \"aws:RequestTag/BedrockModelCustomizationJobArn\": \\n [\"arn:aws:bedrock: region:account-id :model-customization-job/*\"] \\n               } \\n            } \\n        },  \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"ec2:CreateNetworkInterface\", \\n(Optional) Set up a VPC 429Amazon Bedrock User Guide\\n            ], \\n            \"Resource\":[ \\n               \"arn:aws:ec2: region:account-id :subnet/ subnet-id \", \\n               \"arn:aws:ec2: region:account-id :subnet/ subnet-id2 \", \\n               \"arn:aws:ec2: region:account-id :security-group/ security-group-id \" \\n            ] \\n        },  \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"ec2:CreateNetworkInterfacePermission\", \\n                \"ec2:DeleteNetworkInterface\", \\n                \"ec2:DeleteNetworkInterfacePermission\", \\n            ], \\n            \"Resource\": \"*\", \\n            \"Condition\": { \\n               \"ArnEquals\": { \\n                   \"ec2:Subnet\": [ \\n                       \"arn:aws:ec2: region:account-id :subnet/ subnet-id \", \\n                       \"arn:aws:ec2: region:account-id :subnet/ subnet-id2 \" \\n                   ], \\n                   \"ec2:ResourceTag/BedrockModelCustomizationJobArn\": \\n [\"arn:aws:bedrock: region:account-id :model-customization-job/*\"] \\n               }, \\n               \"StringEquals\": {  \\n                   \"ec2:ResourceTag/BedrockManaged\": \"true\" \\n               } \\n            } \\n        },  \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"ec2:CreateTags\" \\n            ], \\n            \"Resource\": \"arn:aws:ec2: region:account-id :network-interface/*\", \\n            \"Condition\": { \\n                \"StringEquals\": { \\n                    \"ec2:CreateAction\": [ \\n                        \"CreateNetworkInterface\" \\n                    ]     \\n                }, \\n                \"ForAllValues:StringEquals\": { \\n                    \"aws:TagKeys\": [ \\n                        \"BedrockManaged\", \\n(Optional) Set up a VPC 430Amazon Bedrock User Guide\\n                        \"BedrockModelCustomizationJobArn\" \\n                    ] \\n                } \\n         } \\n    ]\\n}\\nAdd the VPC conﬁguration when submitting a model customization job\\nAfter you conﬁgure the VPC and the required roles and permissions as described in the previous \\nsections, you can create a model customization job that uses this VPC.\\nWhen you specify the VPC subnets and security groups for a job, Amazon Bedrock creates elastic \\nnetwork interfaces (ENIs) that are associated with your security groups in one of the subnets. ENIs \\nallow the Amazon Bedrock job to connect to resources in your VPC. For information about ENIs, see\\nElastic Network Interfaces in the Amazon VPC User Guide . Amazon Bedrock tags ENIs that it creates \\nwith BedrockManaged  and BedrockModelCusomizationJobArn  tags.\\nWe recommend that you provide at least one subnet in each Availability Zone.\\nYou can use security groups to establish rules for controlling Amazon Bedrock access to your VPC \\nresources.\\nYou can conﬁgure the VPC to use in either the console or through the API. Select the tab \\ncorresponding to your method of choice and follow the steps.\\nConsole\\nFor the Amazon Bedrock console, you specify VPC subnets and security groups in the optional\\nVPC settings section when you create the model customization job. For more information \\nabout conﬁguring jobs, see Submit a model customization job .\\nNote\\nFor a job that includes VPC conﬁguration, the console can\\'t automatically create \\na service role for you. Follow the guidance at Create a service role for model \\ncustomization  to create a custom role.\\n(Optional) Set up a VPC 431Amazon Bedrock User Guide\\nAPI\\nWhen you submit a CreateModelCustomizationJob request, you can include a VpcConfig  as \\na request parameter to specify the VPC subnets and security groups to use, as in the following \\nexample.\\n\"VpcConfig\": {  \\n\"SecurityGroupIds\": [ \\n    \"sg-0123456789abcdef0 \"\\n],\\n\"Subnets\": [ \\n    \"subnet-0123456789abcdef0 \", \\n    \"subnet-0123456789abcdef1 \", \\n    \"subnet-0123456789abcdef2 \"\\n]\\n}\\nSubmit a model customization job\\nYou can create a custom model by using Fine-tuning or Continued Pre-training in the Amazon \\nBedrock console or API. The customization job can take several hours. The duration of the job \\ndepends on the size of the training data (number of records, input tokens, and output tokens), \\nnumber of epochs, and batch size. Select the tab corresponding to your method of choice and \\nfollow the steps.\\nSee code examples\\nConsole\\nTo submit a model customization job in the console, carry out the following steps.\\n1. In the Amazon Bedrock console, choose Custom models  under Foundation models from \\nthe left navigation pane.\\n2. In the Models  tab, choose Customize model and then Create Fine-tuning job  or Create \\nContinued Pre-training job , depending on the type of model you want to train.\\n3. In the Model details  section, do the following.\\na. Choose the model that you want to customize with your own data and give your \\nresulting model a name.\\nSubmit a job 432Amazon Bedrock User Guide\\nb. (Optional) By default, Amazon Bedrock encrypts your model with a key owned and \\nmanaged by AWS. To use a custom KMS key, select Model encryption and choose a \\nkey.\\nc. (Optional) To associate tags with the custom model, expand the Tags section and \\nselect Add new tag .\\n4. In the Job conﬁguration section, enter a name for the job and optionally add any tags to \\nassociate with the job.\\n5. (Optional) To use a virtual private cloud (VPC) to protect your training data and \\ncustomization job , select a VPC that contains the input data and output data Amazon S3 \\nlocations, its subnets, and security groups in the VPC settings section.\\nNote\\nIf you include a VPC conﬁguration, the console cannot create a new service role for \\nthe job. Create a custom service role and add permissions similar to the example \\ndescribed in Attach VPC permissions to a model customization role.\\n6. In the Input data  section, select the S3 location of the training dataset ﬁle and, if \\napplicable, the validation dataset ﬁle.\\n7. In the Hyperparameters  section, input values for hyperparameters to use in training.\\n8. In the Output data  section, enter the Amazon S3 location where Amazon Bedrock should \\nsave the output of the job. Amazon Bedrock stores the training loss metrics and validation \\nloss metrics for each epoch in separate ﬁles in the location that you specify.\\n9. In the Service access section, select one of the following:\\n•Use an existing service role – Select a service role from the drop-down list. For more \\ninformation on setting up a custom role with the appropriate permissions, see Create a \\nservice role for model customization.\\n•Create and use a new service role – Enter a name for the service role.\\n10. Choose Fine-tune model  or Create Continued Pre-training job  to begin the job.\\nAPI\\nRequest\\nSubmit a job 433Amazon Bedrock User Guide\\nSend a CreateModelCustomizationJob (see link for request and response formats and \\nﬁeld details) request with an Amazon Bedrock control plane endpoint to submit a model \\ncustomization job. Minimally, you must provide the following ﬁelds.\\n•roleArn – The ARN of the service role with permissions to customize models. Amazon \\nBedrock can automatically create a role with the appropriate permissions if you use the \\nconsole, or you can create a custom role by following the steps at Create a service role for \\nmodel customization .\\nNote\\nIf you include a vpcConfig  ﬁeld, make sure that the role has the proper permissions \\nto access the VPC. For an example, see Attach VPC permissions to a model \\ncustomization role.\\n•baseModelIdentifier  – The model ID  or ARN of the foundation model to customize.\\n•customModelName  – The name to give the newly customized model.\\n•jobName – The name to give the training job.\\n•hyperParameters  – Hyperparameters  that aﬀect the model customization process.\\n•trainingDataConfig  – An object containing the Amazon S3 URI of the training \\ndataset. Depending on the customization method and model, you can also include a\\nvalidationDataConfig . For more information about preparing the datasets, see Prepare \\nthe datasets .\\n•outputDataConfig  – An object containing the Amazon S3 URI to write the output data to.\\nIf you don\\'t specify the customizationType , the model customization method defaults to\\nFINE_TUNING .\\nTo prevent the request from completing more than once, include a clientRequestToken .\\nYou can include the following optional ﬁelds for extra conﬁgurations.\\n•jobTags  and/or customModelTags  – Associate tags with the customization job or resulting \\ncustom model.\\n•customModelKmsKeyId  – Include a custom KMS key to encrypt your custom model.\\n•vpcConfig  – Include the conﬁguration for a virtual private cloud (VPC) to protect your \\ntraining data and customization job .\\nSubmit a job 434Amazon Bedrock User Guide\\nResponse\\nThe response returns a jobArn that you can use to monitor  or stop  the job.\\nManage a model customization job\\nOnce you start a model customization job, you can track its progress or stop it. If you do so through \\nthe API, you will need the jobArn. You can ﬁnd it in one of the following ways:\\n1.In the Amazon Bedrock console\\n1. Select Custom models  under Foundation models from the left navigation pane.\\n2. Choose the job from the Training jobs table to see details, including the ARN of the job.\\n2.Look in the jobArn ﬁeld in the response returned from the CreateModelCustomizationJob call \\nthat created the job or from a CreateModelCustomizationJob call.\\nMonitor a model customization job\\nAfter you begin a job, you can monitor its progress in the console or API. Select the tab \\ncorresponding to your method of choice and follow the steps.\\nSee code examples\\nConsole\\nTo monitor the status of your ﬁne-tuning jobs\\n1. In the Amazon Bedrock console, choose Custom models  under Foundation models from \\nthe left navigation pane.\\n2. Select the Training jobs tab to display the ﬁne-tuning jobs that you have initiated. Look at \\nthe Status  column to monitor the progress of the job.\\n3. Select a job to view the details you input for training.\\nAPI\\nTo list information about all your model customization jobs, send a\\nCreateModelCustomizationJob request with an Amazon Bedrock control plane endpoint. Refer \\nto CreateModelCustomizationJob for ﬁlters that you can use.\\nManage a job 435Amazon Bedrock User Guide\\nTo monitor the status of a model customization job, send a GetModelCustomizationJob  request \\nwith an Amazon Bedrock control plane endpoint with the jobArn  of the job.\\nStop a model customization job\\nYou can stop an Amazon Bedrock model customization job while it\\'s in progress. Select the tab \\ncorresponding to your method of choice and follow the steps.\\nSee code examples\\nWarning\\nYou can\\'t resume a stopped job. Amazon Bedrock charges for the tokens that it used \\nto train the model before you stopped the job. Amazon Bedrock doesn\\'t create an \\nintermediate custom model for a stopped job.\\nConsole\\nTo stop a model customization job\\n1. In the Amazon Bedrock console, choose Custom models  under Foundation models from \\nthe left navigation pane.\\n2. In the Training Jobs tab, choose the radio button next to the job to stop or select the job \\nto stop to navigate to the details page.\\n3. Select the Stop job  button. You can only stop a job if its status is Training .\\n4. A modal appears to warn you that you can\\'t resume the training job if you stop it. Select\\nStop job  to conﬁrm.\\nAPI\\nTo stop a model customization job, send a CreateModelCustomizationJob (see link for request \\nand response formats and ﬁeld details) request with a Amazon Bedrock control plane endpoint, \\nusing the jobArn  of the job.\\nYou can only stop a job if its status is IN_PROGRESS . Check the status  with a\\nGetModelCustomizationJob  request. The system marks the job for termination and sets the \\nstate to STOPPING . Once the job is stopped, the state becomes STOPPED .\\nStop a job 436Amazon Bedrock User Guide\\nAnalyze the results of a model customization job\\nAfter a model customization job completes, you can analyze the results of the training process by \\nlooking at the ﬁles in the output S3 folder that you speciﬁed when you submitted the job or view \\ndetails about the model. Amazon Bedrock stores your customized models in AWS-managed storage \\nscoped to your account.\\nYou can also evaluate your model by running a model evaluation job. For more information, see\\nModel evaluation .\\nThe S3 output for a model customization job contains the following output ﬁles in your S3 folder. \\nThe validation artifacts only appear if you included a validation dataset.\\n- model-customization-job- training-job-id / \\n    - training_artifacts/ \\n        - step_wise_training_metrics.csv \\n    - validation_artifacts/ \\n        - post_fine_tuning_validation/ \\n            - validation_metrics.csv\\nUse the step_wise_training_metrics.csv  and the validation_metrics.csv  ﬁles to \\nanalyze the model customization job and to help you adjust the model as necessary.\\nThe columns in the step_wise_training_metrics.csv  ﬁle are as follows.\\n•step_number – The step in the training process. Starts from 0.\\n•epoch_number – The epoch in the training process.\\n•training_loss – Indicates how well the model ﬁts the training data. A lower value indicates a \\nbetter ﬁt.\\n•perplexity – Indicates how well the model can predict a sequence of tokens. A lower value \\nindicates better predictive ability.\\nThe columns in the validation_metrics.csv  ﬁle are the same as the training ﬁle, except \\nthat validation_loss  (how well the model ﬁts the validation data) appears in place of\\ntraining_loss .\\nAnalyze job results 437Amazon Bedrock User Guide\\nYou can ﬁnd the output ﬁles by opening up the https://console.aws.amazon.com/s3 directly or \\nby ﬁnding the link to the output folder within your model details. Select the tab corresponding to \\nyour method of choice and follow the steps.\\nSee code examples\\nConsole\\n1. In the Amazon Bedrock console, choose Custom models  under Foundation models from \\nthe left navigation pane.\\n2. In the Models  tab, select a model to view its details. The Job name  can be found in the\\nModel details  section.\\n3. To view the output S3 ﬁles, select the S3 location in the Output data  section.\\n4. Find the training and validation metrics ﬁles in the folder whose name matches the Job \\nname  for the model.\\nAPI\\nTo list information about all your custom models, send a ListCustomModels  (see link for \\nrequest and response formats and ﬁeld details) request with an Amazon Bedrock control plane \\nendpoint . Refer to ListCustomModels  for ﬁlters that you can use.\\nTo monitor the status of a model customization job, send a GetCustomModel  (see link for \\nrequest and response formats and ﬁeld details) request with an Amazon Bedrock control plane \\nendpoint  with the modelIdentifier , which is either of the following.\\n•The name that you gave the model.\\n•The ARN of the model.\\nYou can see trainingMetrics  and validationMetrics  for a model customization job in \\neither the GetModelCustomizationJob  or GetCustomModel  response.\\nTo download the training and validation metrics ﬁles, follow the steps at Downloading objects. \\nUse the S3 URI you provided in the outputDataConfig .\\nAnalyze job results 438Amazon Bedrock User Guide\\nUse a custom model\\nBefore you can use a customized model, you need to purchase Provisioned Throughput for it. For \\nmore information about Provisioned Throughput, see Provisioned Throughput. You can then use \\nthe resulting provisioned model for inference. Select the tab corresponding to your method of \\nchoice and follow the steps.\\nSee code examples\\nConsole\\nTo purchase Provisioned Throughput for a custom model.\\n1. In the Amazon Bedrock console, choose Custom models  under Foundation models from \\nthe left navigation pane.\\n2. In the Models  tab, choose the radio button next to the model for which you want to buy \\nProvisioned Throughput or select the model name to navigate to the details page.\\n3. Select Purchase Provisioned Throughput.\\nWhen you carry out any operation that supports usage of custom models, you will see your \\ncustom model as an option in the model selection menu.\\nAPI\\nTo purchase Provisioned Throughput for a custom model, send a\\nCreateProvisionedModelThroughput (see link for request and response formats and ﬁeld \\ndetails) request with a Amazon Bedrock control plane endpoint, using the name or ARN of \\nyour custom model as the modelId. The response returns a provisionedModelArn  that you \\ncan use as the modelId  when making an InvokeModel or InvokeModelWithResponseStream\\nrequest.\\nCode samples for model customization\\nThe following code samples show how to prepare a basic dataset, set up permissions, create a \\ncustom model, view the output ﬁles, purchase throughput for the model, and run inference on the \\nmodel. You can modify these code snippets to your speciﬁc use-case.\\n1. Prepare the training dataset.\\nUse a custom model 439Amazon Bedrock User Guide\\na. Create a training dataset ﬁle containing the following one line and name it train.jsonl .\\n{\"prompt\": \"what is AWS\", \"completion\": \"it\\'s Amazon Web Services\"}\\nb. Create an S3 bucket for your training data and another one for your output data (the \\nnames must be unique).\\nc. Upload train.jsonl  into the training data bucket.\\n2. Create a policy to access your training and attach it to an IAM role with a Amazon Bedrock \\ntrust relationship. Select the tab corresponding to your method of choice and follow the steps.\\nConsole\\n1. Create the S3 policy.\\na. Navigate to the IAM console at https://console.aws.amazon.com/iam and choose\\nPolicies from the left navigation pane.\\nb. Select Create policy and then choose JSON to open the Policy editor.\\nc. Paste the following policy, replacing training-bucket  and output-bucket\\nwith your bucket names, and then select Next.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: training-bucket \", \\n                \"arn:aws:s3::: training-bucket /*\" \\n            ] \\n        }, \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:PutObject\", \\n                \"s3:ListBucket\" \\nCode samples 440Amazon Bedrock User Guide\\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: output-bucket \", \\n                \"arn:aws:s3::: output-bucket /*\" \\n            ] \\n        } \\n    ]\\n}\\nd. Name the policy MyFineTuningDataAccess  and select Create policy.\\n2. Create an IAM role and attach the policy.\\na. From the left navigation pane, choose Roles and then select Create role.\\nb. Select Custom trust policy, paste the following policy, and select Next.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"Service\": \"bedrock.amazonaws.com\" \\n            }, \\n            \"Action\": \"sts:AssumeRole\" \\n        } \\n    ]  \\n}\\nc. Search for the MyFineTuningDataAccess  policy you created, select the \\ncheckbox, and choose Next.\\nd. Name the role MyCustomizationRole  and select Create role .\\nCLI\\n1. Create a ﬁle called BedrockTrust.json  and paste the following policy into it.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\nCode samples 441Amazon Bedrock User Guide\\n            \"Principal\": { \\n                \"Service\": \"bedrock.amazonaws.com\" \\n            }, \\n            \"Action\": \"sts:AssumeRole\" \\n        } \\n    ]  \\n}\\n2. Create another ﬁle called MyFineTuningDataAccess.json  and paste the following \\npolicy into it, replacing training-bucket  and output-bucket  with your bucket \\nnames.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: training-bucket \", \\n                \"arn:aws:s3::: training-bucket /*\" \\n            ] \\n        }, \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:PutObject\", \\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: training-bucket \", \\n                \"arn:aws:s3::: training-bucket /*\" \\n            ] \\n        } \\n    ]\\n}\\n3. In a terminal, navigate to the folder containing the policies you created.\\nCode samples 442Amazon Bedrock User Guide\\n4. Make a CreateRole request to create an IAM role called MyCustomizationRole  and \\nattach the BedrockTrust.json  trust policy that you created.\\naws iam create-role \\\\ \\n    --role-name MyCustomizationRole \\\\ \\n    --assume-role-policy-document file://BedrockTrust.json\\n5. Make a CreatePolicy request to create the S3 data access policy with the\\nMyFineTuningDataAccess.json  ﬁle you created. The response returns an Arn for \\nthe policy.\\naws iam create-policy \\\\ \\n    --policy-name MyFineTuningDataAccess \\\\ \\n    --policy-document file://myFineTuningDataAccess.json\\n6. Make an AttachRolePolicy request to attach the S3 data access policy to your role, \\nreplacing the policy-arn  with the ARN in the response from the previous step:\\naws iam attach-role-policy \\\\ \\n    --role-name MyCustomizationRole \\\\ \\n    --policy-arn policy-arn\\nPython\\n1. Run the following code to make a CreateRole request to create an IAM role called\\nMyCustomizationRole  and to make a CreatePolicy request to create an S3 data \\naccess policy called MyFineTuningDataAccess . For the S3 data access policy, replace\\ntraining-bucket  and output-bucket  with your S3 bucket names.\\nimport boto3\\nimport json\\niam = boto3.client(\"iam\")\\niam.create_role( \\n    RoleName=\"MyCustomizationRole\", \\n    AssumeRolePolicyDocument=json.dumps({ \\n        \"Version\": \"2012-10-17\", \\n        \"Statement\": [ \\n            { \\nCode samples 443Amazon Bedrock User Guide\\n                \"Effect\": \"Allow\", \\n                \"Principal\": { \\n                    \"Service\": \"bedrock.amazonaws.com\" \\n                }, \\n                \"Action\": \"sts:AssumeRole\" \\n            } \\n        ]  \\n    })\\n)\\niam.create_policy( \\n    PolicyName=\"MyFineTuningDataAccess\", \\n    PolicyDocument=json.dumps({ \\n        \"Version\": \"2012-10-17\", \\n        \"Statement\": [ \\n            { \\n                \"Effect\": \"Allow\", \\n                \"Action\": [ \\n                    \"s3:GetObject\", \\n                    \"s3:ListBucket\" \\n                ], \\n                \"Resource\": [ \\n                    \"arn:aws:s3::: training-bucket \", \\n                    \"arn:aws:s3::: training-bucket /*\" \\n                ] \\n            }, \\n            { \\n                \"Effect\": \"Allow\", \\n                \"Action\": [ \\n                    \"s3:GetObject\", \\n                    \"s3:PutObject\", \\n                    \"s3:ListBucket\" \\n                ], \\n                \"Resource\": [ \\n                    \"arn:aws:s3::: output-bucket \", \\n                    \"arn:aws:s3::: output-bucket /*\" \\n                ] \\n            } \\n        ] \\n    })\\n)\\n2. An Arn is returned in the response. Run the following code snippet to make an\\nAttachRolePolicy request, replacing policy-arn  with the returned Arn.\\nCode samples 444Amazon Bedrock User Guide\\niam.attach_role_policy( \\n    RoleName=\"MyCustomizationRole\", \\n    PolicyArn=\" policy-arn \"\\n)\\n3. Select a language to see code samples to call the model customization API operations.\\nCLI\\nFirst, create a text ﬁle named FineTuningData.json . Copy the JSON code from below into \\nthe text ﬁle, replacing training-bucket  and output-bucket  with your S3 bucket names.\\n{ \\n    \"trainingDataConfig\": { \\n        \"s3Uri\": \"s3:// training-bucket /train.jsonl\" \\n    }, \\n    \"outputDataConfig\": { \\n        \"s3Uri\": \"s3:// output-bucket \" \\n    }\\n}\\nTo submit a model customization job, navigate to the folder containing\\nFineTuningData.json  in a terminal and run the following command in the command line, \\nreplacing your-customization-role-arn  with the model customization role that you set \\nup.\\naws bedrock create-model-customization-job \\\\ \\n    --customization-type FINE_TUNING \\\\ \\n    --base-model-identifier arn:aws:bedrock:us-east-1::foundation-model/\\namazon.titan-text-express-v1 \\\\ \\n    --role-arn your-customization-role-arn  \\\\ \\n    --job-name myFineTuningJob \\\\ \\n    --custom-model-name myCustomModel \\\\ \\n    --hyper-parameters \\n epochCount=1,batchSize=1,learningRate=.005,learningRateWarmupSteps=0 \\\\ \\n    --cli-input-json file://FineTuningData.json \\n                 \\nThe response returns a jobArn. Allow the job some time to complete. You can check its status \\nwith the following command.\\nCode samples 445Amazon Bedrock User Guide\\naws bedrock get-model-customization-job \\\\ \\n    --job-identifier \" jobArn\"\\nWhen the status  is COMPLETE , you can see the trainingMetrics  in the response. You can \\ndownload the artifacts to the current folder by running the following command, replacing\\naet.et-bucket  with your output bucket name and jobId  with the ID of the customization \\njob (the sequence following the last slash in the jobArn ).\\naws s3 cp s3:// output-bucket /model-customization-job- jobId . --recursive\\nPurchase a no-commitment Provisioned Throughput for your custom model with the following \\ncommand.\\nNote\\nYou will be charged hourly for this purchase. Use the console to see price estimates for \\ndiﬀerent options.\\naws bedrock create-provisioned-model-throughput \\\\ \\n    --model-id myCustomModel \\\\ \\n    --provisioned-model-name myProvisionedCustomModel \\\\ \\n    --model-units 1\\nThe response returns a provisionedModelArn  that you can use as a modelId in inference. \\nAllow the Provisioned Throughput some time to be created. You can check its status with the \\nfollowing command.\\naws bedrock get-provisioned-model-throughput \\\\ \\n    --provisioned-model-id provisionedModelArn\\nWhen the status  is InService , you can run inference with your custom model with the \\nfollowing command. Replace the provisionedModelArn  with the one returned to you. The \\noutput is written to a ﬁle named output.txt  in your current folder.\\naws bedrock-runtime invoke-model \\\\ \\n    --model-id provisionedModelArn  \\\\ \\nCode samples 446Amazon Bedrock User Guide\\n    --body \\'{\"inputText\": \"What is AWS?\", \"textGenerationConfig\": {\"temperature\": \\n 0.5}}\" \\\\ \\n    --cli-binary-format raw-in-base64-out \\\\ \\n    output.txt\\nPython\\nRun the following code snippet to submit a ﬁne-tuning job. Replace your-customization-\\nrole-arn  with the ARN of the myCustomizationRole  that you set up and replace\\ntraining-bucket  and output-bucket  with your S3 bucket names.\\nimport boto3\\nimport json\\nbedrock = boto3.client(service_name=\\'bedrock\\') \\n     \\n# Set parameters\\ncustomizationType = \"FINE_TUNING\"\\nbaseModelIdentifier = \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-\\ntext-express-v1\"\\nroleArn = \" your-customization-role-arn \"\\njobName = \"myFineTuningJob\"\\ncustomModelName = \"myCustomModel\"\\nhyperParameters = { \\n        \"epochCount\": \"1\", \\n        \"batchSize\": \"1\", \\n        \"learningRate\": \".005\", \\n        \"learningRateWarmupSteps\": \"0\" \\n    }\\ntrainingDataConfig = {\"s3Uri\": \"s3:// training-bucket /myInputData/train.jsonl\"}\\noutputDataConfig = {\"s3Uri\": \"s3:// output-bucket /myOutputData\"}\\n# Create job\\nresponse_ft = bedrock.create_model_customization_job( \\n    jobName=jobName,  \\n    customModelName=customModelName, \\n    roleArn=roleArn, \\n    baseModelIdentifier=baseModelIdentifier, \\n    hyperParameters=hyperParameters, \\n    trainingDataConfig=trainingDataConfig, \\n    outputDataConfig=outputDataConfig\\n)\\nCode samples 447Amazon Bedrock User Guide\\njobArn = response_ft.get(\\'jobArn\\')\\nThe response returns a jobArn. Allow the job some time to complete. You can check its status \\nwith the following command.\\nbedrock.get_model_customization_job(jobIdentifier=jobArn).get(\\'status\\')\\nWhen the status  is COMPLETE , you can see the trainingMetrics  in the\\nGetModelCustomizationJob  response. You can also follow the steps at Downloading objects to \\ndownload the metrics.\\nPurchase a no-commitment Provisioned Throughput for your custom model with the following \\ncommand.\\nresponse_pt = bedrock.create_provisioned_model_throughput( \\n    modelId=\"myCustomModel\", \\n    provisionedModelName=\"myProvisionedCustomModel\" \\n    modelUnits=\"1\"\\n)\\nprovisionedModelArn = response_pt.get(\\'provisionedModelArn\\')\\nThe response returns a provisionedModelArn  that you can use as a modelId in inference. \\nAllow the Provisioned Throughput some time to be created. You can check its status with the \\nfollowing command.\\nbedrock.get_provisioned_model_throughput(provisionedModelId=provisionedModelArn)\\nWhen the status  is InService , you can run inference with your custom model with the \\nfollowing command.\\nimport json\\nimport logging\\nimport boto3\\nfrom botocore.exceptions import ClientError\\nclass ImageError(Exception): \\n    \"Custom exception for errors returned by the model\" \\nCode samples 448Amazon Bedrock User Guide\\n    def __init__(self, message): \\n        self.message = message\\nlogger = logging.getLogger(__name__)\\nlogging.basicConfig(level=logging.INFO)\\ndef generate_text(model_id, body): \\n    \"\"\" \\n    Generate text using your provisioned custom model. \\n    Args: \\n        model_id (str): The model ID to use. \\n        body (str) : The request body to use. \\n    Returns: \\n        response (json): The response from the model. \\n    \"\"\" \\n    logger.info( \\n        \"Generating text with your provisioned custom model %s\", model_id) \\n    brt = boto3.client(service_name=\\'bedrock-runtime\\') \\n    accept = \"application/json\" \\n    content_type = \"application/json\" \\n    response = brt.invoke_model( \\n        body=body, modelId=model_id, accept=accept, contentType=content_type \\n    ) \\n    response_body = json.loads(response.get(\"body\").read()) \\n    finish_reason = response_body.get(\"error\") \\n    if finish_reason is not None: \\n        raise ImageError(f\"Text generation error. Error is {finish_reason}\") \\n    logger.info( \\n        \"Successfully generated text with provisioned custom model %s\", model_id) \\n    return response_body\\ndef main(): \\n    \"\"\" \\nCode samples 449Amazon Bedrock User Guide\\n    Entrypoint for example. \\n    \"\"\" \\n    try: \\n        logging.basicConfig(level=logging.INFO, \\n                            format=\"%(levelname)s: %(message)s\") \\n        model_id = provisionedModelArn \\n        prompt = \"What is A.W.S.?\" \\n        body = json.dumps({ \\n            \"inputText\": \"what is AWS?\" \\n        }) \\n        response_body = generate_text(model_id, body) \\n        print(f\"Input token count: {response_body[\\'inputTextTokenCount\\']}\") \\n        for result in response_body[\\'results\\']: \\n            print(f\"Token count: {result[\\'tokenCount\\']}\") \\n            print(f\"Output text: {result[\\'outputText\\']}\") \\n            print(f\"Completion reason: {result[\\'completionReason\\']}\") \\n    except ClientError as err: \\n        message = err.response[\"Error\"][\"Message\"] \\n        logger.error(\"A client error occurred: %s\", message) \\n        print(\"A client error occured: \" + \\n              format(message)) \\n    except ImageError as err: \\n        logger.error(err.message) \\n        print(err.message) \\n    else: \\n        print( \\n            f\"Finished generating text with your provisioned custom model \\n {model_id}.\")\\nif __name__ == \"__main__\": \\n    main()\\nCode samples 450Amazon Bedrock User Guide\\nGuidelines for model customization\\nThe ideal parameters for customizing a model depend on the dataset and the task for which the \\nmodel is intended. You should experiment with values to determine which parameters work best \\nfor your speciﬁc case. To help, evaluate your model by running a model evaluation job. For more \\ninformation, see Model evaluation .\\nThis topic provides guidelines and recommended values as a baseline for customization of the \\nAmazon Titan Text G1 - Express model. For other models, check the provider\\'s documentation.\\nUse the training and validation metrics from the output ﬁles  generated when you submit  a ﬁne-\\ntuning job to help you adjust your parameters. Find these ﬁles in the Amazon S3 bucket to which \\nyou wrote the output, or use the GetCustomModel  operation.\\nAmazon Titan Text G1 - Express\\nThe following guidelines are for the Titan Text Express text-to-text model model. For information \\nabout the hyperparameters that you can set, see Amazon Titan text model customization \\nhyperparameters.\\nImpact on other tasks types\\nIn general, the larger the training dataset, the better the performance for a speciﬁc task. However, \\ntraining for a speciﬁc task might make the model perform worse on diﬀerent tasks, especially if \\nyou use a lot of examples. For example, if the training dataset for a summarization task contains \\n100,000 samples, the model might perform worse on a classiﬁcation task).\\nModel size\\nIn general, the larger the model, the better the task performs given limited training data.\\nIf you are using the model for a classiﬁcation  task, you might see relatively small gains for few-shot \\nﬁne-tuning (less than 100 samples), especially if the number of classes is relatively small (less than \\n100).\\nEpochs\\nWe recommend using the following metrics to determine the number of epochs to set:\\n1.Validation output accuracy – Set the number of epochs to one that yields a high accuracy.\\nGuidelines 451Amazon Bedrock User Guide\\n2.Training and validation loss – Determine the number of epochs after which the training and \\nvalidation loss becomes stable. This corresponds to when the model converges. Find the training \\nloss values in the step_wise_training_metrics.csv  and validation_metrics.csv  ﬁles.\\nBatch size\\nWhen you change the batch size, we recommend that you change the learning rate using the \\nfollowing formula:\\nnewLearningRate = oldLearningRate x newBatchSize / oldBatchSize\\nLearning rate\\nIn general, use smaller learning rates for larger models. We recommend using a learning rate in the \\nrange of 1.00E-06 to 1.00E-05.\\nThe following table shows recommended learning rate values for ﬁne-tuning:\\nTask Minimum learning \\nrateDefault learning rateMax learning rate\\nSummarization 1.00E-06 3.00E-06 5.00E-05\\nClassiﬁcation 5.00E-06 5.00E-05 5.00E-05\\nQuestion-answer 5.00E-06 5.00E-06 5.00E-05\\nLearning warmup steps\\nWe recommend the default value of 0.\\nTroubleshooting\\nThis section summarizes errors that you might encounter and what to check if you do.\\nPermissions issues\\nIf you encounter an issue with permissions to access an Amazon S3 bucket, check that the \\nfollowing are true:\\nTroubleshooting 452Amazon Bedrock User Guide\\n1.If the Amazon S3 bucket uses a CM-KMS key for Server Side encryption, ensure that the IAM role \\npassed to Amazon Bedrock has kms:Decrypt  permissions for the AWS KMS key. For example, \\nsee Allow a user to enccrypt and decrypt with any AWS KMS key in a speciﬁc AWS account.\\n2.The Amazon S3 bucket is in the same region as the Amazon Bedrock model customization job.\\n3.The IAM role trust policy includes the service SP (bedrock.amazonaws.com ).\\nThe following messages indicate issues with permissions to access training or validation data in an \\nAmazon S3 bucket:\\nCould not validate GetObject permissions to access Amazon S3 bucket: training-data-\\nbucket at key train.jsonl\\nCould not validate GetObject permissions to access Amazon S3 bucket: validation-data-\\nbucket at key validation.jsonl\\nIf you encounter one of the above errors, check that the IAM role passed to the service has\\ns3:GetObject  and s3:ListBucket  permissions for the training and validation dataset Amazon \\nS3 URIs.\\nThe following message indicates issues with permissions to write the output data in an Amazon S3 \\nbucket:\\nAmazon S3 perms missing (PutObject): Could not validate PutObject permissions to access \\n S3 bucket: bedrock-output-bucket  at key output/.write_access_check_file.tmp\\nIf you encounter the above error, check that the IAM role passed to the service has s3:PutObject\\npermissions for the output data Amazon S3 URI.\\nData issues\\nThe following errors are related to issues with the training, validation, or output data ﬁles:\\nInvalid ﬁle format\\nUnable to parse Amazon S3 file: fileName.jsonl . Data files must conform to JSONL \\n format.\\nIf you encounter the above error, check that the following are true:\\nData issues 453Amazon Bedrock User Guide\\n1.Each line is in JSON.\\n2.Each JSON has two keys, an input  and an output, and each key is a string. For example:\\n{ \\n    \"input\": \"this is my input\", \\n    \"output\": \"this is my output\"\\n}\\n3.There are no additional new lines or empty lines.\\nCharacter quota exceeded\\nInput size exceeded in file fileName.jsonl  for record starting with...\\nIf you encounter an error beginning with the text above, ensure that the number of characters \\nconforms to the character quota in Model customization quotas .\\nToken count exceeded\\nMaximum input token count 4097 exceeds limit of 4096\\nMaximum output token count 4097 exceeds limit of 4096\\nMax sum of input and output token length 4097 exceeds total limit of 4096\\nIf you encounter an error similar to the preceeding example, make sure that the number of tokens \\nconforms to the token quota in Model customization quotas .\\nInternal error\\nEncountered an unexpected error when processing the request, please try again\\nIf you encounter the above error, there might be an issue with the service. Try the job again. If the \\nissue persists, contact AWS Support.\\nInternal error 454Amazon Bedrock User Guide\\nProvisioned Throughput\\nNote\\nProvisioned Throughput is only available in the US East (N. Virginia), US West (Oregon), and \\nAWS GovCloud (US-West) Regions.\\nWhen you conﬁgure Provisioned Throughput for a model, you receive a level of throughput at a \\nﬁxed cost.\\nYou can use Provisioned Throughput with Amazon and third-party base models, and with \\ncustomized models.\\nProvisioned Throughput pricing varies depending on the model that you use and the level of \\ncommitment you choose. You receive a discounted rate when you commit to a longer period \\nof time. For details about pricing for each model, see the Model providers page in the Amazon \\nBedrock console.\\nYour options for throughput for a model diﬀer depending on whether you run inference on a base \\nmodel or a custom model.\\nNote\\nIn the AWS GovCloud (US) region, you can only purchase Provisioned Throughput for \\ncustom models with no commitment.\\nPricing option Base model Custom model\\nProvisioned Throughput, no \\ncommitment (hourly pricing)Not available Available (maximum 2 \\nProvisioned Throughputs per \\naccount)\\nProvisioned Throughput, 1 \\nmonth commitmentAvailable Available\\n455Amazon Bedrock User Guide\\nPricing option Base model Custom model\\nProvisioned Throughput, 6 \\nmonth commitmentAvailable Available\\nYou specify Provisioned Throughput in Model Units (MU). A model unit delivers a speciﬁc \\nthroughput level for the speciﬁed model. The throughput level of a MU for a given Text model \\nspeciﬁes the following:\\n•The total number of input tokens per minute – The number of input tokens that an MU can \\nprocess across all requests within a span of one minute.\\n•The total number of output tokens per minute – The number of output tokens that an MU can \\ngenerate across all requests within a span of one minute.\\nModel unit quotas depend on the level of commitment you specify for the Provisioned Throughput.\\n•For custom models with no commitment, a quota of one model unit is available for each \\nProvisioned Throughput. You can create up to two Provisioned Throughputs per account.\\n•For base or custom models with commitment, there is a default quota of 0 model units. To \\nrequest an increase, use the limit increase form.\\nTopics\\n•Supported regions and models for Provisioned Throughput\\n•Procedures\\n•Permissions\\n•Provisioned Throughput console procedures\\n•Using the Provisioned Throughput API\\nSupported regions and models for Provisioned Throughput\\nProvisioned Throughput is supported in the following regions:\\nSupported regions and models 456Amazon Bedrock User Guide\\nRegion\\nUS East (N. Virginia)\\nUS West (Oregon)\\nAWS GovCloud (US-West)\\nIf you purchase Provisioned Throughput through the Amazon Bedrock API, you must specify \\ncontextual variants of Amazon Bedrock FMs for the model ID. The following table shows the \\nmodels for which you can purchase Provisioned Throughput and the model ID to use when \\npurchasing Provisioned Throughput:\\nModel name Model ID for \\nProvisioned \\nThroughput\\nAmazon Titan Text \\nG1 - Expressamazon.titan-text- \\nexpress-v1:0:8k\\nAmazon Titan Text \\nG1 - Liteamazon.titan-text- \\nlite-v1:0:4k\\nAmazon Titan \\nEmbeddings G1 - \\nTextamazon.titan-embed-\\ntext-v1:2:8k\\nAmazon Titan \\nMultimodal \\nEmbeddings G1amazon.titan-embed-\\nimage-v1:0\\nAmazon Titan Image \\nGenerator G1amazon.titan-image-\\ngenerator-v1:0\\nAnthropic Claude V2 \\n18Kanthropic.claude-v \\n2:0:18k\\nSupported regions and models 457Amazon Bedrock User Guide\\nModel name Model ID for \\nProvisioned \\nThroughput\\nAnthropic Claude V2 \\n100Kanthropic.claude-v \\n2:0:100k\\nAnthropic Claude \\nV2.1 18Kanthropic.claude-v \\n2:1:18k\\nAnthropic Claude \\nV2.1 100Kanthropic.claude-v \\n2:1:100k\\nAnthropic Claude \\nInstant V1 100Kanthropic.claude-i \\nnstant-v1:2:100K\\nCohere Commandcohere.command-tex \\nt-v14:7:4k\\nCohere Command \\nLightcohere.command-lig \\nht-text-v14:7:4k\\nStable Diﬀusion XL \\n1.0stability.stable-d \\niﬀusion-xl-v1:0\\nMeta Llama 2 Chat \\n13Bmeta.llama2-13b-ch \\nat-v1:0:4k\\nMeta Llama 2 13B (see note below)\\nMeta Llama 2 70B (see note below)\\nNote\\nThe Meta Llama 2 (non-chat) models can only be used after being customized and after\\npurchasing Provisioned Throughput for them.\\nSupported regions and models 458Amazon Bedrock User Guide\\nProcedures\\nProvisioned Throughput supports the following procedures.\\nCreating\\nWhen you create a Provisioned Throughput, the Provisioned Throughput starts in an interim \\nstate (Creating ) while Bedrock creates the Provisioned Throughput resources. If the creation is \\nsuccessful, the Provisioned Throughput transitions to InService  state, and you can start using it \\nfor inference.\\nIf the creation fails, the Provisioned Throughput transitions to Failed  state.\\nUpdating\\nYou can perform the following types of updates to a Provisioned Throughput:\\n•Change the name of the Provisioned Throughput.\\n•Specify a new custom model that uses the same base model as the current custom model.\\n•Specify a base model. It must be the base model of the current custom model.\\nWhen you update a Provisioned Throughput, it transitions to the Updating  state while Bedrock \\nperforms the update. If the update is successful, the Provisioned Throughput transitions to\\nInService  state. During the update, you can run inference using the Provisioned Throughput \\nwithout disrupting the on-going traﬃc from your end customers. If the update includes a new \\nmodel, you may receive output from the old model until the update is fully deployed.\\nIf the update fails, the Provisioned Throughput transitions to Failed  state.\\nDeleting\\nDeleting a Provisioned Throughput is a synchronous operation. The Provisioned Throughput \\ndeletion takes eﬀect immediately.\\nRunning inference\\nYou can run inference using a Provisioned Throughput that is in InService  state.\\nIf you request more throughput than is conﬁgured for the Provisioned Throughput, the request is \\nthrottled (you receive the throughput deﬁned by the Provisioned Throughput).\\nProcedures 459Amazon Bedrock User Guide\\nPermissions\\nTo add Provisioned Throughput to a base model or a model that was customized from a base \\nmodel, you must have ﬁrst requested access to the base model by following the steps at Model \\naccess.\\nTo add Provisioned Throughput to a custom model that is encrypted, your role must include \\npermissions to carry out the kms:Decrypt  action on the model. For an example, see Create a key \\npolicy and attach it to the customer managed key.\\nProvisioned Throughput console procedures\\nThis section describes the console procedures for Provisioned Throughput.\\nTopics\\n•View Provisioned Throughput summary\\n•Purchase Provisioned Throughput\\n•View details of a Provisioned Throughput\\n•Edit a Provisioned Throughput\\n•Delete a Provisioned Throughput\\nView Provisioned Throughput summary\\nUse the summary page to review the status of each Provisioned Throughput. The Overview panel \\ndisplays the number of Provisioned Throughput resources in each state. You can update or delete \\nan active Provisioned Throughput, and you can create a new Provisioned Throughput.\\n1. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n2. From the left navigation pane, choose Provisioned throughput under Deployments.\\n3. From the Provisioned Throughput table, you can review summary information about each \\nProvisioned Throughput.\\nPurchase Provisioned Throughput\\nYou can purchase Provisioned Throughput for a foundation or custom model.\\nPermissions 460Amazon Bedrock User Guide\\n1. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n2. From the left menu, choose Provisioned Throughput under Deployments. Then select\\nPurchase Provisioned Throughput. The console opens the Purchase Provisioned Throughput\\npage.\\n3. Under Provisioned Throughput details:\\na. Enter a name for the Provisioned Throughput.\\nb. Select the model category and model for the Provisioned Throughput.\\nc. (Optional) Under Tags, you can associate one or more tags with this Provisioned \\nThroughput.\\n4. Under Model units & commitment term:\\na. Enter the desired number of model units.\\nb. Choose the amount of time for which you want to commit to using the Provisioned \\nThroughput. To opt out of commitment for a custom model, you must set the number of \\nmodel units to 1 and then select No commitment. With this option, you pay an hourly \\namount for the allocated throughput until you delete it.\\nNote\\nTo see limitations on model units and commitment term, see Provisioned Throughput.\\n5. Under Estimated purchase summary, review the estimated cost.\\n6. Choose Purchase Provisioned Throughput.\\n7. Review the note that appears and acknowledge the commitment duration and price by \\nselecting the checkbox. Then choose Conﬁrm purchase .\\nThe console displays the overview page. For the Provisioned Throughput that you just purchased, \\nthe console displays it in the table, with the status set to Creating .\\nView details of a Provisioned Throughput\\nFrom the summary page, you can view the details for any of your Provisioned Throughput \\nresources.\\n1. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\nView details of a Provisioned Throughput 461Amazon Bedrock User Guide\\n2. From the left menu, choose Provisioned Throughput.\\n3. From the Provisioned Throughput table, choose a Provisioned Throughput. The console opens \\nthe details page.\\n4. Under Provisioned Throughput overview:\\n5. Under Tags, the console displays the tags that are associated with this Provisioned \\nThroughput. Choose Manage tags  to add or remove tags for this Provisioned Throughput.\\nEdit a Provisioned Throughput\\nYou can edit only a few ﬁelds of a Provisioned Throughput.\\n1. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n2. From the left menu, choose Provisioned Throughput.\\n3. From the Provisioned Throughput table, select the Provisioned Throughput to edit.\\n4. The console displays the Provisioned Throughput ﬁelds that you can edit.\\n5. Choose Save to start the update.\\nDelete a Provisioned Throughput\\nNote\\nYou can’t delete a Provisioned Throughput with commitment before the commitment term \\nis complete.\\n1. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n2. From the left menu, choose Provisioned Throughput.\\n3. From the Provisioned Throughput table, select the Provisioned Throughput to delete.\\n4. The console displays a modal form to warn you that delete is permanent. Choose Conﬁrm  to \\nproceed.\\nEdit a Provisioned Throughput 462Amazon Bedrock User Guide\\nUsing the Provisioned Throughput API\\nAmazon Bedrock provides API operations to create and manage your Provisioned Throughput \\nresources.\\nTopics\\n•Create Provisioned Throughput\\n•Run inference using Provisioned Throughput\\n•Update Provisioned Throughput\\n•Get Provisioned Throughput\\n•Delete Provisioned Throughput\\n•List Provisioned Throughput resources\\nCreate Provisioned Throughput\\nUse the  CreateProvisionedModelThroughput operation to create a Provisioned Throughput for a \\nbase or custom model.\\nWhen you send a CreateProvisionedModelThroughput  operation for a base model, Bedrock \\nvalidates your access permissions for the requested model and checks for capacity availability. If \\nthe validations are successful, Bedrock creates the provisioned throughput and returns the ARN of \\nthe Provisioned Throughput.\\nWhen you send a CreateProvisionedModelThroughput  operation for a custom model, \\nBedrock validates your access permissions for the requested custom model. and checks for \\ncapacity availability. If the custom model is encrypted using a customer-managed KMS key, your \\npermissions must include kms:Decrypt  permission for this model.\\nNote\\nTo see quotas for your options for commitmentDuration  and modelUnits , see\\nProvisioned Throughput.\\nTo request on-demand Provisioned Throughput for a custom model, omit the\\ncommitmentDuration  ﬁeld in the request.\\nAPI operations 463Amazon Bedrock User Guide\\nTo create a Provisioned Throughput for an Titan foundation model, use the following IDs instead of \\nthe default ones.\\nModel name Model ID for \\nProvisioned \\nThroughput\\nAmazon Titan Text \\nG1 - Expressamazon.titan-text- \\nexpress-v1:0:8k\\nAmazon Titan Text \\nG1 - Liteamazon.titan-text- \\nlite-v1:0:4k\\nAmazon Titan \\nEmbeddings G1 - \\nTextamazon.titan-embed-\\ntext-v1:2:8k\\nAmazon Titan \\nMultimodal \\nEmbeddings G1amazon.titan-embed-\\nimage-v1:0\\nAmazon Titan Image \\nGenerator G1amazon.titan-image-\\ngenerator-v1:0\\nAnthropic Claude V2 \\n18Kanthropic.claude-v \\n2:0:18k\\nAnthropic Claude V2 \\n100Kanthropic.claude-v \\n2:0:100k\\nAnthropic Claude \\nV2.1 18Kanthropic.claude-v \\n2:1:18k\\nAnthropic Claude \\nV2.1 100Kanthropic.claude-v \\n2:1:100k\\nAnthropic Claude \\nInstant V1 100Kanthropic.claude-i \\nnstant-v1:2:100K\\nCreate Provisioned Throughput 464Amazon Bedrock User Guide\\nModel name Model ID for \\nProvisioned \\nThroughput\\nCohere Commandcohere.command-tex \\nt-v14:7:4k\\nCohere Command \\nLightcohere.command-lig \\nht-text-v14:7:4k\\nStable Diﬀusion XL \\n1.0stability.stable-d \\niﬀusion-xl-v1:0\\nMeta Llama 2 Chat \\n13Bmeta.llama2-13b-ch \\nat-v1:0:4k\\nMeta Llama 2 13B (see note below)\\nMeta Llama 2 70B (see note below)\\nNote\\nThe Meta Llama 2 (non-chat) models can only be used after being customized and after\\npurchasing Provisioned Throughput for them.\\nThe following code examples demonstrate how to create a Provisioned Throughput using the AWS \\nCLI and the Python SDK.\\nAWS CLI\\nCreate the Provisioned Throughput using the following command in the AWS CLI:\\naws bedrock create-provisioned-model-throughput \\n   --model-units 1 \\n   --commitment-duration SixMonths \\n   --provisioned-model-name test-model  \\n   --model-id arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2    \\nCreate Provisioned Throughput 465Amazon Bedrock User Guide\\nPython (Boto)\\nThe following example demonstrates how to create the Provisioned Throughput using Python:\\nimport boto3  \\nbedrock = boto3.client(service_name=\\'bedrock\\')\\nbedrock.create_provisioned_model_throughput( \\n    modelUnits=1, \\n    commitmentDuration=\\'SixMonths\\', \\n    provisionedModelName=\\'test-model\\',  \\n    modelId=\\'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2\\'  \\n   )                \\nRun inference using Provisioned Throughput\\nUse the InvokeModel or InvokeModelWithResponseStream operation to run inference using \\nProvisioned Throughput. Specify the provisioned model ARN as the modelId parameter.\\nThe following code examples show how to run inference for an Anthropic Anthropic Claude model \\nwith a Provisioned Throughput using the AWS CLI and Python. For information about the prompt \\nformat and inference parameters, see Inference parameters for foundation models.\\nAWS CLI\\nThe following example demonstrates how to run inference for an Anthropic Anthropic Claude \\nmodel with a Provisioned Throughput in the AWS CLI.\\naws bedrock-runtime invoke-model \\n    --model-id provisioned-model-arn  \\\\ \\n    --body \"{\\\\\"prompt\\\\\": \\\\\"\\\\n\\\\nHuman:  story of two dogs \\\\n\\\\nAssistant:\\\\\"}\" invoke-\\nmodel-output.txt\\nPython (Boto)\\nThe following example demonstrates how to run inference for an Anthropic Anthropic Claude \\nmodel with a Provisioned Throughput using Python:\\nimport boto3\\nimport json\\nbedrock = boto3.client(service_name=\\'bedrock-runtime\\')\\nRun inference using Provisioned Throughput 466Amazon Bedrock User Guide\\nbody = json.dumps({\"prompt\": \"\\\\n\\\\nHuman: explain black holes to 8th graders \\\\n\\n\\\\nAssistant:\"})\\nmodelId = \\' provisioned-model-arn \\'\\naccept = \\'application/json\\'\\ncontentType = \\'application/json\\'\\nresponse = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, \\n contentType=contentType)\\nresponse_body = json.loads(response.get(\\'body\\').read())\\n# text\\nprint(response_body.get(\\'results\\')[0].get(\\'outputText\\'))\\n# embedding\\nprint(response_body.get(\\'embedding\\'))      \\nUpdate Provisioned Throughput\\nUse the  UpdateProvisionedModelThroughput operation to update the speciﬁed Provisioned \\nThroughput.\\nThe following code examples demonstrate how to update a Provisioned Throughput using the AWS \\nCLI and Python.\\nAWS CLI\\nUpdate the Provisioned Throughput using the following command in the AWS CLI:\\naws bedrock update-provisioned-model-throughput\\n--provisioned-model-id provisioned-model-arn | provisioned-model-name  \\n--model-arn custom-model-arn | foundation-model-arn\\nPython (Boto)\\nThe following example demonstrates how to update the Provisioned Throughput using Python:\\nimport boto3  \\nbedrock = boto3.client(service_name=\\'bedrock\\')\\nbedrock.update_provisioned_model_throughput( \\nUpdate Provisioned Throughput 467Amazon Bedrock User Guide\\n    provisionedModelName=\\' provisioned-model-arn | provisioned-model-name \\' \\n    modelArn=\\' custom-model-arn | foundation-model-arn \\'  \\n)       \\nGet Provisioned Throughput\\nUse the GetProvisionedModelThroughput operation to retrieve information about the speciﬁed \\nProvisioned Throughput.\\nThe following code examples demonstrates how to retrieve information using the AWS CLI and \\nPython.\\nAWS CLI\\nRetrieve information about the Provisioned Throughput using the following command in the \\nAWS CLI:\\naws bedrock get-provisioned-model-throughput  \\n--provisioned-model-id provisioned-model-arn | provisioned-model-name\\nPython (Boto)\\nThe following example demonstrates how to retrieve information about the Provisioned \\nThroughput using Python:\\nimport boto3  \\nbedrock = boto3.client(service_name=\\'bedrock\\')\\nbedrock.get_provisioned_model_throughput( \\n    provisionedModelName=\\' my-provisioned-model-arn | provisioned model name \\'  \\n)                    \\nDelete Provisioned Throughput\\nUse the  DeleteProvisionedModelThroughput operation to delete the speciﬁed provisioned \\nthroughput.\\nThe following code examples demonstrate how to delete a Provisioned Throughput using the AWS \\nCLI and Python.\\nGet Provisioned Throughput 468Amazon Bedrock User Guide\\nAWS CLI\\nDelete the Provisioned Throughput using the following command in the AWS CLI:\\naws bedrock delete-provisioned-model-throughput  \\n  --provisioned-model-id provisioned-model-arn | provisioned-model-name\\nPython (Boto)\\nThe following example demonstrates how to delete the Provisioned Throughput using Python:\\nimport boto3  \\nbedrock = boto3.client(service_name=\\'bedrock\\')\\nbedrock.delete_provisioned_model_throughput( \\n    provisionedModelName=\\' my-provisioned-model-arn | provisioned model name \\'\\n)                    \\nList Provisioned Throughput resources\\nUse the  ListProvisionedModelThroughputs operation to list the Provisioned Throughput resources \\nthat you have deﬁned.\\nThe following code examples demonstrate how to list the Provisioned Throughput resources using \\nthe AWS CLI and Python.\\nAWS CLI\\nList the Provisioned Throughput resources using the following command in the AWS CLI:\\naws bedrock list-provisioned-model-throughputs\\nPython (Boto)\\nThe following example demonstrates how to list the Provisioned Throughput resources using \\nPython:\\nimport boto3  \\nbedrock = boto3.client(service_name=\\'bedrock\\')\\nList Provisioned Throughput resources 469Amazon Bedrock User Guide\\nbedrock.list_provisioned_model_throughputs()       \\nList Provisioned Throughput resources 470Amazon Bedrock User Guide\\nTag resources\\nTo help you manage your Amazon Bedrock resources, you can assign metadata to each resource as \\ntags. A tag is a label that you assign to an AWS resource. Each tag consists of a key and a value.\\nTags enable you to categorize your AWS resources in diﬀerent ways, for example, by purpose, \\nowner, or application. Tags help you to do the following:\\n•Identify and organize your AWS resources. Many AWS resources support tagging, so you can \\nassign the same tag to resources in diﬀerent services to indicate that the resources are the same.\\n•Allocate costs. You activate tags on the AWS Billing and Cost Management dashboard. AWS uses \\nthe tags to categorize your costs and deliver a monthly cost allocation report to you. For more \\ninformation, see Use cost allocation tags in the AWS Billing and Cost Management User Guide.\\n•Control access to your resources. You can use tags with Amazon Bedrock to create policies to \\ncontrol access to Amazon Bedrock resources. These policies can be attached to an IAM role or \\nuser to enable tag-based access control.\\nThe Amazon Bedrock resources that you can tag are:\\n•Custom models\\n•Model customization jobs\\n•Provisioned models\\n•Batch inference jobs (API only)\\n•Agents\\n•Agent aliases\\n•Knowledge bases\\n•Model evaluations (console only)\\nTopics\\n•Use the console\\n•Use the API\\n•Best practices and restrictions\\n471Amazon Bedrock User Guide\\nUse the console\\nYou can add, modify, and remove tags at any time while creating or editing a supported resource.\\nUse the API\\nTo carry out tagging operations, you need the Amazon Resource Name (ARN) of the resource \\non which you want to carry out a tagging operation. There are two sets of tagging operations, \\ndepending on the resource for which you are adding or managing tags.\\n1.The following resources use the Amazon Bedrock TagResource, UntagResource, and\\nListTagsForResource operations.\\n•Custom models\\n•Model customization jobs\\n•Provisioned models\\n•Batch inference jobs\\n2.The following resources use the Agents for Amazon Bedrock TagResource, UntagResource, and\\nListTagsForResource operations.\\n•Agents\\n•Agent aliases\\n•Knowledge bases\\nTo add tags to a resource, send a Amazon Bedrock TagResource or Agents for Amazon Bedrock\\nTagResource request.\\nTo untag a resource, send an UntagResource or UntagResource request.\\nTo list the tags for a resource, send a ListTagsForResource or ListTagsForResource request.\\nSelect a tab to see code examples in an interface or language.\\nAWS CLI\\nAdd two tags to an agent. Separate key/value pairs with a space.\\naws bedrock-agent tag-resource \\\\ \\n    --resource-arn \"arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345\" \\\\ \\nUse the console 472Amazon Bedrock User Guide\\n    --tags key=department,value=billing key=facing,value=internal\\nRemove the tags from the agent. Separate keys with a space.\\naws bedrock-agent untag-resource \\\\ \\n    --resource-arn \"arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345\" \\\\ \\n    --tag-keys key=department facing\\nList the tags for the agent.\\naws bedrock-agent list-tags-for-resource \\\\ \\n    --resource-arn \"arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345\"\\nPython (Boto)\\nAdd two tags to an agent.\\nimport boto3\\nbedrock = boto3.client(service_name=\\'bedrock-agent\\')\\ntags = [ \\n    { \\n        \\'key\\': \\'department\\', \\n        \\'value\\': \\'billing\\' \\n    }, \\n    { \\n        \\'key\\': \\'facing\\', \\n        \\'value\\': \\'internal\\' \\n    }\\n]\\nbedrock.tag_resource(resourceArn=\\'arn:aws:bedrock:us-east-1:123456789012:agent/\\nAGENT12345\\', tags=tags)\\nRemove the tags from the agent.\\nbedrock.untag_resource( \\n    resourceArn=\\'arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345\\',  \\n    tagKeys=[\\'department\\', \\'facing\\']\\n)\\nUse the API 473Amazon Bedrock User Guide\\nList the tags for the agent.\\nbedrock.list_tags_for_resource(resourceArn=\\'arn:aws:bedrock:us-\\neast-1:123456789012:agent/AGENT12345\\')\\nBest practices and restrictions\\nFor best practices and restrictions on tagging, see Tagging your AWS resources.\\nBest practices and restrictions 474Amazon Bedrock User Guide\\nAmazon Titan Models\\nAmazon Titan foundation models (FMs) are a family of FMs pretrained by AWS on large datasets, \\nmaking them powerful, general-purpose models built to support a variety of use cases. Use them \\nas-is or privately customize them with your own data.\\nAmazon Titan supports the following models for Amazon Bedrock.\\n•Amazon Titan Text\\n•Amazon Titan Embeddings G1 - Text\\n•Amazon Titan Multimodal Embeddings G1\\n•Amazon Titan Image Generator G1 (preview)\\nNote\\nAmazon Titan Image Generator G1 is in public preview release.\\nTopics\\n•Amazon Titan Text models\\n•Amazon Titan Embeddings G1 - Text models\\n•Amazon Titan Multimodal Embeddings G1 model\\n•Amazon Titan Image Generator G1 model\\nAmazon Titan Text models\\nAmazon Titan text models include Amazon Titan Text G1 - Express and Amazon Titan Text G1 - \\nLite.\\nAmazon Titan Text G1 - Express\\nAmazon Titan Text G1 - Express is a large language model for text generation. It is useful for a wide \\nrange of advanced, general language tasks such as open-ended text generation and conversational \\nchat, as well as support within Retrieval Augmented Generation (RAG). At launch, the model is \\nAmazon Titan Text 475Amazon Bedrock User Guide\\noptimized for English, with multilingual support for more than 100 additional languages available \\nin preview.\\n•Model ID  – amazon.titan-text-express-v1\\n•Max tokens – 8K\\n•Languages  – English (GA), 100 additional languages (Preview)\\n•Supported use cases – Retrieval augmented generation, open-ended text generation, \\nbrainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, \\nchain of thought, rewrite, extraction, QnA, and chat.\\nAmazon Titan Text G1 - Lite\\nAmazon Titan Text G1 - Lite is a light weight eﬃcient model, ideal for ﬁne-tuning of English-\\nlanguage tasks, including like summarizations and copy writing, where customers want a smaller, \\nmore cost-eﬀective model that is also highly customizable.\\n•Model ID  – amazon.titan-text-lite-v1\\n•Max tokens – 4K\\n•Languages  – English\\n•Supported use cases – Open-ended text generation, brainstorming, summarizations, code \\ngeneration, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, \\nQnA, and chat.\\nAmazon Titan Text Model Customization\\nFor more information on customizing Amazon Titan text models, see the following pages.\\n•Prepare the datasets\\n•Amazon Titan text model customization hyperparameters\\nAmazon Titan Text Prompt Engineering Guidelines\\nAmazon Titan text models can be used in a wide variety of applications for diﬀerent use cases. \\nAmazon Titan Text models have prompt engineering guidelines for the following applications \\nincluding:\\nAmazon Titan Text G1 - Lite 476Amazon Bedrock User Guide\\n•Chatbot\\n•Text2SQL\\n•Function Calling\\n•RAG (Retrieval Augmented Generation)\\nFor more information on Amazon Titan Text prompt engineering guidelines, see Amazon Titan Text \\nPrompt Engineering Guidelines.\\nFor general prompt engineering guidelines, see Prompt Engineering Guidelines.\\nAWS AI Service Card - Amazon Titan Text\\nAI Service Cards provide transparency and document the intended use cases and fairness \\nconsiderations for our AWS AI services. AI Service Cards provide a single place to ﬁnd information \\non the intended use cases, responsible AI design choices, best practices, and performance for a set \\nof AI service use cases.\\nAmazon Titan Embeddings G1 - Text models\\nAmazon Titan Embeddings text models include Amazon Titan Embeddings G1 - Text G1.\\nText embeddings represent meaningful vector representations of unstructured text such as \\ndocuments, paragraphs, and sentences. You input a body of text and the output is a (1 x n) vector. \\nYou can use embedding vectors for a wide variety of applications.\\nThe Amazon Titan Embeddings G1 - Text model (amazon.titan-embed-text-v1 ). The Amazon \\nTitan Embeddings G1 - Text – Text v1.2 can intake up to 8k tokens and outputs a vector of 1,536 \\ndimensions. The model also works in 25+ diﬀerent languages. The model is optimized for text \\nretrieval tasks, but can also perform additional tasks, such as semantic similarity and clustering. \\nAmazon Titan Embeddings G1 - Text – Text v1.2 also supports long documents, however, for \\nretrieval tasks it is recommended to segment documents into logical segments (such as paragraphs \\nor sections). In line with our recommendation.\\nNote\\nTitan Embeddings G1 - Text model doesn\\'t support inference parameters such as\\nmaxTokenCount  or topP .\\nAmazon Titan Embeddings G1 - Text 477Amazon Bedrock User Guide\\nTo use the text or image embeddings models, use the Invoke Model  API operation with\\namazon.titan-embed-text-v1  or amazon.titan-embed-image-v1  as the model Id  and \\nretrieve the embedding object in the response.\\nTo see Jupyter notebook examples:\\n1. Sign in to the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/home.\\n2. From the left-side menu, choose Base models .\\n3. Scroll down and select the Amazon Titan Embeddings G1 - Text model\\n4. In the Amazon Titan Embeddings G1 - Text tab (depending on which model you chose), select\\nView example notebook to see example notebooks for embeddings.\\nFor more information on preparing your dataset for multimodal training, see Preparing your \\ndataset .\\nAmazon Titan Multimodal Embeddings G1 model\\nAmazon Titan Multimodal Embeddings G1 Generation 1 (G1) is a multimodal embeddings model \\nfor use cases like searching images by text, image, or a combination of text and image. Designed \\nfor high accuracy and fast responses, this model is an ideal choice for search and recommendations \\nuse cases.\\n•Model ID  – amazon.titan-embed-image-v1\\n•Max input text tokens – 128\\n•Languages  – English\\n•Max input image size – 5 MB\\n•Output vector size – 1,024 (default), 384, 256\\n•Inference types – On-Demand, Provisioned Throughput\\n•Supported use cases – image search, recommendations, and personalization\\nEmbedding length\\nSetting a custom embedding length is optional. The embedding default length is 1024 characters \\nwhich will work for most use cases. The embedding length can be set to 256, 384, or 1024 \\ncharacters. Larger embedding sizes create more detailed responses, but will also increase the \\nAmazon Titan Multimodal Embeddings G1 478Amazon Bedrock User Guide\\ncomputational time. Shorter embedding lengths are less detailed but will improve the response \\ntime.\\n    # EmbeddingConfig Shape \\n    { \\n     \\'outputEmbeddingLength\\': int // Optional, One of: [256, 384, 1024], default: 1024 \\n    } \\n     \\n    # Updated API Payload Example \\n    body = json.dumps({ \\n     \"inputText\": \"hi\", \\n     \"inputImage\": image_string, \\n     \"embeddingConfig\": {  \\n     \"outputEmbeddingLength\": 256 \\n     } \\n    }) \\n   \\nFinetuning\\n•Input to the Amazon Titan Multimodal Embeddings G1 ﬁnetuning is image-text pairs.\\n•Image formats: PNG, JPEG\\n•Input image size limit: 5 MB\\n•Image dimensions: min: 128 px, max: 4,096 px\\n•Max number of tokens in caption: 128\\n•Training dataset size range: 1000 - 500,000\\n•Validation dataset size range: 8 - 50,000\\n•Caption length in characters: 0 - 2,560\\n•Maximum total pixels per image: 2048*2048*3\\n•Aspect ratio (w/h): min: 0.25, max: 4\\nPreparing datasets\\nFor the training dataset, create a .jsonlﬁle with multiple JSON lines. Each JSON line contains \\nboth an image-ref  and caption attributes similar to Sagemaker Augmented Manifest format. A \\nvalidation dataset is required. Auto-captioning is not currently supported.\\nFinetuning 479Amazon Bedrock User Guide\\n   {\"image-ref\": \"s3://bucket-1/folder1/0001.png\", \"caption\": \"some text\"} \\n   {\"image-ref\": \"s3://bucket-1/folder2/0002.png\", \"caption\": \"some text\"} \\n   {\"image-ref\": \"s3://bucket-1/folder1/0003.png\", \"caption\": \"some text\"} \\n   \\nFor both the training and validation datasets, you will create .jsonlﬁles with multiple JSON lines.\\nThe Amazon S3 paths need to be in the same folders where you have provided permissions for \\nAmazon Bedrock to access the data by attaching an IAM policy to your Amazon Bedrock service \\nrole. For more information on granting an IAM policies for training data, see Grant custom jobs \\naccess to your training data.\\nHyperparameters\\nThese values can be adjusted for the Multimodal Embeddings model hyperparameters. The default \\nvalues will work well for most use cases.\\n•Learning rate - (min/max learning rate) – default: 5.00E-05, min: 5.00E-08, max: 1\\n•Batch size - Eﬀective batch size – default: 576, min: 256, max: 9,216\\n•Max epochs – default: \"auto\", min: 1, max: 100\\nAmazon Titan Image Generator G1 model\\nAmazon Titan Image Generator G1 is an image generation model. It generates images from text, \\nand allows users to upload and edit an existing image. Users can edit an image with a text prompt \\n(without a mask) or parts of an image with an image mask. You can extend the boundaries of an \\nimage with outpainting, and ﬁll in an image with inpainting. It can also generate variations of an \\nimage based on an optional text prompt. Amazon Titan Image Generator G1 Generator includes \\nwatermarking on the output ﬁles.\\nNote\\nAmazon Titan Image Generator G1 is currently in preview release. It is not recommended \\nfor production work. Some features may not perform as expected. Images and output data \\nmay produce less than accurate results.\\nHyperparameters 480Amazon Bedrock User Guide\\nFor more information on Amazon Titan Image Generator G1 prompt engineering guidelines, see\\nAmazon Titan Image Generator G1 Prompt Engineering Best Practices.\\n•Model ID  – amazon.titan-image-generator-v1\\n•Max input characters – 1,024 char\\n•Max input image size – 50 MB (only some speciﬁc resolutions are supported)\\n•Max image size using in/outpainting – 1,024 x 1,024 px\\n•Max image size using image variation – 4,096 x 4,096 px\\n•Languages  – English\\n•Output type – image\\n•Supported image types – JPEG, JPG, PNG\\n•Inference types – On-Demand, Provisioned Throughput\\n•Supported use cases – image generation, image editing, image variations\\nFeatures\\n•Text-to-image (T2I) generation – Input a text prompt and generate a new image as output. The \\ngenerated image captures the concepts described by the text prompt.\\n•Finetuning of a T2I model – Import several images to capture your own style and personalization \\nand then ﬁne tune the core T2I model. The ﬁne-tuned model generates images that follow the \\nstyle and personalization of a speciﬁc user.\\n•Image editing options – includes inpainting, outpainting, generating variations, and automatic \\nediting without an image mask.\\n•Inpainting – Uses an image and a segmentation mask as input (either from the user or estimated \\nby the model) and reconstructs the region within the mask. Use inpainting to remove masked \\nelements and replace them with background pixels.\\n•Outpainting – Uses an image and a segmentation mask as input (either from the user or \\nestimated by the model) and generates new pixels that seamlessly extend the region. Use \\nprecise outpainting to preserve the pixels of the masked image when extending the image to \\nthe boundaries. Use default outpainting to extend the pixels of the masked image to the image \\nboundaries based on segmentation settings.\\n•Image variation – Uses an image and an optional prompt as input. It generates a new image that \\npreserves the content of the input image, but variates its style and background.\\nFeatures 481Amazon Bedrock User Guide\\nNote\\nif you are using a ﬁne-tuned model, you cannot use inpainting or outpainting features of \\nthe API or the model.\\nParameters\\nFor information on Amazon Titan Image Generator G1 inference parameters, see Amazon Titan \\nImage Generator G1 inference parameters.\\nFine-tuning\\nFor more information on ﬁne-tuning the Amazon Titan Image Generator G1 model, see the \\nfollowing pages.\\n•Prepare the datasets\\n•Amazon Titan Image Generator G1 model customization hyperparameters\\nTitan Image Generator G1 ﬁne-tuning and pricing\\nThe model uses the following example formula to calculate the total price per job:\\nTotal Price = Steps * Batch size * Price per image seen\\nMinimum values (auto):\\n•Minimum steps (auto) - 500\\n•Minimum batch size - 8\\n•Default learning rate - 0.00001\\n•Price per image seen - 0.005\\nFine-tuning hyperparameter settings\\nSteps  – The number of times the model is exposed to each batch. There is no default step count \\nset. You must select a number between 10 - 40,000, or a String value of \"Auto.\"\\nStep settings - Auto – Amazon Bedrock determines a reasonable value based on training \\ninformation. Select this option to prioritize model performance over training cost. The number of \\nParameters 482Amazon Bedrock User Guide\\nsteps is determined automatically. This number will typically be between 1,000 and 8,000 based on \\nyour dataset. Job costs are impacted by the number of steps used to expose the model to the data. \\nRefer to the pricing examples section of pricing details to understand how job cost is calculated. \\n(See example table above to see how step count is related to number of images when Auto is \\nselected.)\\nStep settings - Custom – You can enter the number of steps you want Bedrock to expose your \\ncustom model to the training data. This value can be between 10 and 40,000. You can reduce the \\ncost per image produced by the model by using a lower step count value.\\nBatch size – The number of sample processed before model parameters are updated. This value is \\nbetween 8 and 192 and is a multiple of 8.\\nLearning rate  – The rate at which model parameters are updated after each batch of training data. \\nThis is a ﬂoat value between 0 and 1. The learning rate is set to 0.00001 by default.\\nFor more information on the ﬁne-tuning procedure, see Submit a model customization job.\\nOutput\\nTitan Image Generator G1 uses the output image size and quality to determine how an image is \\npriced. Titan Image Generator G1 has two pricing segments based on size: one for 512*512 images \\nand another for 1024*1024 images. Pricing is based on image size height*width, less than or equal \\nto 512*512 or greater than 512*512.\\nFor more information on Amazon Bedrock pricing, see Amazon Bedrock Pricing.\\nWatermark detection\\nNote\\nWatermark detection is in public preview release and will only detect a watermark \\ngenerated from Titan Image Generator G1. This feature is currently only available in the \\nPDX and IAD regions. Watermark detection is a highly accurate detection of the watermark \\ngenerated by Titan Image Generator G1. Images that are modiﬁed from the original image \\nmay produce less accurate detection results.\\nThis model adds an invisible watermark to all generated images to reduce the spread of \\nmisinformation, assist with copyright protection, and track content usage. In the future, a \\nOutput 483Amazon Bedrock User Guide\\nwatermark detection API will be available to help you conﬁrm whether an image was generated by \\nthe Titan Image Generator G1 model, which checks for the existence of this watermark.\\nYou can upload your image to detect if a watermark from Titan Image Generator G1 is present on \\nthe image. Use the console to detect a watermark from this model by following the below steps.\\nTo detect a watermark with Titan Image Generator G1:\\n1. Open the Amazon Bedrock console at Amazon Bedrock console\\n2. Select Overview from the navigation pane in Amazon Bedrock. Choose the Build and Test tab.\\n3. In the Safeguards  section, go to Watermark detection and choose View watermark \\ndetection.\\n4. Select Upload image and locate a ﬁle that is in JPG or PNG format. The maximum ﬁle size \\nallowed is 5 MB.\\n5. Once uploaded, a thumbnail of image is shown with the name, ﬁle size, and the last date \\nmodiﬁed. Select X to delete or replace image from the Upload section.\\n6. Select Analyze to begin watermark detection analysis.\\n7. The image is previewed under Results, and indicates if a watermark is detected with\\nWatermark detected below the image and a banner across the image. If no watermark is \\ndetected, the text below the image will say Watermark NOT detected.\\n8. To load the next image, select X in the thumbnail of the image in the Upload section and \\nchoose a new image to analyze.\\nPrompt Engineering Guidelines\\nMask prompt  – This algorithm classiﬁes pixels into concepts. The user can give a text prompt that \\nwill be used to classify the areas of the image to mask, based on the interpretation of the mask \\nprompt. The prompt option can interpret more complex prompts, and encode the mask into the \\nsegmentation algorithm.\\nImage mask  – You can also use an image mask to set the mask values. The image mask can be \\ncombined with prompt input for the mask to improve accuracy. The image mask ﬁle must conform \\nto the following parameters:\\n•Mask image values must be 0 (black) or 255 (white) for the mask image. The image mask area \\nwith the value of 0 will be regenerated with the image from the user prompt and/or input \\nimage.\\nPrompt Engineering Guidelines 484Amazon Bedrock User Guide\\n•The maskImage  ﬁeld must be a base64 encoded image string.\\n•Mask image must have the same dimensions as the input image (same height and width).\\n•Only PNG or JPG ﬁles can be used for the input image and the mask image.\\n•Mask image must only use black and white pixels values.\\n•Mask image can only use the RGB channels (alpha channel not supported).\\nFor more information on Amazon Titan Image Generator G1 prompt engineering, see Amazon \\nTitan Image Generator G1 Prompt Engineering Best Practices.\\nFor general prompt engineering guidelines, see Prompt Engineering Guidelines.\\nPrompt Engineering Guidelines 485Amazon Bedrock User Guide\\nSecurity in Amazon Bedrock\\nCloud security at AWS is the highest priority. As an AWS customer, you beneﬁt from data centers \\nand network architectures that are built to meet the requirements of the most security-sensitive \\norganizations.\\nSecurity is a shared responsibility between AWS and you. The shared responsibility model describes \\nthis as security of the cloud and security in the cloud:\\n•Security of the cloud – AWS is responsible for protecting the infrastructure that runs AWS \\nservices in the AWS Cloud. AWS also provides you with services that you can use securely. Third-\\nparty auditors regularly test and verify the eﬀectiveness of our security as part of the AWS \\nCompliance Programs. To learn about the compliance programs that apply to Amazon Bedrock, \\nsee AWS Services in Scope by Compliance Program.\\n•Security in the cloud – Your responsibility is determined by the AWS service that you use. You \\nare also responsible for other factors including the sensitivity of your data, your company’s \\nrequirements, and applicable laws and regulations.\\nThis documentation helps you understand how to apply the shared responsibility model when \\nusing Amazon Bedrock. The following topics show you how to conﬁgure Amazon Bedrock to meet \\nyour security and compliance objectives. You also learn how to use other AWS services that help \\nyou to monitor and secure your Amazon Bedrock resources.\\nTopics\\n•Data protection\\n•Identity and access management for Amazon Bedrock\\n•Compliance validation for Amazon Bedrock\\n•Incident response in Amazon Bedrock\\n•Resilience in Amazon Bedrock\\n•Infrastructure security in Amazon Bedrock\\n•Cross-service confused deputy prevention\\n•Conﬁguration and vulnerability analysis in Amazon Bedrock\\n•Use interface VPC endpoints (AWS PrivateLink)\\n486Amazon Bedrock User Guide\\nData protection\\nThe AWS shared responsibility model applies to data protection in Amazon Bedrock. As described \\nin this model, AWS is responsible for protecting the global infrastructure that runs all of the \\nAWS Cloud. You are responsible for maintaining control over your content that is hosted on this \\ninfrastructure. You are also responsible for the security conﬁguration and management tasks for \\nthe AWS services that you use. For more information about data privacy, see the Data Privacy FAQ.\\nFor information about data protection in Europe, see the AWS Shared Responsibility Model and \\nGDPR  blog post on the AWS Security Blog.\\nFor data protection purposes, we recommend that you protect AWS account credentials and set \\nup individual users with AWS IAM Identity Center or AWS Identity and Access Management (IAM). \\nThat way, each user is given only the permissions necessary to fulﬁll their job duties. We also \\nrecommend that you secure your data in the following ways:\\n•Use multi-factor authentication (MFA) with each account.\\n•Use SSL/TLS to communicate with AWS resources. We require TLS 1.2 and recommend TLS 1.3.\\n•Set up API and user activity logging with AWS CloudTrail.\\n•Use AWS encryption solutions, along with all default security controls within AWS services.\\n•Use advanced managed security services such as Amazon Macie, which assists in discovering and \\nsecuring sensitive data that is stored in Amazon S3.\\n•If you require FIPS 140-2 validated cryptographic modules when accessing AWS through a \\ncommand line interface or an API, use a FIPS endpoint. For more information about the available \\nFIPS endpoints, see Federal Information Processing Standard (FIPS) 140-2.\\nWe strongly recommend that you never put conﬁdential or sensitive information, such as your \\ncustomers\\' email addresses, into tags or free-form text ﬁelds such as a Name  ﬁeld. This includes \\nwhen you work with Amazon Bedrock or other AWS services using the console, API, AWS CLI, or \\nAWS SDKs. Any data that you enter into tags or free-form text ﬁelds used for names may be used \\nfor billing or diagnostic logs. If you provide a URL to an external server, we strongly recommend \\nthat you do not include credentials information in the URL to validate your request to that server.\\nData protection in Amazon Bedrock\\nAmazon Bedrock doesn\\'t use your prompts and continuations to train any AWS models or \\ndistribute them to third parties.\\nData protection 487Amazon Bedrock User Guide\\nEach model provider has an escrow account that they upload their models to. The Amazon Bedrock \\ninference account has permissions to call these models, but the escrow accounts themselves don\\'t \\nhave outbound permissions to Amazon Bedrock accounts. Additionally, model providers don\\'t have \\naccess to Amazon Bedrock logs or access to customer prompts and continuations.\\nAmazon Bedrock doesn’t store or log your data in its service logs.\\nData protection in Amazon Bedrock model customization\\nYour training data isn\\'t used to train the base Titan models or distributed to third parties. Other \\nusage data, such as usage timestamps, logged account IDs, and other information logged by the \\nservice, is also not used to train the models.\\nAmazon Bedrock uses the ﬁne tuning data you provide only for ﬁne tuning an Amazon Bedrock \\nfoundation model. Amazon Bedrock doesn\\'t use ﬁne tuning data for any other purpose, such as \\ntraining base foundation models.\\nBedrock uses your training data with the CreateModelCustomizationJob action, or with the console, \\nto create a custom model which is a ﬁne tuned version of an Amazon Bedrock foundational model. \\nYour custom models are managed and stored by AWS. By default, custom models are encrypted \\nwith AWS Key Management Service keys that AWS owns, but you can use your own AWS KMS keys \\nto encrypt your custom models. You encrypt a custom model when you submit a ﬁne tuning job \\nwith the console or programmatically with the CreateModelCustomizationJob  action.\\nNone of the training or validation data you provide for ﬁne tuning is stored in Amazon Bedrock \\naccounts, once the ﬁne tuning job completes. During training, your data exists in AWS Service \\nManagement Connector instance memory, but is encrypted on these machines using an XTS-\\nAES-256 cipher that is implemented on a hardware module, on the instance itself.\\nWe don\\'t recommend using conﬁdential data to train a custom model as the model might generate \\ninference responses based on that conﬁdential data. If you use conﬁdential data to train a custom \\nmodel, the only way to prevent responses based on that data is to delete the custom model, \\nremove the conﬁdential data from your training dataset, and retrain the custom model.\\nCustom model metadata (name and Amazon Resource Name) and a provisioned model\\'s metadata \\nis stored in an Amazon DynamoDB table that is encrypted with a key that the Amazon Bedrock \\nservice owns.\\nTopics\\n•Data encryption\\nData protection 488Amazon Bedrock User Guide\\n•Protect your data using Amazon VPC and AWS PrivateLink\\nData encryption\\nAmazon Bedrock uses encryption to protect data at rest and data in transit.\\nTopics\\n•Encryption in transit\\n•Encryption at rest\\n•Key management\\n•Encryption of model customization jobs and artifacts\\n•Encryption of agent resources\\n•Encryption of knowledge base resources\\nEncryption in transit\\nWithin AWS, all inter-network data in transit supports TLS 1.2 encryption.\\nRequests to the Amazon Bedrock API and console are made over a secure (SSL) connection. You \\npass AWS Identity and Access Management (IAM) roles to Amazon Bedrock to provide permissions \\nto access resources on your behalf for training and deployment.\\nEncryption at rest\\nAmazon Bedrock provides Encryption of model customization jobs and artifacts at rest.\\nKey management\\nUse the AWS Key Management Service to manage the keys that you use to encrypt your resources. \\nFor more information, see AWS Key Management Service concepts. You can encrypt the following \\nresources with a KMS key.\\n•Through Amazon Bedrock\\n•Model customization jobs and their output custom models – During job creation in the console \\nor by specifying the customModelKmsKeyId  ﬁeld in the CreateModelCustomizationJob API \\ncall.\\nData encryption 489Amazon Bedrock User Guide\\n•Agents – During agent creation in the console or by specifying the  ﬁeld in the CreateAgent API \\ncall.\\n•Data source ingestion jobs for knowledge bases – During knowledge base creation in the \\nconsole or by specifying the kmsKeyArn  ﬁeld in the CreateDataSource or UpdateDataSource\\nAPI call.\\n•Vector stores in Amazon OpenSearch Service – During vector store creation. For more \\ninformation, see Creating, listing, and deleting Amazon OpenSearch Service collections and\\nEncryption of data at rest for Amazon OpenSearch Service.\\n•Through Amazon S3 – For more information, see Using server-side encryption with AWS KMS \\nkeys (SSE-KMS).\\n•Training, validation, and output data for model customization\\n•Data sources for knowledge bases\\n•Through AWS Secrets Manager – For more information, see Secret encryption and decryption in \\nAWS Secrets Manager\\n•Vector stores for third-party models\\nAfter you encrypt a resource, you can ﬁnd the ARN of the KMS key by selecting a resource and \\nviewing its Details  in the console or by using the following Get API calls.\\n•GetModelCustomizationJob\\n•GetAgent\\n•GetIngestionJob\\nEncryption of model customization jobs and artifacts\\nBy default, Amazon Bedrock encrypts the following model artifacts from your model customization \\njobs with an AWS managed key.\\n•The model customization job\\n•The output ﬁles (training and validation metrics) from the model customization job\\n•The resulting custom model\\nData encryption 490Amazon Bedrock User Guide\\nOptionally, you can encrypt the model artifacts by creating a customer managed key. For more \\ninformation about AWS KMS keys, see Customer managed keys in the AWS Key Management \\nService Developer Guide. To use a customer managed key, carry out the following steps.\\n1.Create a customer managed key with the AWS Key Management Service.\\n2.Attach a resource-based policy with permissions for the speciﬁed-roles to create or use custom \\nmodels.\\nTopics\\n•Create a customer managed key\\n•Create a key policy and attach it to the customer managed key\\n•Encryption of training, validation, and output data\\nCreate a customer managed key\\nFirst ensure that you have CreateKey  permissions. Then follow the steps at Creating keys to \\ncreate a customer managed key either in the AWS KMS console or the CreateKey API operation. \\nMake sure to create a symmetric encryption key.\\nCreation of the key returns an Arn for the key that you can use as the customModelKmsKeyId\\nwhen submitting a model customization job.\\nCreate a key policy and attach it to the customer managed key\\nAttach the following resource-based policy to the KMS key by following the steps at Creating a key \\npolicy. The policy contains two statements.\\n1.Permissions for a role to encrypt model customization artifacts. Add ARNs of custom model \\nbuilder roles to the Principal  ﬁeld.\\n2.Permissions for a role to use a custom model in inference. Add ARNs of custom model user roles \\nto the Principal  ﬁeld.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Id\": \"KMS Key Policy\", \\n    \"Statement\": [ \\n        { \\nData encryption 491Amazon Bedrock User Guide\\n            \"Sid\": \" Permissions for custom model builders \", \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"AWS\": \"arn:aws:iam:: account-id :user/role\" \\n            }, \\n            \"Action\": [ \\n                \"kms:Decrypt\", \\n                \"kms:GenerateDataKey\", \\n                \"kms:DescribeKey\", \\n                \"kms:CreateGrant\" \\n            ], \\n            \"Resource\": \"*\" \\n        }, \\n        { \\n            \"Sid\": \" Permissions for custom model users \", \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"AWS\": \"arn:aws:iam:: account-id :user/role\" \\n            }, \\n            \"Action\": \"kms:Decrypt\", \\n            \"Resource\": \"*\" \\n        }       \\n}\\nEncryption of training, validation, and output data\\nWhen you use Amazon Bedrock to run a model customization job, you store the input (training/\\nvalidation data) ﬁles in your Amazon S3 bucket. When the job completes, Amazon Bedrock stores \\nthe output metrics ﬁles in the S3 bucket that you specifed when creating the job and the resulting \\ncustom model artifacts in an Amazon S3 bucket controlled by AWS.\\nThe input and output ﬁles are encrypted with Amazon S3 SSE-S3 server-side encryption by default, \\nusing an AWS managed key. This type of key is created, managed, and used on your behalf by AWS.\\nYou can instead choose to encrypt these ﬁles with a customer managed key  that you create, own, \\nand manage yourself. Refer to the preceding sections and the following links to learn how to create \\ncustomer managed keys and key policies.\\n•To learn more about Amazon S3 SSE-S3 server-side encryption, see Using server-side encryption \\nwith Amazon S3 managed keys (SSE-S3)\\n•To learn more about customer managed keys for encrypting S3 objects, see Using server-side \\nencryption with AWS KMS keys (SSE-KMS)\\nData encryption 492Amazon Bedrock User Guide\\nEncryption of agent resources\\nAmazon Bedrock encrypts your agent\\'s session information. By default, Amazon Bedrock encrypts \\nthis data using an AWS managed key. Optionally, you can encrypt the agent artifacts using a \\ncustomer managed key.\\nFor more information about AWS KMS keys, see Customer managed keys in the AWS Key \\nManagement Service Developer Guide.\\nIf you encrypt sessions with your agent with a custom KMS key, you must set up the following \\nidentity-based policy and resource-based policy to allow Amazon Bedrock to encrypt and decrypt \\nagent resources on your behalf.\\n1.Attach the following identity-based policy to an IAM role or user with permissions to make\\nInvokeAgent  calls. This policy validates the user making an InvokeAgent  call has KMS \\npermissions. Replace the region , account-id , agent-id , and key-id with the appropriate \\nvalues.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"Allow Amazon Bedrock to encrypt and decrypt Agent resources on \\n behalf of authorized users\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"kms:GenerateDataKey\", \\n                \"kms:Decrypt\" \\n            ], \\n            \"Resource\": \"arn:aws:kms: region:account-id :key/key-id\", \\n            \"Condition\": { \\n                \"StringEquals\": { \\n                    \"kms:EncryptionContext:aws:bedrock:arn\": \\n \"arn:aws:bedrock: region:account-id :agent/agent-id \" \\n                } \\n            } \\n        } \\n    ]\\n}\\nData encryption 493Amazon Bedrock User Guide\\n2.Attach the following resource-based policy to your KMS key. Change the scope of the \\npermissions as necessary. Replace the region , account-id , agent-id , and key-id  with the \\nappropriate values.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"Allows account root to modify the KMS key, not used by Amazon \\n Bedrock. Change it as per your permission requirements.\", \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"AWS\": \"arn:aws:iam:: account-id :root\" \\n            }, \\n            \"Action\": \"kms:*\", \\n            \"Resource\": \"arn:aws:kms: region:account-id :key/key-id\" \\n        }, \\n        { \\n            \"Sid\": \"Allow Amazon Bedrock to encrypt and decrypt Agent resources on \\n behalf of authorized users\", \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"Service\": \"bedrock.amazonaws.com\" \\n            }, \\n            \"Action\": [ \\n                \"kms:GenerateDataKey\", \\n                \"kms:Decrypt\" \\n            ], \\n            \"Resource\": \"arn:aws:kms: region:account-id :key/key-id\", \\n            \"Condition\": { \\n                \"StringEquals\": { \\n                    \"kms:EncryptionContext:aws:bedrock:arn\": \\n \"arn:aws:bedrock: region:account-id :agent/agent-id \" \\n                } \\n            } \\n        } \\n    ]\\n}\\nData encryption 494Amazon Bedrock User Guide\\nEncryption of knowledge base resources\\nAmazon Bedrock encrypts resources related to your knowledge bases. By default, Amazon Bedrock \\nencrypts this data using an AWS managed key. Optionally, you can encrypt the model artifacts \\nusing a customer managed key.\\nEncryption with a KMS key can occur with the following processes:\\n•Transient data storage while ingesting your data sources\\n•Passing information to OpenSearch Service if you let Amazon Bedrock set up your vector \\ndatabase\\n•Querying a knowledge base\\nThe following resources used by your knowledge bases can be encrypted with a KMS key. If you \\nencrypt them, you need to add permissions to decrypt the KMS key.\\n•Data sources stored in an Amazon S3 bucket\\n•Third-party vector stores\\nFor more information about AWS KMS keys, see Customer managed keys in the AWS Key \\nManagement Service Developer Guide.\\nTopics\\n•Encryption of transient data storage during data ingestion\\n•Encryption of information passed to Amazon OpenSearch Service\\n•Encryption of knowledge base retrieval\\n•Permissions to decrypt your AWS KMS key for your data sources in Amazon S3\\n•Permissions to decrypt an AWS Secrets Manager secret for the vector store containing your \\nknowledge base\\nEncryption of transient data storage during data ingestion\\nWhen you set up a data ingestion job for your knowledge base, you can encrypt the job with a \\ncustom KMS key.\\nData encryption 495Amazon Bedrock User Guide\\nTo allow the creation of a AWS KMS key for transient data storage in the process of ingesting your \\ndata source, attach the following policy to your Amazon Bedrock service role. Replace the region ,\\naccount-id , and key-id with the appropriate values.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n          \"Effect\": \"Allow\", \\n          \"Action\": [ \\n              \"kms:GenerateDataKey\", \\n              \"kms:Decrypt\" \\n          ], \\n          \"Resource\": [ \\n              \"arn:aws:kms: region:account-id :key/key-id\" \\n          ] \\n        } \\n    ]\\n}\\nEncryption of information passed to Amazon OpenSearch Service\\nIf you opt to let Amazon Bedrock create a vector store in Amazon OpenSearch Service for your \\nknowledge base, Amazon Bedrock can pass a KMS key that you choose to Amazon OpenSearch \\nService for encryption. To learn more about encryption in Amazon OpenSearch Service, see\\nEncryption in Amazon OpenSearch Service.\\nEncryption of knowledge base retrieval\\nYou can encrypt sessions in which you generate responses from querying a knowledge base \\nwith a KMS key. To do so, include the ARN of a KMS key in the kmsKeyArn  ﬁeld when making a\\nRetrieveAndGenerate request. Attach the following policy, replacing the values appropriately to \\nallow Amazon Bedrock to encrypt the session context.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"Service\": \"bedrock.amazonaws.com\" \\n            }, \\nData encryption 496Amazon Bedrock User Guide\\n            \"Action\": [ \\n                \"kms:GenerateDataKey\",  \\n                \"kms:Decrypt\" \\n            ], \\n            \"Resource\": \"arn:aws:kms: region:account-id :key/key-id\\n        } \\n    ]\\n}\\nPermissions to decrypt your AWS KMS key for your data sources in Amazon S3\\nYou store the data sources for your knowledge base in your Amazon S3 bucket. To encrypt these \\ndocuments at rest, you can use the Amazon S3 SSE-S3 server-side encryption option. With this \\noption, objects are encrypted with service keys managed by the Amazon S3 service.\\nFor more information, see Protecting data using server-side encryption with Amazon S3-managed \\nencryption keys (SSE-S3) in the Amazon Simple Storage Service User Guide.\\nIf you encrypted your data sources in Amazon S3 with a custom AWS KMS key, attach the following \\npolicy to your Amazon Bedrock service role to allow Amazon Bedrock to decrypt your key. Replace\\nregion  and account-id  with the region and account ID to which the key belongs. Replace key-\\nid with the ID of your AWS KMS key.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Effect\": \"Allow\", \\n        \"Action\": [ \\n            \"KMS:Decrypt\", \\n        ], \\n        \"Resource\": [ \\n            \"arn:aws:kms: region:account-id :key/key-id\" \\n        ], \\n        \"Condition\": { \\n            \"StringEquals\": { \\n                \"kms:ViaService\": [ \\n                    \"s3. region.amazonaws.com\" \\n               ] \\n           } \\n        } \\n    }]\\n}\\nData encryption 497Amazon Bedrock User Guide\\nPermissions to decrypt an AWS Secrets Manager secret for the vector store containing your \\nknowledge base\\nIf the vector store containing your knowledge base is conﬁgured with an AWS Secrets Manager \\nsecret, you can encrypt the secret with a custom AWS KMS key by following the steps at Secret \\nencryption and decryption in AWS Secrets Manager.\\nIf you do so, you attach the following policy to your Amazon Bedrock service role to allow it to \\ndecrypt your key. Replace region  and account-id  with the region and account ID to which the \\nkey belongs. Replace key-id with the ID of your AWS KMS key.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"kms:Decrypt\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:kms: region:account-id :key/key-id\" \\n            ] \\n        } \\n    ]\\n}\\nProtect your data using Amazon VPC and AWS PrivateLink\\nTo control access to your data, we recommend that you use a virtual private cloud (VPC) with\\nAmazon VPC. Using a VPC protects your data and lets you monitor all network traﬃc in and out of \\nthe AWS job containers by using VPC Flow Logs. You can further protect your data by conﬁguring \\nyour VPC so that your data isn\\'t available over the internet and instead creating a VPC interface \\nendpoint with AWS PrivateLink to establish a private connection to your data.\\nFor an example of using VPC to protect data that you integrate with Amazon Bedrock see Protect \\nmodel customization jobs using a VPC .\\nUse interface VPC endpoints (AWS PrivateLink)\\nYou can use AWS PrivateLink to create a private connection between your VPC and Amazon \\nBedrock. You can access Amazon Bedrock as if it were in your VPC, without the use of an internet \\nUse Amazon VPC and AWS PrivateLink 498Amazon Bedrock User Guide\\ngateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC \\ndon\\'t need public IP addresses to access Amazon Bedrock.\\nYou establish this private connection by creating an interface endpoint, powered by AWS \\nPrivateLink. We create an endpoint network interface in each subnet that you enable for the \\ninterface endpoint. These are requester-managed network interfaces that serve as the entry point \\nfor traﬃc destined for Amazon Bedrock.\\nFor more information, see Access AWS services through AWS PrivateLink in the AWS PrivateLink \\nGuide .\\nConsiderations for Amazon Bedrock VPC endpoints\\nBefore you set up an interface endpoint for Amazon Bedrock, review Considerations  in the AWS \\nPrivateLink Guide .\\nAmazon Bedrock supports making the following API calls through VPC endpoints.\\nCategory Endpoint preﬁx\\nAmazon Bedrock Control Plane API actionsbedrock\\nAmazon Bedrock Runtime API actions bedrock-runtime\\nAgents for Amazon Bedrock Build-time API \\nactionsbedrock-agent\\nAgents for Amazon Bedrock Runtime API \\nactionsbedrock-agent-runtime\\nAvailability Zones\\nAmazon Bedrock and Agents for Amazon Bedrock endpoints are available in multiple Availability \\nZones.\\nCreate an interface endpoint for Amazon Bedrock\\nYou can create an interface endpoint for Amazon Bedrock using either the Amazon VPC console \\nor the AWS Command Line Interface (AWS CLI). For more information, see Create an interface \\nendpoint  in the AWS PrivateLink Guide.\\nUse Amazon VPC and AWS PrivateLink 499Amazon Bedrock User Guide\\nCreate an interface endpoint for Amazon Bedrock using any of the following service names:\\n•com.amazonaws. region.bedrock\\n•com.amazonaws. region.bedrock-runtime\\n•com.amazonaws. region.bedrock-agent\\n•com.amazonaws. region.bedrock-agent-runtime\\nAfter you create the endpoint, you have the option to enable a private DNS hostname. Enable \\nthis setting by selecting Enable Private DNS Name in the VPC console when you create the VPC \\nendpoint.\\nIf you enable private DNS for the interface endpoint, you can make API requests to Amazon \\nBedrock using its default Regional DNS name. The following examples show the format of the \\ndefault Regional DNS names.\\n•bedrock. region.amazonaws.com\\n•bedrock-runtime. region.amazonaws.com\\n•bedrock-agent. region.amazonaws.com\\n•bedrock-agent-runtime. region.amazonaws.com\\nCreate an endpoint policy for your interface endpoint\\nAn endpoint policy is an IAM resource that you can attach to an interface endpoint. The default \\nendpoint policy allows full access to Amazon Bedrock through the interface endpoint. To control \\nthe access allowed to Amazon Bedrock from your VPC, attach a custom endpoint policy to the \\ninterface endpoint.\\nAn endpoint policy speciﬁes the following information:\\n•The principals that can perform actions (AWS accounts, IAM users, and IAM roles).\\n•The actions that can be performed.\\n•The resources on which the actions can be performed.\\nFor more information, see Control access to services using endpoint policies in the AWS PrivateLink \\nGuide .\\nUse Amazon VPC and AWS PrivateLink 500Amazon Bedrock User Guide\\nExample: VPC endpoint policy for Amazon Bedrock actions\\nThe following is an example of a custom endpoint policy. When you attach this resource-based \\npolicy to your interface endpoint, it grants access to the listed Amazon Bedrock actions for all \\nprincipals on all resources.\\n{ \\n   \"Version\": \"2012-10-17\", \\n   \"Statement\": [ \\n      { \\n         \"Principal\": \"*\", \\n         \"Effect\": \"Allow\", \\n         \"Action\": [ \\n            \"bedrock:InvokeModel\", \\n            \"bedrock:InvokeModelWithResponseStream\" \\n         ], \\n         \"Resource\":\"*\" \\n      } \\n   ]\\n}\\nIdentity and access management for Amazon Bedrock\\nAWS Identity and Access Management (IAM) is an AWS service that helps an administrator securely \\ncontrol access to AWS resources. IAM administrators control who can be authenticated  (signed in) \\nand authorized  (have permissions) to use Amazon Bedrock resources. IAM is an AWS service that \\nyou can use with no additional charge.\\nTopics\\n•Audience\\n•Authenticating with identities\\n•Managing access using policies\\n•How Amazon Bedrock works with IAM\\n•Identity-based policy examples for Amazon Bedrock\\n•AWS managed policies for Amazon Bedrock\\n•Service roles\\n•Troubleshooting Amazon Bedrock identity and access\\nIdentity and access management 501Amazon Bedrock User Guide\\nAudience\\nHow you use AWS Identity and Access Management (IAM) diﬀers, depending on the work that you \\ndo in Amazon Bedrock.\\nService user – If you use the Amazon Bedrock service to do your job, then your administrator \\nprovides you with the credentials and permissions that you need. As you use more Amazon Bedrock \\nfeatures to do your work, you might need additional permissions. Understanding how access is \\nmanaged can help you request the right permissions from your administrator. If you cannot access \\na feature in Amazon Bedrock, see Troubleshooting Amazon Bedrock identity and access.\\nService administrator – If you\\'re in charge of Amazon Bedrock resources at your company, you \\nprobably have full access to Amazon Bedrock. It\\'s your job to determine which Amazon Bedrock \\nfeatures and resources your service users should access. You must then submit requests to your IAM \\nadministrator to change the permissions of your service users. Review the information on this page \\nto understand the basic concepts of IAM. To learn more about how your company can use IAM with \\nAmazon Bedrock, see How Amazon Bedrock works with IAM.\\nIAM administrator  – If you\\'re an IAM administrator, you might want to learn details about how \\nyou can write policies to manage access to Amazon Bedrock. To view example Amazon Bedrock \\nidentity-based policies that you can use in IAM, see Identity-based policy examples for Amazon \\nBedrock.\\nAuthenticating with identities\\nAuthentication is how you sign in to AWS using your identity credentials. You must be\\nauthenticated  (signed in to AWS) as the AWS account root user, as an IAM user, or by assuming an \\nIAM role.\\nYou can sign in to AWS as a federated identity by using credentials provided through an identity \\nsource. AWS IAM Identity Center (IAM Identity Center) users, your company\\'s single sign-on \\nauthentication, and your Google or Facebook credentials are examples of federated identities. \\nWhen you sign in as a federated identity, your administrator previously set up identity federation \\nusing IAM roles. When you access AWS by using federation, you are indirectly assuming a role.\\nDepending on the type of user you are, you can sign in to the AWS Management Console or the \\nAWS access portal. For more information about signing in to AWS, see How to sign in to your AWS \\naccount in the AWS Sign-In User Guide.\\nAudience 502Amazon Bedrock User Guide\\nIf you access AWS programmatically, AWS provides a software development kit (SDK) and a \\ncommand line interface (CLI) to cryptographically sign your requests by using your credentials. If \\nyou don\\'t use AWS tools, you must sign requests yourself. For more information about using the \\nrecommended method to sign requests yourself, see Signing AWS API requests in the IAM User \\nGuide .\\nRegardless of the authentication method that you use, you might be required to provide additional \\nsecurity information. For example, AWS recommends that you use multi-factor authentication \\n(MFA) to increase the security of your account. To learn more, see Multi-factor authentication in the\\nAWS IAM Identity Center User Guide and Using multi-factor authentication (MFA) in AWS in the IAM \\nUser Guide .\\nAWS account root user\\nWhen you create an AWS account, you begin with one sign-in identity that has complete access to \\nall AWS services and resources in the account. This identity is called the AWS account root user  and \\nis accessed by signing in with the email address and password that you used to create the account. \\nWe strongly recommend that you don\\'t use the root user for your everyday tasks. Safeguard your \\nroot user credentials and use them to perform the tasks that only the root user can perform. For \\nthe complete list of tasks that require you to sign in as the root user, see Tasks that require root \\nuser credentials in the IAM User Guide .\\nFederated identity\\nAs a best practice, require human users, including users that require administrator access, to use \\nfederation with an identity provider to access AWS services by using temporary credentials.\\nA federated identity  is a user from your enterprise user directory, a web identity provider, the AWS \\nDirectory Service, the Identity Center directory, or any user that accesses AWS services by using \\ncredentials provided through an identity source. When federated identities access AWS accounts, \\nthey assume roles, and the roles provide temporary credentials.\\nFor centralized access management, we recommend that you use AWS IAM Identity Center. You can \\ncreate users and groups in IAM Identity Center, or you can connect and synchronize to a set of users \\nand groups in your own identity source for use across all your AWS accounts and applications. For \\ninformation about IAM Identity Center, see What is IAM Identity Center? in the AWS IAM Identity \\nCenter User Guide .\\nAuthenticating with identities 503Amazon Bedrock User Guide\\nIAM users and groups\\nAn IAM user  is an identity within your AWS account that has speciﬁc permissions for a single person \\nor application. Where possible, we recommend relying on temporary credentials instead of creating \\nIAM users who have long-term credentials such as passwords and access keys. However, if you have \\nspeciﬁc use cases that require long-term credentials with IAM users, we recommend that you rotate \\naccess keys. For more information, see Rotate access keys regularly for use cases that require long-\\nterm credentials in the IAM User Guide .\\nAn IAM group  is an identity that speciﬁes a collection of IAM users. You can\\'t sign in as a group. You \\ncan use groups to specify permissions for multiple users at a time. Groups make permissions easier \\nto manage for large sets of users. For example, you could have a group named IAMAdmins  and give \\nthat group permissions to administer IAM resources.\\nUsers are diﬀerent from roles. A user is uniquely associated with one person or application, but \\na role is intended to be assumable by anyone who needs it. Users have permanent long-term \\ncredentials, but roles provide temporary credentials. To learn more, see When to create an IAM user \\n(instead of a role) in the IAM User Guide .\\nIAM roles\\nAn IAM role  is an identity within your AWS account that has speciﬁc permissions. It is similar to an \\nIAM user, but is not associated with a speciﬁc person. You can temporarily assume an IAM role in \\nthe AWS Management Console by switching roles. You can assume a role by calling an AWS CLI or \\nAWS API operation or by using a custom URL. For more information about methods for using roles, \\nsee Using IAM roles in the IAM User Guide .\\nIAM roles with temporary credentials are useful in the following situations:\\n•Federated user access – To assign permissions to a federated identity, you create a role \\nand deﬁne permissions for the role. When a federated identity authenticates, the identity \\nis associated with the role and is granted the permissions that are deﬁned by the role. For \\ninformation about roles for federation, see  Creating a role for a third-party Identity Provider\\nin the IAM User Guide . If you use IAM Identity Center, you conﬁgure a permission set. To control \\nwhat your identities can access after they authenticate, IAM Identity Center correlates the \\npermission set to a role in IAM. For information about permissions sets, see  Permission sets in \\nthe AWS IAM Identity Center User Guide.\\n•Temporary IAM user permissions – An IAM user or role can assume an IAM role to temporarily \\ntake on diﬀerent permissions for a speciﬁc task.\\nAuthenticating with identities 504Amazon Bedrock User Guide\\n•Cross-account access – You can use an IAM role to allow someone (a trusted principal) in a \\ndiﬀerent account to access resources in your account. Roles are the primary way to grant cross-\\naccount access. However, with some AWS services, you can attach a policy directly to a resource \\n(instead of using a role as a proxy). To learn the diﬀerence between roles and resource-based \\npolicies for cross-account access, see How IAM roles diﬀer from resource-based policies in the\\nIAM User Guide .\\n•Cross-service access – Some AWS services use features in other AWS services. For example, when \\nyou make a call in a service, it\\'s common for that service to run applications in Amazon EC2 or \\nstore objects in Amazon S3. A service might do this using the calling principal\\'s permissions, \\nusing a service role, or using a service-linked role.\\n•Forward access sessions (FAS) – When you use an IAM user or role to perform actions in \\nAWS, you are considered a principal. When you use some services, you might perform an \\naction that then initiates another action in a diﬀerent service. FAS uses the permissions of the \\nprincipal calling an AWS service, combined with the requesting AWS service to make requests \\nto downstream services. FAS requests are only made when a service receives a request that \\nrequires interactions with other AWS services or resources to complete. In this case, you must \\nhave permissions to perform both actions. For policy details when making FAS requests, see\\nForward access sessions.\\n•Service role – A service role is an IAM role that a service assumes to perform actions on your \\nbehalf. An IAM administrator can create, modify, and delete a service role from within IAM. For \\nmore information, see Creating a role to delegate permissions to an AWS service in the IAM \\nUser Guide .\\n•Service-linked role – A service-linked role is a type of service role that is linked to an AWS \\nservice. The service can assume the role to perform an action on your behalf. Service-linked \\nroles appear in your AWS account and are owned by the service. An IAM administrator can \\nview, but not edit the permissions for service-linked roles.\\n•Applications running on Amazon EC2 – You can use an IAM role to manage temporary \\ncredentials for applications that are running on an EC2 instance and making AWS CLI or AWS API \\nrequests. This is preferable to storing access keys within the EC2 instance. To assign an AWS role \\nto an EC2 instance and make it available to all of its applications, you create an instance proﬁle \\nthat is attached to the instance. An instance proﬁle contains the role and enables programs that \\nare running on the EC2 instance to get temporary credentials. For more information, see Using \\nan IAM role to grant permissions to applications running on Amazon EC2 instances in the IAM \\nUser Guide .\\nAuthenticating with identities 505Amazon Bedrock User Guide\\nTo learn whether to use IAM roles or IAM users, see When to create an IAM role (instead of a user)\\nin the IAM User Guide .\\nManaging access using policies\\nYou control access in AWS by creating policies and attaching them to AWS identities or resources. \\nA policy is an object in AWS that, when associated with an identity or resource, deﬁnes their \\npermissions. AWS evaluates these policies when a principal (user, root user, or role session) makes \\na request. Permissions in the policies determine whether the request is allowed or denied. Most \\npolicies are stored in AWS as JSON documents. For more information about the structure and \\ncontents of JSON policy documents, see Overview of JSON policies in the IAM User Guide .\\nAdministrators can use AWS JSON policies to specify who has access to what. That is, which\\nprincipal  can perform actions on what resources, and under what conditions.\\nBy default, users and roles have no permissions. To grant users permission to perform actions on \\nthe resources that they need, an IAM administrator can create IAM policies. The administrator can \\nthen add the IAM policies to roles, and users can assume the roles.\\nIAM policies deﬁne permissions for an action regardless of the method that you use to perform the \\noperation. For example, suppose that you have a policy that allows the iam:GetRole  action. A \\nuser with that policy can get role information from the AWS Management Console, the AWS CLI, or \\nthe AWS API.\\nIdentity-based policies\\nIdentity-based policies are JSON permissions policy documents that you can attach to an identity, \\nsuch as an IAM user, group of users, or role. These policies control what actions users and roles can \\nperform, on which resources, and under what conditions. To learn how to create an identity-based \\npolicy, see Creating IAM policies in the IAM User Guide .\\nIdentity-based policies can be further categorized as inline policies  or managed policies . Inline \\npolicies are embedded directly into a single user, group, or role. Managed policies are standalone \\npolicies that you can attach to multiple users, groups, and roles in your AWS account. Managed \\npolicies include AWS managed policies and customer managed policies. To learn how to choose \\nbetween a managed policy or an inline policy, see Choosing between managed policies and inline \\npolicies  in the IAM User Guide .\\nManaging access using policies 506Amazon Bedrock User Guide\\nResource-based policies\\nResource-based policies are JSON policy documents that you attach to a resource. Examples of \\nresource-based policies are IAM role trust policies  and Amazon S3 bucket policies . In services that \\nsupport resource-based policies, service administrators can use them to control access to a speciﬁc \\nresource. For the resource where the policy is attached, the policy deﬁnes what actions a speciﬁed \\nprincipal can perform on that resource and under what conditions. You must specify a principal\\nin a resource-based policy. Principals can include accounts, users, roles, federated users, or AWS \\nservices.\\nResource-based policies are inline policies that are located in that service. You can\\'t use AWS \\nmanaged policies from IAM in a resource-based policy.\\nAccess control lists (ACLs)\\nAccess control lists (ACLs) control which principals (account members, users, or roles) have \\npermissions to access a resource. ACLs are similar to resource-based policies, although they do not \\nuse the JSON policy document format.\\nAmazon S3, AWS WAF, and Amazon VPC are examples of services that support ACLs. To learn more \\nabout ACLs, see Access control list (ACL) overview in the Amazon Simple Storage Service Developer \\nGuide .\\nOther policy types\\nAWS supports additional, less-common policy types. These policy types can set the maximum \\npermissions granted to you by the more common policy types.\\n•Permissions boundaries – A permissions boundary is an advanced feature in which you set \\nthe maximum permissions that an identity-based policy can grant to an IAM entity (IAM user \\nor role). You can set a permissions boundary for an entity. The resulting permissions are the \\nintersection of an entity\\'s identity-based policies and its permissions boundaries. Resource-based \\npolicies that specify the user or role in the Principal  ﬁeld are not limited by the permissions \\nboundary. An explicit deny in any of these policies overrides the allow. For more information \\nabout permissions boundaries, see Permissions boundaries for IAM entities in the IAM User Guide .\\n•Service control policies (SCPs) – SCPs are JSON policies that specify the maximum permissions \\nfor an organization or organizational unit (OU) in AWS Organizations. AWS Organizations is a \\nservice for grouping and centrally managing multiple AWS accounts that your business owns. If \\nManaging access using policies 507Amazon Bedrock User Guide\\nyou enable all features in an organization, then you can apply service control policies (SCPs) to \\nany or all of your accounts. The SCP limits permissions for entities in member accounts, including \\neach AWS account root user. For more information about Organizations and SCPs, see How SCPs \\nwork in the AWS Organizations User Guide.\\n•Session policies  – Session policies are advanced policies that you pass as a parameter when you \\nprogrammatically create a temporary session for a role or federated user. The resulting session\\'s \\npermissions are the intersection of the user or role\\'s identity-based policies and the session \\npolicies. Permissions can also come from a resource-based policy. An explicit deny in any of these \\npolicies overrides the allow. For more information, see Session policies  in the IAM User Guide .\\nMultiple policy types\\nWhen multiple types of policies apply to a request, the resulting permissions are more complicated \\nto understand. To learn how AWS determines whether to allow a request when multiple policy \\ntypes are involved, see Policy evaluation logic in the IAM User Guide .\\nHow Amazon Bedrock works with IAM\\nBefore you use IAM to manage access to Amazon Bedrock, learn what IAM features are available to \\nuse with Amazon Bedrock.\\nIAM features you can use with Amazon Bedrock\\nIAM feature Amazon Bedrock support\\nIdentity-based policies Yes\\nResource-based policies No\\nPolicy actions Yes\\nPolicy resources Yes\\nPolicy condition keys Yes\\nACLs No\\nABAC (tags in policies) Yes\\nHow Amazon Bedrock works with IAM 508Amazon Bedrock User Guide\\nIAM feature Amazon Bedrock support\\nTemporary credentials Yes\\nPrincipal permissions Yes\\nService roles Yes\\nService-linked roles No\\nTo get a high-level view of how Amazon Bedrock and other AWS services work with most IAM \\nfeatures, see AWS services that work with IAM in the IAM User Guide .\\nIdentity-based policies for Amazon Bedrock\\nSupports identity-based policies Yes\\nIdentity-based policies are JSON permissions policy documents that you can attach to an identity, \\nsuch as an IAM user, group of users, or role. These policies control what actions users and roles can \\nperform, on which resources, and under what conditions. To learn how to create an identity-based \\npolicy, see Creating IAM policies in the IAM User Guide .\\nWith IAM identity-based policies, you can specify allowed or denied actions and resources as well \\nas the conditions under which actions are allowed or denied. You can\\'t specify the principal in an \\nidentity-based policy because it applies to the user or role to which it is attached. To learn about all \\nof the elements that you can use in a JSON policy, see IAM JSON policy elements reference in the\\nIAM User Guide .\\nIdentity-based policy examples for Amazon Bedrock\\nTo view examples of Amazon Bedrock identity-based policies, see Identity-based policy examples \\nfor Amazon Bedrock.\\nResource-based policies within Amazon Bedrock\\nSupports resource-based policies No\\nHow Amazon Bedrock works with IAM 509Amazon Bedrock User Guide\\nResource-based policies are JSON policy documents that you attach to a resource. Examples of \\nresource-based policies are IAM role trust policies  and Amazon S3 bucket policies . In services that \\nsupport resource-based policies, service administrators can use them to control access to a speciﬁc \\nresource. For the resource where the policy is attached, the policy deﬁnes what actions a speciﬁed \\nprincipal can perform on that resource and under what conditions. You must specify a principal\\nin a resource-based policy. Principals can include accounts, users, roles, federated users, or AWS \\nservices.\\nTo enable cross-account access, you can specify an entire account or IAM entities in another \\naccount as the principal in a resource-based policy. Adding a cross-account principal to a resource-\\nbased policy is only half of establishing the trust relationship. When the principal and the resource \\nare in diﬀerent AWS accounts, an IAM administrator in the trusted account must also grant \\nthe principal entity (user or role) permission to access the resource. They grant permission by \\nattaching an identity-based policy to the entity. However, if a resource-based policy grants access \\nto a principal in the same account, no additional identity-based policy is required. For more \\ninformation, see How IAM roles diﬀer from resource-based policies in the IAM User Guide .\\nPolicy actions for Amazon Bedrock\\nSupports policy actions Yes\\nAdministrators can use AWS JSON policies to specify who has access to what. That is, which\\nprincipal  can perform actions on what resources, and under what conditions.\\nThe Action element of a JSON policy describes the actions that you can use to allow or deny \\naccess in a policy. Policy actions usually have the same name as the associated AWS API operation. \\nThere are some exceptions, such as permission-only actions that don\\'t have a matching API \\noperation. There are also some operations that require multiple actions in a policy. These \\nadditional actions are called dependent actions .\\nInclude actions in a policy to grant permissions to perform the associated operation.\\nTo see a list of Amazon Bedrock actions, see Actions deﬁned by Amazon Bedrock  in the Service \\nAuthorization Reference.\\nPolicy actions in Amazon Bedrock use the following preﬁx before the action:\\nHow Amazon Bedrock works with IAM 510Amazon Bedrock User Guide\\nbedrock\\nTo specify multiple actions in a single statement, separate them with commas.\\n\"Action\": [ \\n   \"bedrock: action1\", \\n   \"bedrock: action2\"\\n]\\nTo view examples of Amazon Bedrock identity-based policies, see Identity-based policy examples \\nfor Amazon Bedrock.\\nPolicy resources for Amazon Bedrock\\nSupports policy resources Yes\\nAdministrators can use AWS JSON policies to specify who has access to what. That is, which\\nprincipal  can perform actions on what resources, and under what conditions.\\nThe Resource  JSON policy element speciﬁes the object or objects to which the action applies. \\nStatements must include either a Resource  or a NotResource  element. As a best practice, \\nspecify a resource using its Amazon Resource Name (ARN). You can do this for actions that support \\na speciﬁc resource type, known as resource-level permissions .\\nFor actions that don\\'t support resource-level permissions, such as listing operations, use a wildcard \\n(*) to indicate that the statement applies to all resources.\\n\"Resource\": \"*\"\\nTo see a list of Amazon Bedrock resource types and their ARNs, see Resources deﬁned by Amazon \\nBedrock  in the Service Authorization Reference. To learn with which actions you can specify the \\nARN of each resource, see Actions deﬁned by Amazon Bedrock .\\nSome Amazon Bedrock API actions support multiple resources. For example,\\nAssociateAgentKnowledgeBase accesses AGENT12345  and KB12345678 , so a principal must have \\nHow Amazon Bedrock works with IAM 511Amazon Bedrock User Guide\\npermissions to access both resources. To specify multiple resources in a single statement, separate \\nthe ARNs with commas.\\n\"Resource\": [ \\n   \"arn:aws:bedrock: aws-region :111122223333 :agent/AGENT12345 \", \\n   \"arn:aws:bedrock: aws-region :111122223333 :knowledge-base/ KB12345678 \"\\n]\\nTo view examples of Amazon Bedrock identity-based policies, see Identity-based policy examples \\nfor Amazon Bedrock.\\nPolicy condition keys for Amazon Bedrock\\nSupports service-speciﬁc policy condition keysYes\\nAdministrators can use AWS JSON policies to specify who has access to what. That is, which\\nprincipal  can perform actions on what resources, and under what conditions.\\nThe Condition  element (or Condition  block ) lets you specify conditions in which a statement \\nis in eﬀect. The Condition  element is optional. You can create conditional expressions that use\\ncondition operators, such as equals or less than, to match the condition in the policy with values in \\nthe request.\\nIf you specify multiple Condition  elements in a statement, or multiple keys in a single\\nCondition  element, AWS evaluates them using a logical AND operation. If you specify multiple \\nvalues for a single condition key, AWS evaluates the condition using a logical OR operation. All of \\nthe conditions must be met before the statement\\'s permissions are granted.\\nYou can also use placeholder variables when you specify conditions. For example, you can grant \\nan IAM user permission to access a resource only if it is tagged with their IAM user name. For more \\ninformation, see IAM policy elements: variables and tags in the IAM User Guide .\\nAWS supports global condition keys and service-speciﬁc condition keys. To see all AWS global \\ncondition keys, see AWS global condition context keys in the IAM User Guide .\\nTo see a list of Amazon Bedrock condition keys, see Condition Keys for Amazon Bedrock  in the\\nService Authorization Reference. To learn with which actions and resources you can use a condition \\nkey, see Actions deﬁned by Amazon Bedrock .\\nHow Amazon Bedrock works with IAM 512Amazon Bedrock User Guide\\nAll Amazon Bedrock actions support condition keys using Amazon Bedrock models as the resource.\\nTo view examples of Amazon Bedrock identity-based policies, see Identity-based policy examples \\nfor Amazon Bedrock.\\nACLs in Amazon Bedrock\\nSupports ACLs No\\nAccess control lists (ACLs) control which principals (account members, users, or roles) have \\npermissions to access a resource. ACLs are similar to resource-based policies, although they do not \\nuse the JSON policy document format.\\nABAC with Amazon Bedrock\\nSupports ABAC (tags in policies) Yes\\nAttribute-based access control (ABAC) is an authorization strategy that deﬁnes permissions based \\non attributes. In AWS, these attributes are called tags. You can attach tags to IAM entities (users or \\nroles) and to many AWS resources. Tagging entities and resources is the ﬁrst step of ABAC. Then \\nyou design ABAC policies to allow operations when the principal\\'s tag matches the tag on the \\nresource that they are trying to access.\\nABAC is helpful in environments that are growing rapidly and helps with situations where policy \\nmanagement becomes cumbersome.\\nTo control access based on tags, you provide tag information in the condition element of a policy \\nusing the aws:ResourceTag/ key-name , aws:RequestTag/ key-name , or aws:TagKeys\\ncondition keys.\\nIf a service supports all three condition keys for every resource type, then the value is Yes for the \\nservice. If a service supports all three condition keys for only some resource types, then the value is\\nPartial.\\nFor more information about ABAC, see What is ABAC? in the IAM User Guide . To view a tutorial with \\nsteps for setting up ABAC, see Use attribute-based access control (ABAC) in the IAM User Guide .\\nHow Amazon Bedrock works with IAM 513Amazon Bedrock User Guide\\nUsing temporary credentials with Amazon Bedrock\\nSupports temporary credentials Yes\\nSome AWS services don\\'t work when you sign in using temporary credentials. For additional \\ninformation, including which AWS services work with temporary credentials, see AWS services that \\nwork with IAM in the IAM User Guide .\\nYou are using temporary credentials if you sign in to the AWS Management Console using \\nany method except a user name and password. For example, when you access AWS using your \\ncompany\\'s single sign-on (SSO) link, that process automatically creates temporary credentials. You \\nalso automatically create temporary credentials when you sign in to the console as a user and then \\nswitch roles. For more information about switching roles, see Switching to a role (console) in the\\nIAM User Guide .\\nYou can manually create temporary credentials using the AWS CLI or AWS API. You can then use \\nthose temporary credentials to access AWS. AWS recommends that you dynamically generate \\ntemporary credentials instead of using long-term access keys. For more information, see\\nTemporary security credentials in IAM.\\nCross-service principal permissions for Amazon Bedrock\\nSupports forward access sessions (FAS) Yes\\nWhen you use an IAM user or role to perform actions in AWS, you are considered a principal. \\nWhen you use some services, you might perform an action that then initiates another action in a \\ndiﬀerent service. FAS uses the permissions of the principal calling an AWS service, combined with \\nthe requesting AWS service to make requests to downstream services. FAS requests are only made \\nwhen a service receives a request that requires interactions with other AWS services or resources to \\ncomplete. In this case, you must have permissions to perform both actions. For policy details when \\nmaking FAS requests, see Forward access sessions.\\nService roles for Amazon Bedrock\\nSupports service roles Yes\\nHow Amazon Bedrock works with IAM 514Amazon Bedrock User Guide\\nA service role is an IAM role that a service assumes to perform actions on your behalf. An IAM \\nadministrator can create, modify, and delete a service role from within IAM. For more information, \\nsee Creating a role to delegate permissions to an AWS service in the IAM User Guide .\\nWarning\\nChanging the permissions for a service role might break Amazon Bedrock functionality. Edit \\nservice roles only when Amazon Bedrock provides guidance to do so.\\nService-linked roles for Amazon Bedrock\\nSupports service-linked roles No\\nA service-linked role is a type of service role that is linked to an AWS service. The service can \\nassume the role to perform an action on your behalf. Service-linked roles appear in your AWS \\naccount and are owned by the service. An IAM administrator can view, but not edit the permissions \\nfor service-linked roles.\\nIdentity-based policy examples for Amazon Bedrock\\nBy default, users and roles don\\'t have permission to create or modify Amazon Bedrock resources. \\nThey also can\\'t perform tasks by using the AWS Management Console, AWS Command Line \\nInterface (AWS CLI), or AWS API. To grant users permission to perform actions on the resources \\nthat they need, an IAM administrator can create IAM policies. The administrator can then add the \\nIAM policies to roles, and users can assume the roles.\\nTo learn how to create an IAM identity-based policy by using these example JSON policy \\ndocuments, see Creating IAM policies in the IAM User Guide .\\nFor details about actions and resource types deﬁned by Amazon Bedrock, including the format of \\nthe ARNs for each of the resource types, see Actions, Resources, and Condition Keys for Amazon \\nBedrock  in the Service Authorization Reference.\\nTopics\\n•Policy best practices\\n•Use the Amazon Bedrock console\\nIdentity-based policy examples 515Amazon Bedrock User Guide\\n•Allow users to view their own permissions\\n•Allow access to third-party model subscriptions\\n•Deny access for inference on speciﬁc models\\n•Identity-based policy examples for Agents for Amazon Bedrock\\nPolicy best practices\\nIdentity-based policies determine whether someone can create, access, or delete Amazon Bedrock \\nresources in your account. These actions can incur costs for your AWS account. When you create or \\nedit identity-based policies, follow these guidelines and recommendations:\\n•Get started with AWS managed policies and move toward least-privilege permissions – To \\nget started granting permissions to your users and workloads, use the AWS managed policies\\nthat grant permissions for many common use cases. They are available in your AWS account. We \\nrecommend that you reduce permissions further by deﬁning AWS customer managed policies \\nthat are speciﬁc to your use cases. For more information, see AWS managed policies or AWS \\nmanaged policies for job functions in the IAM User Guide .\\n•Apply least-privilege permissions – When you set permissions with IAM policies, grant only the \\npermissions required to perform a task. You do this by deﬁning the actions that can be taken on \\nspeciﬁc resources under speciﬁc conditions, also known as least-privilege permissions . For more \\ninformation about using IAM to apply permissions, see  Policies and permissions in IAM in the\\nIAM User Guide .\\n•Use conditions in IAM policies to further restrict access – You can add a condition to your \\npolicies to limit access to actions and resources. For example, you can write a policy condition to \\nspecify that all requests must be sent using SSL. You can also use conditions to grant access to \\nservice actions if they are used through a speciﬁc AWS service, such as AWS CloudFormation. For \\nmore information, see  IAM JSON policy elements: Condition in the IAM User Guide .\\n•Use IAM Access Analyzer to validate your IAM policies to ensure secure and functional \\npermissions  – IAM Access Analyzer validates new and existing policies so that the policies \\nadhere to the IAM policy language (JSON) and IAM best practices. IAM Access Analyzer provides \\nmore than 100 policy checks and actionable recommendations to help you author secure and \\nfunctional policies. For more information, see IAM Access Analyzer policy validation in the IAM \\nUser Guide .\\n•Require multi-factor authentication (MFA) – If you have a scenario that requires IAM users \\nor a root user in your AWS account, turn on MFA for additional security. To require MFA when \\nIdentity-based policy examples 516Amazon Bedrock User Guide\\nAPI operations are called, add MFA conditions to your policies. For more information, see \\nConﬁguring MFA-protected API access in the IAM User Guide .\\nFor more information about best practices in IAM, see Security best practices in IAM in the IAM User \\nGuide .\\nUse the Amazon Bedrock console\\nTo access the Amazon Bedrock console, you must have a minimum set of permissions. These \\npermissions must allow you to list and view details about the Amazon Bedrock resources in your \\nAWS account. If you create an identity-based policy that is more restrictive than the minimum \\nrequired permissions, the console won\\'t function as intended for entities (users or roles) with that \\npolicy.\\nYou don\\'t need to allow minimum console permissions for users that are making calls only to the \\nAWS CLI or the AWS API. Instead, allow access to only the actions that match the API operation \\nthat they\\'re trying to perform.\\nTo provide access to the Amazon Bedrock console, attach the following policy to the roles or \\nentities that need access. A few of the actions in the policy are for use by the Amazon Bedrock \\nconsole only, so IAM might raise Invalid Action  errors. You can ignore these errors and choose\\nNext to complete the task.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"BedrockConsole\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [   \\n               \"bedrock:PutFoundationModelEntitlement\", \\n               \"bedrock:GetModelInvocationLoggingConfiguration\", \\n               \"bedrock:PutModelInvocationLoggingConfiguration\", \\n               \"bedrock:CreateFoundationModelAgreement\", \\n               \"bedrock:DeleteFoundationModelAgreement\", \\n               \"bedrock:ListFoundationModelAgreementOffers\", \\n               \"bedrock:GetUseCaseForModelAccess\", \\n               \"bedrock:PutUseCaseForModelAccess\", \\n               \"bedrock:ListFoundationModels\", \\n               \"bedrock:GetFoundationModel\", \\n               \"bedrock:InvokeModel\",  \\nIdentity-based policy examples 517Amazon Bedrock User Guide\\n               \"bedrock:InvokeModelWithResponseStream\",  \\n               \"bedrock:CreateModelCustomizationJob\",  \\n               \"bedrock:GetModelCustomizationJob\",  \\n               \"bedrock:GetFoundationModelAvailability\", \\n               \"bedrock:ListModelCustomizationJobs\",  \\n               \"bedrock:StopModelCustomizationJob\",  \\n               \"bedrock:GetCustomModel\",  \\n               \"bedrock:ListCustomModels\",  \\n               \"bedrock:DeleteCustomModel\", \\n               \"bedrock:CreateProvisionedModelThroughput\",  \\n               \"bedrock:UpdateProvisionedModelThroughput\",  \\n               \"bedrock:GetProvisionedModelThroughput\",  \\n               \"bedrock:ListProvisionedModelThroughputs\",  \\n               \"bedrock:DeleteProvisionedModelThroughput\",  \\n               \"bedrock:TagResource\",  \\n               \"bedrock:UntagResource\",  \\n               \"bedrock:ListTagsForResource\",  \\n               \"bedrock:CreateAgent\", \\n               \"bedrock:UpdateAgent\",  \\n               \"bedrock:GetAgent\",  \\n               \"bedrock:ListAgents\",  \\n               \"bedrock:DeleteAgent\", \\n               \"bedrock:CreateAgentActionGroup\",  \\n               \"bedrock:UpdateAgentActionGroup\",  \\n               \"bedrock:GetAgentActionGroup\",  \\n               \"bedrock:ListAgentActionGroups\",  \\n               \"bedrock:DeleteAgentActionGroup\", \\n               \"bedrock:GetAgentVersion\", \\n               \"bedrock:ListAgentVersions\",  \\n               \"bedrock:CreateAgentAlias\",  \\n               \"bedrock:UpdateAgentAlias\",                \\n               \"bedrock:GetAgentAlias\", \\n               \"bedrock:ListAgentAliases\", \\n               \"bedrock:DeleteAgentAlias\", \\n               \"bedrock:AssociateAgentKnowledgeBase\", \\n               \"bedrock:DisassociateAgentKnowledgeBase\", \\n               \"bedrock:GetKnowledgeBase\", \\n               \"bedrock:ListKnowledgeBases\", \\n               \"bedrock:PrepareAgent\", \\n               \"bedrock:InvokeAgent\",  \\n               \"bedrock:CreateKnowledgeBase\", \\n               \"bedrock:UpdateKnowledgeBase\", \\n               \"bedrock:GetKnowledgeBase\", \\n               \"bedrock:ListKnowledgeBases\", \\nIdentity-based policy examples 518Amazon Bedrock User Guide\\n               \"bedrock:DeleteKnowledgeBase\", \\n               \"bedrock:CreateDataSource\", \\n               \"bedrock:UpdateDataSource\", \\n               \"bedrock:GetDataSource\", \\n               \"bedrock:ListDataSources\", \\n               \"bedrock:DeleteDataSource\", \\n               \"bedrock:CreateIngestionJob\", \\n               \"bedrock:GetIngestionJob\", \\n               \"bedrock:ListIngestionJobs\", \\n               \"bedrock:Retrieve\", \\n               \"bedrock:RetrieveAndGenerate\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]    \\n}          \\nFor more information, see Adding permissions to a user in the IAM User Guide .\\nAllow users to view their own permissions\\nThis example shows how you might create a policy that allows IAM users to view the inline and \\nmanaged policies that are attached to their user identity. This policy includes permissions to \\ncomplete this action on the console or programmatically using the AWS CLI or AWS API.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"ViewOwnUserInfo\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"iam:GetUserPolicy\", \\n                \"iam:ListGroupsForUser\", \\n                \"iam:ListAttachedUserPolicies\", \\n                \"iam:ListUserPolicies\", \\n                \"iam:GetUser\" \\n            ], \\n            \"Resource\": [\"arn:aws:iam::*:user/${aws:username}\"] \\n        }, \\n        { \\n            \"Sid\": \"NavigateInConsole\", \\n            \"Effect\": \"Allow\", \\nIdentity-based policy examples 519Amazon Bedrock User Guide\\n            \"Action\": [ \\n                \"iam:GetGroupPolicy\", \\n                \"iam:GetPolicyVersion\", \\n                \"iam:GetPolicy\", \\n                \"iam:ListAttachedGroupPolicies\", \\n                \"iam:ListGroupPolicies\", \\n                \"iam:ListPolicyVersions\", \\n                \"iam:ListPolicies\", \\n                \"iam:ListUsers\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]\\n}\\nAllow access to third-party model subscriptions\\nTo access the Amazon Bedrock models for the ﬁrst time, you use the Amazon Bedrock console \\nto subscribe to third-party models. Your IAM user or role that the console user assumes requires \\npermission to access the subscription API operations.\\nThe following example shows an identity-based policy to allow access to the subscription API \\noperations.\\nUse a condition key, as in the example, to limits the scope of the policy to a subset of the Amazon \\nBedrock foundation models in the Marketplace. To see a list of product IDs and which foundation \\nmodels they correspond to, see the table in Control model access permissions.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"aws-marketplace:Subscribe\" \\n            ], \\n            \"Resource\": \"*\", \\n            \"Condition\": { \\n                \"ForAnyValue:StringEquals\": { \\n                    \"aws-marketplace:ProductId\": [ \\n                        \"1d288c71-65f9-489a-a3e2-9c7f4f6e6a85\", \\n                        \"cc0bdd50-279a-40d8-829c-4009b77a1fcc\", \\nIdentity-based policy examples 520Amazon Bedrock User Guide\\n                        \"c468b48a-84df-43a4-8c46-8870630108a7\", \\n                        \"99d90be8-b43e-49b7-91e4-752f3866c8c7\", \\n                        \"b0eb9475-3a2c-43d1-94d3-56756fd43737\", \\n                        \"d0123e8d-50d6-4dba-8a26-3fed4899f388\", \\n                        \"a61c46fe-1747-41aa-9af0-2e0ae8a9ce05\", \\n                        \"216b69fd-07d5-4c7b-866b-936456d68311\", \\n                        \"b7568428-a1ab-46d8-bab3-37def50f6f6a\", \\n                        \"38e55671-c3fe-4a44-9783-3584906e7cad\", \\n                        \"prod-ariujvyzvd2qy\", \\n                        \"prod-2c2yc2s3guhqy\", \\n                        \"prod-6dw3qvchef7zy\", \\n                        \"prod-ozonys2hmmpeu\" \\n                    ] \\n                } \\n            } \\n        }, \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"aws-marketplace:Unsubscribe\", \\n                \"aws-marketplace:ViewSubscriptions\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]\\n}\\nDeny access for inference on speciﬁc models\\nThe following example shows an identity-based policy that denies access to running inference on a \\nspeciﬁc model.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": { \\n        \"Sid\": \"DenyInference\", \\n        \"Effect\": \"Deny\", \\n        \"Action\": [ \\n            \"bedrock:InvokeModel\", \\n            \"bedrock:InvokeModelWithResponseStream\" \\n         ], \\n        \"Resource\": \"arn:aws:bedrock:*::foundation-model/ model-id \" \\n    }\\nIdentity-based policy examples 521Amazon Bedrock User Guide\\n}         \\nIdentity-based policy examples for Agents for Amazon Bedrock\\nSelect a topic to see example IAM policies that you can attach to an IAM role to provision \\npermissions for actions in Agents for Amazon Bedrock.\\nTopics\\n•Required permissions for Agents for Amazon Bedrock\\n•Allow users to view information about and invoke an agent\\nRequired permissions for Agents for Amazon Bedrock\\nFor an IAM identity to use Agents for Amazon Bedrock, you must conﬁgure it with the necessary \\npermissions. You can attach the AmazonBedrockFullAccess policy to grant the proper permissions \\nto the role.\\nTo restrict permissions to only actions that are used in Agents for Amazon Bedrock, attach the \\nfollowing identity-based policy to an IAM role:\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"AgentsRole\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [   \\n                \"bedrock:ListFoundationModels\", \\n                \"bedrock:GetFoundationModel\", \\n                \"bedrock:TagResource\",  \\n                \"bedrock:UntagResource\",  \\n                \"bedrock:ListTagsForResource\",  \\n                \"bedrock:CreateAgent\",  \\n                \"bedrock:UpdateAgent\",  \\n                \"bedrock:GetAgent\",  \\n                \"bedrock:ListAgents\",  \\n                \"bedrock:DeleteAgent\", \\n                \"bedrock:CreateAgentActionGroup\",  \\n                \"bedrock:UpdateAgentActionGroup\",  \\n                \"bedrock:GetAgentActionGroup\",  \\n                \"bedrock:ListAgentActionGroups\",  \\nIdentity-based policy examples 522Amazon Bedrock User Guide\\n                \"bedrock:DeleteAgentActionGroup\", \\n                \"bedrock:GetAgentVersion\", \\n                \"bedrock:ListAgentVersions\",  \\n                \"bedrock:DeleteAgentVersion\", \\n                \"bedrock:CreateAgentAlias\",  \\n                \"bedrock:UpdateAgentAlias\",                \\n                \"bedrock:GetAgentAlias\", \\n                \"bedrock:ListAgentAliases\", \\n                \"bedrock:DeleteAgentAlias\", \\n                \"bedrock:AssociateAgentKnowledgeBase\", \\n                \"bedrock:DisassociateAgentKnowledgeBase\", \\n                \"bedrock:GetKnowledgeBase\", \\n                \"bedrock:ListKnowledgeBases\", \\n                \"bedrock:PrepareAgent\", \\n                \"bedrock:InvokeAgent\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]    \\n}\\nYou can further restrict permissions by omitting actions or specifying resources and condition \\nkeys. An IAM identity can call API operations on speciﬁc resources. For example, the UpdateAgent\\noperation can only be used on agent resources and the InvokeAgent operation can only be \\nused on alias resources. For API operations that aren\\'t used on a speciﬁc resource type (such as\\nCreateAgent), specify * as the Resource . If you specify an API operation that can\\'t be used on the \\nresource speciﬁed in the policy, Amazon Bedrock returns an error.\\nAllow users to view information about and invoke an agent\\nThe following is a sample policy that you can attach to an IAM role to allow it to view information \\nabout or edit an agent with the ID AGENT12345  and to interact with its alias with the ID\\nALIAS12345 . For example, you could attach this policy to a role that you want to only have \\npermissions to troubleshoot an agent and update it.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \" sid\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\nIdentity-based policy examples 523Amazon Bedrock User Guide\\n                \"bedrock:GetAgent\", \\n                \"bedrock:UpdateAgent\" \\n            ] \\n            \"Resource\": \"arn:aws:bedrock: aws-region :111122223333 :agent/AGENT12345 \" \\n        }, \\n        { \\n            \"Sid\": \" sid\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:InvokeAgent\" \\n            ], \\n            \"Resource\": \"arn:aws:bedrock: aws-region :111122223333 :agent-\\nalias/AGENT12345 /ALIAS12345 \" \\n        }, \\n    ]\\n}\\nAWS managed policies for Amazon Bedrock\\nTo add permissions to users, groups, and roles, it\\'s easier to use AWS managed policies than to \\nwrite policies yourself. It takes time and expertise to create IAM customer managed policies that \\nprovide your team with only the permissions they need. To get started quickly, you can use our \\nAWS managed policies. These policies cover common use cases and are available in your AWS \\naccount. For more information about AWS managed policies, see AWS managed policies in the IAM \\nUser Guide .\\nAWS services maintain and update AWS managed policies. You can\\'t change the permissions in \\nAWS managed policies. Services occasionally add additional permissions to an AWS managed \\npolicy to support new features. This type of update aﬀects all identities (users, groups, and roles) \\nwhere the policy is attached. Services are most likely to update an AWS managed policy when \\na new feature is launched or when new operations become available. Services do not remove \\npermissions from an AWS managed policy, so policy updates won\\'t break your existing permissions.\\nAdditionally, AWS supports managed policies for job functions that span multiple services. For \\nexample, the ReadOnlyAccess AWS managed policy provides read-only access to all AWS services \\nand resources. When a service launches a new feature, AWS adds read-only permissions for new \\noperations and resources. For a list and descriptions of job function policies, see AWS managed \\npolicies for job functions in the IAM User Guide .\\nAWS managed policies 524Amazon Bedrock User Guide\\nAWS managed policy: AmazonBedrockFullAccess\\nYou can attach the AmazonBedrockFullAccess  policy to your IAM identities.\\nThis policy grants administrative permissions that allow the user permission to create, read, \\nupdate, and delete Amazon Bedrock resources.\\nNote\\nFine-tuning and model access require extra permissions. See Allow access to third-party \\nmodel subscriptions  and Permissions to access training and validation ﬁles and to write \\noutput ﬁles in S3  for more information.\\nPermissions details\\nThis policy includes the following permissions:\\n•ec2 (Amazon Elastic Compute Cloud) – Allows permissions to describe VPCs, subnets, and \\nsecurity groups.\\n•iam (AWS Identity and Access Management) – Allows principals to pass roles, but only allows \\nIAM roles with \"Amazon Bedrock\" in them to be passed to the Amazon Bedrock service. The \\npermissions are restricted to bedrock.amazonaws.com  for Amazon Bedrock operations.\\n•kms (AWS Key Management Service) – Allows principals to describe AWS KMS keys and aliases.\\n•bedrock (Amazon Bedrock) – Allows principals read and write access to all actions in the \\nAmazon Bedrock control plane and runtime service.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"BedrockAll\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:*\" \\n            ], \\n            \"Resource\": \"*\" \\n        }, \\n        { \\nAWS managed policies 525Amazon Bedrock User Guide\\n            \"Sid\": \"DescribeKey\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"kms:DescribeKey\" \\n            ], \\n            \"Resource\": \"arn:*:kms:*:::*\" \\n        }, \\n        { \\n            \"Sid\": \"APIsWithAllResourceAccess\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"iam:ListRoles\", \\n                \"ec2:DescribeVpcs\", \\n                \"ec2:DescribeSubnets\", \\n                \"ec2:DescribeSecurityGroups\" \\n            ], \\n            \"Resource\": \"*\" \\n        }, \\n        { \\n            \"Sid\": \"PassRoleToBedrock\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"iam:PassRole\" \\n            ], \\n            \"Resource\": \"arn:aws:iam::*:role/*AmazonBedrock*\", \\n            \"Condition\": { \\n                \"StringEquals\": { \\n                    \"iam:PassedToService\": [ \\n                        \"bedrock.amazonaws.com\" \\n                    ] \\n                } \\n            } \\n        } \\n    ]\\n}\\nAWS managed policy: AmazonBedrockReadOnly\\nYou can attach the AmazonBedrockReadOnly  policy to your IAM identities.\\nThis policy grants read-only permissions that allow users to view all resources in Amazon Bedrock.\\n{ \\nAWS managed policies 526Amazon Bedrock User Guide\\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \"AmazonBedrockReadOnly\", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:GetFoundationModel\", \\n                \"bedrock:ListFoundationModels\", \\n                \"bedrock:GetModelInvocationLoggingConfiguration\", \\n                \"bedrock:GetProvisionedModelThroughput\", \\n                \"bedrock:ListProvisionedModelThroughputs\", \\n                \"bedrock:GetModelCustomizationJob\", \\n                \"bedrock:ListModelCustomizationJobs\", \\n                \"bedrock:ListCustomModels\", \\n                \"bedrock:GetCustomModel\", \\n                \"bedrock:ListTagsForResource\", \\n                \"bedrock:GetFoundationModelAvailability\" \\n            ], \\n            \"Resource\": \"*\" \\n        } \\n    ]\\n}\\nAmazon Bedrock updates to AWS managed policies\\nView details about updates to AWS managed policies for Amazon Bedrock since this service began \\ntracking these changes. For automatic alerts about changes to this page, subscribe to the RSS feed \\non the Document history for the Amazon Bedrock User Guide.\\nChange Description Date\\nAmazonBedrockFullAccess – \\nNew policyAmazon Bedrock added a new \\npolicy to give users permissio \\nns to create, read, update, \\nand delete resources.December 12, 2023\\nAmazonBedrockReadOnly – \\nNew policyAmazon Bedrock added a new \\npolicy to give users read-only \\npermissions for all actions.December 12, 2023\\nAWS managed policies 527Amazon Bedrock User Guide\\nChange Description Date\\nAmazon Bedrock started \\ntracking changesAmazon Bedrock started \\ntracking changes for its AWS \\nmanaged policies.December 12, 2023\\nService roles\\nAmazon Bedrock uses IAM service roles for the following features to let Amazon Bedrock carry out \\ntasks on your behalf.\\nThe console automatically creates service roles for supported features.\\nYou can also create a custom service role and customize the attached permissions to your speciﬁc \\nuse-case. If you use the console, you can select this role instead of letting Amazon Bedrock create \\none for you.\\nTo set up the custom service role, you carry out the following general steps.\\n1. Create the role by following the steps at Creating a role to delegate permissions to an AWS \\nservice.\\n2. Attach a trust policy.\\n3. Attach the relevant identity-based permissions.\\nRefer to the following links for more information about IAM concepts that are relevant to setting \\nservice role permissions.\\n•AWS service role\\n•Identity-based policies and resource-based policies\\n•Using resource-based policies for Lambda\\n•AWS global condition context keys\\n•Condition keys for Amazon Bedrock\\nSelect a topic to learn more about service roles for a speciﬁc feature.\\nTopics\\nService roles 528Amazon Bedrock User Guide\\n•Create a service role for model customization\\n•Create a service role for Agents for Amazon Bedrock\\n•Create a service role for Knowledge base for Amazon Bedrock\\nCreate a service role for model customization\\nTo use a custom role for model customization instead of the one Amazon Bedrock automatically \\ncreates, create an IAM role and attach the following permissions by following the steps at Creating \\na role to delegate permissions to an AWS service.\\n•Trust relationship\\n•Permissions to access your training and validation data in S3 and to write your output data to S3\\n•(Optional) If you encrypt any of the following resources with a KMS key, permissions to decrypt \\nthe key (see Encryption of model customization jobs and artifacts)\\n•A model customization job or the resulting custom model\\n•The training, validation, or output data for the model customization job\\nTopics\\n•Trust relationship\\n•Permissions to access training and validation ﬁles and to write output ﬁles in S3\\nTrust relationship\\nThe following policy allows Amazon Bedrock to assume this role and carry out the model \\ncustomization job. The following shows an example policy you can use.\\nYou can optionally restrict the scope of the permission for cross-service confused deputy \\nprevention by using one or more global condition context keys with the Condition  ﬁeld. For more \\ninformation, see AWS global condition context keys.\\n•Set the aws:SourceAccount  value to your account ID.\\n•(Optional) Use the ArnEquals  or ArnLike condition to restrict the scope to speciﬁc model \\ncustomization jobs in your account ID.\\n{ \\nService roles 529Amazon Bedrock User Guide\\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"Service\": \"bedrock.amazonaws.com\" \\n            }, \\n            \"Action\": \"sts:AssumeRole\", \\n            \"Condition\": { \\n                \"StringEquals\": { \\n                    \"aws:SourceAccount\": \" account-id \" \\n                }, \\n                \"ArnEquals\": { \\n                    \"aws:SourceArn\": \"arn:aws:bedrock:us-east-1: account-id :model-\\ncustomization-job/*\" \\n                } \\n            } \\n        } \\n    ]  \\n}\\nPermissions to access training and validation ﬁles and to write output ﬁles in S3\\nAttach the following policy to allow the role to access your training and validation data and the \\nbucket to which to write your output data. Replace the values in the Resource  list with your actual \\nbucket names.\\nTo restrict access to a speciﬁc folder in a bucket, add an s3:prefix  condition key with your folder \\npath. You can follow the User policy example in Example 2: Getting a list of objects in a bucket \\nwith a speciﬁc preﬁx\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: training-bucket \", \\n                \"arn:aws:s3::: training-bucket/* \", \\nService roles 530Amazon Bedrock User Guide\\n                \"arn:aws:s3::: validation-bucket \", \\n                \"arn:aws:s3::: validation-bucket/* \" \\n            ] \\n        }, \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\", \\n                \"s3:PutObject\", \\n                \"s3:ListBucket\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: output-bucket \", \\n                \"arn:aws:s3::: output-bucket/* \" \\n            ] \\n        } \\n    ]\\n}\\nCreate a service role for Agents for Amazon Bedrock\\nTo use a custom service role for agents instead of the one Amazon Bedrock automatically creates, \\ncreate an IAM role with the preﬁx AmazonBedrockExecutionRoleForAgents_  and attach the \\nfollowing permissions by following the steps at Creating a role to delegate permissions to an AWS \\nservice.\\n•Trust policy\\n•A policy containing the following identity-based permissions\\n•Access to the Amazon Bedrock base models\\n•Access to the Amazon S3 objects containing the OpenAPI schemas for the action groups in \\nyour agents\\n•Permissions for Amazon Bedrock to query knowledge bases that you want to attach to your \\nagents\\n•(Optional) If you encrypt your agent with a KMS key, permissions to decrypt the key (see\\nEncryption of agent resources)\\nWhether you use a custom role or not, you also need to attach a resource-based policy to the \\nLambda functions for the action groups in your agents to provide permissions for the service role \\nService roles 531Amazon Bedrock User Guide\\nto access the functions. For more information, see Resource-based policy to allow Amazon Bedrock \\nto invoke an action group Lambda function.\\nTopics\\n•Trust relationship\\n•Identity-based permissions for the Agents service role.\\n•Resource-based policy to allow Amazon Bedrock to invoke an action group Lambda function\\nTrust relationship\\nThe following trust policy allows Amazon Bedrock to assume this role and create and manage \\nagents. Replace the values as necessary. The policy contains optional condition keys (see\\nCondition keys for Amazon Bedrock and AWS global condition context keys) in the Condition\\nﬁeld that we recommend you use as a security best practice.\\nNote\\nAs a best practice for security purposes, replace the * with speciﬁc agent IDs after you have \\ncreated them.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Effect\": \"Allow\", \\n        \"Principal\": { \\n            \"Service\": \"bedrock.amazonaws.com\" \\n        }, \\n        \"Action\": \"sts:AssumeRole\", \\n        \"Condition\": { \\n            \"StringEquals\": { \\n                \"aws:SourceAccount\": \" account-id \" \\n            }, \\n            \"ArnLike\": { \\n                \"AWS:SourceArn\": \"arn:aws:bedrock: region:account-id :agent/*\" \\n            } \\n        } \\n    }]\\n}\\nService roles 532Amazon Bedrock User Guide\\nIdentity-based permissions for the Agents service role.\\nAttach the following policy to provide permissions for the service role, replacing values  as \\nnecessary. The policy contains the following statements. Omit a statement if it isn\\'t applicable to \\nyour use-case. The policy contains optional condition keys (see Condition keys for Amazon Bedrock\\nand AWS global condition context keys) in the Condition  ﬁeld that we recommend you use as a \\nsecurity best practice.\\nNote\\nIf you encrypt your agent with a customer-managed KMS key, refer to Encryption of agent \\nresources for further permissions you need to add.\\n•Permissions to use Amazon Bedrock foundation models to run model inference on prompts used \\nin your agent\\'s orchestration.\\n•Permissions to access your agent\\'s action group API schemas in Amazon S3. Omit this statement \\nif your agent has no action groups.\\n•Permissions to access knowledge bases associated with your agent. Omit this statement if your \\nagent has no associated knowledge bases.\\n•Permissions to access a third-party (Pinecone or Redis Enterprise Cloud) knowledge base \\nassociated with your agent. Omit this statement if your knowledge base is ﬁrst-party (Amazon \\nOpenSearch Serverless or Amazon Aurora) or if your agent has no associated knowledge bases.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Sid\": \" Allow model invocation for orchestration \", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:InvokeModel\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:bedrock: region::foundation-model/anthropic.claude-v2\", \\n                \"arn:aws:bedrock: region::foundation-model/anthropic.claude-v2:1\", \\n                \"arn:aws:bedrock: region::foundation-model/anthropic.claude-instant-v1\" \\n            ] \\n        }, \\nService roles 533Amazon Bedrock User Guide\\n        { \\n            \"Sid\": \" Allow access to action group API schemas in S3 \", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"s3:GetObject\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:s3::: bucket/path/to/schema \" \\n            ], \\n            \"Condition\": { \\n                \"StringEquals\": { \\n                    \"aws:ResourceAccount\": \" account-id \" \\n                } \\n            } \\n        }, \\n        { \\n            \"Sid\": \" Query associated knowledge bases \", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:Retrieve\", \\n                \"bedrock:RetrieveAndGenerate\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:bedrock: region:account-id :knowledge-base/ knowledge-base-id \" \\n            ] \\n        }, \\n        { \\n            \"Sid\": \" Associate a third-party knowledge base with your agent \", \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:AssociateThirdPartyKnowledgeBase\", \\n            ], \\n            \"Resource\": \"arn:aws:bedrock: region:account-id :knowledge-base/ knowledge-\\nbase-id\", \\n            \"Condition\": {  \\n                \"StringEquals\" : {  \\n                    \"bedrock:ThirdPartyKnowledgeBaseCredentialsSecretArn\": \\n \"arn:aws:kms: region:account-id :key/key-id\" \\n                } \\n            } \\n        } \\n    ]\\n}\\nService roles 534Amazon Bedrock User Guide\\nResource-based policy to allow Amazon Bedrock to invoke an action group Lambda function\\nFollow the steps at Using resource-based policies for Lambda and attach the following resource-\\nbased policy to a Lambda function to allow Amazon Bedrock to access the Lambda function \\nfor your agent\\'s action groups, replacing the values as necessary. The policy contains optional \\ncondition keys (see Condition keys for Amazon Bedrock and AWS global condition context keys) in \\nthe Condition  ﬁeld that we recommend you use as a security best practice.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Sid\": \" Allow Amazon Bedrock to access action group Lambda function \", \\n        \"Effect\": \"Allow\", \\n        \"Principal\": { \\n            \"Service\": \"bedrock.amazonaws.com\" \\n        }, \\n        \"Action\": \"lambda:InvokeFunction\", \\n        \"Resource\":  \"arn:aws:lambda: region:account-id :function: function-name \", \\n        \"Condition\": { \\n            \"StringEquals\": { \\n                \"AWS:SourceAccount\": \" account-id \" \\n            }, \\n            \"ArnLike\": { \\n                \"AWS:SourceArn\": \"arn:aws:bedrock: region:account-id :agent/agent-id \" \\n            } \\n        } \\n    }]\\n}\\nCreate a service role for Knowledge base for Amazon Bedrock\\nTo use a custom role for knowledge base instead of the one Amazon Bedrock automatically \\ncreates, create an IAM role and attach the following permissions by following the steps at Creating \\na role to delegate permissions to an AWS service. You can use the same role across your knowledge \\nbases.\\n•Trust relationship\\n•Access to the Amazon Bedrock base models\\n•Access to the Amazon S3 objects containing your data sources\\nService roles 535Amazon Bedrock User Guide\\n•(If you create a vector database in Amazon OpenSearch Service) Access to your OpenSearch \\nService collection\\n•(If you create a vector database in Amazon Aurora)\\n•(If you create a vector database in Pinecone or Redis Enterprise Cloud) Permissions for AWS \\nSecrets Manager to authenticate your Pinecone or Redis Enterprise Cloud account\\n•(Optional) If you encrypt any of the following resources with a KMS key, permissions to decrypt \\nthe key (see Encryption of knowledge base resources).\\n•Your knowledge base\\n•Data sources for your knowledge base\\n•Your vector database in Amazon OpenSearch Service\\n•The secret for your third-party vector database in AWS Secrets Manager\\n•A data ingestion job\\nTopics\\n•Trust relationship\\n•Permissions to access Amazon Bedrock models\\n•Permissions to access your data sources in Amazon S3\\n•(Optional) Permissions to access your vector database in Amazon OpenSearch Service\\n•(Optional) Permissions to access your Amazon Aurora database cluster\\n•(Optional) Permissions to access a vector database conﬁgured with an AWS Secrets Manager \\nsecret\\n•(Optional) Permissions for AWS to manage a AWS KMS key for transient data storage during data \\ningestion\\nTrust relationship\\nThe following policy allows Amazon Bedrock to assume this role and create and manage \\nknowledge bases. The following shows an example policy you can use. You can restrict the scope \\nof the permission by using one or more global condition context keys. For more information, see\\nAWS global condition context keys. Set the aws:SourceAccount  value to your account ID. Use the\\nArnEquals  or ArnLike condition to restrict the scope to speciﬁc knowledge bases.\\nService roles 536Amazon Bedrock User Guide\\nNote\\nAs a best practice for security purposes, replace the * with speciﬁc knowledge base IDs \\nafter you have created them.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Effect\": \"Allow\", \\n        \"Principal\": { \\n            \"Service\": \"bedrock.amazonaws.com\" \\n        }, \\n        \"Action\": \"sts:AssumeRole\", \\n        \"Condition\": { \\n            \"StringEquals\": { \\n                \"aws:SourceAccount\": \" account-id \" \\n            }, \\n            \"ArnLike\": { \\n                \"AWS:SourceArn\": \"arn:aws:bedrock: region:account-id :knowledge-base/ *\" \\n            } \\n        } \\n    }]\\n}\\nPermissions to access Amazon Bedrock models\\nAttach the following policy to provide permissions for the role to use Amazon Bedrock models to \\nembed your source data.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:ListFoundationModels\", \\n                \"bedrock:ListCustomModels\" \\n            ], \\n            \"Resource\": \"*\" \\n        }, \\n        { \\nService roles 537Amazon Bedrock User Guide\\n            \"Effect\": \"Allow\", \\n            \"Action\": [ \\n                \"bedrock:InvokeModel\" \\n            ], \\n            \"Resource\": [ \\n                \"arn:aws:bedrock: region::foundation-model/amazon.titan-embed-text-v1\", \\n                \"arn:aws:bedrock: region::foundation-model/cohere.embed-english-v3\", \\n                \"arn:aws:bedrock: region::foundation-model/cohere.embed-multilingual-v3\" \\n            ] \\n        } \\n    ]\\n}\\nPermissions to access your data sources in Amazon S3\\nAttach the following policy to provide permissions for the role to access the Amazon S3 URIs \\ncontaining the data source ﬁles for your knowledge base. In the Resource  ﬁeld, provide an \\nAmazon S3 object containing the data sources or add the URI of each data source to the list.\\nIf you encrypted these data sources with a AWS KMS key, attach permissions to decrypt the key to \\nthe role by following the steps at Permissions to decrypt your AWS KMS key for your data sources \\nin Amazon S3.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Effect\": \"Allow\", \\n        \"Action\": [ \\n            \"s3:GetObject\", \\n            \"s3:ListBucket\" \\n        ], \\n        \"Resource\": [ \\n            \"arn:aws:s3::: bucket/path/to/folder \", \\n            \"arn:aws:s3::: bucket/path/to/folder /*\" \\n        ], \\n        \"Condition\": { \\n            \"StringEquals\": { \\n                \"aws:PrincipalAccount\": \" account-id \" \\n            } \\n        } \\n    }]\\n}\\nService roles 538Amazon Bedrock User Guide\\n(Optional) Permissions to access your vector database in Amazon OpenSearch Service\\nIf you created a vector database in Amazon OpenSearch Service for your knowledge base, attach \\nthe following policy to your Knowledge base for Amazon Bedrock service role to allow access to \\nthe collection. Replace region  and account-id  with the region and account ID to which the \\ndatabase belongs. Input the ID of your Amazon OpenSearch Service collection in collection-id . \\nYou can allow access to multiple collections by adding them to the Resource  list.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Effect\": \"Allow\", \\n        \"Action\": [ \\n            \"aoss:APIAccessAll\" \\n        ], \\n        \"Resource\": [ \\n            \"arn:aws:aoss: region:account-id :collection/ collection-id \" \\n        ] \\n    }]\\n}\\n(Optional) Permissions to access your Amazon Aurora database cluster\\nIf you created a database (DB) cluster in Amazon Aurora for your knowledge base, attach the \\nfollowing policy to your Knowledge base for Amazon Bedrock service role to allow access to the \\nDB cluster and to provide read and write permissions on it. Replace region  and account-id  with \\nthe region and account ID to which the DB cluster belongs. Input the ID of your Amazon Aurora \\ndatabase cluster in db-cluster-id . You can allow access to multiple DB clusters by adding them \\nto the Resource  list.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n    { \\n        \"Sid\": \" RdsDescribeStatementID \", \\n        \"Effect\": \"Allow\", \\n        \"Action\": [ \\n            \"rds:DescribeDBClusters\" \\n        ], \\n        \"Resource\": [ \\n            \"arn:aws:rds: region:account-id :cluster: db-cluster-id \" \\nService roles 539Amazon Bedrock User Guide\\n        ] \\n    }, \\n    { \\n        \"Sid\": \"DataAPIStatementID\", \\n        \"Effect\": \"Allow\", \\n        \"Action\": [ \\n            \"rds-data:BatchExecuteStatement\", \\n            \"rds-data:ExecuteStatement\" \\n        ], \\n        \"Resource\": [ \\n            \"arn:aws:rds: region:account-id :cluster: db-cluster-id \" \\n        ] \\n    }]\\n}\\n(Optional) Permissions to access a vector database conﬁgured with an AWS Secrets Manager \\nsecret\\nIf your vector database is conﬁgured with an AWS Secrets Manager secret, attach the following \\npolicy to your Knowledge base for Amazon Bedrock service role to allow AWS Secrets Manager \\nto authenticate your account to access the database. Replace region  and account-id  with the \\nregion and account ID to which the database belongs. Replace secret-id  with the ID of your \\nsecret.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [{ \\n        \"Effect\": \"Allow\", \\n        \"Action\": [ \\n            \"secretsmanager:GetSecretValue\" \\n        ], \\n        \"Resource\": [ \\n            \"arn:aws:secretsmanager: region:account-id :secret: secret-id \" \\n        ] \\n    }]\\n}\\nIf you encrypted your secret with a AWS KMS key, attach permissions to decrypt the key to the role \\nby following the steps at Permissions to decrypt an AWS Secrets Manager secret for the vector \\nstore containing your knowledge base.\\nService roles 540Amazon Bedrock User Guide\\n(Optional) Permissions for AWS to manage a AWS KMS key for transient data storage during \\ndata ingestion\\nTo allow the creation of a AWS KMS key for transient data storage in the process of ingesting your \\ndata source, attach the following policy to your Knowledge base for Amazon Bedrock service role. \\nReplace the region , account-id , and key-id with the appropriate values.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n          \"Effect\": \"Allow\", \\n          \"Action\": [ \\n              \"kms:GenerateDataKey\", \\n              \"kms:Decrypt\" \\n          ], \\n          \"Resource\": [ \\n              \"arn:aws:kms: region:account-id :key/key-id\" \\n          ] \\n        } \\n    ]\\n}\\nTroubleshooting Amazon Bedrock identity and access\\nUse the following information to help you diagnose and ﬁx common issues that you might \\nencounter when working with Amazon Bedrock and IAM.\\nTopics\\n•I am not authorized to perform an action in Amazon Bedrock\\n•I am not authorized to perform iam:PassRole\\n•I want to allow people outside of my AWS account to access my Amazon Bedrock resources\\nI am not authorized to perform an action in Amazon Bedrock\\nIf you receive an error that you\\'re not authorized to perform an action, your policies must be \\nupdated to allow you to perform the action.\\nTroubleshooting 541Amazon Bedrock User Guide\\nThe following example error occurs when the mateojackson  IAM user tries to use the console \\nto view details about a ﬁctional my-example-widget  resource but doesn\\'t have the ﬁctional\\nbedrock: GetWidget  permissions.\\nUser: arn:aws:iam::123456789012:user/mateojackson is not authorized to perform: \\n bedrock: GetWidget  on resource: my-example-widget\\nIn this case, the policy for the mateojackson  user must be updated to allow access to the my-\\nexample-widget  resource by using the bedrock: GetWidget  action.\\nIf you need help, contact your AWS administrator. Your administrator is the person who provided \\nyou with your sign-in credentials.\\nI am not authorized to perform iam:PassRole\\nIf you receive an error that you\\'re not authorized to perform the iam:PassRole  action, your \\npolicies must be updated to allow you to pass a role to Amazon Bedrock.\\nSome AWS services allow you to pass an existing role to that service instead of creating a new \\nservice role or service-linked role. To do this, you must have permissions to pass the role to the \\nservice.\\nThe following example error occurs when an IAM user named marymajor  tries to use the console \\nto perform an action in Amazon Bedrock. However, the action requires the service to have \\npermissions that are granted by a service role. Mary does not have permissions to pass the role to \\nthe service.\\nUser: arn:aws:iam::123456789012:user/ marymajor  is not authorized to perform: \\n iam:PassRole\\nIn this case, Mary\\'s policies must be updated to allow her to perform the iam:PassRole  action.\\nIf you need help, contact your AWS administrator. Your administrator is the person who provided \\nyou with your sign-in credentials.\\nI want to allow people outside of my AWS account to access my Amazon Bedrock \\nresources\\nYou can create a role that users in other accounts or people outside of your organization can use to \\naccess your resources. You can specify who is trusted to assume the role. For services that support \\nTroubleshooting 542Amazon Bedrock User Guide\\nresource-based policies or access control lists (ACLs), you can use those policies to grant people \\naccess to your resources.\\nTo learn more, consult the following:\\n•To learn whether Amazon Bedrock supports these features, see How Amazon Bedrock works with \\nIAM.\\n•To learn how to provide access to your resources across AWS accounts that you own, see\\nProviding access to an IAM user in another AWS account that you own in the IAM User Guide .\\n•To learn how to provide access to your resources to third-party AWS accounts, see Providing \\naccess to AWS accounts owned by third parties in the IAM User Guide .\\n•To learn how to provide access through identity federation, see Providing access to externally \\nauthenticated users (identity federation) in the IAM User Guide .\\n•To learn the diﬀerence between using roles and resource-based policies for cross-account access, \\nsee How IAM roles diﬀer from resource-based policies in the IAM User Guide .\\nCompliance validation for Amazon Bedrock\\nTo learn whether an AWS service is within the scope of speciﬁc compliance programs, see AWS \\nservices in Scope by Compliance Program and choose the compliance program that you are \\ninterested in. For general information, see AWS Compliance Programs.\\nYou can download third-party audit reports using AWS Artifact. For more information, see\\nDownloading Reports in AWS Artifact.\\nYour compliance responsibility when using AWS services is determined by the sensitivity of your \\ndata, your company\\'s compliance objectives, and applicable laws and regulations. AWS provides the \\nfollowing resources to help with compliance:\\n•Security and Compliance Quick Start Guides – These deployment guides discuss architectural \\nconsiderations and provide steps for deploying baseline environments on AWS that are security \\nand compliance focused.\\n•Architecting for HIPAA Security and Compliance on Amazon Web Services – This whitepaper \\ndescribes how companies can use AWS to create HIPAA-eligible applications.\\nCompliance validation 543Amazon Bedrock User Guide\\nNote\\nNot all AWS services are HIPAA eligible. For more information, see the HIPAA Eligible \\nServices Reference.\\n•AWS Compliance Resources – This collection of workbooks and guides might apply to your \\nindustry and location.\\n•AWS Customer Compliance Guides – Understand the shared responsibility model through the \\nlens of compliance. The guides summarize the best practices for securing AWS services and map \\nthe guidance to security controls across multiple frameworks (including National Institute of \\nStandards and Technology (NIST), Payment Card Industry Security Standards Council (PCI), and \\nInternational Organization for Standardization (ISO)).\\n•Evaluating Resources with Rules in the AWS Conﬁg Developer Guide – The AWS Conﬁg service \\nassesses how well your resource conﬁgurations comply with internal practices, industry \\nguidelines, and regulations.\\n•AWS Security Hub – This AWS service provides a comprehensive view of your security state within \\nAWS. Security Hub uses security controls to evaluate your AWS resources and to check your \\ncompliance against security industry standards and best practices. For a list of supported services \\nand controls, see Security Hub controls reference.\\n•AWS Audit Manager – This AWS service helps you continuously audit your AWS usage to simplify \\nhow you manage risk and compliance with regulations and industry standards.\\nIncident response in Amazon Bedrock\\nSecurity is the highest priority at AWS. As part of the AWS Cloud shared responsibility model, \\nAWS manages a data center, network, and software architecture that meets the requirements \\nof the most security-sensitive organizations. AWS is responsible for any incident response with \\nrespect to the Amazon Bedrock service itself. Also, as an AWS customer, you share a responsibility \\nfor maintaining security in the cloud. This means that you control the security you choose to \\nimplement from the AWS tools and features you have access to. In addition, you’re responsible for \\nincident response on your side of the shared responsibility model.\\nBy establishing a security baseline that meets the objectives for your applications running in the \\ncloud, you\\'re able to detect deviations that you can respond to. To help you understand the impact \\nIncident response 544Amazon Bedrock User Guide\\nthat incident response and your choices have on your corporate goals, we encourage you to review \\nthe following resources:\\n•AWS Security Incident Response Guide\\n•AWS Best Practices for Security, Identity, and Compliance\\n•Security Perspective of the AWS Cloud Adoption Framework (CAF) whitepaper\\nResilience in Amazon Bedrock\\nThe AWS global infrastructure is built around AWS Regions and Availability Zones. AWS Regions \\nprovide multiple physically separated and isolated Availability Zones, which are connected with \\nlow-latency, high-throughput, and highly redundant networking. With Availability Zones, you \\ncan design and operate applications and databases that automatically fail over between zones \\nwithout interruption. Availability Zones are more highly available, fault tolerant, and scalable than \\ntraditional single or multiple data center infrastructures.\\nFor more information about AWS Regions and Availability Zones, see AWS Global Infrastructure.\\nInfrastructure security in Amazon Bedrock\\nAs a managed service, Amazon Bedrock is protected by the AWS global network security. For \\ninformation about AWS security services and how AWS protects infrastructure, see AWS Cloud \\nSecurity. To design your AWS environment using the best practices for infrastructure security, see\\nInfrastructure Protection in Security Pillar AWS Well‐Architected Framework.\\nYou use AWS published API calls to access Amazon Bedrock through the network. Clients must \\nsupport the following:\\n•Transport Layer Security (TLS). We require TLS 1.2 and recommend TLS 1.3.\\n•Cipher suites with perfect forward secrecy (PFS) such as DHE (Ephemeral Diﬃe-Hellman) or \\nECDHE (Elliptic Curve Ephemeral Diﬃe-Hellman). Most modern systems such as Java 7 and later \\nsupport these modes.\\nAdditionally, requests must be signed by using an access key ID and a secret access key that is \\nassociated with an IAM principal. Or you can use the AWS Security Token Service (AWS STS) to \\ngenerate temporary security credentials to sign requests.\\nResilience 545Amazon Bedrock User Guide\\nCross-service confused deputy prevention\\nThe confused deputy problem is a security issue where an entity that doesn\\'t have permission to \\nperform an action can coerce a more-privileged entity to perform the action. In AWS, cross-service \\nimpersonation can result in the confused deputy problem. Cross-service impersonation can occur \\nwhen one service (the calling service) calls another service (the called service). The calling service \\ncan be manipulated to use its permissions to act on another customer\\'s resources in a way it should \\nnot otherwise have permission to access. To prevent this, AWS provides tools that help you protect \\nyour data for all services with service principals that have been given access to resources in your \\naccount.\\nWe recommend using the aws:SourceArn  and aws:SourceAccount  global condition context \\nkeys in resource policies to limit the permissions that Amazon Bedrock gives another service to \\nthe resource. Use aws:SourceArn  if you want only one resource to be associated with the cross-\\nservice access. Use aws:SourceAccount  if you want to allow any resource in that account to be \\nassociated with the cross-service use.\\nThe most eﬀective way to protect against the confused deputy problem is to use the\\naws:SourceArn  global condition context key with the full ARN of the resource. If you don\\'t know \\nthe full ARN of the resource or if you are specifying multiple resources, use the aws:SourceArn\\nglobal context condition key with wildcard characters (*) for the unknown portions of the ARN. For \\nexample, arn:aws:bedrock:*:123456789012:* .\\nIf the aws:SourceArn  value does not contain the account ID, such as an Amazon S3 bucket ARN, \\nyou must use both global condition context keys to limit permissions.\\nThe value of aws:SourceArn  must be ResourceDescription.\\nThe following example shows how you can use the aws:SourceArn  and aws:SourceAccount\\nglobal condition context keys in Bedrock to prevent the confused deputy problem.\\n{ \\n    \"Version\": \"2012-10-17\", \\n    \"Statement\": [ \\n        { \\n            \"Effect\": \"Allow\", \\n            \"Principal\": { \\n                \"Service\": \"bedrock.amazonaws.com\" \\n            }, \\n            \"Action\": \"sts:AssumeRole\", \\nCross-service confused deputy prevention 546Amazon Bedrock User Guide\\n            \"Condition\": { \\n                \"StringEquals\": { \\n                    \"aws:SourceAccount\": \" 111122223333 \" \\n                }, \\n                \"ArnEquals\": { \\n                    \"aws:SourceArn\": \"arn:aws:bedrock: us-east-1 :111122223333 :model-\\ncustomization-job/*\" \\n                } \\n            } \\n        } \\n    ]  \\n}\\nConﬁguration and vulnerability analysis in Amazon Bedrock\\nConﬁguration and IT controls are a shared responsibility between AWS and you, our customer. For \\nmore information, see the AWS shared responsibility model.\\nUse interface VPC endpoints (AWS PrivateLink)\\nYou can use AWS PrivateLink to create a private connection between your VPC and Amazon \\nBedrock. You can access Amazon Bedrock as if it were in your VPC, without the use of an internet \\ngateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC \\ndon\\'t need public IP addresses to access Amazon Bedrock.\\nYou establish this private connection by creating an interface endpoint, powered by AWS \\nPrivateLink. We create an endpoint network interface in each subnet that you enable for the \\ninterface endpoint. These are requester-managed network interfaces that serve as the entry point \\nfor traﬃc destined for Amazon Bedrock.\\nFor more information, see Access AWS services through AWS PrivateLink in the AWS PrivateLink \\nGuide .\\nConsiderations for Amazon Bedrock VPC endpoints\\nBefore you set up an interface endpoint for Amazon Bedrock, review Considerations  in the AWS \\nPrivateLink Guide .\\nAmazon Bedrock supports making the following API calls through VPC endpoints.\\nConﬁguration and vulnerability analysis in Amazon Bedrock 547Amazon Bedrock User Guide\\nCategory Endpoint preﬁx\\nAmazon Bedrock Control Plane API actionsbedrock\\nAmazon Bedrock Runtime API actions bedrock-runtime\\nAgents for Amazon Bedrock Build-time API \\nactionsbedrock-agent\\nAgents for Amazon Bedrock Runtime API \\nactionsbedrock-agent-runtime\\nAvailability Zones\\nAmazon Bedrock and Agents for Amazon Bedrock endpoints are available in multiple Availability \\nZones.\\nCreate an interface endpoint for Amazon Bedrock\\nYou can create an interface endpoint for Amazon Bedrock using either the Amazon VPC console \\nor the AWS Command Line Interface (AWS CLI). For more information, see Create an interface \\nendpoint  in the AWS PrivateLink Guide.\\nCreate an interface endpoint for Amazon Bedrock using any of the following service names:\\n•com.amazonaws. region.bedrock\\n•com.amazonaws. region.bedrock-runtime\\n•com.amazonaws. region.bedrock-agent\\n•com.amazonaws. region.bedrock-agent-runtime\\nAfter you create the endpoint, you have the option to enable a private DNS hostname. Enable \\nthis setting by selecting Enable Private DNS Name in the VPC console when you create the VPC \\nendpoint.\\nIf you enable private DNS for the interface endpoint, you can make API requests to Amazon \\nBedrock using its default Regional DNS name. The following examples show the format of the \\ndefault Regional DNS names.\\nCreate an interface endpoint 548Amazon Bedrock User Guide\\n•bedrock. region.amazonaws.com\\n•bedrock-runtime. region.amazonaws.com\\n•bedrock-agent. region.amazonaws.com\\n•bedrock-agent-runtime. region.amazonaws.com\\nCreate an endpoint policy for your interface endpoint\\nAn endpoint policy is an IAM resource that you can attach to an interface endpoint. The default \\nendpoint policy allows full access to Amazon Bedrock through the interface endpoint. To control \\nthe access allowed to Amazon Bedrock from your VPC, attach a custom endpoint policy to the \\ninterface endpoint.\\nAn endpoint policy speciﬁes the following information:\\n•The principals that can perform actions (AWS accounts, IAM users, and IAM roles).\\n•The actions that can be performed.\\n•The resources on which the actions can be performed.\\nFor more information, see Control access to services using endpoint policies in the AWS PrivateLink \\nGuide .\\nExample: VPC endpoint policy for Amazon Bedrock actions\\nThe following is an example of a custom endpoint policy. When you attach this resource-based \\npolicy to your interface endpoint, it grants access to the listed Amazon Bedrock actions for all \\nprincipals on all resources.\\n{ \\n   \"Version\": \"2012-10-17\", \\n   \"Statement\": [ \\n      { \\n         \"Principal\": \"*\", \\n         \"Effect\": \"Allow\", \\n         \"Action\": [ \\n            \"bedrock:InvokeModel\", \\n            \"bedrock:InvokeModelWithResponseStream\" \\n         ], \\n         \"Resource\":\"*\" \\nCreate an endpoint policy 549Amazon Bedrock User Guide\\n      } \\n   ]\\n}\\nCreate an endpoint policy 550Amazon Bedrock User Guide\\nMonitor Amazon Bedrock\\nYou can monitor Amazon Bedrock with Amazon CloudWatch and with Amazon EventBridge.\\nTopics\\n•Model invocation logging\\n•Monitor Amazon Bedrock with Amazon CloudWatch\\n•Monitor Amazon Bedrock events in Amazon EventBridge\\n•Log Amazon Bedrock API calls using AWS CloudTrail\\nModel invocation logging\\nModel invocation logging can be used to collect invocation logs, model input data, and model \\noutput data for all invocations in your AWS account used in Amazon Bedrock. By default, logging is \\ndisabled.\\nWith invocation logging, you can collect the full request data, response data, and metadata \\nassociated with all calls performed in your account. Logging can be conﬁgured to provide the \\ndestination resources where the log data will be published. Supported destinations include Amazon \\nCloudWatch Logs and Amazon Simple Storage Service (Amazon S3). Only destinations from the \\nsame account and region are supported.\\nBefore you can enable invocation logging, you need to set up an Amazon S3 or CloudWatch Logs \\ndestination. You can enable invocation logging through either the console or the API.\\nTopics\\n•Set up an Amazon S3 destination\\n•Set up CloudWatch Logs destination\\n•Using the console\\n•Using APIs with invocation logging\\nSet up an Amazon S3 destination\\nYou can set up an S3 destination for logging in Amazon Bedrock with these steps:\\nModel invocation logging 551Amazon Bedrock User Guide\\n1. Create an S3 bucket where the logs will be delivered.\\n2. Add a bucket policy to it like the one below (Replace values for accountId , region ,\\nbucketName , and optionally prefix ):\\nNote\\nA bucket policy is automatically attached to the bucket on your behalf when \\nyou conﬁgure logging with the permissions S3:GetBucketPolicy  and\\nS3:PutBucketPolicy .\\n{ \\n  \"Version\": \"2012-10-17\", \\n  \"Statement\": [ \\n    { \\n      \"Sid\": \"AmazonBedrockLogsWrite\", \\n      \"Effect\": \"Allow\", \\n      \"Principal\": { \\n        \"Service\": \"bedrock.amazonaws.com\" \\n      }, \\n      \"Action\": [ \\n        \"s3:PutObject\" \\n      ], \\n      \"Resource\": [ \\n        \"arn:aws:s3::: bucketName /prefix/AWSLogs/ accountId /\\nBedrockModelInvocationLogs/*\" \\n      ], \\n      \"Condition\": { \\n        \"StringEquals\": { \\n          \"aws:SourceAccount\": \" accountId \"  \\n        }, \\n        \"ArnLike\": { \\n           \"aws:SourceArn\": \"arn:aws:bedrock: region:accountId :*\" \\n        } \\n      } \\n    } \\n  ]\\n} \\n                 \\n3. (Optional) If conﬁguring SSE-KMS on the bucket, add the below policy on the KMS key:\\nSet up an Amazon S3 destination 552Amazon Bedrock User Guide\\n{ \\n    \"Effect\": \"Allow\", \\n    \"Principal\": { \\n        \"Service\": \"bedrock.amazonaws.com\" \\n    }, \\n    \"Action\": \"kms:GenerateDataKey\", \\n    \"Resource\": \"*\", \\n    \"Condition\": { \\n        \"StringEquals\": { \\n          \"aws:SourceAccount\": \" accountId \"  \\n        }, \\n        \"ArnLike\": { \\n           \"aws:SourceArn\": \"arn:aws:bedrock: region:accountId :*\" \\n        } \\n    }\\n}                 \\nFor more information on S3 SSE-KMS conﬁgurations, see Specifying KMS Encryption.\\nNote\\nThe bucket ACL must be disabled in order for the bucket policy to take eﬀect. For more \\ninformation, see Disabling ACLs for all new buckets and enforcing Object Ownership.\\nSet up CloudWatch Logs destination\\nYou can set up a Amazon CloudWatch Logs destination for logging in Amazon Bedrock with the \\nfollowing steps:\\n1. Create a CloudWatch log group where the logs will be published.\\n2. Create an IAM role with the following permissions for CloudWatch Logs.\\nTrusted entity:\\n{ \\n  \"Version\": \"2012-10-17\", \\n  \"Statement\": [ \\n    { \\nSet up CloudWatch Logs destination 553Amazon Bedrock User Guide\\n      \"Effect\": \"Allow\", \\n      \"Principal\": { \\n        \"Service\": \"bedrock.amazonaws.com\" \\n      }, \\n      \"Action\": \"sts:AssumeRole\", \\n      \"Condition\": { \\n        \"StringEquals\": { \\n          \"aws:SourceAccount\": \" accountId \"  \\n        }, \\n        \"ArnLike\": { \\n          \"aws:SourceArn\": \"arn:aws:bedrock: region:accountId :*\" \\n        } \\n      } \\n    } \\n  ]\\n} \\n                 \\nRole policy:\\n{ \\n    \"Version\": \"2012-10-17\",  \\n    \"Statement\": [  \\n        { \\n            \"Effect\": \"Allow\",  \\n            \"Action\": [  \\n                \"logs:CreateLogStream\",  \\n                \"logs:PutLogEvents\"  \\n            ],  \\n            \"Resource\": \"arn:aws:logs: region:accountId :log-group: logGroupName :log-\\nstream:aws/bedrock/modelinvocations\"  \\n         }  \\n    ]\\n} \\n                 \\nFor more information on setting up SSE for CloudWatch Logs, see Encrypt log data in CloudWatch \\nLogs using AWS Key Management Service.\\nSet up CloudWatch Logs destination 554Amazon Bedrock User Guide\\nUsing the console\\nTo enable model invocation logging, drag the slider button next to the Logging  toggle switch in \\nthe Settings page. Additional conﬁguration settings for logging will appear on the panel.\\nChoose which data requests and responses you want to publish to the logs. You can choose any \\ncombination of the following output options:\\n•Text\\n•Image\\n•Embedding\\nChoose where to publish the logs:\\n•Amazon S3 only\\n•CloudWatch Logs only\\n•Both Amazon S3 and CloudWatch Logs\\nAmazon S3 and CloudWatch Logs destinations are supported for invocation logs, and small \\ninput and output data. For large input and output data or binary image outputs, only Amazon \\nS3 is supported. The following details summarize how the data will be represented in the target \\nlocation.\\n•S3 destination  — Gzipped JSON ﬁles, each containing a batch of invocation log records, are \\ndelivered to the speciﬁed S3 bucket. Similar to a CloudWatch Logs event, each record will contain \\nthe invocation metadata, and input and output JSON bodies of up to 100 KB in size. Binary \\ndata or JSON bodies larger than 100 KB will be uploaded as individual objects in the speciﬁed \\nAmazon S3 bucket under the data preﬁx. The data can be queried using Amazon S3 Select and \\nAmazon Athena, and can be catalogued for ETL using AWS Glue. The data can be loaded into \\nOpenSearch service, or be processed by any Amazon EventBridge targets.\\n•CloudWatch Logs destination — JSON invocation log events are delivered to a speciﬁed log \\ngroup in CloudWatch Logs. The log event contains the invocation metadata, and input and \\noutput JSON bodies of up to 100 KB in size. If an Amazon S3 location for large data delivery is \\nprovided, binary data or JSON bodies larger than 100 KB will be uploaded to the Amazon S3 \\nbucket under the data preﬁx instead. data can be queried using CloudWatch Logs Insights, and \\ncan be further streamed to various services in real-time using CloudWatch Logs.\\nUsing the console 555Amazon Bedrock User Guide\\nUsing APIs with invocation logging\\nModel invocation logging can be conﬁgured using the following APIs:\\n•PutModelInvocationLoggingConfiguration\\n•GetModelInvocationLoggingConfiguration\\n•DeleteModelInvocationLoggingConfiguration\\nFor more information on how to use APIs with invocation logging, see the Bedrock API Guide.\\nMonitor Amazon Bedrock with Amazon CloudWatch\\nYou can monitor Amazon Bedrock using Amazon CloudWatch, which collects raw data and \\nprocesses it into readable, near real-time metrics. You can graph the metrics using the CloudWatch \\nconsole. You can also set alarms that watch for certain thresholds, and send notiﬁcations or take \\nactions when values exceed those thresholds.\\nFor more information, see What is Amazon CloudWatch in the Amazon CloudWatch User Guide.\\nTopics\\n•Runtime metrics\\n•Logging CloudWatch metrics\\n•Use CloudWatch metrics for Amazon Bedrock\\n•View Amazon Bedrock metrics\\nRuntime metrics\\nThe following table describes runtime metrics provided by Amazon Bedrock.\\nMetric name Unit Description\\nInvocations SampleCount Number of requests to the\\nInvokeModel or InvokeMod \\nelWithResponseStream API \\noperations.\\nUsing APIs with invocation logging 556Amazon Bedrock User Guide\\nMetric name Unit Description\\nInvocationLatencyMilliSeconds Latency of the invocations.\\nInvocationClientErrors SampleCount Number of invocations that \\nresult in client-side errors.\\nInvocationServerErrors SampleCount Number of invocations that \\nresult in AWS server-side \\nerrors.\\nInvocationThrottles SampleCount Number of invocations that \\nthe system throttled.\\nInputTokenCount SampleCount Number of tokens of text \\ninput.\\nLegacyModelInvocations SampleCount Number of invocations using\\nLegacy models\\nOutputTokenCount SampleCount Number of tokens of text \\noutput.\\nOutputImageCount SampleCount Number of output images.\\nLogging CloudWatch metrics\\nFor each delivery success or failure attempt, the following Amazon CloudWatch metrics are emitted \\nunder the namespace AWS/Bedrock , and Across all model IDs  dimension:\\n•ModelInvocationLogsCloudWatchDeliverySuccess\\n•ModelInvocationLogsCloudWatchDeliveryFailure\\n•ModelInvocationLogsS3DeliverySuccess\\n•ModelInvocationLogsS3DeliveryFailure\\n•ModelInvocationLargeDataS3DeliverySuccess\\n•ModelInvocationLargeDataS3DeliveryFailure\\nLogging CloudWatch metrics 557Amazon Bedrock User Guide\\nIf logs fail to deliver due to permission misconﬁguration or transient failures, the delivery is retried \\nperiodically for up to 24 hours.\\nUse CloudWatch metrics for Amazon Bedrock\\nTo retrieve metrics for your Amazon Bedrock operations, you specify the following information:\\n•The metric dimension. A dimension  is a set of name-value pairs that you use to identify a metric. \\nAmazon Bedrock supports the following dimensions:\\n•ModelId  – all metrics\\n•ModelId + ImageSize + BucketedStepSize  – OutputImageCount\\n•The metric name, such as InvocationClientErrors .\\nYou can get metrics for Amazon Bedrock with the AWS Management Console, the AWS CLI, or the \\nCloudWatch API. You can use the CloudWatch API through one of the AWS Software Development \\nKits (SDKs) or the CloudWatch API tools.\\nYou must have the appropriate CloudWatch permissions to monitor Amazon Bedrock with \\nCloudWatch For more information, see  Authentication and Access Control for Amazon CloudWatch\\nin the Amazon CloudWatch User Guide.\\nView Amazon Bedrock metrics\\nView Amazon Bedrock metrics in the CloudWatch console.\\nTo view metrics (CloudWatch console)\\n1. Sign in to the AWS Management Console and open the CloudWatch console at https:// \\nconsole.aws.amazon.com/cloudwatch/.\\n2. Choose Metrics , choose All Metrics , and then search for ModelId .\\nMonitor Amazon Bedrock events in Amazon EventBridge\\nYou can use Amazon EventBridge to monitor status change events in Amazon Bedrock. With \\nAmazon EventBridge, you can conﬁgure Amazon SageMaker to respond automatically to a model \\ncustomization job status change in Amazon Bedrock. Events from Amazon Bedrock are delivered \\nto Amazon EventBridge in near real time. You can write simple rules to automate actions when an \\nevent matches a rule. If you use Amazon EventBridge with Amazon Bedrock, you can:\\nUse CloudWatch metrics for Amazon Bedrock 558Amazon Bedrock User Guide\\n•Publish notiﬁcations whenever there is a state change event in the model customization you \\nhave triggered, whether you add new asynchronous workﬂows in the future. The event published \\nshould give you enough information to react to events in downstream workﬂows.\\n•Deliver job status updates without invoking the GetModelCustomizationJob API, which can mean \\nhandling API rate limit issues, API updates, and reduction in additional compute resources.\\nThere is no cost to receive AWS events from Amazon EventBridge. For more information about, \\nAmazon EventBridge, see Amazon EventBridge\\nNote\\n•Amazon Bedrock emits events on a best-eﬀort basis. Events are delivered to Amazon \\nEventBridge in near real time. With Amazon EventBridge, you can create rules that \\ntrigger programmatic actions in response to an event. For example, you can conﬁgure a \\nrule that invokes an SNS topic to send an email notiﬁcation or invokes a function to take \\nsome action. For more information, see the Amazon EventBridge User Guide .\\n•Amazon Bedrock creates a new event every time there is a state change in a model \\ncustomization job that you trigger and make best-eﬀort delivery of such event.\\nTopics\\n•How it works\\n•EventBridge schema\\n•Rules and targets\\n•Create a rule to handle Amazon Bedrock events\\nHow it works\\nTo receive events from Amazon Bedrock, you need to create rules and targets to match, receive, \\nand handle state change data through Amazon EventBridge. Amazon EventBridge is a serverless \\nevent bus that ingests change state events from AWS services, SaaS partners, and customer \\napplications. It processes events based on rules or patterns that you create, and routes these events \\nto one or more “targets” that you choose, such as AWS Lambda, Amazon Simple Queue Service, \\nand Amazon Simple Notiﬁcation Service.\\nHow it works 559Amazon Bedrock User Guide\\nAmazon Bedrock publishes your events via Amazon EventBridge whenever there is a change in \\nthe state of a model customization job. In each case, a new event is created and sent to Amazon \\nEventBridge, which then sends the event to your default event-bus. The event shows which \\ncustomization job’s state has changed, and the current state of the job. When Amazon EventBridge \\nreceives an event that matches a rule that you created, Amazon EventBridge routes it to the target \\nthat you speciﬁed. When you create a rule, you can conﬁgure these targets as well as downstream \\nworkﬂows based on the contents of the event.\\nEventBridge schema\\nThe following event ﬁelds in the EventBridge event schema are speciﬁc to Amazon Bedrock.\\n•jobArn  — The ARN of the model customization job.\\n•outputModelArn  — The ARN of the output model. Published when the training job has \\ncompleted.\\n•jobStatus  — The current status of the job.\\n•FailureMessage  — A failure message. Published when the training job has failed.\\nEvent example\\nThe folllowing is example event JSON for a failed model customization job.\\n{ \\n    \"version\": \"0\",  \\n    \"id\": \"UUID\",  \\n    \"detail-type\": \"Model Customization Job State Change\",  \\n    \"source\": \"aws.bedrock\",  \\n    \"account\": \"123412341234\",  \\n    \"time\": \"2023-08-11T12:34:56Z\",  \\n    \"region\": \"us-east-1\",  \\n    \"resources\": [ \"arn:aws:bedrock:us-east-1:123412341234:model-customization-job/\\nabcdefghwxyz\" ],  \\n    \"detail\": {  \\n        \"version\": \"0.0\", \\n        \"jobName\": \"abcd-wxyz\", \\n        \"jobArn\": \"arn:aws:bedrock:us-east-1:123412341234:model-customization-job/\\nabcdefghwxyz\", \\n        \"outputModelName\": \"dummy-output-model-name\", \\n        \"outputModelArn\": \"arn:aws:bedrock:us-east-1:123412341234:dummy-output-model-\\nname\", \\nEventBridge schema 560Amazon Bedrock User Guide\\n        \"roleArn\": \"arn:aws:iam::123412341234:role/JobExecutionRole\", \\n        \"jobStatus\": \"Failed\", \\n        \"failureMessage\": \"Failure Message here.\", \\n        \"creationTime\": \"2023-08-11T10:11:12Z\", \\n        \"lastModifiedTime\": \"2023-08-11T12:34:56Z\", \\n        \"endTime\": \"2023-08-11T12:34:56Z\", \\n        \"baseModelArn\": \"arn:aws:bedrock:us-east-1:123412341234:base-model-name\", \\n        \"hyperParameters\": { \\n            \"batchSize\" : \"batchSizeNumberUsed\", \\n            \"epochCount\": \"epochCountNumberUsed\", \\n            \"learningRate\": \"learningRateUsed\", \\n            \"learningRateWarmupSteps\": \"learningRateWarmupStepsUsed\" \\n            }, \\n        \"trainingDataConfig\": { \\n            \"s3Uri\": \"s3://bucket/key\", \\n            }, \\n        \"validationDataConfig\": { \\n            \"s3Uri\": \"s3://bucket/key\", \\n            }, \\n        \"outputDataConfig\": { \\n            \"s3Uri\": \"s3://bucket/key\", \\n            } \\n    }\\n}\\nRules and targets\\nWhen an incoming event matches a rule that you created, the event is routed to the target that you \\nspeciﬁed for that rule, and the target processes these events. Targets support JSON format and can \\ninclude AWS services such as Amazon EC2 instances, Lambda functions, Kinesis streams, Amazon \\nECS tasks, Step Functions, Amazon SNS topics, and Amazon SQS. To receive and process events \\ncorrectly, you need to create rules and targets for matching, receiving, and correctly handling event \\ndata. You can create these rules and targets either through the Amazon EventBridge console, or \\nthrough the AWS CLI.\\nExample rule\\nThis rule matches an event pattern emitted by: source [“aws.bedrock”] . The rule captures all \\nevents sent by Amazon EventBridge that have source “aws.bedrock” to your default event bus.\\n{ \\nRules and targets 561Amazon Bedrock User Guide\\n    \"source\": [\"aws.bedrock\"]\\n}\\nTarget\\nWhen creating a rule in Amazon EventBridge, you need to specify a target where EventBridge \\nsends the event that matches your rule pattern. These targets can be a SageMaker pipeline, \\na Lambda function, an SNS topic, an SQS queue or any of the other targets that EventBridge \\ncurrently supports. You can refer to the Amazon EventBridge  documentation to learn how to set \\ntargets for events. For a procedure that shows how to use Amazon Simple Notiﬁcation Service as a \\ntarget, see Create a rule to handle Amazon Bedrock events.\\nCreate a rule to handle Amazon Bedrock events\\nComplete the following procedures in order to receive email notiﬁcations about your Amazon \\nBedrock events.\\nCreate an Amazon Simple Notiﬁcation Service topic\\n1. Open the Amazon SNS console at https://console.aws.amazon.com/sns/v3/home.\\n2. In the navigation pane, choose Topics.\\n3. Choose Create topic .\\n4. For Type, choose Standard .\\n5. For Name , enter a name for your topic.\\n6. Choose Create topic .\\n7. Choose Create subscription .\\n8. For Protocol, choose Email .\\n9. For Endpoint , enter the email address that receives the notiﬁcations.\\n10. Choose Create subscription .\\n11. You\\'ll receive an email message with the following subject line: AWS Notification - \\nSubscription Confirmation . Follow the directions to conﬁrm your subscription.\\nUse the following procedure to create a rule to handle your Amazon Bedrock events.\\nTo create a rule to handle Amazon Bedrock events\\n1. Open the Amazon EventBridge console at https://console.aws.amazon.com/events/.\\nCreate a rule to handle Amazon Bedrock events 562Amazon Bedrock User Guide\\n2. Choose Create rule.\\n3. For Name , enter a name for your rule.\\n4. For Rule type, choose Rule with an event pattern.\\n5. Choose Next.\\n6. For Event pattern, do the following:\\na. For Event source, choose AWS services.\\nb. For AWS service, choose Amazon Bedrock.\\nc. For Event type, choose Model Customization Job State Change .\\nd. By default, we send notiﬁcations for every event. If you prefer, you can create an event \\npattern that ﬁlters events for a speciﬁc job state.\\ne. Choose Next.\\n7. Specify a target as follows:\\na. For Target types, choose AWS service.\\nb. For Select a target, choose SNS topic .\\nc. For Topic, choose the SNS topic that you created for notiﬁcations.\\nd. Choose Next.\\n8. (Optional) Add tags to your rule.\\n9. Choose Next.\\n10. Choose Create rule.\\nLog Amazon Bedrock API calls using AWS CloudTrail\\nAmazon Bedrock is integrated with AWS CloudTrail, a service that provides a record of actions \\ntaken by a user, role, or an AWS service in Amazon Bedrock. CloudTrail captures all API calls for \\nAmazon Bedrock as events. The calls captured include calls from the Amazon Bedrock console and \\ncode calls to the Amazon Bedrock API operations. If you create a trail, you can enable continuous \\ndelivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon Bedrock. If \\nyou don\\'t conﬁgure a trail, you can still view the most recent events in the CloudTrail console in\\nEvent history. Using the information collected by CloudTrail, you can determine the request that \\nwas made to Amazon Bedrock, the IP address from which the request was made, who made the \\nrequest, when it was made, and additional details.\\nCloudTrail logs 563Amazon Bedrock User Guide\\nTo learn more about CloudTrail, see the AWS CloudTrail User Guide.\\nAmazon Bedrock information in CloudTrail\\nCloudTrail is enabled on your AWS account when you create the account. When activity occurs \\nin Amazon Bedrock, that activity is recorded in a CloudTrail event along with other AWS service \\nevents in Event history. You can view, search, and download recent events in your AWS account. \\nFor more information, see Viewing events with CloudTrail Event history.\\nFor an ongoing record of events in your AWS account, including events for Amazon Bedrock, create \\na trail. A trail enables CloudTrail to deliver log ﬁles to an Amazon S3 bucket. By default, when \\nyou create a trail in the console, the trail applies to all AWS Regions. The trail logs events from all \\nRegions in the AWS partition and delivers the log ﬁles to the Amazon S3 bucket that you specify. \\nAdditionally, you can conﬁgure other AWS services to further analyze and act upon the event data \\ncollected in CloudTrail logs. For more information, see the following:\\n•Overview for creating a trail\\n•CloudTrail supported services and integrations\\n•Conﬁguring Amazon SNS notiﬁcations for CloudTrail\\n•Receiving CloudTrail log ﬁles from multiple regions and Receiving CloudTrail log ﬁles from \\nmultiple accounts\\nEvery event or log entry contains information about who generated the request. The identity \\ninformation helps you determine the following:\\n•Whether the request was made with root or AWS Identity and Access Management (IAM) user \\ncredentials.\\n•Whether the request was made with temporary security credentials for a role or federated user.\\n•Whether the request was made by another AWS service.\\nFor more information, see the CloudTrail userIdentity element.\\nAmazon Bedrock data events in CloudTrail\\nData events provide information about the resource operations performed on or in a resource \\n(for example, reading or writing to an Amazon S3 object). These are also known as data plane \\noperations. Data events are often high-volume activities that CloudTrail doesn’t log by default.\\nAmazon Bedrock information in CloudTrail 564Amazon Bedrock User Guide\\nAmazon Bedrock doesn\\'t log Amazon Bedrock Runtime API operations (InvokeModel  and\\nInvokeModelWithResponseStream ).\\nAmazon Bedrock logs all Agents for Amazon Bedrock Runtime API operations actions to CloudTrail \\nas data events .\\n•To log InvokeAgent calls, conﬁgure advanced event selectors to record data events for the\\nAWS::Bedrock::AgentAlias  resource type.\\n•To log Retrieve and RetrieveAndGenerate calls, conﬁgure advanced event selectors to record data \\nevents for the AWS::Bedrock::KnowledgeBase  resource type.\\nFrom the CloudTrail console, choose Bedrock agent alias  or Bedrock knowledge base for the Data \\nevent type. You can additionally ﬁlter on the eventName  and resources.ARN  ﬁelds by choosing \\na custom log selector template. For more information, see Logging data events with the AWS \\nManagement Console .\\nFrom the AWS CLI, set the resource.type  value equal to AWS::Bedrock::AgentAlias\\nor AWS::Bedrock::KnowledgeBase  and set the eventCategory  equal to Data. For more \\ninformation, see Logging data events with the AWS CLI.\\nThe following example shows how to conﬁgure a trail to log all Amazon Bedrock data events for all \\nAmazon Bedrock resource types in the AWS CLI.\\naws cloudtrail put-event-selectors --trail-name trailName  \\\\\\n--advanced-event-selectors \\\\\\n\\'[ \\n  { \\n    \"Name\": \"Log all data events on an Agents for Amazon Bedrock agent alias\", \\n    \"FieldSelectors\": [ \\n      { \"Field\": \"eventCategory\", \"Equals\": [\"Data\"] }, \\n      { \"Field\": \"resources.type\", \"Equals\": [\"AWS::Bedrock::AgentAlias\"] } \\n    ] \\n  }, \\n  { \\n    \"Name\": \"Log all data events on an Agents for Amazon Bedrock knowledge base\", \\n    \"FieldSelectors\": [ \\n      { \"Field\": \"eventCategory\", \"Equals\": [\"Data\"] }, \\n      { \"Field\": \"resources.type\", \"Equals\": [\"AWS::Bedrock::KnowledgeBase\"] } \\n    ] \\n  }\\nAmazon Bedrock data events in CloudTrail 565Amazon Bedrock User Guide\\n]\\'\\nYou can additionally ﬁlter on the eventName  and resources.ARN  ﬁelds. For more information \\nabout these ﬁelds, see AdvancedFieldSelector.\\nAdditional charges apply for data events. For more information about CloudTrail pricing, see AWS \\nCloudTrail Pricing.\\nAmazon Bedrock management events in CloudTrail\\nManagement events provide information about management operations that are performed on \\nresources in your AWS account. These are also known as control plane operations. CloudTrail logs \\nmanagement event API operations by default.\\nAmazon Bedrock logs the remainder of Amazon Bedrock API operations as management events. \\nFor a list of the Amazon Bedrock API operations that Amazon Bedrock logs to CloudTrail, see the \\nfollowing pages in the Amazon Bedrock API reference.\\nAll Amazon Bedrock API operations and Agents for Amazon Bedrock API operations are logged \\nby CloudTrail and documented in the Amazon Bedrock API Reference. For example, calls to the\\nInvokeModel , StopModelCustomizationJob , and CreateAgent  actions generate entries in \\nthe CloudTrail log ﬁles.\\nUnderstanding Amazon Bedrock log ﬁle entries\\nA trail is a conﬁguration that enables delivery of events as log ﬁles to an Amazon S3 bucket that \\nyou specify. CloudTrail log ﬁles contain one or more log entries. An event represents a single \\nrequest from any source and includes information about the requested action, the date and time of \\nthe action, request parameters, and so on. CloudTrail log ﬁles aren\\'t an ordered stack trace of the \\npublic API calls, so they don\\'t appear in any speciﬁc order.\\nThe following example shows a CloudTrail log entry that demonstrates the InvokeModel  action.\\n{ \\n    \"eventVersion\": \"1.08\", \\n    \"userIdentity\": { \\n        \"type\": \"IAMUser\", \\n        \"principalId\": \"AROAICFHPEXAMPLE\", \\n        \"arn\": \"arn:aws:iam::111122223333:user/userxyz\", \\n        \"accountId\": \"111122223333\", \\nAmazon Bedrock management events in CloudTrail 566Amazon Bedrock User Guide\\n        \"accessKeyId\": \"AKIAIOSFODNN7EXAMPLE\", \\n        \"userName\": \"userxyz\" \\n    }, \\n    \"eventTime\": \"2023-10-11T21:58:59Z\", \\n    \"eventSource\": \"bedrock.amazonaws.com\", \\n    \"eventName\": \"InvokeModel\", \\n    \"awsRegion\": \"us-west-2\", \\n    \"sourceIPAddress\": \"192.0.2.0\", \\n    \"userAgent\": \"Boto3/1.28.62 md/Botocore#1.31.62 ua/2.0 os/macos#22.6.0 md/\\narch#arm64 lang/python#3.9.6 md/pyimpl#CPython cfg/retry-mode#legacy Botocore/1.31.62\", \\n    \"requestParameters\": { \\n        \"modelId\": \"stability.stable-diffusion-xl-v0\" \\n    }, \\n    \"responseElements\": null, \\n    \"requestID\": \"a1b2c3d4-5678-90ab-cdef-EXAMPLE22222\", \\n    \"eventID\": \"a1b2c3d4-5678-90ab-cdef-EXAMPLE11111 \", \\n    \"readOnly\": false, \\n    \"eventType\": \"AwsApiCall\", \\n    \"managementEvent\": true, \\n    \"recipientAccountId\": \"111122223333\", \\n    \"eventCategory\": \"Management\", \\n    \"tlsDetails\": { \\n        \"tlsVersion\": \"TLSv1.2\", \\n        \"cipherSuite\": \"cipher suite\", \\n        \"clientProvidedHostHeader\": \"bedrock-runtime.us-west-2.amazonaws.com\" \\n    }\\n}\\nUnderstanding Amazon Bedrock log ﬁle entries 567Amazon Bedrock User Guide\\nCode examples for Amazon Bedrock using AWS SDKs\\nThe following code examples show how to use Amazon Bedrock with an AWS software \\ndevelopment kit (SDK).\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nCode examples\\n•Code examples for Amazon Bedrock using AWS SDKs\\n•Actions for Amazon Bedrock using AWS SDKs\\n•Get details about an Amazon Bedrock foundation model using an AWS SDK\\n•List the available Amazon Bedrock foundation models using an AWS SDK\\n•Scenarios for Amazon Bedrock using AWS SDKs\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\n•Code examples for Amazon Bedrock Runtime using AWS SDKs\\n•Actions for Amazon Bedrock Runtime using AWS SDKs\\n•Invoke the Amazon Titan Image Generator G1 model on Amazon Bedrock for image \\ngeneration\\n•Invoke the Stability.ai Stable Diﬀusion XL model on Amazon Bedrock for image generation\\n•Invoke Anthropic Claude 3 on Amazon Bedrock with a multimodal prompt\\n•Invoke the AI21 Labs Jurassic-2 model on Amazon Bedrock for text generation\\n•Invoke the Amazon Titan Text G1 model on Amazon Bedrock for text generation\\n•Invoke the Anthropic Claude 2 model on Amazon Bedrock for text generation\\n•Invoke the Anthropic Claude 2 model on Amazon Bedrock for text generation with a \\nresponse stream\\n•Invoke Anthropic Claude 3 on Amazon Bedrock to generate text\\n•Invoke the Meta Llama 2 Chat model on Amazon Bedrock for text generation\\n•Invoke the Mistral 7B model on Amazon Bedrock for text generation\\n•Invoke the Mixtral 8x7B model on Amazon Bedrock for text generation\\n•Scenarios for Amazon Bedrock Runtime using AWS SDKs568Amazon Bedrock User Guide\\n•Create a sample application that oﬀers playgrounds to interact with Amazon Bedrock \\nfoundation models using an AWS SDK\\n•Invoke multiple large-language models (LLMs) on Amazon Bedrock\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\n•Code examples for Agents for Amazon Bedrock using AWS SDKs\\n•Actions for Agents for Amazon Bedrock using AWS SDKs\\n•Create an Amazon Bedrock agent using an AWS SDK\\n•Create an Amazon Bedrock agent action group using an AWS SDK\\n•Create an Amazon Bedrock agent alias using an AWS SDK\\n•Delete an Amazon Bedrock agent using an AWS SDK\\n•Delete an Amazon Bedrock agent alias using an AWS SDK\\n•Get information about an Amazon Bedrock agent using an AWS SDK\\n•List the action groups for a Amazon Bedrock agent using an AWS SDK\\n•List the Agents for Amazon Bedrock belonging to an account using an AWS SDK\\n•List the knowledge bases associated with a Amazon Bedrock agent using an AWS SDK\\n•Prepare an Amazon Bedrock agent using an AWS SDK\\n•Scenarios for Agents for Amazon Bedrock using AWS SDKs\\n•An end-to-end example showing how to create and invoke Amazon Bedrock agents using \\nan AWS SDK\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\n•Code examples for Agents for Amazon Bedrock Runtime using AWS SDKs\\n•Actions for Agents for Amazon Bedrock Runtime using AWS SDKs\\n•Invoke an Amazon Bedrock agent using an AWS SDK\\n•Scenarios for Agents for Amazon Bedrock Runtime using AWS SDKs\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nCode examples for Amazon Bedrock using AWS SDKs\\nThe following code examples show how to use Amazon Bedrock with an AWS software \\ndevelopment kit (SDK).Amazon Bedrock 569Amazon Bedrock User Guide\\nActions  are code excerpts from larger programs and must be run in context. While actions show you \\nhow to call individual service functions, you can see actions in context in their related scenarios and \\ncross-service examples.\\nScenarios  are code examples that show you how to accomplish a speciﬁc task by calling multiple \\nfunctions within the same service.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nGet started\\nHello Amazon Bedrock\\nThe following code examples show how to get started using Amazon Bedrock.\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nusing Amazon;\\nusing Amazon.Bedrock;\\nusing Amazon.Bedrock.Model;\\nnamespace ListFoundationModelsExample\\n{ \\n    /// <summary> \\n    /// This example shows how to list foundation models. \\n    /// </summary> \\n    internal class HelloBedrock \\n    { \\n        /// <summary> \\n        /// Main method to call the ListFoundationModelsAsync method. \\n        /// </summary> \\n        /// <param name=\"args\"> The command line arguments. </param> \\nAmazon Bedrock 570Amazon Bedrock User Guide\\n        static async Task Main(string[] args) \\n        { \\n            // Specify a region endpoint where Amazon Bedrock is available. \\n For a list of supported region see https://docs.aws.amazon.com/bedrock/latest/\\nuserguide/what-is-bedrock.html#bedrock-regions \\n            AmazonBedrockClient bedrockClient = new(RegionEndpoint.USWest2); \\n            await ListFoundationModelsAsync(bedrockClient); \\n        } \\n        /// <summary> \\n        /// List foundation models. \\n        /// </summary> \\n        /// <param name=\"bedrockClient\"> The Amazon Bedrock client. </param> \\n        private static async Task ListFoundationModelsAsync(AmazonBedrockClient \\n bedrockClient) \\n        { \\n            Console.WriteLine(\"List foundation models with no filter\"); \\n            try \\n            { \\n                ListFoundationModelsResponse response = await \\n bedrockClient.ListFoundationModelsAsync(new ListFoundationModelsRequest() \\n                { \\n                }); \\n                if (response?.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    foreach (var fm in response.ModelSummaries) \\n                    { \\n                        WriteToConsole(fm); \\n                    } \\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"Something wrong happened\"); \\n                } \\n            } \\n            catch (AmazonBedrockException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\nAmazon Bedrock 571Amazon Bedrock User Guide\\n        } \\n        /// <summary> \\n        /// Write the foundation model summary to console. \\n        /// </summary> \\n        /// <param name=\"foundationModel\"> The foundation model summary to write \\n to console. </param> \\n        private static void WriteToConsole(FoundationModelSummary \\n foundationModel) \\n        { \\n            Console.WriteLine($\"{foundationModel.ModelId}, Customization: \\n {String.Join(\", \", foundationModel.CustomizationsSupported)}, Stream: \\n {foundationModel.ResponseStreamingSupported}, Input: {String.Join(\", \\n \", foundationModel.InputModalities)}, Output: {String.Join(\", \", \\n foundationModel.OutputModalities)}\"); \\n        } \\n    }\\n}\\n•For API details, see ListFoundationModels in AWS SDK for .NET API Reference.\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\npackage main\\nimport ( \\n \"context\" \\n \"fmt\" \\n \"github.com/aws/aws-sdk-go-v2/config\" \\n \"github.com/aws/aws-sdk-go-v2/service/bedrock\"\\nAmazon Bedrock 572Amazon Bedrock User Guide\\n)\\nconst region = \"us-east-1\"\\n// main uses the AWS SDK for Go (v2) to create an Amazon Bedrock client and\\n// list the available foundation models in your account and the chosen region.\\n// This example uses the default settings specified in your shared credentials\\n// and config files.\\nfunc main() { \\n    sdkConfig, err := config.LoadDefaultConfig(context.TODO(), \\n config.WithRegion(region)) \\n    if err != nil { \\n        fmt.Println(\"Couldn\\'t load default configuration. Have you set up your \\n AWS account?\") \\n        fmt.Println(err) \\n        return \\n    } \\n    bedrockClient := bedrock.NewFromConfig(sdkConfig) \\n    result, err := bedrockClient.ListFoundationModels(context.TODO(), \\n &bedrock.ListFoundationModelsInput{}) \\n    if err != nil { \\n  fmt.Printf(\"Couldn\\'t list foundation models. Here\\'s why: %v\\\\n\", err) \\n  return \\n    } \\n    if len(result.ModelSummaries) == 0 { \\n    fmt.Println(\"There are no foundation models.\")} \\n    for _, modelSummary := range result.ModelSummaries { \\n        fmt.Println(*modelSummary.ModelId) \\n    }\\n}\\n•For API details, see ListFoundationModels in AWS SDK for Go API Reference.\\nAmazon Bedrock 573Amazon Bedrock User Guide\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  BedrockClient, \\n  ListFoundationModelsCommand,\\n} from \"@aws-sdk/client-bedrock\";\\nconst REGION = \"us-east-1\";\\nconst client = new BedrockClient({ region: REGION });\\nexport const main = async () => { \\n  const command = new ListFoundationModelsCommand({}); \\n  const response = await client.send(command); \\n  const models = response.modelSummaries; \\n  console.log(\"Listing the available Bedrock foundation models:\"); \\n  for (let model of models) { \\n    console.log(\"=\".repeat(42)); \\n    console.log(` Model: ${model.modelId}`); \\n    console.log(\"-\".repeat(42)); \\n    console.log(` Name: ${model.modelName}`); \\n    console.log(` Provider: ${model.providerName}`); \\n    console.log(` Model ARN: ${model.modelArn}`); \\n    console.log(` Input modalities: ${model.inputModalities}`); \\n    console.log(` Output modalities: ${model.outputModalities}`); \\n    console.log(` Supported customizations: ${model.customizationsSupported}`); \\n    console.log(` Supported inference types: ${model.inferenceTypesSupported}`); \\nAmazon Bedrock 574Amazon Bedrock User Guide\\n    console.log(` Lifecycle status: ${model.modelLifecycle.status}`); \\n    console.log(\"=\".repeat(42) + \"\\\\n\"); \\n  } \\n  const active = models.filter( \\n    (m) => m.modelLifecycle.status === \"ACTIVE\", \\n  ).length; \\n  const legacy = models.filter( \\n    (m) => m.modelLifecycle.status === \"LEGACY\", \\n  ).length; \\n  console.log( \\n    `There are ${active} active and ${legacy} legacy foundation models in \\n ${REGION}.`, \\n  ); \\n  return response;\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  await main();\\n}\\n•For API details, see ListFoundationModels in AWS SDK for JavaScript API Reference.\\nCode examples\\n•Actions for Amazon Bedrock using AWS SDKs\\n•Get details about an Amazon Bedrock foundation model using an AWS SDK\\n•List the available Amazon Bedrock foundation models using an AWS SDK\\n•Scenarios for Amazon Bedrock using AWS SDKs\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nActions for Amazon Bedrock using AWS SDKs\\nThe following code examples demonstrate how to perform individual Amazon Bedrock actions \\nwith AWS SDKs. These excerpts call the Amazon Bedrock API and are code excerpts from larger \\nActions 575Amazon Bedrock User Guide\\nprograms that must be run in context. Each example includes a link to GitHub, where you can ﬁnd \\ninstructions for setting up and running the code.\\nThe following examples include only the most commonly used actions. For a complete list, see the\\nAmazon Bedrock API Reference.\\nExamples\\n•Get details about an Amazon Bedrock foundation model using an AWS SDK\\n•List the available Amazon Bedrock foundation models using an AWS SDK\\nGet details about an Amazon Bedrock foundation model using an AWS SDK\\nThe following code examples show how to get details about an Amazon Bedrock foundation \\nmodel.\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nGet details about a foundation model using the synchronous Amazon Bedrock client.\\n    /** \\n     * Get details about an Amazon Bedrock foundation model. \\n     * \\n     * @param bedrockClient   The service client for accessing Amazon Bedrock. \\n     * @param modelIdentifier The model identifier. \\n     * @return An object containing the foundation model\\'s details. \\n     */ \\n    public static FoundationModelDetails getFoundationModel(BedrockClient \\n bedrockClient, String modelIdentifier) { \\n        try { \\n            GetFoundationModelResponse response = \\n bedrockClient.getFoundationModel( \\n                    r -> r.modelIdentifier(modelIdentifier) \\nActions 576Amazon Bedrock User Guide\\n            ); \\n            FoundationModelDetails model = response.modelDetails(); \\n            System.out.println(\" Model ID:                     \" + \\n model.modelId()); \\n            System.out.println(\" Model ARN:                    \" + \\n model.modelArn()); \\n            System.out.println(\" Model Name:                   \" + \\n model.modelName()); \\n            System.out.println(\" Provider Name:                \" + \\n model.providerName()); \\n            System.out.println(\" Lifecycle status:             \" + \\n model.modelLifecycle().statusAsString()); \\n            System.out.println(\" Input modalities:             \" + \\n model.inputModalities()); \\n            System.out.println(\" Output modalities:            \" + \\n model.outputModalities()); \\n            System.out.println(\" Supported customizations:     \" + \\n model.customizationsSupported()); \\n            System.out.println(\" Supported inference types:    \" + \\n model.inferenceTypesSupported()); \\n            System.out.println(\" Response streaming supported: \" + \\n model.responseStreamingSupported()); \\n            return model; \\n        } catch (ValidationException e) { \\n            throw new IllegalArgumentException(e.getMessage()); \\n        } catch (SdkException e) { \\n            System.err.println(e.getMessage()); \\n            throw new RuntimeException(e); \\n        } \\n    }\\nGet details about a foundation model using the asynchronous Amazon Bedrock client.\\n    /** \\n     * Get details about an Amazon Bedrock foundation model. \\n     * \\n     * @param bedrockClient   The async service client for accessing Amazon \\n Bedrock. \\nActions 577Amazon Bedrock User Guide\\n     * @param modelIdentifier The model identifier. \\n     * @return An object containing the foundation model\\'s details. \\n     */ \\n    public static FoundationModelDetails getFoundationModel(BedrockAsyncClient \\n bedrockClient, String modelIdentifier) { \\n        try { \\n            CompletableFuture<GetFoundationModelResponse> future = \\n bedrockClient.getFoundationModel( \\n                    r -> r.modelIdentifier(modelIdentifier) \\n            ); \\n            FoundationModelDetails model = future.get().modelDetails(); \\n            System.out.println(\" Model ID:                     \" + \\n model.modelId()); \\n            System.out.println(\" Model ARN:                    \" + \\n model.modelArn()); \\n            System.out.println(\" Model Name:                   \" + \\n model.modelName()); \\n            System.out.println(\" Provider Name:                \" + \\n model.providerName()); \\n            System.out.println(\" Lifecycle status:             \" + \\n model.modelLifecycle().statusAsString()); \\n            System.out.println(\" Input modalities:             \" + \\n model.inputModalities()); \\n            System.out.println(\" Output modalities:            \" + \\n model.outputModalities()); \\n            System.out.println(\" Supported customizations:     \" + \\n model.customizationsSupported()); \\n            System.out.println(\" Supported inference types:    \" + \\n model.inferenceTypesSupported()); \\n            System.out.println(\" Response streaming supported: \" + \\n model.responseStreamingSupported()); \\n            return model; \\n        } catch (ExecutionException e) { \\n            if (e.getMessage().contains(\"ValidationException\")) { \\n                throw new IllegalArgumentException(e.getMessage()); \\n            } else { \\n                System.err.println(e.getMessage()); \\n                throw new RuntimeException(e); \\n            } \\n        } catch (InterruptedException e) { \\nActions 578Amazon Bedrock User Guide\\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n            throw new RuntimeException(e); \\n        } \\n    }\\n•For API details, see GetFoundationModel in AWS SDK for Java 2.x API Reference.\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nGet details about a foundation model.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  BedrockClient, \\n  GetFoundationModelCommand,\\n} from \"@aws-sdk/client-bedrock\";\\n/** \\n * Get details about an Amazon Bedrock foundation model. \\n * \\n * @return {FoundationModelDetails} - The list of available bedrock foundation \\n models. \\n */\\nexport const getFoundationModel = async () => { \\n  const client = new BedrockClient(); \\n  const command = new GetFoundationModelCommand({ \\n    modelIdentifier: \"amazon.titan-embed-text-v1\", \\nActions 579Amazon Bedrock User Guide\\n  }); \\n  const response = await client.send(command); \\n  return response.modelDetails;\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  const model = await getFoundationModel(); \\n  console.log(model);\\n}\\n•For API details, see GetFoundationModel in AWS SDK for JavaScript API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nGet details about a foundation model.\\n    def get_foundation_model(self, model_identifier): \\n        \"\"\" \\n        Get details about an Amazon Bedrock foundation model. \\n        :return: The foundation model\\'s details. \\n        \"\"\" \\n        try: \\n            return self.bedrock_client.get_foundation_model( \\n                modelIdentifier=model_identifier \\n            )[\"modelDetails\"] \\n        except ClientError: \\n            logger.error( \\n                f\"Couldn\\'t get foundation models details for {model_identifier}\" \\nActions 580Amazon Bedrock User Guide\\n            ) \\n            raise\\n•For API details, see GetFoundationModel in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nList the available Amazon Bedrock foundation models using an AWS SDK\\nThe following code examples show how to list available Amazon Bedrock foundation models.\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the available Bedrock foundation models.\\n        /// <summary> \\n        /// List foundation models. \\n        /// </summary> \\n        /// <param name=\"bedrockClient\"> The Amazon Bedrock client. </param> \\n        private static async Task ListFoundationModelsAsync(AmazonBedrockClient \\n bedrockClient) \\n        { \\n            Console.WriteLine(\"List foundation models with no filter\"); \\n            try \\n            { \\n                ListFoundationModelsResponse response = await \\n bedrockClient.ListFoundationModelsAsync(new ListFoundationModelsRequest() \\nActions 581Amazon Bedrock User Guide\\n                { \\n                }); \\n                if (response?.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    foreach (var fm in response.ModelSummaries) \\n                    { \\n                        WriteToConsole(fm); \\n                    } \\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"Something wrong happened\"); \\n                } \\n            } \\n            catch (AmazonBedrockException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\n        }\\n•For API details, see ListFoundationModels in AWS SDK for .NET API Reference.\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the available Bedrock foundation models.\\n// FoundationModelWrapper encapsulates Amazon Bedrock actions used in the \\n examples.\\n// It contains a Bedrock service client that is used to perform foundation model \\n actions.\\nActions 582Amazon Bedrock User Guide\\ntype FoundationModelWrapper struct { \\n BedrockClient *bedrock.Client\\n}\\n// ListPolicies lists Bedrock foundation models that you can use.\\nfunc (wrapper FoundationModelWrapper) ListFoundationModels() \\n ([]types.FoundationModelSummary, error) { \\n    var models []types.FoundationModelSummary \\n    result, err := wrapper.BedrockClient.ListFoundationModels(context.TODO(), \\n &bedrock.ListFoundationModelsInput{}) \\n    if err != nil { \\n        log.Printf(\"Couldn\\'t list foundation models. Here\\'s why: %v\\\\n\", err) \\n    } else { \\n        models = result.ModelSummaries \\n    } \\n    return models, err\\n}\\n•For API details, see ListFoundationModels in AWS SDK for Go API Reference.\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the available Amazon Bedrock foundation models using the synchronous Amazon \\nBedrock client.\\n    /** \\nActions 583Amazon Bedrock User Guide\\n     * Lists Amazon Bedrock foundation models that you can use. \\n     * You can filter the results with the request parameters. \\n     * \\n     * @param bedrockClient The service client for accessing Amazon Bedrock. \\n     * @return A list of objects containing the foundation models\\' details \\n     */ \\n    public static List<FoundationModelSummary> listFoundationModels(BedrockClient \\n bedrockClient) { \\n        try { \\n            ListFoundationModelsResponse response = \\n bedrockClient.listFoundationModels(r -> {}); \\n            List<FoundationModelSummary> models = response.modelSummaries(); \\n            if (models.isEmpty()) { \\n                System.out.println(\"No available foundation models in \" + \\n region.toString()); \\n            } else { \\n                for (FoundationModelSummary model : models) { \\n                    System.out.println(\"Model ID: \" + model.modelId()); \\n                    System.out.println(\"Provider: \" + model.providerName()); \\n                    System.out.println(\"Name:     \" + model.modelName()); \\n                    System.out.println(); \\n                } \\n            } \\n            return models; \\n        } catch (SdkClientException e) { \\n            System.err.println(e.getMessage()); \\n            throw new RuntimeException(e); \\n        } \\n    }\\nList the available Amazon Bedrock foundation models using the asynchronous Amazon \\nBedrock client.\\n    /** \\n     * Lists Amazon Bedrock foundation models that you can use. \\n     * You can filter the results with the request parameters. \\n     * \\nActions 584Amazon Bedrock User Guide\\n     * @param bedrockClient The async service client for accessing Amazon \\n Bedrock. \\n     * @return A list of objects containing the foundation models\\' details \\n     */ \\n    public static List<FoundationModelSummary> \\n listFoundationModels(BedrockAsyncClient bedrockClient) { \\n        try { \\n            CompletableFuture<ListFoundationModelsResponse> future = \\n bedrockClient.listFoundationModels(r -> {}); \\n            List<FoundationModelSummary> models = future.get().modelSummaries(); \\n            if (models.isEmpty()) { \\n                System.out.println(\"No available foundation models in \" + \\n region.toString()); \\n            } else { \\n                for (FoundationModelSummary model : models) { \\n                    System.out.println(\"Model ID: \" + model.modelId()); \\n                    System.out.println(\"Provider: \" + model.providerName()); \\n                    System.out.println(\"Name:     \" + model.modelName()); \\n                    System.out.println(); \\n                } \\n            } \\n            return models; \\n        } catch (InterruptedException e) { \\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n            throw new RuntimeException(e); \\n        } catch (ExecutionException e) { \\n            System.err.println(e.getMessage()); \\n            throw new RuntimeException(e); \\n        } \\n    }\\n•For API details, see ListFoundationModels in AWS SDK for Java 2.x API Reference.\\nActions 585Amazon Bedrock User Guide\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the available foundation models.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  BedrockClient, \\n  ListFoundationModelsCommand,\\n} from \"@aws-sdk/client-bedrock\";\\n/** \\n * List the available Amazon Bedrock foundation models. \\n * \\n * @return {FoundationModelSummary[]} - The list of available bedrock foundation \\n models. \\n */\\nexport const listFoundationModels = async () => { \\n  const client = new BedrockClient(); \\n  const input = { \\n    // byProvider: \\'STRING_VALUE\\', \\n    // byCustomizationType: \\'FINE_TUNING\\' || \\'CONTINUED_PRE_TRAINING\\', \\n    // byOutputModality: \\'TEXT\\' || \\'IMAGE\\' || \\'EMBEDDING\\', \\n    // byInferenceType: \\'ON_DEMAND\\' || \\'PROVISIONED\\', \\n  }; \\n  const command = new ListFoundationModelsCommand(input); \\n  const response = await client.send(command); \\n  return response.modelSummaries;\\nActions 586Amazon Bedrock User Guide\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  const models = await listFoundationModels(); \\n  console.log(models);\\n}\\n•For API details, see ListFoundationModels in AWS SDK for JavaScript API Reference.\\nKotlin\\nSDK for Kotlin\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the available Amazon Bedrock foundation models.\\nsuspend fun listFoundationModels(): List<FoundationModelSummary>? { \\n    BedrockClient { region = \"us-east-1\" }.use { bedrockClient -> \\n        val response = \\n bedrockClient.listFoundationModels(ListFoundationModelsRequest {}) \\n        response.modelSummaries?.forEach { model -> \\n            println(\"==========================================\") \\n            println(\" Model ID: ${model.modelId}\") \\n            println(\"------------------------------------------\") \\n            println(\" Name: ${model.modelName}\") \\n            println(\" Provider: ${model.providerName}\") \\n            println(\" Input modalities: ${model.inputModalities}\") \\n            println(\" Output modalities: ${model.outputModalities}\") \\n            println(\" Supported customizations: \\n ${model.customizationsSupported}\") \\n            println(\" Supported inference types: \\n ${model.inferenceTypesSupported}\") \\n            println(\"------------------------------------------\\\\n\") \\n        } \\n        return response.modelSummaries \\nActions 587Amazon Bedrock User Guide\\n    }\\n}\\n•For API details, see ListFoundationModels in AWS SDK for Kotlin API reference.\\nPHP\\nSDK for PHP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the available Amazon Bedrock foundation models.\\n    public function listFoundationModels() \\n    { \\n        $result = $this->bedrockClient->listFoundationModels(); \\n        return $result; \\n    }\\n•For API details, see ListFoundationModels in AWS SDK for PHP API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the available Amazon Bedrock foundation models.\\n    def list_foundation_models(self): \\nActions 588Amazon Bedrock User Guide\\n        \"\"\" \\n        List the available Amazon Bedrock foundation models. \\n        :return: The list of available bedrock foundation models. \\n        \"\"\" \\n        try: \\n            response = self.bedrock_client.list_foundation_models() \\n            models = response[\"modelSummaries\"] \\n            logger.info(\"Got %s foundation models.\", len(models)) \\n            return models \\n        except ClientError: \\n            logger.error(\"Couldn\\'t list foundation models.\") \\n            raise\\n•For API details, see ListFoundationModels in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nScenarios for Amazon Bedrock using AWS SDKs\\nThe following code examples show you how to implement common scenarios in Amazon Bedrock \\nwith AWS SDKs. These scenarios show you how to accomplish speciﬁc tasks by calling multiple \\nfunctions within Amazon Bedrock. Each scenario includes a link to GitHub, where you can ﬁnd \\ninstructions on how to set up and run the code.\\nExamples\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nBuild and orchestrate generative AI applications with Amazon Bedrock and Step \\nFunctions\\nThe following code example shows how to build and orchestrate generative AI applications with \\nAmazon Bedrock and Step Functions.\\nScenarios 589Amazon Bedrock User Guide\\nPython\\nSDK for Python (Boto3)\\nThe Amazon Bedrock Serverless Prompt Chaining scenario demonstrates how AWS Step \\nFunctions, Amazon Bedrock, and Agents for Amazon Bedrock can be used to build and \\norchestrate complex, serverless, and highly scalable generative AI applications. It contains \\nthe following working examples:\\n•Write an analysis of a given novel for a literature blog. This example illustrates a simple, \\nsequential chain of prompts.\\n•Generate a short story about a given topic. This example illustrates how the AI can \\niteratively process a list of items that it previously generated.\\n•Create an itinerary for a weekend vacation to a given destination. This example illustrates \\nhow to parallelize multiple distinct prompts.\\n•Pitch movie ideas to a human user acting as a movie producer. This example illustrates \\nhow to parallelize the same prompt with diﬀerent inference parameters, how to backtrack \\nto a previous step in the chain, and how to include human input as part of the workﬂow.\\n•Plan a meal based on ingredients the user has at hand. This example illustrates how \\nprompt chains can incorporate two distinct AI conversations, with two AI personas \\nengaging in a debate with each other to improve the ﬁnal outcome.\\n•Find and summarize today\\'s highest trending GitHub repository. This example illustrates \\nchaining multiple AI agents that interact with external APIs.\\nFor complete source code and instructions to set up and run, see the full project on GitHub .\\nServices used in this example\\n•Amazon Bedrock\\n•Amazon Bedrock Runtime\\n•Agents for Amazon Bedrock\\n•Agents for Amazon Bedrock Runtime\\n•Step Functions\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nScenarios 590Amazon Bedrock User Guide\\nCode examples for Amazon Bedrock Runtime using AWS SDKs\\nThe following code examples show how to use Amazon Bedrock Runtime with an AWS software \\ndevelopment kit (SDK).\\nActions  are code excerpts from larger programs and must be run in context. While actions show you \\nhow to call individual service functions, you can see actions in context in their related scenarios and \\ncross-service examples.\\nScenarios  are code examples that show you how to accomplish a speciﬁc task by calling multiple \\nfunctions within the same service.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nGet started\\nHello Amazon Bedrock\\nThe following code example shows how to get started using Amazon Bedrock.\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\npackage main\\nimport ( \\n \"context\" \\n \"encoding/json\" \\n \"flag\" \\n \"fmt\" \\n \"log\" \\n \"os\" \\nAmazon Bedrock Runtime 591Amazon Bedrock User Guide\\n \"strings\" \\n \"github.com/aws/aws-sdk-go-v2/aws\" \\n \"github.com/aws/aws-sdk-go-v2/config\" \\n \"github.com/aws/aws-sdk-go-v2/service/bedrockruntime\"\\n)\\n// Each model provider defines their own individual request and response formats.\\n// For the format, ranges, and default values for the different models, refer to:\\n// https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html\\ntype ClaudeRequest struct { \\n Prompt            string `json:\"prompt\"` \\n MaxTokensToSample int    `json:\"max_tokens_to_sample\"` \\n // Omitting optional request parameters\\n}\\ntype ClaudeResponse struct { \\n Completion string `json:\"completion\"`\\n}\\n// main uses the AWS SDK for Go (v2) to create an Amazon Bedrock Runtime client\\n// and invokes Anthropic Claude 2 inside your account and the chosen region.\\n// This example uses the default settings specified in your shared credentials\\n// and config files.\\nfunc main() { \\n region := flag.String(\"region\", \"us-east-1\", \"The AWS region\") \\n flag.Parse() \\n fmt.Printf(\"Using AWS region: %s\\\\n\", *region) \\n sdkConfig, err := config.LoadDefaultConfig(context.Background(), \\n config.WithRegion(*region)) \\n if err != nil { \\n  fmt.Println(\"Couldn\\'t load default configuration. Have you set up your AWS \\n account?\") \\n  fmt.Println(err) \\n  return \\n } \\n client := bedrockruntime.NewFromConfig(sdkConfig) \\n modelId := \"anthropic.claude-v2\" \\nAmazon Bedrock Runtime 592Amazon Bedrock User Guide\\n prompt := \"Hello, how are you today?\" \\n // Anthropic Claude requires you to enclose the prompt as follows: \\n prefix := \"Human: \" \\n postfix := \"\\\\n\\\\nAssistant:\" \\n wrappedPrompt := prefix + prompt + postfix \\n request := ClaudeRequest{ \\n  Prompt:            wrappedPrompt, \\n  MaxTokensToSample: 200, \\n } \\n body, err := json.Marshal(request) \\n if err != nil { \\n  log.Panicln(\"Couldn\\'t marshal the request: \", err) \\n } \\n result, err := client.InvokeModel(context.Background(), \\n &bedrockruntime.InvokeModelInput{ \\n  ModelId:     aws.String(modelId), \\n  ContentType: aws.String(\"application/json\"), \\n  Body:        body, \\n }) \\n if err != nil { \\n  errMsg := err.Error() \\n  if strings.Contains(errMsg, \"no such host\") { \\n   fmt.Printf(\"Error: The Bedrock service is not available in the selected \\n region. Please double-check the service availability for your region at https://\\naws.amazon.com/about-aws/global-infrastructure/regional-product-services/.\\\\n\") \\n  } else if strings.Contains(errMsg, \"Could not resolve the foundation model\") { \\n   fmt.Printf(\"Error: Could not resolve the foundation model from model \\n identifier: \\\\\"%v\\\\\". Please verify that the requested model exists and is \\n accessible within the specified region.\\\\n\", modelId) \\n  } else { \\n   fmt.Printf(\"Error: Couldn\\'t invoke Anthropic Claude. Here\\'s why: %v\\\\n\", err) \\n  } \\n  os.Exit(1) \\n } \\n var response ClaudeResponse \\n err = json.Unmarshal(result.Body, &response) \\nAmazon Bedrock Runtime 593Amazon Bedrock User Guide\\n if err != nil { \\n  log.Fatal(\"failed to unmarshal\", err) \\n } \\n fmt.Println(\"Prompt:\\\\n\", prompt) \\n fmt.Println(\"Response from Anthropic Claude:\\\\n\", response.Completion)\\n}\\n•For API details, see InvokeModel in AWS SDK for Go API Reference.\\nCode examples\\n•Actions for Amazon Bedrock Runtime using AWS SDKs\\n•Invoke the Amazon Titan Image Generator G1 model on Amazon Bedrock for image generation\\n•Invoke the Stability.ai Stable Diﬀusion XL model on Amazon Bedrock for image generation\\n•Invoke Anthropic Claude 3 on Amazon Bedrock with a multimodal prompt\\n•Invoke the AI21 Labs Jurassic-2 model on Amazon Bedrock for text generation\\n•Invoke the Amazon Titan Text G1 model on Amazon Bedrock for text generation\\n•Invoke the Anthropic Claude 2 model on Amazon Bedrock for text generation\\n•Invoke the Anthropic Claude 2 model on Amazon Bedrock for text generation with a response \\nstream\\n•Invoke Anthropic Claude 3 on Amazon Bedrock to generate text\\n•Invoke the Meta Llama 2 Chat model on Amazon Bedrock for text generation\\n•Invoke the Mistral 7B model on Amazon Bedrock for text generation\\n•Invoke the Mixtral 8x7B model on Amazon Bedrock for text generation\\n•Scenarios for Amazon Bedrock Runtime using AWS SDKs\\n•Create a sample application that oﬀers playgrounds to interact with Amazon Bedrock \\nfoundation models using an AWS SDK\\n•Invoke multiple large-language models (LLMs) on Amazon Bedrock\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nAmazon Bedrock Runtime 594Amazon Bedrock User Guide\\nActions for Amazon Bedrock Runtime using AWS SDKs\\nThe following code examples demonstrate how to perform individual Amazon Bedrock Runtime \\nactions with AWS SDKs. These excerpts call the Amazon Bedrock Runtime API and are code \\nexcerpts from larger programs that must be run in context. Each example includes a link to GitHub, \\nwhere you can ﬁnd instructions for setting up and running the code.\\nThe following examples include only the most commonly used actions. For a complete list, see the\\nAmazon Bedrock Runtime API Reference.\\nExamples\\n•Invoke the Amazon Titan Image Generator G1 model on Amazon Bedrock for image generation\\n•Invoke the Stability.ai Stable Diﬀusion XL model on Amazon Bedrock for image generation\\n•Invoke Anthropic Claude 3 on Amazon Bedrock with a multimodal prompt\\n•Invoke the AI21 Labs Jurassic-2 model on Amazon Bedrock for text generation\\n•Invoke the Amazon Titan Text G1 model on Amazon Bedrock for text generation\\n•Invoke the Anthropic Claude 2 model on Amazon Bedrock for text generation\\n•Invoke the Anthropic Claude 2 model on Amazon Bedrock for text generation with a response \\nstream\\n•Invoke Anthropic Claude 3 on Amazon Bedrock to generate text\\n•Invoke the Meta Llama 2 Chat model on Amazon Bedrock for text generation\\n•Invoke the Mistral 7B model on Amazon Bedrock for text generation\\n•Invoke the Mixtral 8x7B model on Amazon Bedrock for text generation\\nInvoke the Amazon Titan Image Generator G1 model on Amazon Bedrock for \\nimage generation\\nThe following code examples show how to invoke the Amazon Titan Image Generator G1 model on \\nAmazon Bedrock for image generation.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Invoke multiple LLMs on Amazon Bedrock\\nActions 595Amazon Bedrock User Guide\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Amazon Titan Image Generator G1 foundation model to \\ngenerate images.\\n        /// <summary> \\n        /// Asynchronously invokes the Amazon Titan Image Generator G1 model to \\n run an inference based on the provided input. \\n        /// </summary> \\n        /// <param name=\"prompt\">The prompt that describes the image Amazon Titan \\n Image Generator G1 has to generate.</param> \\n        /// <returns>A base-64 encoded image generated by model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for Amazon Titan Image \\n Generator G1, refer to: \\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-titan-image.html \\n        /// </remarks> \\n        public static async Task<string?> InvokeTitanImageGeneratorG1Async(string \\n prompt, int seed) \\n        { \\n            string titanImageGeneratorG1ModelId = \"amazon.titan-image-generator-\\nv1\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USEast1); \\n            string payload = new JsonObject() \\n            { \\n                { \"taskType\", \"TEXT_IMAGE\" }, \\n                { \"textToImageParams\", new JsonObject() \\n                    { \\nActions 596Amazon Bedrock User Guide\\n                        { \"text\", prompt } \\n                    } \\n                }, \\n                { \"imageGenerationConfig\", new JsonObject() \\n                    { \\n                        { \"numberOfImages\", 1 }, \\n                        { \"quality\", \"standard\" }, \\n                        { \"cfgScale\", 8.0f }, \\n                        { \"height\", 512 }, \\n                        { \"width\", 512 }, \\n                        { \"seed\", seed } \\n                    } \\n                } \\n            }.ToJsonString(); \\n            try \\n            { \\n                InvokeModelResponse response = await client.InvokeModelAsync(new \\n InvokeModelRequest() \\n                { \\n                    ModelId = titanImageGeneratorG1ModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n                if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    var results = JsonNode.ParseAsync(response.Body).Result?\\n[\"images\"]?.AsArray(); \\n                    return results?[0]?.GetValue<string>(); \\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"InvokeModelAsync failed with status code \" \\n + response.HttpStatusCode); \\n                } \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\n            return null; \\nActions 597Amazon Bedrock User Guide\\n        }\\n•For API details, see InvokeModel in AWS SDK for .NET API Reference.\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Amazon Titan Image Generator G1 model to generate images.\\ntype TitanImageRequest struct { \\n    TaskType              string                `json:\"taskType\"` \\n    TextToImageParams     TextToImageParams     `json:\"textToImageParams\"` \\n    ImageGenerationConfig ImageGenerationConfig `json:\"imageGenerationConfig\"`\\n}\\ntype TextToImageParams struct { \\n    Text string `json:\"text\"`\\n}\\ntype ImageGenerationConfig struct { \\n    NumberOfImages int     `json:\"numberOfImages\"` \\n    Quality        string  `json:\"quality\"` \\n    CfgScale       float64 `json:\"cfgScale\"` \\n    Height         int     `json:\"height\"` \\n    Width          int     `json:\"width\"` \\n    Seed           int64   `json:\"seed\"`\\n}\\ntype TitanImageResponse struct { \\n    Images []string `json:\"images\"`\\n}\\n// Invokes the Titan Image model to create an image using the input provided\\n// in the request body.\\nActions 598Amazon Bedrock User Guide\\nfunc (wrapper InvokeModelWrapper) InvokeTitanImage(prompt string, seed int64) \\n (string, error) { \\n    modelId := \"amazon.titan-image-generator-v1\" \\n    body, err := json.Marshal(TitanImageRequest { \\n        TaskType: \"TEXT_IMAGE\", \\n        TextToImageParams: TextToImageParams { \\n            Text: prompt, \\n        }, \\n        ImageGenerationConfig: ImageGenerationConfig { \\n            NumberOfImages: 1, \\n            Quality: \"standard\", \\n            CfgScale: 8.0, \\n            Height: 512, \\n            Width: 512, \\n            Seed: seed, \\n        }, \\n    }) \\n    if err != nil { log.Fatal(\"failed to marshal\", err) } \\n    output, err := wrapper.BedrockRuntimeClient.InvokeModel(context.TODO(), \\n &bedrockruntime.InvokeModelInput{ \\n        ModelId: aws.String(modelId), \\n        ContentType: aws.String(\"application/json\"), \\n        Body: body, \\n    }) \\n    if err != nil { ProcessError(err, modelId) } \\n    var response TitanImageResponse \\n    if err := json.Unmarshal(output.Body, &response); err != nil { \\n        log.Fatal(\"failed to unmarshal\", err) \\n    } \\n    base64ImageData := response.Images[0] \\n    return base64ImageData, nil\\n}\\n•For API details, see InvokeModel in AWS SDK for Go API Reference.\\nActions 599Amazon Bedrock User Guide\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Amazon Titan Image Generator G1 model to generate images.\\n    /** \\n     * Invokes the Amazon Titan image generation model to create an image using \\n the \\n     * input \\n     * provided in the request body. \\n     * \\n     * @param prompt The prompt that you want Amazon Titan to use for image \\n     *               generation. \\n     * @param seed   The random noise seed for image generation (Range: 0 to \\n     *               2147483647). \\n     * @return A Base64-encoded string representing the generated image. \\n     */ \\n    public static String invokeTitanImage(String prompt, long seed) { \\n        /* \\n         * The different model providers have individual request and response \\n formats. \\n         * For the format, ranges, and default values for Titan Image models \\n refer to: \\n         * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\ntitan- \\n         * image.html \\n         */ \\n        String titanImageModelId = \"amazon.titan-image-generator-v1\"; \\n        BedrockRuntimeAsyncClient client = BedrockRuntimeAsyncClient.builder() \\n                .region(Region.US_EAST_1) \\n                .credentialsProvider(ProfileCredentialsProvider.create()) \\n                .build(); \\n        var textToImageParams = new JSONObject().put(\"text\", prompt); \\nActions 600Amazon Bedrock User Guide\\n        var imageGenerationConfig = new JSONObject() \\n                .put(\"numberOfImages\", 1) \\n                .put(\"quality\", \"standard\") \\n                .put(\"cfgScale\", 8.0) \\n                .put(\"height\", 512) \\n                .put(\"width\", 512) \\n                .put(\"seed\", seed); \\n        JSONObject payload = new JSONObject() \\n                .put(\"taskType\", \"TEXT_IMAGE\") \\n                .put(\"textToImageParams\", textToImageParams) \\n                .put(\"imageGenerationConfig\", imageGenerationConfig); \\n        InvokeModelRequest request = InvokeModelRequest.builder() \\n                .body(SdkBytes.fromUtf8String(payload.toString())) \\n                .modelId(titanImageModelId) \\n                .contentType(\"application/json\") \\n                .accept(\"application/json\") \\n                .build(); \\n        CompletableFuture<InvokeModelResponse> completableFuture = \\n client.invokeModel(request) \\n                .whenComplete((response, exception) -> { \\n                    if (exception != null) { \\n                        System.out.println(\"Model invocation failed: \" + \\n exception); \\n                    } \\n                }); \\n        String base64ImageData = \"\"; \\n        try { \\n            InvokeModelResponse response = completableFuture.get(); \\n            JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n            base64ImageData = responseBody \\n                    .getJSONArray(\"images\") \\n                    .getString(0); \\n        } catch (InterruptedException e) { \\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n        } catch (ExecutionException e) { \\n            System.err.println(e.getMessage()); \\n        } \\nActions 601Amazon Bedrock User Guide\\n        return base64ImageData; \\n    }\\nInvoke the Amazon Titan Image Generator G1 model to generate images.\\n        /** \\n         * Invokes the Amazon Titan image generation model to create an image \\n using the \\n         * input \\n         * provided in the request body. \\n         * \\n         * @param prompt The prompt that you want Amazon Titan to use for image \\n         *               generation. \\n         * @param seed   The random noise seed for image generation (Range: 0 to \\n         *               2147483647). \\n         * @return A Base64-encoded string representing the generated image. \\n         */ \\n        public static String invokeTitanImage(String prompt, long seed) { \\n                /* \\n                 * The different model providers have individual request and \\n response formats. \\n                 * For the format, ranges, and default values for Titan Image \\n models refer to: \\n                 * https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-titan- \\n                 * image.html \\n                 */ \\n                String titanImageModelId = \"amazon.titan-image-generator-v1\"; \\n                BedrockRuntimeClient client = BedrockRuntimeClient.builder() \\n                                .region(Region.US_EAST_1) \\n                                \\n .credentialsProvider(ProfileCredentialsProvider.create()) \\n                                .build(); \\n                var textToImageParams = new JSONObject().put(\"text\", prompt); \\n                var imageGenerationConfig = new JSONObject() \\n                                .put(\"numberOfImages\", 1) \\n                                .put(\"quality\", \"standard\") \\n                                .put(\"cfgScale\", 8.0) \\nActions 602Amazon Bedrock User Guide\\n                                .put(\"height\", 512) \\n                                .put(\"width\", 512) \\n                                .put(\"seed\", seed); \\n                JSONObject payload = new JSONObject() \\n                                .put(\"taskType\", \"TEXT_IMAGE\") \\n                                .put(\"textToImageParams\", textToImageParams) \\n                                .put(\"imageGenerationConfig\", \\n imageGenerationConfig); \\n                InvokeModelRequest request = InvokeModelRequest.builder() \\n                                \\n .body(SdkBytes.fromUtf8String(payload.toString())) \\n                                .modelId(titanImageModelId) \\n                                .contentType(\"application/json\") \\n                                .accept(\"application/json\") \\n                                .build(); \\n                InvokeModelResponse response = client.invokeModel(request); \\n                JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n                String base64ImageData = responseBody \\n                                .getJSONArray(\"images\") \\n                                .getString(0); \\n                return base64ImageData; \\n        }\\n•For API details, see InvokeModel in AWS SDK for Java 2.x API Reference.\\nPHP\\nSDK for PHP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nActions 603Amazon Bedrock User Guide\\nInvoke the Amazon Titan Image Generator G1 model to generate images.\\n    public function invokeTitanImage(string $prompt, int $seed) \\n    { \\n        # The different model providers have individual request and response \\n formats. \\n        # For the format, ranges, and default values for Titan Image models refer \\n to: \\n        # https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\ntitan-image.html \\n        $base64_image_data = \"\"; \\n        try { \\n            $modelId = \\'amazon.titan-image-generator-v1\\'; \\n            $request = json_encode([ \\n                \\'taskType\\' => \\'TEXT_IMAGE\\', \\n                \\'textToImageParams\\' => [ \\n                    \\'text\\' => $prompt \\n                ], \\n                \\'imageGenerationConfig\\' => [ \\n                    \\'numberOfImages\\' => 1, \\n                    \\'quality\\' => \\'standard\\', \\n                    \\'cfgScale\\' => 8.0, \\n                    \\'height\\' => 512, \\n                    \\'width\\' => 512, \\n                    \\'seed\\' => $seed \\n                ] \\n            ]); \\n            $result = $this->bedrockRuntimeClient->invokeModel([ \\n                \\'contentType\\' => \\'application/json\\', \\n                \\'body\\' => $request, \\n                \\'modelId\\' => $modelId, \\n            ]); \\n            $response_body = json_decode($result[\\'body\\']); \\n            $base64_image_data = $response_body->images[0]; \\n        } catch (Exception $e) { \\n            echo \"Error: ({$e->getCode()}) - {$e->getMessage()}\\\\n\"; \\n        } \\nActions 604Amazon Bedrock User Guide\\n        return $base64_image_data; \\n    }\\n•For API details, see InvokeModel in AWS SDK for PHP API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Amazon Titan Image Generator G1 model to generate images.\\n    def invoke_titan_image(self, prompt, seed): \\n        \"\"\" \\n        Invokes the Titan Image model to create an image using the input provided \\n in the request body. \\n        :param prompt: The prompt that you want Amazon Titan to use for image \\n generation. \\n        :param seed: Random noise seed (range: 0 to 2147483647) \\n        :return: Base64-encoded inference response from the model. \\n        \"\"\" \\n        try: \\n            # The different model providers have individual request and response \\n formats. \\n            # For the format, ranges, and default values for Titan Image models \\n refer to: \\n            # https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-titan-image.html \\n            request = json.dumps( \\n                { \\n                    \"taskType\": \"TEXT_IMAGE\", \\n                    \"textToImageParams\": {\"text\": prompt}, \\n                    \"imageGenerationConfig\": { \\nActions 605Amazon Bedrock User Guide\\n                        \"numberOfImages\": 1, \\n                        \"quality\": \"standard\", \\n                        \"cfgScale\": 8.0, \\n                        \"height\": 512, \\n                        \"width\": 512, \\n                        \"seed\": seed, \\n                    }, \\n                } \\n            ) \\n            response = self.bedrock_runtime_client.invoke_model( \\n                modelId=\"amazon.titan-image-generator-v1\", body=request \\n            ) \\n            response_body = json.loads(response[\"body\"].read()) \\n            base64_image_data = response_body[\"images\"][0] \\n            return base64_image_data \\n        except ClientError: \\n            logger.error(\"Couldn\\'t invoke Titan Image generator\") \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke the Stability.ai Stable Diﬀusion XL model on Amazon Bedrock for image \\ngeneration\\nThe following code examples show how to invoke the Stability.ai Stable Diﬀusion XL model on \\nAmazon Bedrock for image generation.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\nActions 606Amazon Bedrock User Guide\\n•Invoke multiple LLMs on Amazon Bedrock\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke Stability.ai Stable Diﬀusion XL foundation model to generate images.\\n        /// <summary> \\n        /// Asynchronously invokes the Stability.ai Stable Diffusion XLmodel to \\n run an inference based on the provided input. \\n        /// </summary> \\n        /// <param name=\"prompt\">The prompt that describes the image Stability.ai \\n Stable Diffusion XL has to generate.</param> \\n        /// <returns>A base-64 encoded image generated by model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for Stability.ai Stable \\n Diffusion XL, refer to: \\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-stability-diffusion.html \\n        /// </remarks> \\n        public static async Task<string?> InvokeStableDiffusionXLG1Async(string \\n prompt, int seed, string? stylePreset = null) \\n        { \\n            string stableDiffusionXLModelId = \"stability.stable-diffusion-xl\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USEast1); \\n            var jsonPayload = new JsonObject() \\n            { \\n                { \"text_prompts\", new JsonArray() { \\n                    new JsonObject() \\n                        { \\nActions 607Amazon Bedrock User Guide\\n                            { \"text\", prompt } \\n                        } \\n                    } \\n                }, \\n                { \"seed\", seed } \\n            }; \\n            if (!string.IsNullOrEmpty(stylePreset)) \\n            { \\n                jsonPayload.Add(\"style_preset\", stylePreset); \\n            } \\n            string payload = jsonPayload.ToString(); \\n            try \\n            { \\n                InvokeModelResponse response = await client.InvokeModelAsync(new \\n InvokeModelRequest() \\n                { \\n                    ModelId = stableDiffusionXLModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n                if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    var results = JsonNode.ParseAsync(response.Body).Result?\\n[\"artifacts\"]?.AsArray(); \\n                    return results?[0]?[\"base64\"]?.GetValue<string>(); \\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"InvokeModelAsync failed with status code \" \\n + response.HttpStatusCode); \\n                } \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\n            return null; \\n        }\\nActions 608Amazon Bedrock User Guide\\n•For API details, see InvokeModel in AWS SDK for .NET API Reference.\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Stability.ai Stable Diﬀusion XL foundation model to generate \\nimages.\\n    /** \\n     * Asynchronously invokes the Stability.ai Stable Diffusion XL model to \\n create \\n     * an image based on the provided input. \\n     * \\n     * @param prompt      The prompt that guides the Stable Diffusion model. \\n     * @param seed        The random noise seed for image generation (use 0 or \\n omit \\n     *                    for a random seed). \\n     * @param stylePreset The style preset to guide the image model towards a \\n     *                    specific style. \\n     * @return A Base64-encoded string representing the generated image. \\n     */ \\n    public static String invokeStableDiffusion(String prompt, long seed, String \\n stylePreset) { \\n        /* \\n         * The different model providers have individual request and response \\n formats. \\n         * For the format, ranges, and available style_presets of Stable \\n Diffusion \\n         * models refer to: \\n         * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nstability-diffusion.html \\n         */ \\nActions 609Amazon Bedrock User Guide\\n        String stableDiffusionModelId = \"stability.stable-diffusion-xl\"; \\n        BedrockRuntimeAsyncClient client = BedrockRuntimeAsyncClient.builder() \\n                .region(Region.US_EAST_1) \\n                .credentialsProvider(ProfileCredentialsProvider.create()) \\n                .build(); \\n        JSONArray wrappedPrompt = new JSONArray().put(new \\n JSONObject().put(\"text\", prompt)); \\n        JSONObject payload = new JSONObject() \\n                .put(\"text_prompts\", wrappedPrompt) \\n                .put(\"seed\", seed); \\n        if (stylePreset != null && !stylePreset.isEmpty()) { \\n            payload.put(\"style_preset\", stylePreset); \\n        } \\n        InvokeModelRequest request = InvokeModelRequest.builder() \\n                .body(SdkBytes.fromUtf8String(payload.toString())) \\n                .modelId(stableDiffusionModelId) \\n                .contentType(\"application/json\") \\n                .accept(\"application/json\") \\n                .build(); \\n        CompletableFuture<InvokeModelResponse> completableFuture = \\n client.invokeModel(request) \\n                .whenComplete((response, exception) -> { \\n                    if (exception != null) { \\n                        System.out.println(\"Model invocation failed: \" + \\n exception); \\n                    } \\n                }); \\n        String base64ImageData = \"\"; \\n        try { \\n            InvokeModelResponse response = completableFuture.get(); \\n            JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n            base64ImageData = responseBody \\n                    .getJSONArray(\"artifacts\") \\n                    .getJSONObject(0) \\n                    .getString(\"base64\"); \\nActions 610Amazon Bedrock User Guide\\n        } catch (InterruptedException e) { \\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n        } catch (ExecutionException e) { \\n            System.err.println(e.getMessage()); \\n        } \\n        return base64ImageData; \\n    }\\nInvoke the Stability.ai Stable Diﬀusion XL foundation model to generate images.\\n        /** \\n         * Invokes the Stability.ai Stable Diffusion XL model to create an image \\n based \\n         * on the provided input. \\n         * \\n         * @param prompt      The prompt that guides the Stable Diffusion model. \\n         * @param seed        The random noise seed for image generation (use 0 \\n or omit \\n         *                    for a random seed). \\n         * @param stylePreset The style preset to guide the image model towards a \\n         *                    specific style. \\n         * @return A Base64-encoded string representing the generated image. \\n         */ \\n        public static String invokeStableDiffusion(String prompt, long seed, \\n String stylePreset) { \\n                /* \\n                 * The different model providers have individual request and \\n response formats. \\n                 * For the format, ranges, and available style_presets of Stable \\n Diffusion \\n                 * models refer to: \\n                 * https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-stability-diffusion.html \\n                 */ \\n                String stableDiffusionModelId = \"stability.stable-diffusion-xl\"; \\n                BedrockRuntimeClient client = BedrockRuntimeClient.builder() \\n                                .region(Region.US_EAST_1) \\nActions 611Amazon Bedrock User Guide\\n                               \\n .credentialsProvider(ProfileCredentialsProvider.create()) \\n                                .build(); \\n                JSONArray wrappedPrompt = new JSONArray().put(new \\n JSONObject().put(\"text\", prompt)); \\n                JSONObject payload = new JSONObject() \\n                                .put(\"text_prompts\", wrappedPrompt) \\n                                .put(\"seed\", seed); \\n                if (!(stylePreset == null || stylePreset.isEmpty())) { \\n                        payload.put(\"style_preset\", stylePreset); \\n                } \\n                InvokeModelRequest request = InvokeModelRequest.builder() \\n                                \\n .body(SdkBytes.fromUtf8String(payload.toString())) \\n                                .modelId(stableDiffusionModelId) \\n                                .contentType(\"application/json\") \\n                                .accept(\"application/json\") \\n                                .build(); \\n                InvokeModelResponse response = client.invokeModel(request); \\n                JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n                String base64ImageData = responseBody \\n                                .getJSONArray(\"artifacts\") \\n                                .getJSONObject(0) \\n                                .getString(\"base64\"); \\n                return base64ImageData; \\n        }\\n•For API details, see InvokeModel in AWS SDK for Java 2.x API Reference.\\nActions 612Amazon Bedrock User Guide\\nPHP\\nSDK for PHP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Stability.ai Stable Diﬀusion XL foundation model to generate images.\\n    public function invokeStableDiffusion(string $prompt, int $seed, string \\n $style_preset) \\n    { \\n        # The different model providers have individual request and response \\n formats. \\n        # For the format, ranges, and available style_presets of Stable Diffusion \\n models refer to: \\n        # https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nstability-diffusion.html \\n        $base64_image_data = \"\"; \\n        try { \\n            $modelId = \\'stability.stable-diffusion-xl\\'; \\n            $body = [ \\n                \\'text_prompts\\' => [ \\n                    [\\'text\\' => $prompt] \\n                ], \\n                \\'seed\\' => $seed, \\n                \\'cfg_scale\\' => 10, \\n                \\'steps\\' => 30 \\n            ]; \\n            if ($style_preset) { \\n                $body[\\'style_preset\\'] = $style_preset; \\n            } \\n            $result = $this->bedrockRuntimeClient->invokeModel([ \\n                \\'contentType\\' => \\'application/json\\', \\n                \\'body\\' => json_encode($body), \\nActions 613Amazon Bedrock User Guide\\n                \\'modelId\\' => $modelId, \\n            ]); \\n            $response_body = json_decode($result[\\'body\\']); \\n            $base64_image_data = $response_body->artifacts[0]->base64; \\n        } catch (Exception $e) { \\n            echo \"Error: ({$e->getCode()}) - {$e->getMessage()}\\\\n\"; \\n        } \\n        return $base64_image_data; \\n    }\\n•For API details, see InvokeModel in AWS SDK for PHP API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Stability.ai Stable Diﬀusion XL foundation model to generate images.\\n    def invoke_stable_diffusion(self, prompt, seed, style_preset=None): \\n        \"\"\" \\n        Invokes the Stability.ai Stable Diffusion XL model to create an image \\n using \\n        the input provided in the request body. \\n        :param prompt: The prompt that you want Stable Diffusion  to use for \\n image generation. \\n        :param seed: Random noise seed (omit this option or use 0 for a random \\n seed) \\n        :param style_preset: Pass in a style preset to guide the image model \\n towards \\n                             a particular style. \\n        :return: Base64-encoded inference response from the model. \\nActions 614Amazon Bedrock User Guide\\n        \"\"\" \\n        try: \\n            # The different model providers have individual request and response \\n formats. \\n            # For the format, ranges, and available style_presets of Stable \\n Diffusion models refer to: \\n            # https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-stability-diffusion.html \\n            body = { \\n                \"text_prompts\": [{\"text\": prompt}], \\n                \"seed\": seed, \\n                \"cfg_scale\": 10, \\n                \"steps\": 30, \\n            } \\n            if style_preset: \\n                body[\"style_preset\"] = style_preset \\n            response = self.bedrock_runtime_client.invoke_model( \\n                modelId=\"stability.stable-diffusion-xl\", body=json.dumps(body) \\n            ) \\n            response_body = json.loads(response[\"body\"].read()) \\n            base64_image_data = response_body[\"artifacts\"][0][\"base64\"] \\n            return base64_image_data \\n        except ClientError: \\n            logger.error(\"Couldn\\'t invoke Stable Diffusion XL\") \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nActions 615Amazon Bedrock User Guide\\nSAP ABAP\\nSDK for SAP ABAP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Stability.ai Stable Diﬀusion XL foundation model to generate images.\\n    \"Stable Diffusion Input Parameters should be in a format like this:\\n*   {\\n*     \"text_prompts\": [\\n*       {\"text\":\"Draw a dolphin with a mustache\"},\\n*       {\"text\":\"Make it photorealistic\"}\\n*     ],\\n*     \"cfg_scale\":10,\\n*     \"seed\":0,\\n*     \"steps\":50\\n*   } \\n    TYPES: BEGIN OF prompt_ts, \\n             text TYPE /aws1/rt_shape_string, \\n           END OF prompt_ts. \\n    DATA: BEGIN OF ls_input, \\n            text_prompts TYPE STANDARD TABLE OF prompt_ts, \\n            cfg_scale    TYPE /aws1/rt_shape_integer, \\n            seed         TYPE /aws1/rt_shape_integer, \\n            steps        TYPE /aws1/rt_shape_integer, \\n          END OF ls_input. \\n    APPEND VALUE prompt_ts( text = iv_prompt ) TO ls_input-text_prompts. \\n    ls_input-cfg_scale = 10. \\n    ls_input-seed = 0. \"or better, choose a random integer. \\n    ls_input-steps = 50. \\n    DATA(lv_json) = /ui2/cl_json=>serialize( \\n      data = ls_input \\n                pretty_name   = /ui2/cl_json=>pretty_mode-low_case ). \\n    TRY. \\nActions 616Amazon Bedrock User Guide\\n        DATA(lo_response) = lo_bdr->invokemodel( \\n          iv_body = /aws1/cl_rt_util=>string_to_xstring( lv_json ) \\n          iv_modelid = \\'stability.stable-diffusion-xl-v0\\' \\n          iv_accept = \\'application/json\\' \\n          iv_contenttype = \\'application/json\\' ). \\n        \"Stable Diffusion Result Format:\\n*       {\\n*         \"result\": \"success\",\\n*         \"artifacts\": [\\n*           {\\n*             \"seed\": 0,\\n*             \"base64\": \"iVBORw0KGgoAAAANSUhEUgAAAgAAA....\\n*             \"finishReason\": \"SUCCESS\"\\n*           }\\n*         ]\\n*       } \\n        TYPES: BEGIN OF artifact_ts, \\n                 seed         TYPE /aws1/rt_shape_integer, \\n                 base64       TYPE /aws1/rt_shape_string, \\n                 finishreason TYPE /aws1/rt_shape_string, \\n               END OF artifact_ts. \\n        DATA: BEGIN OF ls_response, \\n                result    TYPE /aws1/rt_shape_string, \\n                artifacts TYPE STANDARD TABLE OF artifact_ts, \\n              END OF ls_response. \\n        /ui2/cl_json=>deserialize( \\n          EXPORTING jsonx = lo_response->get_body( ) \\n                    pretty_name = /ui2/cl_json=>pretty_mode-camel_case \\n          CHANGING  data  = ls_response ). \\n        IF ls_response-artifacts IS NOT INITIAL. \\n          DATA(lv_image) = \\n cl_http_utility=>if_http_utility~decode_x_base64( ls_response-artifacts[ 1 ]-\\nbase64 ). \\n        ENDIF. \\n      CATCH /aws1/cx_bdraccessdeniedex INTO DATA(lo_ex). \\n        WRITE / lo_ex->get_text( ). \\n        WRITE / |Don\\'t forget to enable model access at https://\\nconsole.aws.amazon.com/bedrock/home?#/modelaccess|. \\n    ENDTRY.\\nActions 617Amazon Bedrock User Guide\\nInvoke the Stability.ai Stable Diﬀusion XL foundation model to generate images using L2 \\nhigh level client.\\n    TRY. \\n        DATA(lo_bdr_l2_sd) = /aws1/\\ncl_bdr_l2_factory=>create_stable_diffusion_10( lo_bdr ). \\n      \" iv_prompt contains a prompt like \\'Show me a picture of a unicorn reading \\n an enterprise financial report\\'. \\n        DATA(lv_image) = lo_bdr_l2_sd->text_to_image( iv_prompt ). \\n      CATCH /aws1/cx_bdraccessdeniedex INTO DATA(lo_ex). \\n        WRITE / lo_ex->get_text( ). \\n        WRITE / |Don\\'t forget to enable model access at https://\\nconsole.aws.amazon.com/bedrock/home?#/modelaccess|. \\n    ENDTRY.\\n•For API details, see InvokeModel in AWS SDK for SAP ABAP API reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke Anthropic Claude 3 on Amazon Bedrock with a multimodal prompt\\nThe following code example shows how to invoke Anthropic Claude 3 on Amazon Bedrock with a \\nmultimodal prompt.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Invoke multiple LLMs on Amazon Bedrock\\nActions 618Amazon Bedrock User Guide\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke Anthropic Claude 3 with a multimodal prompt to analyze an image.\\n    def invoke_claude_3_multimodal(self, prompt, base64_image_data): \\n        \"\"\" \\n        Invokes Anthropic Claude 3 Sonnet to run a multimodal inference using the \\n input \\n        provided in the request body. \\n        :param prompt:            The prompt that you want Claude 3 to use. \\n        :param base64_image_data: The base64-encoded image that you want to add \\n to the request. \\n        :return: Inference response from the model. \\n        \"\"\" \\n        # Initialize the Amazon Bedrock runtime client \\n        client = self.client or boto3.client( \\n            service_name=\"bedrock-runtime\", region_name=\"us-east-1\" \\n        ) \\n        # Invoke the model with the prompt and the encoded image \\n        model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\" \\n        request_body = { \\n            \"anthropic_version\": \"bedrock-2023-05-31\", \\n            \"max_tokens\": 2048, \\n            \"messages\": [ \\n                { \\n                    \"role\": \"user\", \\n                    \"content\": [ \\n                        { \\n                            \"type\": \"text\", \\n                            \"text\": prompt, \\n                        }, \\n                        { \\nActions 619Amazon Bedrock User Guide\\n                            \"type\": \"image\", \\n                            \"source\": { \\n                                \"type\": \"base64\", \\n                                \"media_type\": \"image/png\", \\n                                \"data\": base64_image_data, \\n                            }, \\n                        }, \\n                    ], \\n                } \\n            ], \\n        } \\n        try: \\n            response = client.invoke_model( \\n                modelId=model_id, \\n                body=json.dumps(request_body), \\n            ) \\n            # Process and print the response \\n            result = json.loads(response.get(\"body\").read()) \\n            input_tokens = result[\"usage\"][\"input_tokens\"] \\n            output_tokens = result[\"usage\"][\"output_tokens\"] \\n            output_list = result.get(\"content\", []) \\n            print(\"Invocation details:\") \\n            print(f\"- The input length is {input_tokens} tokens.\") \\n            print(f\"- The output length is {output_tokens} tokens.\") \\n            print(f\"- The model returned {len(output_list)} response(s):\") \\n            for output in output_list: \\n                print(output[\"text\"]) \\n            return result \\n        except ClientError as err: \\n            logger.error( \\n                \"Couldn\\'t invoke Claude 3 Sonnet. Here\\'s why: %s: %s\", \\n                err.response[\"Error\"][\"Code\"], \\n                err.response[\"Error\"][\"Message\"], \\n            ) \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nActions 620Amazon Bedrock User Guide\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke the AI21 Labs Jurassic-2 model on Amazon Bedrock for text generation\\nThe following code examples show how to invoke the AI21 Labs Jurassic-2 model on Amazon \\nBedrock for text generation.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Invoke multiple LLMs on Amazon Bedrock\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the AI21 Labs Jurassic-2 foundation model.\\n        /// <summary> \\n        /// Asynchronously invokes the AI21 Labs Jurassic-2 model to run an \\n inference based on the provided input. \\n        /// </summary> \\n        /// <param name=\"prompt\">The prompt that you want Claude to complete.</\\nparam> \\n        /// <returns>The inference response from the model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for AI21 Labs Jurassic-2, \\n refer to: \\nActions 621Amazon Bedrock User Guide\\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-jurassic2.html \\n        /// </remarks> \\n        public static async Task<string> InvokeJurassic2Async(string prompt) \\n        { \\n            string jurassic2ModelId = \"ai21.j2-mid-v1\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USEast1); \\n            string payload = new JsonObject() \\n            { \\n                { \"prompt\", prompt }, \\n                { \"maxTokens\", 200 }, \\n                { \"temperature\", 0.5 } \\n            }.ToJsonString(); \\n            string generatedText = \"\"; \\n            try \\n            { \\n                InvokeModelResponse response = await client.InvokeModelAsync(new \\n InvokeModelRequest() \\n                { \\n                    ModelId = jurassic2ModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n                if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    return JsonNode.ParseAsync(response.Body) \\n                        .Result?[\"completions\"]? \\n                        .AsArray()[0]?[\"data\"]? \\n                        .AsObject()[\"text\"]?.GetValue<string>() ?? \"\"; \\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"InvokeModelAsync failed with status code \" \\n + response.HttpStatusCode); \\n                } \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\n            { \\n                Console.WriteLine(e.Message); \\nActions 622Amazon Bedrock User Guide\\n            } \\n            return generatedText; \\n        }\\n•For API details, see InvokeModel in AWS SDK for .NET API Reference.\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the AI21 Labs Jurassic-2 foundation model to generate text.\\n// Each model provider has their own individual request and response formats.\\n// For the format, ranges, and default values for AI21 Labs Jurassic-2, refer to:\\n// https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\njurassic2.html\\ntype Jurassic2Request struct { \\n Prompt      string   `json:\"prompt\"` \\n MaxTokens   int      `json:\"maxTokens,omitempty\"` \\n Temperature float64  `json:\"temperature,omitempty\"`\\n}\\ntype Jurassic2Response struct { \\n    Completions []Completion `json:\"completions\"`\\n}\\ntype Completion struct { \\n    Data Data `json:\"data\"`\\n}\\ntype Data struct { \\n    Text string `json:\"text\"`\\n}\\nActions 623Amazon Bedrock User Guide\\n// Invokes AI21 Labs Jurassic-2 on Amazon Bedrock to run an inference using the \\n input\\n// provided in the request body.\\nfunc (wrapper InvokeModelWrapper) InvokeJurassic2(prompt string) (string, error) \\n { \\n    modelId := \"ai21.j2-mid-v1\" \\n body, err := json.Marshal(Jurassic2Request { \\n  Prompt:            prompt, \\n  MaxTokens:      200, \\n  Temperature:       0.5, \\n }) \\n if err != nil { log.Fatal(\"failed to marshal\", err) } \\n output, err := wrapper.BedrockRuntimeClient.InvokeModel(context.TODO(), \\n &bedrockruntime.InvokeModelInput{ \\n  ModelId: aws.String(modelId), \\n  ContentType: aws.String(\"application/json\"), \\n  Body: body, \\n }) \\n if err != nil { ProcessError(err, modelId) } \\n var response Jurassic2Response \\n    if err := json.Unmarshal(output.Body, &response); err != nil { \\n        log.Fatal(\"failed to unmarshal\", err) \\n    } \\n return response.Completions[0].Data.Text, nil\\n}\\n•For API details, see InvokeModel in AWS SDK for Go API Reference.\\nActions 624Amazon Bedrock User Guide\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the AI21 Labs Jurassic-2 foundation model to generate text.\\n    /** \\n     * Asynchronously invokes the AI21 Labs Jurassic-2 model to run an inference \\n     * based on the provided input. \\n     * \\n     * @param prompt The prompt that you want Jurassic to complete. \\n     * @return The inference response generated by the model. \\n     */ \\n    public static String invokeJurassic2(String prompt) { \\n        /* \\n         * The different model providers have individual request and response \\n formats. \\n         * For the format, ranges, and default values for Anthropic Claude, refer \\n to: \\n         * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nclaude.html \\n         */ \\n        String jurassic2ModelId = \"ai21.j2-mid-v1\"; \\n        BedrockRuntimeAsyncClient client = BedrockRuntimeAsyncClient.builder() \\n                .region(Region.US_EAST_1) \\n                .credentialsProvider(ProfileCredentialsProvider.create()) \\n                .build(); \\n        String payload = new JSONObject() \\n                .put(\"prompt\", prompt) \\n                .put(\"temperature\", 0.5) \\n                .put(\"maxTokens\", 200) \\n                .toString(); \\n        InvokeModelRequest request = InvokeModelRequest.builder() \\nActions 625Amazon Bedrock User Guide\\n                .body(SdkBytes.fromUtf8String(payload)) \\n                .modelId(jurassic2ModelId) \\n                .contentType(\"application/json\") \\n                .accept(\"application/json\") \\n                .build(); \\n        CompletableFuture<InvokeModelResponse> completableFuture = \\n client.invokeModel(request) \\n                .whenComplete((response, exception) -> { \\n                    if (exception != null) { \\n                        System.out.println(\"Model invocation failed: \" + \\n exception); \\n                    } \\n                }); \\n        String generatedText = \"\"; \\n        try { \\n            InvokeModelResponse response = completableFuture.get(); \\n            JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n            generatedText = responseBody \\n                    .getJSONArray(\"completions\") \\n                    .getJSONObject(0) \\n                    .getJSONObject(\"data\") \\n                    .getString(\"text\"); \\n        } catch (InterruptedException e) { \\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n        } catch (ExecutionException e) { \\n            System.err.println(e.getMessage()); \\n        } \\n        return generatedText; \\n    }\\nInvoke the AI21 Labs Jurassic-2 foundation model to generate text.\\n        /** \\n         * Invokes the AI21 Labs Jurassic-2 model to run an inference based on \\n the \\n         * provided input. \\nActions 626Amazon Bedrock User Guide\\n         * \\n         * @param prompt The prompt for Jurassic to complete. \\n         * @return The generated response. \\n         */ \\n        public static String invokeJurassic2(String prompt) { \\n                /* \\n                 * The different model providers have individual request and \\n response formats. \\n                 * For the format, ranges, and default values for AI21 Labs \\n Jurassic-2, refer \\n                 * to: \\n                 * https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-jurassic2.html \\n                 */ \\n                String jurassic2ModelId = \"ai21.j2-mid-v1\"; \\n                BedrockRuntimeClient client = BedrockRuntimeClient.builder() \\n                                .region(Region.US_EAST_1) \\n                                \\n .credentialsProvider(ProfileCredentialsProvider.create()) \\n                                .build(); \\n                String payload = new JSONObject() \\n                                .put(\"prompt\", prompt) \\n                                .put(\"temperature\", 0.5) \\n                                .put(\"maxTokens\", 200) \\n                                .toString(); \\n                InvokeModelRequest request = InvokeModelRequest.builder() \\n                                .body(SdkBytes.fromUtf8String(payload)) \\n                                .modelId(jurassic2ModelId) \\n                                .contentType(\"application/json\") \\n                                .accept(\"application/json\") \\n                                .build(); \\n                InvokeModelResponse response = client.invokeModel(request); \\n                JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n                String generatedText = responseBody \\n                                .getJSONArray(\"completions\") \\n                                .getJSONObject(0) \\nActions 627Amazon Bedrock User Guide\\n                                .getJSONObject(\"data\") \\n                                .getString(\"text\"); \\n                return generatedText; \\n        }\\n•For API details, see InvokeModel in AWS SDK for Java 2.x API Reference.\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the AI21 Labs Jurassic-2 foundation model to generate text.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  AccessDeniedException, \\n  BedrockRuntimeClient, \\n  InvokeModelCommand,\\n} from \"@aws-sdk/client-bedrock-runtime\";\\n/** \\n * @typedef {Object} Data \\n * @property {string} text \\n * \\n * @typedef {Object} Completion \\n * @property {Data} data \\n * \\n * @typedef {Object} ResponseBody \\n * @property {Completion[]} completions \\n */\\nActions 628Amazon Bedrock User Guide\\n/** \\n * Invokes the AI21 Labs Jurassic-2 large-language model to run an inference \\n * using the input provided in the request body. \\n * \\n * @param {string} prompt - The prompt that you want Jurassic-2 to complete. \\n * @returns {string} The inference response (completion) from the model. \\n */\\nexport const invokeJurassic2 = async (prompt) => { \\n  const client = new BedrockRuntimeClient({ region: \"us-east-1\" }); \\n  const modelId = \"ai21.j2-mid-v1\"; \\n  /* The different model providers have individual request and response formats. \\n   * For the format, ranges, and default values for AI21 Labs Jurassic-2, refer \\n to: \\n   * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\njurassic2.html \\n   */ \\n  const payload = { \\n    prompt, \\n    maxTokens: 500, \\n    temperature: 0.5, \\n  }; \\n  const command = new InvokeModelCommand({ \\n    body: JSON.stringify(payload), \\n    contentType: \"application/json\", \\n    accept: \"application/json\", \\n    modelId, \\n  }); \\n  try { \\n    const response = await client.send(command); \\n    const decodedResponseBody = new TextDecoder().decode(response.body); \\n    /** @type {ResponseBody} */ \\n    const responseBody = JSON.parse(decodedResponseBody); \\n    return responseBody.completions[0].data.text; \\n  } catch (err) { \\n    if (err instanceof AccessDeniedException) { \\n      console.error( \\nActions 629Amazon Bedrock User Guide\\n        `Access denied. Ensure you have the correct permissions to invoke \\n ${modelId}.`, \\n      ); \\n    } else { \\n      throw err; \\n    } \\n  }\\n};\\n// Invoke the function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  const prompt = \\'Complete the following: \"Once upon a time...\"\\'; \\n  console.log(\"\\\\nModel: AI21 Labs Jurassic-2\"); \\n  console.log(`Prompt: ${prompt}`); \\n  const completion = await invokeJurassic2(prompt); \\n  console.log(\"Completion:\"); \\n  console.log(completion); \\n  console.log(\"\\\\n\");\\n}\\n•For API details, see InvokeModel in AWS SDK for JavaScript API Reference.\\nPHP\\nSDK for PHP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the AI21 Labs Jurassic-2 foundation model to generate text.\\n    public function invokeJurassic2($prompt) \\n    { \\n        # The different model providers have individual request and response \\n formats. \\n        # For the format, ranges, and default values for AI21 Labs Jurassic-2, \\n refer to: \\nActions 630Amazon Bedrock User Guide\\n        # https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\njurassic2.html \\n        $completion = \"\"; \\n        try { \\n            $modelId = \\'ai21.j2-mid-v1\\'; \\n            $body = [ \\n                \\'prompt\\' => $prompt, \\n                \\'temperature\\' => 0.5, \\n                \\'maxTokens\\' => 200, \\n            ]; \\n            $result = $this->bedrockRuntimeClient->invokeModel([ \\n                \\'contentType\\' => \\'application/json\\', \\n                \\'body\\' => json_encode($body), \\n                \\'modelId\\' => $modelId, \\n            ]); \\n            $response_body = json_decode($result[\\'body\\']); \\n            $completion = $response_body->completions[0]->data->text; \\n        } catch (Exception $e) { \\n            echo \"Error: ({$e->getCode()}) - {$e->getMessage()}\\\\n\"; \\n        } \\n        return $completion; \\n    }\\n•For API details, see InvokeModel in AWS SDK for PHP API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nActions 631Amazon Bedrock User Guide\\nInvoke the AI21 Labs Jurassic-2 foundation model to generate text.\\n    def invoke_jurassic2(self, prompt): \\n        \"\"\" \\n        Invokes the AI21 Labs Jurassic-2 large-language model to run an inference \\n        using the input provided in the request body. \\n        :param prompt: The prompt that you want Jurassic-2 to complete. \\n        :return: Inference response from the model. \\n        \"\"\" \\n        try: \\n            # The different model providers have individual request and response \\n formats. \\n            # For the format, ranges, and default values for AI21 Labs \\n Jurassic-2, refer to: \\n            # https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-jurassic2.html \\n            body = { \\n                \"prompt\": prompt, \\n                \"temperature\": 0.5, \\n                \"maxTokens\": 200, \\n            } \\n            response = self.bedrock_runtime_client.invoke_model( \\n                modelId=\"ai21.j2-mid-v1\", body=json.dumps(body) \\n            ) \\n            response_body = json.loads(response[\"body\"].read()) \\n            completion = response_body[\"completions\"][0][\"data\"][\"text\"] \\n            return completion \\n        except ClientError: \\n            logger.error(\"Couldn\\'t invoke Jurassic-2\") \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nActions 632Amazon Bedrock User Guide\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke the Amazon Titan Text G1 model on Amazon Bedrock for text generation\\nThe following code examples show how to invoke the Amazon Titan Text G1 model on Amazon \\nBedrock for text generation.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Invoke multiple LLMs on Amazon Bedrock\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Amazon Titan Text G1 foundation model to generate text.\\n        /// <summary> \\n        /// Asynchronously invokes the Amazon Titan Text G1 Express model to run \\n an inference based on the provided input. \\n        /// </summary> \\n        /// <param name=\"prompt\">The prompt that you want Amazon Titan Text G1 \\n Express to complete.</param> \\n        /// <returns>The inference response from the model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for Amazon Titan Text G1 \\n Express, refer to: \\nActions 633Amazon Bedrock User Guide\\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-titan-text.html \\n        /// </remarks> \\n        public static async Task<string> InvokeTitanTextG1Async(string prompt) \\n        { \\n            string titanTextG1ModelId = \"amazon.titan-text-express-v1\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USEast1); \\n            string payload = new JsonObject() \\n            { \\n                { \"inputText\", prompt }, \\n                { \"textGenerationConfig\", new JsonObject() \\n                    { \\n                        { \"maxTokenCount\", 512 }, \\n                        { \"temperature\", 0f }, \\n                        { \"topP\", 1f } \\n                    } \\n                } \\n            }.ToJsonString(); \\n            string generatedText = \"\"; \\n            try \\n            { \\n                InvokeModelResponse response = await client.InvokeModelAsync(new \\n InvokeModelRequest() \\n                { \\n                    ModelId = titanTextG1ModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n                if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    var results = JsonNode.ParseAsync(response.Body).Result?\\n[\"results\"]?.AsArray(); \\n                    return results is null ? \"\" : string.Join(\" \", \\n results.Select(x => x?[\"outputText\"]?.GetValue<string?>())); \\n                } \\n                else \\n                { \\nActions 634Amazon Bedrock User Guide\\n                    Console.WriteLine(\"InvokeModelAsync failed with status code \" \\n + response.HttpStatusCode); \\n                } \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\n            return generatedText; \\n        }\\n•For API details, see InvokeModel in AWS SDK for .NET API Reference.\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Amazon Titan Text G1 foundation model to generate text.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  AccessDeniedException, \\n  BedrockRuntimeClient, \\n  InvokeModelCommand,\\n} from \"@aws-sdk/client-bedrock-runtime\";\\n/** \\n * @typedef {Object} ResponseBody \\n * @property {Object[]} results \\n */\\nActions 635Amazon Bedrock User Guide\\n/** \\n * Invokes the Titan Text G1 - Express model to run an inference \\n * using the input provided in the request body. \\n * \\n * @param {string} prompt - The prompt that you want Titan Text Express to \\n complete. \\n * @returns {object[]} The inference response (results) from the model. \\n */\\nexport const invokeTitanTextExpressV1 = async (prompt) => { \\n  const client = new BedrockRuntimeClient({ region: \"us-east-1\" }); \\n  const modelId = \"amazon.titan-text-express-v1\"; \\n  /* The different model providers have individual request and response formats. \\n   * For the format, ranges, and default values for Titan text, refer to: \\n   * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-\\ntext.html \\n   */ \\n  const textGenerationConfig = { \\n    maxTokenCount: 4096, \\n    stopSequences: [], \\n    temperature: 0, \\n    topP: 1, \\n  }; \\n  const payload = { \\n    inputText: prompt, \\n    textGenerationConfig, \\n  }; \\n  const command = new InvokeModelCommand({ \\n    body: JSON.stringify(payload), \\n    contentType: \"application/json\", \\n    accept: \"application/json\", \\n    modelId, \\n  }); \\n  try { \\n    const response = await client.send(command); \\n    const decodedResponseBody = new TextDecoder().decode(response.body); \\n    /** @type {ResponseBody} */ \\n    const responseBody = JSON.parse(decodedResponseBody); \\nActions 636Amazon Bedrock User Guide\\n    return responseBody.results; \\n  } catch (err) { \\n    if (err instanceof AccessDeniedException) { \\n      console.error( \\n        `Access denied. Ensure you have the correct permissions to invoke \\n ${modelId}.`, \\n      ); \\n    } else { \\n      throw err; \\n    } \\n  }\\n};\\n// Invoke the function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  const prompt = `Meeting transcript: Miguel: Hi Brant, I want to discuss the \\n workstream   \\n    for our new product launch Brant: Sure Miguel, is there anything in \\n particular you want \\n    to discuss? Miguel: Yes, I want to talk about how users enter into the \\n product. \\n    Brant: Ok, in that case let me add in Namita. Namita: Hey everyone  \\n    Brant: Hi Namita, Miguel wants to discuss how users enter into the product. \\n    Miguel: its too complicated and we should remove friction.   \\n    for example, why do I need to fill out additional forms?   \\n    I also find it difficult to find where to access the product \\n    when I first land on the landing page. Brant: I would also add that \\n    I think there are too many steps. Namita: Ok, I can work on the \\n    landing page to make the product more discoverable but brant \\n    can you work on the additonal forms? Brant: Yes but I would need  \\n    to work with James from another team as he needs to unblock the sign up \\n workflow. \\n    Miguel can you document any other concerns so that I can discuss with James \\n only once? \\n    Miguel: Sure. \\n    From the meeting transcript above, Create a list of action items for each \\n person.`; \\n  console.log(\"\\\\nModel: Titan Text Express v1\"); \\n  console.log(`Prompt: ${prompt}`); \\n  const results = await invokeTitanTextExpressV1(prompt); \\n  console.log(\"Completion:\"); \\n  for (const result of results) { \\nActions 637Amazon Bedrock User Guide\\n    console.log(result.outputText); \\n  } \\n  console.log(\"\\\\n\");\\n}\\n•For API details, see InvokeModel in AWS SDK for JavaScript API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke the Anthropic Claude 2 model on Amazon Bedrock for text generation\\nThe following code examples show how to invoke the Anthropic Claude 2 model on Amazon \\nBedrock for text generation.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Invoke multiple LLMs on Amazon Bedrock\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Anthropic Claude 2 foundation model to generate text.\\n        /// <summary> \\n        /// Asynchronously invokes the Anthropic Claude 2 model to run an \\n inference based on the provided input. \\n        /// </summary> \\nActions 638Amazon Bedrock User Guide\\n        /// <param name=\"prompt\">The prompt that you want Claude to complete.</\\nparam> \\n        /// <returns>The inference response from the model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for Anthropic Claude, \\n refer to: \\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-claude.html \\n        /// </remarks> \\n        public static async Task<string> InvokeClaudeAsync(string prompt) \\n        { \\n            string claudeModelId = \"anthropic.claude-v2\"; \\n            // Claude requires you to enclose the prompt as follows: \\n            string enclosedPrompt = \"Human: \" + prompt + \"\\\\n\\\\nAssistant:\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USEast1); \\n            string payload = new JsonObject() \\n            { \\n                { \"prompt\", enclosedPrompt }, \\n                { \"max_tokens_to_sample\", 200 }, \\n                { \"temperature\", 0.5 }, \\n                { \"stop_sequences\", new JsonArray(\"\\\\n\\\\nHuman:\") } \\n            }.ToJsonString(); \\n            string generatedText = \"\"; \\n            try \\n            { \\n                InvokeModelResponse response = await client.InvokeModelAsync(new \\n InvokeModelRequest() \\n                { \\n                    ModelId = claudeModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n                if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    return JsonNode.ParseAsync(response.Body).Result?\\n[\"completion\"]?.GetValue<string>() ?? \"\"; \\nActions 639Amazon Bedrock User Guide\\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"InvokeModelAsync failed with status code \" \\n + response.HttpStatusCode); \\n                } \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\n            return generatedText; \\n        }\\n•For API details, see InvokeModel in AWS SDK for .NET API Reference.\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Anthropic Claude 2 foundation model to generate text.\\n// Each model provider has their own individual request and response formats.\\n// For the format, ranges, and default values for Anthropic Claude, refer to:\\n// https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nclaude.html\\ntype ClaudeRequest struct { \\n Prompt            string   `json:\"prompt\"` \\n MaxTokensToSample int      `json:\"max_tokens_to_sample\"` \\n Temperature       float64  `json:\"temperature,omitempty\"` \\n StopSequences     []string `json:\"stop_sequences,omitempty\"`\\n}\\nActions 640Amazon Bedrock User Guide\\ntype ClaudeResponse struct { \\n Completion string `json:\"completion\"`\\n}\\n// Invokes Anthropic Claude on Amazon Bedrock to run an inference using the input\\n// provided in the request body.\\nfunc (wrapper InvokeModelWrapper) InvokeClaude(prompt string) (string, error) { \\n    modelId := \"anthropic.claude-v2\" \\n // Anthropic Claude requires enclosing the prompt as follows: \\n enclosedPrompt := \"Human: \" + prompt + \"\\\\n\\\\nAssistant:\" \\n body, err := json.Marshal(ClaudeRequest { \\n  Prompt:            enclosedPrompt, \\n  MaxTokensToSample: 200, \\n  Temperature:       0.5, \\n  StopSequences:     []string{\"\\\\n\\\\nHuman:\"}, \\n }) \\n if err != nil { log.Fatal(\"failed to marshal\", err) } \\n output, err := wrapper.BedrockRuntimeClient.InvokeModel(context.TODO(), \\n &bedrockruntime.InvokeModelInput{ \\n  ModelId: aws.String(modelId), \\n  ContentType: aws.String(\"application/json\"), \\n  Body: body, \\n }) \\n if err != nil { ProcessError(err, modelId) } \\n var response ClaudeResponse \\n    if err := json.Unmarshal(output.Body, &response); err != nil { \\n        log.Fatal(\"failed to unmarshal\", err) \\n    } \\n return response.Completion, nil\\n}\\n•For API details, see InvokeModel in AWS SDK for Go API Reference.\\nActions 641Amazon Bedrock User Guide\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Anthropic Claude 2 foundation model to generate text.\\n    /** \\n     * Asynchronously invokes the Anthropic Claude 2 model to run an inference \\n based \\n     * on the provided input. \\n     * \\n     * @param prompt The prompt that you want Claude to complete. \\n     * @return The inference response from the model. \\n     */ \\n    public static String invokeClaude(String prompt) { \\n        /* \\n         * The different model providers have individual request and response \\n formats. \\n         * For the format, ranges, and default values for Anthropic Claude, refer \\n to: \\n         * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nclaude.html \\n         */ \\n        String claudeModelId = \"anthropic.claude-v2\"; \\n        // Claude requires you to enclose the prompt as follows: \\n        String enclosedPrompt = \"Human: \" + prompt + \"\\\\n\\\\nAssistant:\"; \\n        BedrockRuntimeAsyncClient client = BedrockRuntimeAsyncClient.builder() \\n                .region(Region.US_EAST_1) \\n                .credentialsProvider(ProfileCredentialsProvider.create()) \\n                .build(); \\n        String payload = new JSONObject() \\n                .put(\"prompt\", enclosedPrompt) \\n                .put(\"max_tokens_to_sample\", 200) \\nActions 642Amazon Bedrock User Guide\\n                .put(\"temperature\", 0.5) \\n                .put(\"stop_sequences\", List.of(\"\\\\n\\\\nHuman:\")) \\n                .toString(); \\n        InvokeModelRequest request = InvokeModelRequest.builder() \\n                .body(SdkBytes.fromUtf8String(payload)) \\n                .modelId(claudeModelId) \\n                .contentType(\"application/json\") \\n                .accept(\"application/json\") \\n                .build(); \\n        CompletableFuture<InvokeModelResponse> completableFuture = \\n client.invokeModel(request) \\n                .whenComplete((response, exception) -> { \\n                    if (exception != null) { \\n                        System.out.println(\"Model invocation failed: \" + \\n exception); \\n                    } \\n                }); \\n        String generatedText = \"\"; \\n        try { \\n            InvokeModelResponse response = completableFuture.get(); \\n            JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n            generatedText = responseBody.getString(\"completion\"); \\n        } catch (InterruptedException e) { \\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n        } catch (ExecutionException e) { \\n            System.err.println(e.getMessage()); \\n        } \\n        return generatedText; \\n    }\\nInvoke the Anthropic Claude 2 foundation model to generate text.\\n        /** \\n         * Invokes the Anthropic Claude 2 model to run an inference based on the \\n         * provided input. \\n         * \\nActions 643Amazon Bedrock User Guide\\n         * @param prompt The prompt for Claude to complete. \\n         * @return The generated response. \\n         */ \\n        public static String invokeClaude(String prompt) { \\n                /* \\n                 * The different model providers have individual request and \\n response formats. \\n                 * For the format, ranges, and default values for Anthropic \\n Claude, refer to: \\n                 * https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-claude.html \\n                 */ \\n                String claudeModelId = \"anthropic.claude-v2\"; \\n                // Claude requires you to enclose the prompt as follows: \\n                String enclosedPrompt = \"Human: \" + prompt + \"\\\\n\\\\nAssistant:\"; \\n                BedrockRuntimeClient client = BedrockRuntimeClient.builder() \\n                                .region(Region.US_EAST_1) \\n                                \\n .credentialsProvider(ProfileCredentialsProvider.create()) \\n                                .build(); \\n                String payload = new JSONObject() \\n                                .put(\"prompt\", enclosedPrompt) \\n                                .put(\"max_tokens_to_sample\", 200) \\n                                .put(\"temperature\", 0.5) \\n                                .put(\"stop_sequences\", List.of(\"\\\\n\\\\nHuman:\")) \\n                                .toString(); \\n                InvokeModelRequest request = InvokeModelRequest.builder() \\n                                .body(SdkBytes.fromUtf8String(payload)) \\n                                .modelId(claudeModelId) \\n                                .contentType(\"application/json\") \\n                                .accept(\"application/json\") \\n                                .build(); \\n                InvokeModelResponse response = client.invokeModel(request); \\n                JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n                String generatedText = responseBody.getString(\"completion\"); \\nActions 644Amazon Bedrock User Guide\\n                return generatedText; \\n        }\\n•For API details, see InvokeModel in AWS SDK for Java 2.x API Reference.\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Anthropic Claude 2 foundation model to generate text.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  AccessDeniedException, \\n  BedrockRuntimeClient, \\n  InvokeModelCommand,\\n} from \"@aws-sdk/client-bedrock-runtime\";\\n/** \\n * @typedef {Object} ResponseBody \\n * @property {string} completion \\n */\\n/** \\n * Invokes the Anthropic Claude 2 model to run an inference using the input \\n * provided in the request body. \\n * \\n * @param {string} prompt - The prompt that you want Claude to complete. \\n * @returns {string} The inference response (completion) from the model. \\n */\\nActions 645Amazon Bedrock User Guide\\nexport const invokeClaude = async (prompt) => { \\n  const client = new BedrockRuntimeClient({ region: \"us-east-1\" }); \\n  const modelId = \"anthropic.claude-v2\"; \\n  /* Claude requires you to enclose the prompt as follows: */ \\n  const enclosedPrompt = `Human: ${prompt}\\\\n\\\\nAssistant:`; \\n  /* The different model providers have individual request and response formats. \\n   * For the format, ranges, and default values for Anthropic Claude, refer to: \\n   * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nclaude.html \\n   */ \\n  const payload = { \\n    prompt: enclosedPrompt, \\n    max_tokens_to_sample: 500, \\n    temperature: 0.5, \\n    stop_sequences: [\"\\\\n\\\\nHuman:\"], \\n  }; \\n  const command = new InvokeModelCommand({ \\n    body: JSON.stringify(payload), \\n    contentType: \"application/json\", \\n    accept: \"application/json\", \\n    modelId, \\n  }); \\n  try { \\n    const response = await client.send(command); \\n    const decodedResponseBody = new TextDecoder().decode(response.body); \\n    /** @type {ResponseBody} */ \\n    const responseBody = JSON.parse(decodedResponseBody); \\n    return responseBody.completion; \\n  } catch (err) { \\n    if (err instanceof AccessDeniedException) { \\n      console.error( \\n        `Access denied. Ensure you have the correct permissions to invoke \\n ${modelId}.`, \\n      ); \\n    } else { \\n      throw err; \\n    } \\nActions 646Amazon Bedrock User Guide\\n  }\\n};\\n// Invoke the function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  const prompt = \\'Complete the following: \"Once upon a time...\"\\'; \\n  console.log(\"\\\\nModel: Anthropic Claude v2\"); \\n  console.log(`Prompt: ${prompt}`); \\n  const completion = await invokeClaude(prompt); \\n  console.log(\"Completion:\"); \\n  console.log(completion); \\n  console.log(\"\\\\n\");\\n}\\n•For API details, see InvokeModel in AWS SDK for JavaScript API Reference.\\nPHP\\nSDK for PHP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Anthropic Claude 2 foundation model to generate text.\\n    public function invokeClaude($prompt) \\n    { \\n        # The different model providers have individual request and response \\n formats. \\n        # For the format, ranges, and default values for Anthropic Claude, refer \\n to: \\n        # https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nclaude.html \\n        $completion = \"\"; \\n        try { \\nActions 647Amazon Bedrock User Guide\\n            $modelId = \\'anthropic.claude-v2\\'; \\n            # Claude requires you to enclose the prompt as follows: \\n            $prompt = \"\\\\n\\\\nHuman: {$prompt}\\\\n\\\\nAssistant:\"; \\n            $body = [ \\n                \\'prompt\\' => $prompt, \\n                \\'max_tokens_to_sample\\' => 200, \\n                \\'temperature\\' => 0.5, \\n                \\'stop_sequences\\' => [\"\\\\n\\\\nHuman:\"], \\n            ]; \\n            $result = $this->bedrockRuntimeClient->invokeModel([ \\n                \\'contentType\\' => \\'application/json\\', \\n                \\'body\\' => json_encode($body), \\n                \\'modelId\\' => $modelId, \\n            ]); \\n            $response_body = json_decode($result[\\'body\\']); \\n            $completion = $response_body->completion; \\n        } catch (Exception $e) { \\n            echo \"Error: ({$e->getCode()}) - {$e->getMessage()}\\\\n\"; \\n        } \\n        return $completion; \\n    }\\n•For API details, see InvokeModel in AWS SDK for PHP API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Anthropic Claude 2 foundation model to generate text.\\nActions 648Amazon Bedrock User Guide\\n    def invoke_claude(self, prompt): \\n        \"\"\" \\n        Invokes the Anthropic Claude 2 model to run an inference using the input \\n        provided in the request body. \\n        :param prompt: The prompt that you want Claude to complete. \\n        :return: Inference response from the model. \\n        \"\"\" \\n        try: \\n            # The different model providers have individual request and response \\n formats. \\n            # For the format, ranges, and default values for Anthropic Claude, \\n refer to: \\n            # https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-claude.html \\n            # Claude requires you to enclose the prompt as follows: \\n            enclosed_prompt = \"Human: \" + prompt + \"\\\\n\\\\nAssistant:\" \\n            body = { \\n                \"prompt\": enclosed_prompt, \\n                \"max_tokens_to_sample\": 200, \\n                \"temperature\": 0.5, \\n                \"stop_sequences\": [\"\\\\n\\\\nHuman:\"], \\n            } \\n            response = self.bedrock_runtime_client.invoke_model( \\n                modelId=\"anthropic.claude-v2\", body=json.dumps(body) \\n            ) \\n            response_body = json.loads(response[\"body\"].read()) \\n            completion = response_body[\"completion\"] \\n            return completion \\n        except ClientError: \\n            logger.error(\"Couldn\\'t invoke Anthropic Claude\") \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nActions 649Amazon Bedrock User Guide\\nSAP ABAP\\nSDK for SAP ABAP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Anthropic Claude 2 foundation model to generate text. This example uses \\nfeatures of /US2/CL_JSON which might not be available on some NetWeaver versions.\\n    \"Claude V2 Input Parameters should be in a format like this:\\n*   {\\n*     \"prompt\":\"\\\\n\\\\nHuman:\\\\\\\\nTell me a joke\\\\n\\\\nAssistant:\\\\n\",\\n*     \"max_tokens_to_sample\":2048,\\n*     \"temperature\":0.5,\\n*     \"top_k\":250,\\n*     \"top_p\":1.0,\\n*     \"stop_sequences\":[]\\n*   } \\n    DATA: BEGIN OF ls_input, \\n            prompt               TYPE string, \\n            max_tokens_to_sample TYPE /aws1/rt_shape_integer, \\n            temperature          TYPE /aws1/rt_shape_float, \\n            top_k                TYPE /aws1/rt_shape_integer, \\n            top_p                TYPE /aws1/rt_shape_float, \\n            stop_sequences       TYPE /aws1/rt_stringtab, \\n          END OF ls_input. \\n    \"Leave ls_input-stop_sequences empty. \\n    ls_input-prompt = |\\\\n\\\\nHuman:\\\\\\\\n{ iv_prompt }\\\\n\\\\nAssistant:\\\\n|. \\n    ls_input-max_tokens_to_sample = 2048. \\n    ls_input-temperature = \\'0.5\\'. \\n    ls_input-top_k = 250. \\n    ls_input-top_p = 1. \\n    \"Serialize into JSON with /ui2/cl_json -- this assumes SAP_UI is installed. \\n    DATA(lv_json) = /ui2/cl_json=>serialize( \\n      data = ls_input \\nActions 650Amazon Bedrock User Guide\\n                pretty_name   = /ui2/cl_json=>pretty_mode-low_case ). \\n    TRY. \\n        DATA(lo_response) = lo_bdr->invokemodel( \\n          iv_body = /aws1/cl_rt_util=>string_to_xstring( lv_json ) \\n          iv_modelid = \\'anthropic.claude-v2\\' \\n          iv_accept = \\'application/json\\' \\n          iv_contenttype = \\'application/json\\' ). \\n        \"Claude V2 Response format will be:\\n*       {\\n*         \"completion\": \"Knock Knock...\",\\n*         \"stop_reason\": \"stop_sequence\"\\n*       } \\n        DATA: BEGIN OF ls_response, \\n                completion  TYPE string, \\n                stop_reason TYPE string, \\n              END OF ls_response. \\n        /ui2/cl_json=>deserialize( \\n          EXPORTING jsonx = lo_response->get_body( ) \\n                    pretty_name = /ui2/cl_json=>pretty_mode-camel_case \\n          CHANGING  data  = ls_response ). \\n        DATA(lv_answer) = ls_response-completion. \\n      CATCH /aws1/cx_bdraccessdeniedex INTO DATA(lo_ex). \\n        WRITE / lo_ex->get_text( ). \\n        WRITE / |Don\\'t forget to enable model access at https://\\nconsole.aws.amazon.com/bedrock/home?#/modelaccess|. \\n    ENDTRY.\\nInvoke the Anthropic Claude 2 foundation model to generate text using L2 high level client.\\n    TRY. \\n        DATA(lo_bdr_l2_claude) = /aws1/\\ncl_bdr_l2_factory=>create_claude_2( lo_bdr ). \\n        \" iv_prompt can contain a prompt like \\'tell me a joke about Java \\n programmers\\'. \\n        DATA(lv_answer) = lo_bdr_l2_claude->prompt_for_text( iv_prompt ). \\n      CATCH /aws1/cx_bdraccessdeniedex INTO DATA(lo_ex). \\n        WRITE / lo_ex->get_text( ). \\nActions 651Amazon Bedrock User Guide\\n        WRITE / |Don\\'t forget to enable model access at https://\\nconsole.aws.amazon.com/bedrock/home?#/modelaccess|. \\n    ENDTRY.\\n•For API details, see InvokeModel in AWS SDK for SAP ABAP API reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke the Anthropic Claude 2 model on Amazon Bedrock for text generation \\nwith a response stream\\nThe following code examples show how to invoke the Anthropic Claude 2 model on Amazon \\nBedrock for text generation with a response stream.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Invoke multiple foundation models on Amazon Bedrock\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Anthropic Claude 2 model and process the response stream.\\n        /// <summary> \\n        /// Asynchronously invokes the Anthropic Claude 2 model to run an \\n inference based on the provided input and process the response stream. \\n        /// </summary> \\nActions 652Amazon Bedrock User Guide\\n        /// <param name=\"prompt\">The prompt that you want Claude to complete.</\\nparam> \\n        /// <returns>The inference response from the model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for Anthropic Claude, \\n refer to: \\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-claude.html \\n        /// </remarks> \\n        public static async IAsyncEnumerable<string> \\n InvokeClaudeWithResponseStreamAsync(string prompt, [EnumeratorCancellation] \\n CancellationToken cancellationToken = default) \\n        { \\n            string claudeModelId = \"anthropic.claude-v2\"; \\n            // Claude requires you to enclose the prompt as follows: \\n            string enclosedPrompt = \"Human: \" + prompt + \"\\\\n\\\\nAssistant:\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USEast1); \\n            string payload = new JsonObject() \\n             { \\n                 { \"prompt\", enclosedPrompt }, \\n                 { \"max_tokens_to_sample\", 200 }, \\n                 { \"temperature\", 0.5 }, \\n                 { \"stop_sequences\", new JsonArray(\"\\\\n\\\\nHuman:\") } \\n             }.ToJsonString(); \\n            InvokeModelWithResponseStreamResponse? response = null; \\n            try \\n            { \\n                response = await client.InvokeModelWithResponseStreamAsync(new \\n InvokeModelWithResponseStreamRequest() \\n                { \\n                    ModelId = claudeModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\nActions 653Amazon Bedrock User Guide\\n            { \\n                Console.WriteLine(e.Message); \\n            } \\n            if (response is not null && response.HttpStatusCode == \\n System.Net.HttpStatusCode.OK) \\n            { \\n                // create a buffer to write the event in to move from a push mode \\n to a pull mode \\n                Channel<string> buffer = Channel.CreateUnbounded<string>(); \\n                bool isStreaming = true; \\n                response.Body.ChunkReceived += BodyOnChunkReceived; \\n                response.Body.StartProcessing(); \\n                while ((!cancellationToken.IsCancellationRequested \\n && isStreaming) || (!cancellationToken.IsCancellationRequested && \\n buffer.Reader.Count > 0)) \\n                { \\n                    // pull the completion from the buffer and add it to the \\n IAsyncEnumerable collection \\n                    yield return await \\n buffer.Reader.ReadAsync(cancellationToken); \\n                } \\n                response.Body.ChunkReceived -= BodyOnChunkReceived; \\n                yield break; \\n                // handle the ChunkReceived events \\n                async void BodyOnChunkReceived(object? sender, \\n EventStreamEventReceivedArgs<PayloadPart> e) \\n                { \\n                    var streamResponse = \\n JsonSerializer.Deserialize<JsonObject>(e.EventStreamEvent.Bytes) ?? \\n throw new NullReferenceException($\"Unable to deserialize \\n {nameof(e.EventStreamEvent.Bytes)}\"); \\n                    if (streamResponse[\"stop_reason\"]?.GetValue<string?>() != \\n null) \\n                    { \\n                        isStreaming = false; \\n                    } \\n                    // write the received completion chunk into the buffer \\nActions 654Amazon Bedrock User Guide\\n                    await \\n buffer.Writer.WriteAsync(streamResponse[\"completion\"]?.GetValue<string>(), \\n cancellationToken); \\n                } \\n            } \\n            else if (response is not null) \\n            { \\n                Console.WriteLine(\"InvokeModelAsync failed with status code \" + \\n response.HttpStatusCode); \\n            } \\n            yield break; \\n        }\\n•For API details, see InvokeModelWithResponseStream in AWS SDK for .NET API Reference.\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Anthropic Claude 2 model and process the response stream.\\n// Each model provider defines their own individual request and response formats.\\n// For the format, ranges, and default values for the different models, refer to:\\n// https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html\\ntype Request struct { \\n Prompt            string  `json:\"prompt\"` \\n MaxTokensToSample int     `json:\"max_tokens_to_sample\"` \\n Temperature       float64 `json:\"temperature,omitempty\"`\\n}\\ntype Response struct { \\nActions 655Amazon Bedrock User Guide\\n Completion string `json:\"completion\"`\\n}\\n// Invokes Anthropic Claude on Amazon Bedrock to run an inference and \\n asynchronously\\n// process the response stream.\\nfunc (wrapper InvokeModelWithResponseStreamWrapper) \\n InvokeModelWithResponseStream(prompt string) (string, error) { \\n modelId := \"anthropic.claude-v2\" \\n // Anthropic Claude requires you to enclose the prompt as follows: \\n prefix := \"Human: \" \\n postfix := \"\\\\n\\\\nAssistant:\" \\n prompt = prefix + prompt + postfix \\n request := ClaudeRequest{ \\n  Prompt:            prompt, \\n  MaxTokensToSample: 200, \\n  Temperature:       0.5, \\n  StopSequences:     []string{\"\\\\n\\\\nHuman:\"}, \\n } \\n body, err := json.Marshal(request) \\n if err != nil { \\n  log.Panicln(\"Couldn\\'t marshal the request: \", err) \\n } \\n output, err := \\n wrapper.BedrockRuntimeClient.InvokeModelWithResponseStream(context.Background(), \\n &bedrockruntime.InvokeModelWithResponseStreamInput{ \\n  Body:        body, \\n  ModelId:     aws.String(modelId), \\n  ContentType: aws.String(\"application/json\"), \\n }) \\n if err != nil { \\n  errMsg := err.Error() \\n  if strings.Contains(errMsg, \"no such host\") { \\n   log.Printf(\"The Bedrock service is not available in the selected region. \\n Please double-check the service availability for your region at https://\\naws.amazon.com/about-aws/global-infrastructure/regional-product-services/.\\\\n\") \\n  } else if strings.Contains(errMsg, \"Could not resolve the foundation model\") { \\nActions 656Amazon Bedrock User Guide\\n   log.Printf(\"Could not resolve the foundation model from model identifier: \\\\\"%v\\n\\\\\". Please verify that the requested model exists and is accessible within the \\n specified region.\\\\n\", modelId) \\n  } else { \\n   log.Printf(\"Couldn\\'t invoke Anthropic Claude. Here\\'s why: %v\\\\n\", err) \\n  } \\n } \\n resp, err := processStreamingOutput(output, func(ctx context.Context, part \\n []byte) error { \\n  fmt.Print(string(part)) \\n  return nil \\n }) \\n if err != nil { \\n  log.Fatal(\"streaming output processing error: \", err) \\n } \\n return resp.Completion, nil\\n}\\ntype StreamingOutputHandler func(ctx context.Context, part []byte) error\\nfunc processStreamingOutput(output \\n *bedrockruntime.InvokeModelWithResponseStreamOutput, handler \\n StreamingOutputHandler) (Response, error) { \\n var combinedResult string \\n resp := Response{} \\n for event := range output.GetStream().Events() { \\n  switch v := event.(type) { \\n  case *types.ResponseStreamMemberChunk: \\n   //fmt.Println(\"payload\", string(v.Value.Bytes)) \\n   var resp Response \\n   err := json.NewDecoder(bytes.NewReader(v.Value.Bytes)).Decode(&resp) \\n   if err != nil { \\n    return resp, err \\n   } \\n   err = handler(context.Background(), []byte(resp.Completion)) \\nActions 657Amazon Bedrock User Guide\\n   if err != nil { \\n    return resp, err \\n   } \\n   combinedResult += resp.Completion \\n  case *types.UnknownUnionMember: \\n   fmt.Println(\"unknown tag:\", v.Tag) \\n  default: \\n   fmt.Println(\"union is nil or unknown type\") \\n  } \\n } \\n resp.Completion = combinedResult \\n return resp, nil\\n}\\n•For API details, see InvokeModelWithResponseStream in AWS SDK for Go API Reference.\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Anthropic Claude 2 model and process the response stream.\\n        /** \\n         * Invokes the Anthropic Claude 2 model and processes the response \\n stream. \\n         * \\n         * @param prompt The prompt for Claude to complete. \\n         * @param silent Suppress console output of the individual response \\n stream \\nActions 658Amazon Bedrock User Guide\\n         *               chunks. \\n         * @return The generated response. \\n         */ \\n        public static String invokeClaude(String prompt, boolean silent) { \\n                BedrockRuntimeAsyncClient client = \\n BedrockRuntimeAsyncClient.builder() \\n                                .region(Region.US_EAST_1) \\n                                \\n .credentialsProvider(ProfileCredentialsProvider.create()) \\n                                .build(); \\n                var finalCompletion = new AtomicReference<>(\"\"); \\n                var payload = new JSONObject() \\n                                .put(\"prompt\", \"Human: \" + prompt + \" \\n Assistant:\") \\n                                .put(\"temperature\", 0.8) \\n                                .put(\"max_tokens_to_sample\", 300) \\n                                .toString(); \\n                var request = InvokeModelWithResponseStreamRequest.builder() \\n                                .body(SdkBytes.fromUtf8String(payload)) \\n                                .modelId(\"anthropic.claude-v2\") \\n                                .contentType(\"application/json\") \\n                                .accept(\"application/json\") \\n                                .build(); \\n                var visitor = \\n InvokeModelWithResponseStreamResponseHandler.Visitor.builder() \\n                                .onChunk(chunk -> { \\n                                        var json = new \\n JSONObject(chunk.bytes().asUtf8String()); \\n                                        var completion = \\n json.getString(\"completion\"); \\n                                        finalCompletion.set(finalCompletion.get() \\n + completion); \\n                                        if (!silent) { \\n                                                System.out.print(completion); \\n                                        } \\n                                }) \\n                                .build(); \\nActions 659Amazon Bedrock User Guide\\n                var handler = \\n InvokeModelWithResponseStreamResponseHandler.builder() \\n                                .onEventStream(stream -> stream.subscribe(event -\\n> event.accept(visitor))) \\n                                .onComplete(() -> { \\n                                }) \\n                                .onError(e -> System.out.println(\"\\\\n\\\\nError: \" + \\n e.getMessage())) \\n                                .build(); \\n                client.invokeModelWithResponseStream(request, handler).join(); \\n                return finalCompletion.get(); \\n        }\\n•For API details, see InvokeModelWithResponseStream in AWS SDK for Java 2.x API \\nReference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Anthropic Claude 2 model and process the response stream.\\n    async def invoke_model_with_response_stream(self, prompt): \\n        \"\"\" \\n        Invokes the Anthropic Claude 2 model to run an inference and process the \\n response stream. \\n        :param prompt: The prompt that you want Claude to complete. \\n        :return: Inference response from the model. \\n        \"\"\" \\n        try: \\nActions 660Amazon Bedrock User Guide\\n            # The different model providers have individual request and response \\n formats. \\n            # For the format, ranges, and default values for Anthropic Claude, \\n refer to: \\n            # https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-claude.html \\n            # Claude requires you to enclose the prompt as follows: \\n            enclosed_prompt = \"Human: \" + prompt + \"\\\\n\\\\nAssistant:\" \\n            body = { \\n                \"prompt\": enclosed_prompt, \\n                \"max_tokens_to_sample\": 1024, \\n                \"temperature\": 0.5, \\n                \"stop_sequences\": [\"\\\\n\\\\nHuman:\"], \\n            } \\n            response = \\n self.bedrock_runtime_client.invoke_model_with_response_stream( \\n                modelId=\"anthropic.claude-v2\", body=json.dumps(body) \\n            ) \\n            for event in response.get(\"body\"): \\n                chunk = json.loads(event[\"chunk\"][\"bytes\"])[\"completion\"] \\n                yield chunk \\n        except ClientError: \\n            logger.error(\"Couldn\\'t invoke Anthropic Claude v2\") \\n            raise\\n•For API details, see InvokeModelWithResponseStream in AWS SDK for Python (Boto3) API \\nReference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nActions 661Amazon Bedrock User Guide\\nInvoke Anthropic Claude 3 on Amazon Bedrock to generate text\\nThe following code example shows how to invoke Anthropic Claude 3 on Amazon Bedrock to \\ngenerate text.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Invoke multiple LLMs on Amazon Bedrock\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke Anthropic Claude 3 to generate text.\\n    def invoke_claude_3_with_text(self, prompt): \\n        \"\"\" \\n        Invokes Anthropic Claude 3 Sonnet to run an inference using the input \\n        provided in the request body. \\n        :param prompt: The prompt that you want Claude 3 to complete. \\n        :return: Inference response from the model. \\n        \"\"\" \\n        # Initialize the Amazon Bedrock runtime client \\n        client = self.client or boto3.client( \\n            service_name=\"bedrock-runtime\", region_name=\"us-east-1\" \\n        ) \\n        # Invoke Claude 3 with the text prompt \\n        model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\" \\nActions 662Amazon Bedrock User Guide\\n        try: \\n            response = client.invoke_model( \\n                modelId=model_id, \\n                body=json.dumps( \\n                    { \\n                        \"anthropic_version\": \"bedrock-2023-05-31\", \\n                        \"max_tokens\": 1024, \\n                        \"messages\": [ \\n                            { \\n                                \"role\": \"user\", \\n                                \"content\": [{\"type\": \"text\", \"text\": prompt}], \\n                            } \\n                        ], \\n                    } \\n                ), \\n            ) \\n            # Process and print the response \\n            result = json.loads(response.get(\"body\").read()) \\n            input_tokens = result[\"usage\"][\"input_tokens\"] \\n            output_tokens = result[\"usage\"][\"output_tokens\"] \\n            output_list = result.get(\"content\", []) \\n            print(\"Invocation details:\") \\n            print(f\"- The input length is {input_tokens} tokens.\") \\n            print(f\"- The output length is {output_tokens} tokens.\") \\n            print(f\"- The model returned {len(output_list)} response(s):\") \\n            for output in output_list: \\n                print(output[\"text\"]) \\n            return result \\n        except ClientError as err: \\n            logger.error( \\n                \"Couldn\\'t invoke Claude 3 Sonnet. Here\\'s why: %s: %s\", \\n                err.response[\"Error\"][\"Code\"], \\n                err.response[\"Error\"][\"Message\"], \\n            ) \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nActions 663Amazon Bedrock User Guide\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke the Meta Llama 2 Chat model on Amazon Bedrock for text generation\\nThe following code examples show how to invoke the Meta Llama 2 Chat model on Amazon \\nBedrock for text generation.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Invoke multiple LLMs on Amazon Bedrock\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Meta Llama 2 foundation model to generate text.\\n        /// <summary> \\n        /// Asynchronously invokes the Meta Llama 2 Chat model to run an \\n inference based on the provided input. \\n        /// </summary> \\n        /// <param name=\"prompt\">The prompt that you want Llama 2 to complete.</\\nparam> \\n        /// <returns>The inference response from the model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for Meta Llama 2 Chat, \\n refer to: \\nActions 664Amazon Bedrock User Guide\\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-meta.html \\n        /// </remarks> \\n        public static async Task<string> InvokeLlama2Async(string prompt) \\n        { \\n            string llama2ModelId = \"meta.llama2-13b-chat-v1\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USEast1); \\n            string payload = new JsonObject() \\n            { \\n                { \"prompt\", prompt }, \\n                { \"max_gen_len\", 512 }, \\n                { \"temperature\", 0.5 }, \\n                { \"top_p\", 0.9 } \\n            }.ToJsonString(); \\n            string generatedText = \"\"; \\n            try \\n            { \\n                InvokeModelResponse response = await client.InvokeModelAsync(new \\n InvokeModelRequest() \\n                { \\n                    ModelId = llama2ModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n                if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    return JsonNode.ParseAsync(response.Body) \\n                        .Result?[\"generation\"]?.GetValue<string>() ?? \"\"; \\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"InvokeModelAsync failed with status code \" \\n + response.HttpStatusCode); \\n                } \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\nActions 665Amazon Bedrock User Guide\\n            return generatedText; \\n        }\\n•For API details, see InvokeModel in AWS SDK for .NET API Reference.\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Meta Llama 2 Chat foundation model to generate text.\\n// Each model provider has their own individual request and response formats.\\n// For the format, ranges, and default values for Meta Llama 2 Chat, refer to:\\n// https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nmeta.html\\ntype Llama2Request struct { \\n Prompt            string   `json:\"prompt\"` \\n MaxGenLength    int      `json:\"max_gen_len,omitempty\"` \\n Temperature       float64  `json:\"temperature,omitempty\"`\\n}\\ntype Llama2Response struct { \\n Generation string `json:\"generation\"`\\n}\\n// Invokes Meta Llama 2 Chat on Amazon Bedrock to run an inference using the \\n input\\n// provided in the request body.\\nfunc (wrapper InvokeModelWrapper) InvokeLlama2(prompt string) (string, error) { \\n    modelId := \"meta.llama2-13b-chat-v1\" \\n body, err := json.Marshal(Llama2Request { \\nActions 666Amazon Bedrock User Guide\\n  Prompt:            prompt, \\n  MaxGenLength:    512, \\n  Temperature:       0.5, \\n }) \\n if err != nil { log.Fatal(\"failed to marshal\", err) } \\n output, err := wrapper.BedrockRuntimeClient.InvokeModel(context.TODO(), \\n &bedrockruntime.InvokeModelInput{ \\n  ModelId: aws.String(modelId), \\n  ContentType: aws.String(\"application/json\"), \\n  Body: body, \\n }) \\n if err != nil { ProcessError(err, modelId) } \\n var response Llama2Response \\n    if err := json.Unmarshal(output.Body, &response); err != nil { \\n        log.Fatal(\"failed to unmarshal\", err) \\n    } \\n return response.Generation, nil\\n}\\n•For API details, see InvokeModel in AWS SDK for Go API Reference.\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Meta Llama 2 Chat foundation model to generate text.\\n    /** \\nActions 667Amazon Bedrock User Guide\\n     * Asynchronously invokes the Meta Llama 2 Chat model to run an inference \\n based \\n     * on the provided input. \\n     * \\n     * @param prompt The prompt that you want Llama 2 to complete. \\n     * @return The inference response generated by the model. \\n     */ \\n    public static String invokeLlama2(String prompt) { \\n        /* \\n         * The different model providers have individual request and response \\n formats. \\n         * For the format, ranges, and default values for Meta Llama 2 Chat, \\n refer to: \\n         * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nmeta. \\n         * html \\n         */ \\n        String llama2ModelId = \"meta.llama2-13b-chat-v1\"; \\n        BedrockRuntimeAsyncClient client = BedrockRuntimeAsyncClient.builder() \\n                .region(Region.US_EAST_1) \\n                .credentialsProvider(ProfileCredentialsProvider.create()) \\n                .build(); \\n        String payload = new JSONObject() \\n                .put(\"prompt\", prompt) \\n                .put(\"max_gen_len\", 512) \\n                .put(\"temperature\", 0.5) \\n                .put(\"top_p\", 0.9) \\n                .toString(); \\n        InvokeModelRequest request = InvokeModelRequest.builder() \\n                .body(SdkBytes.fromUtf8String(payload)) \\n                .modelId(llama2ModelId) \\n                .contentType(\"application/json\") \\n                .accept(\"application/json\") \\n                .build(); \\n        CompletableFuture<InvokeModelResponse> completableFuture = \\n client.invokeModel(request) \\n                .whenComplete((response, exception) -> { \\n                    if (exception != null) { \\nActions 668Amazon Bedrock User Guide\\n                        System.out.println(\"Model invocation failed: \" + \\n exception); \\n                    } \\n                }); \\n        String generatedText = \"\"; \\n        try { \\n            InvokeModelResponse response = completableFuture.get(); \\n            JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n            generatedText = responseBody.getString(\"generation\"); \\n        } catch (InterruptedException e) { \\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n        } catch (ExecutionException e) { \\n            System.err.println(e.getMessage()); \\n        } \\n        return generatedText; \\n    }\\nInvoke the Meta Llama 2 Chat foundation model to generate text.\\n        /** \\n         * Invokes the Meta Llama 2 Chat model to run an inference based on the \\n provided \\n         * input. \\n         * \\n         * @param prompt The prompt for Llama 2 to complete. \\n         * @return The generated response. \\n         */ \\n        public static String invokeLlama2(String prompt) { \\n                /* \\n                 * The different model providers have individual request and \\n response formats. \\n                 * For the format, ranges, and default values for Meta Llama 2 \\n Chat, refer to: \\n                 * https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-meta. \\n                 * html \\n                 */ \\nActions 669Amazon Bedrock User Guide\\n                String llama2ModelId = \"meta.llama2-13b-chat-v1\"; \\n                BedrockRuntimeClient client = BedrockRuntimeClient.builder() \\n                                .region(Region.US_EAST_1) \\n                                \\n .credentialsProvider(ProfileCredentialsProvider.create()) \\n                                .build(); \\n                String payload = new JSONObject() \\n                                .put(\"prompt\", prompt) \\n                                .put(\"max_gen_len\", 512) \\n                                .put(\"temperature\", 0.5) \\n                                .put(\"top_p\", 0.9) \\n                                .toString(); \\n                InvokeModelRequest request = InvokeModelRequest.builder() \\n                                .body(SdkBytes.fromUtf8String(payload)) \\n                                .modelId(llama2ModelId) \\n                                .contentType(\"application/json\") \\n                                .accept(\"application/json\") \\n                                .build(); \\n                InvokeModelResponse response = client.invokeModel(request); \\n                JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n                String generatedText = responseBody.getString(\"generation\"); \\n                return generatedText; \\n        }\\n•For API details, see InvokeModel in AWS SDK for Java 2.x API Reference.\\nActions 670Amazon Bedrock User Guide\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Meta Llama 2 Chat foundation model to generate text.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  AccessDeniedException, \\n  BedrockRuntimeClient, \\n  InvokeModelCommand,\\n} from \"@aws-sdk/client-bedrock-runtime\";\\n/** \\n * @typedef {Object} ResponseBody \\n * @property {generation} text \\n */\\n/** \\n * Invokes the Meta Llama 2 Chat model to run an inference \\n * using the input provided in the request body. \\n * \\n * @param {string} prompt - The prompt that you want Llama-2 to complete. \\n * @returns {string} The inference response (generation) from the model. \\n */\\nexport const invokeLlama2 = async (prompt) => { \\n  const client = new BedrockRuntimeClient({ region: \"us-east-1\" }); \\n  const modelId = \"meta.llama2-13b-chat-v1\"; \\n  /* The different model providers have individual request and response formats. \\n   * For the format, ranges, and default values for Meta Llama 2 Chat, refer to: \\nActions 671Amazon Bedrock User Guide\\n   * https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nmeta.html \\n   */ \\n  const payload = { \\n    prompt, \\n    temperature: 0.5, \\n    top_p: 0.9, \\n    max_gen_len: 512, \\n  }; \\n  const command = new InvokeModelCommand({ \\n    body: JSON.stringify(payload), \\n    contentType: \"application/json\", \\n    accept: \"application/json\", \\n    modelId, \\n  }); \\n  try { \\n    const response = await client.send(command); \\n    const decodedResponseBody = new TextDecoder().decode(response.body); \\n    /** @type {ResponseBody} */ \\n    const responseBody = JSON.parse(decodedResponseBody); \\n    return responseBody.generation; \\n  } catch (err) { \\n    if (err instanceof AccessDeniedException) { \\n      console.error( \\n        `Access denied. Ensure you have the correct permissions to invoke \\n ${modelId}.`, \\n      ); \\n    } else { \\n      throw err; \\n    } \\n  }\\n};\\n// Invoke the function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  const prompt = \\'Complete the following: \"Once upon a time...\"\\'; \\n  console.log(\"\\\\nModel: Meta Llama 2 Chat\"); \\n  console.log(`Prompt: ${prompt}`); \\n  const completion = await invokeLlama2(prompt); \\nActions 672Amazon Bedrock User Guide\\n  console.log(\"Completion:\"); \\n  console.log(completion); \\n  console.log(\"\\\\n\");\\n}\\n•For API details, see InvokeModel in AWS SDK for JavaScript API Reference.\\nPHP\\nSDK for PHP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Meta Llama 2 Chat foundation model to generate text.\\n    public function invokeLlama2($prompt) \\n    { \\n        # The different model providers have individual request and response \\n formats. \\n        # For the format, ranges, and default values for Meta Llama 2 Chat, refer \\n to: \\n        # https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-\\nmeta.html \\n        $completion = \"\"; \\n        try { \\n            $modelId = \\'meta.llama2-13b-chat-v1\\'; \\n            $body = [ \\n                \\'prompt\\' => $prompt, \\n                \\'temperature\\' => 0.5, \\n                \\'max_gen_len\\' => 512, \\n            ]; \\n            $result = $this->bedrockRuntimeClient->invokeModel([ \\n                \\'contentType\\' => \\'application/json\\', \\nActions 673Amazon Bedrock User Guide\\n                \\'body\\' => json_encode($body), \\n                \\'modelId\\' => $modelId, \\n            ]); \\n            $response_body = json_decode($result[\\'body\\']); \\n            $completion = $response_body->generation; \\n        } catch (Exception $e) { \\n            echo \"Error: ({$e->getCode()}) - {$e->getMessage()}\\\\n\"; \\n        } \\n        return $completion; \\n    }\\n•For API details, see InvokeModel in AWS SDK for PHP API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Meta Llama 2 Chat foundation model to generate text.\\n    def invoke_llama2(self, prompt): \\n        \"\"\" \\n        Invokes the Meta Llama 2 large-language model to run an inference \\n        using the input provided in the request body. \\n        :param prompt: The prompt that you want Llama 2 to complete. \\n        :return: Inference response from the model. \\n        \"\"\" \\n        try: \\n            # The different model providers have individual request and response \\n formats. \\nActions 674Amazon Bedrock User Guide\\n            # For the format, ranges, and default values for Meta Llama 2 Chat, \\n refer to: \\n            # https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-meta.html \\n            body = { \\n                \"prompt\": prompt, \\n                \"temperature\": 0.5, \\n                \"top_p\": 0.9, \\n                \"max_gen_len\": 512, \\n            } \\n            response = self.bedrock_runtime_client.invoke_model( \\n                modelId=\"meta.llama2-13b-chat-v1\", body=json.dumps(body) \\n            ) \\n            response_body = json.loads(response[\"body\"].read()) \\n            completion = response_body[\"generation\"] \\n            return completion \\n        except ClientError: \\n            logger.error(\"Couldn\\'t invoke Llama 2\") \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke the Mistral 7B model on Amazon Bedrock for text generation\\nThe following code examples show how to invoke the Mistral 7B model model on Amazon Bedrock \\nfor text generation.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\nActions 675Amazon Bedrock User Guide\\n•Invoke multiple LLMs on Amazon Bedrock\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Mistral 7B foundation model to generate text.\\n        /// <summary> \\n        /// Asynchronously invokes the Mistral 7B model to run an inference based \\n on the provided input. \\n        /// </summary> \\n        /// <param name=\"prompt\">The prompt that you want Mistral 7B to \\n complete.</param> \\n        /// <returns>The inference response from the model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for Mistral 7B, refer to: \\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-mistral.html \\n        /// </remarks> \\n        public static async Task<List<string?>> InvokeMistral7BAsync(string \\n prompt) \\n        { \\n            string mistralModelId = \"mistral.mistral-7b-instruct-v0:2\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USWest2); \\n            string payload = new JsonObject() \\n            { \\n                { \"prompt\", prompt }, \\n                { \"max_tokens\", 200 }, \\n                { \"temperature\", 0.5 } \\n            }.ToJsonString(); \\nActions 676Amazon Bedrock User Guide\\n            List<string?>? generatedText = null; \\n            try \\n            { \\n                InvokeModelResponse response = await client.InvokeModelAsync(new \\n InvokeModelRequest() \\n                { \\n                    ModelId = mistralModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n                if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    var results = JsonNode.ParseAsync(response.Body).Result?\\n[\"outputs\"]?.AsArray(); \\n                    generatedText = results?.Select(x => x?\\n[\"text\"]?.GetValue<string?>())?.ToList(); \\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"InvokeModelAsync failed with status code \" \\n + response.HttpStatusCode); \\n                } \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\n            return generatedText ?? []; \\n        }\\n•For API details, see InvokeModel in AWS SDK for .NET API Reference.\\nActions 677Amazon Bedrock User Guide\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Mistral 7B foundation model to generate text.\\n    /** \\n     * Asynchronously invokes the Mistral 7B model to run an inference based on \\n the provided input. \\n     * \\n     * @param prompt The prompt for Mistral to complete. \\n     * @return The generated response. \\n     */ \\n    public static List<String> invokeMistral7B(String prompt) { \\n        BedrockRuntimeAsyncClient client = BedrockRuntimeAsyncClient.builder() \\n                .region(Region.US_WEST_2) \\n                .credentialsProvider(ProfileCredentialsProvider.create()) \\n                .build(); \\n        // Mistral instruct models provide optimal results when \\n        // embedding the prompt into the following template: \\n        String instruction = \"<s>[INST] \" + prompt + \" [/INST]\"; \\n        String modelId = \"mistral.mistral-7b-instruct-v0:2\"; \\n        String payload = new JSONObject() \\n                .put(\"prompt\", instruction) \\n                .put(\"max_tokens\", 200) \\n                .put(\"temperature\", 0.5) \\n                .toString(); \\n        CompletableFuture<InvokeModelResponse> completableFuture = \\n client.invokeModel(request -> request \\n                .accept(\"application/json\") \\n                .contentType(\"application/json\") \\n                .body(SdkBytes.fromUtf8String(payload)) \\n                .modelId(modelId)) \\nActions 678Amazon Bedrock User Guide\\n        .whenComplete((response, exception) -> { \\n            if (exception != null) { \\n                System.out.println(\"Model invocation failed: \" + exception); \\n            } \\n        }); \\n        try { \\n            InvokeModelResponse response = completableFuture.get(); \\n            JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n            JSONArray outputs = responseBody.getJSONArray(\"outputs\"); \\n            return IntStream.range(0, outputs.length()) \\n                    .mapToObj(i -> outputs.getJSONObject(i).getString(\"text\")) \\n                    .toList(); \\n        } catch (InterruptedException e) { \\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n        } catch (ExecutionException e) { \\n            System.err.println(e.getMessage()); \\n        } \\n        return List.of(); \\n    }\\nInvoke the Mistral 7B foundation model to generate text.\\n        /** \\n         * Invokes the Mistral 7B model to run an inference based on the provided \\n input. \\n         * \\n         * @param prompt The prompt for Mistral to complete. \\n         * @return The generated responses. \\n         */ \\n        public static List<String> invokeMistral7B(String prompt) { \\n                BedrockRuntimeClient client = BedrockRuntimeClient.builder() \\n                        .region(Region.US_WEST_2) \\n                        .credentialsProvider(ProfileCredentialsProvider.create()) \\n                        .build(); \\n                // Mistral instruct models provide optimal results when \\n                // embedding the prompt into the following template: \\nActions 679Amazon Bedrock User Guide\\n                String instruction = \"<s>[INST] \" + prompt + \" [/INST]\"; \\n                String modelId = \"mistral.mistral-7b-instruct-v0:2\"; \\n                String payload = new JSONObject() \\n                        .put(\"prompt\", instruction) \\n                        .put(\"max_tokens\", 200) \\n                        .put(\"temperature\", 0.5) \\n                        .toString(); \\n                InvokeModelResponse response = client.invokeModel(request -> \\n request \\n                        .accept(\"application/json\") \\n                        .contentType(\"application/json\") \\n                        .body(SdkBytes.fromUtf8String(payload)) \\n                        .modelId(modelId)); \\n                JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n                JSONArray outputs = responseBody.getJSONArray(\"outputs\"); \\n                return IntStream.range(0, outputs.length()) \\n                        .mapToObj(i -> \\n outputs.getJSONObject(i).getString(\"text\")) \\n                        .toList(); \\n        }\\n•For API details, see InvokeModel in AWS SDK for Java 2.x API Reference.\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Mistral 7B foundation model to generate text.\\nActions 680Amazon Bedrock User Guide\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  AccessDeniedException, \\n  BedrockRuntimeClient, \\n  InvokeModelCommand,\\n} from \"@aws-sdk/client-bedrock-runtime\";\\n/** \\n * @typedef {Object} Output \\n * @property {string} text \\n * \\n * @typedef {Object} ResponseBody \\n * @property {Output[]} outputs \\n */\\n/** \\n * Invokes the Mistral 7B model to run an inference using the input \\n * provided in the request body. \\n * \\n * @param {string} prompt - The prompt that you want Mistral to complete. \\n * @returns {string[]} A list of inference responses (completions) from the \\n model. \\n */\\nexport const invokeMistral7B = async (prompt) => { \\n  const client = new BedrockRuntimeClient({ region: \"us-west-2\" }); \\n  const modelId = \"mistral.mistral-7b-instruct-v0:2\"; \\n  // Mistral instruct models provide optimal results when embedding \\n  // the prompt into the following template: \\n  const instruction = `<s>[INST] ${prompt} [/INST]`; \\n  const payload = { \\n    prompt: instruction, \\n    max_tokens: 500, \\n    temperature: 0.5, \\n  }; \\n  const command = new InvokeModelCommand({ \\nActions 681Amazon Bedrock User Guide\\n    body: JSON.stringify(payload), \\n    contentType: \"application/json\", \\n    accept: \"application/json\", \\n    modelId, \\n  }); \\n  try { \\n    const response = await client.send(command); \\n    const decodedResponseBody = new TextDecoder().decode(response.body); \\n    /** @type {ResponseBody} */ \\n    const responseBody = JSON.parse(decodedResponseBody); \\n    return responseBody.outputs.map((output) => output.text); \\n  } catch (err) { \\n    if (err instanceof AccessDeniedException) { \\n      console.error( \\n        `Access denied. Ensure you have the correct permissions to invoke \\n ${modelId}.`, \\n      ); \\n    } else { \\n      throw err; \\n    } \\n  }\\n};\\n// Invoke the function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  const prompt = \\'Complete the following: \"Once upon a time...\"\\'; \\n  console.log(\"\\\\nModel: Mistral 7B\"); \\n  console.log(`Prompt: ${prompt}`); \\n  const completions = await invokeMistral7B(prompt); \\n  completions.forEach((completion) => { \\n    console.log(\"Completion:\"); \\n    console.log(completion); \\n    console.log(\"\\\\n\"); \\n  });\\n}\\n•For API details, see InvokeModel in AWS SDK for JavaScript API Reference.\\nActions 682Amazon Bedrock User Guide\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Mistral 7B foundation model to generate text.\\n    def invoke_mistral_7b(self, prompt): \\n        \"\"\" \\n        Invokes the Mistral 7B model to run an inference using the input \\n        provided in the request body. \\n        :param prompt: The prompt that you want Mistral to complete. \\n        :return: List of inference responses from the model. \\n        \"\"\" \\n        try: \\n            # Mistral instruct models provide optimal results when \\n            # embedding the prompt into the following template: \\n            instruction = f\"<s>[INST] {prompt} [/INST]\" \\n            model_id = \"mistral.mistral-7b-instruct-v0:2\" \\n            body = { \\n                \"prompt\": instruction, \\n                \"max_tokens\": 200, \\n                \"temperature\": 0.5, \\n            } \\n            response = self.bedrock_runtime_client.invoke_model( \\n                modelId=model_id, body=json.dumps(body) \\n            ) \\n            response_body = json.loads(response[\"body\"].read()) \\n            outputs = response_body.get(\"outputs\") \\n            completions = [output[\"text\"] for output in outputs] \\nActions 683Amazon Bedrock User Guide\\n            return completions \\n        except ClientError: \\n            logger.error(\"Couldn\\'t invoke Mistral 7B\") \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke the Mixtral 8x7B model on Amazon Bedrock for text generation\\nThe following code examples show how to invoke the Mixtral 8x7B model model on Amazon \\nBedrock for text generation.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code examples:\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Invoke multiple LLMs on Amazon Bedrock\\n.NET\\nAWS SDK for .NET\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Mixtral 8x7B foundation model to generate text.\\n        /// <summary> \\nActions 684Amazon Bedrock User Guide\\n        /// Asynchronously invokes the Mixtral 8x7B model to run an inference \\n based on the provided input. \\n        /// </summary> \\n        /// <param name=\"prompt\">The prompt that you want Mixtral 8x7B to \\n complete.</param> \\n        /// <returns>The inference response from the model</returns> \\n        /// <remarks> \\n        /// The different model providers have individual request and response \\n formats. \\n        /// For the format, ranges, and default values for Mixtral 8x7B, refer \\n to: \\n        ///     https://docs.aws.amazon.com/bedrock/latest/userguide/model-\\nparameters-mistral.html \\n        /// </remarks> \\n        public static async Task<List<string?>> InvokeMixtral8x7BAsync(string \\n prompt) \\n        { \\n            string mixtralModelId = \"mistral.mixtral-8x7b-instruct-v0:1\"; \\n            AmazonBedrockRuntimeClient client = new(RegionEndpoint.USWest2); \\n            string payload = new JsonObject() \\n            { \\n                { \"prompt\", prompt }, \\n                { \"max_tokens\", 200 }, \\n                { \"temperature\", 0.5 } \\n            }.ToJsonString(); \\n            List<string?>? generatedText = null; \\n            try \\n            { \\n                InvokeModelResponse response = await client.InvokeModelAsync(new \\n InvokeModelRequest() \\n                { \\n                    ModelId = mixtralModelId, \\n                    Body = AWSSDKUtils.GenerateMemoryStreamFromString(payload), \\n                    ContentType = \"application/json\", \\n                    Accept = \"application/json\" \\n                }); \\n                if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \\n                { \\n                    var results = JsonNode.ParseAsync(response.Body).Result?\\n[\"outputs\"]?.AsArray(); \\nActions 685Amazon Bedrock User Guide\\n                    generatedText = results?.Select(x => x?\\n[\"text\"]?.GetValue<string?>())?.ToList(); \\n                } \\n                else \\n                { \\n                    Console.WriteLine(\"InvokeModelAsync failed with status code \" \\n + response.HttpStatusCode); \\n                } \\n            } \\n            catch (AmazonBedrockRuntimeException e) \\n            { \\n                Console.WriteLine(e.Message); \\n            } \\n            return generatedText ?? []; \\n        }\\n•For API details, see InvokeModel in AWS SDK for .NET API Reference.\\nJava\\nSDK for Java 2.x\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nAsynchronously invoke the Mistral 8x7B foundation model to generate text.\\n    /** \\n     * Asynchronously invokes the Mixtral 8x7B model to run an inference based on \\n the provided input. \\n     * \\n     * @param prompt The prompt for Mixtral to complete. \\n     * @return The generated response. \\n     */ \\n    public static List<String> invokeMixtral8x7B(String prompt) { \\n        BedrockRuntimeAsyncClient client = BedrockRuntimeAsyncClient.builder() \\nActions 686Amazon Bedrock User Guide\\n                .region(Region.US_WEST_2) \\n                .credentialsProvider(ProfileCredentialsProvider.create()) \\n                .build(); \\n        // Mistral instruct models provide optimal results when \\n        // embedding the prompt into the following template: \\n        String instruction = \"<s>[INST] \" + prompt + \" [/INST]\"; \\n        String modelId = \"mistral.mixtral-8x7b-instruct-v0:1\"; \\n        String payload = new JSONObject() \\n                .put(\"prompt\", instruction) \\n                .put(\"max_tokens\", 200) \\n                .put(\"temperature\", 0.5) \\n                .toString(); \\n        CompletableFuture<InvokeModelResponse> completableFuture = \\n client.invokeModel(request -> request \\n                        .accept(\"application/json\") \\n                        .contentType(\"application/json\") \\n                        .body(SdkBytes.fromUtf8String(payload)) \\n                        .modelId(modelId)) \\n                .whenComplete((response, exception) -> { \\n                    if (exception != null) { \\n                        System.out.println(\"Model invocation failed: \" + \\n exception); \\n                    } \\n                }); \\n        try { \\n            InvokeModelResponse response = completableFuture.get(); \\n            JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n            JSONArray outputs = responseBody.getJSONArray(\"outputs\"); \\n            return IntStream.range(0, outputs.length()) \\n                    .mapToObj(i -> outputs.getJSONObject(i).getString(\"text\")) \\n                    .toList(); \\n        } catch (InterruptedException e) { \\n            Thread.currentThread().interrupt(); \\n            System.err.println(e.getMessage()); \\n        } catch (ExecutionException e) { \\n            System.err.println(e.getMessage()); \\n        } \\nActions 687Amazon Bedrock User Guide\\n        return List.of(); \\n    }\\nInvoke the Mixtral 8x7B foundation model to generate text.\\n        public static List<String> invokeMixtral8x7B(String prompt) { \\n                BedrockRuntimeClient client = BedrockRuntimeClient.builder() \\n                        .region(Region.US_WEST_2) \\n                        .credentialsProvider(ProfileCredentialsProvider.create()) \\n                        .build(); \\n                // Mistral instruct models provide optimal results when \\n                // embedding the prompt into the following template: \\n                String instruction = \"<s>[INST] \" + prompt + \" [/INST]\"; \\n                String modelId = \"mistral.mixtral-8x7b-instruct-v0:1\"; \\n                String payload = new JSONObject() \\n                        .put(\"prompt\", instruction) \\n                        .put(\"max_tokens\", 200) \\n                        .put(\"temperature\", 0.5) \\n                        .toString(); \\n                InvokeModelResponse response = client.invokeModel(request -> \\n request \\n                        .accept(\"application/json\") \\n                        .contentType(\"application/json\") \\n                        .body(SdkBytes.fromUtf8String(payload)) \\n                        .modelId(modelId)); \\n                JSONObject responseBody = new \\n JSONObject(response.body().asUtf8String()); \\n                JSONArray outputs = responseBody.getJSONArray(\"outputs\"); \\n                return IntStream.range(0, outputs.length()) \\n                        .mapToObj(i -> \\n outputs.getJSONObject(i).getString(\"text\")) \\n                        .toList(); \\n        }\\nActions 688Amazon Bedrock User Guide\\n•For API details, see InvokeModel in AWS SDK for Java 2.x API Reference.\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Mixtral 8x7B foundation model to generate text.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  AccessDeniedException, \\n  BedrockRuntimeClient, \\n  InvokeModelCommand,\\n} from \"@aws-sdk/client-bedrock-runtime\";\\nimport { invokeMistral7B } from \"./invoke-mistral7b.js\";\\n/** \\n * @typedef {Object} Output \\n * @property {string} text \\n * \\n * @typedef {Object} ResponseBody \\n * @property {Output[]} outputs \\n */\\n/** \\n * Invokes the Mixtral 8x7B model to run an inference using the input \\n * provided in the request body. \\n * \\n * @param {string} prompt - The prompt that you want Mistral to complete. \\n * @returns {string[]} A list of inference responses (completions) from the \\n model. \\n */\\nActions 689Amazon Bedrock User Guide\\nexport const invokeMixtral8x7B = async (prompt) => { \\n  const client = new BedrockRuntimeClient({ region: \"us-west-2\" }); \\n  // Mistral instruct models provide optimal results when embedding \\n  // the prompt into the following template: \\n  const instruction = `<s>[INST] ${prompt} [/INST]`; \\n  const modelId = \"mistral.mixtral-8x7b-instruct-v0:1\"; \\n  const payload = { \\n    prompt: instruction, \\n    max_tokens: 500, \\n    temperature: 0.5, \\n  }; \\n  const command = new InvokeModelCommand({ \\n    body: JSON.stringify(payload), \\n    contentType: \"application/json\", \\n    accept: \"application/json\", \\n    modelId, \\n  }); \\n  try { \\n    const response = await client.send(command); \\n    const decodedResponseBody = new TextDecoder().decode(response.body); \\n    /** @type {ResponseBody} */ \\n    const responseBody = JSON.parse(decodedResponseBody); \\n    return responseBody.outputs.map((output) => output.text); \\n  } catch (err) { \\n    if (err instanceof AccessDeniedException) { \\n      console.error( \\n        `Access denied. Ensure you have the correct permissions to invoke \\n ${modelId}.`, \\n      ); \\n    } else { \\n      throw err; \\n    } \\n  }\\n};\\n// Invoke the function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\nActions 690Amazon Bedrock User Guide\\n  const prompt = \\'Complete the following: \"Once upon a time...\"\\'; \\n  console.log(\"\\\\nModel: Mixtral 8x7B\"); \\n  console.log(`Prompt: ${prompt}`); \\n  const completions = await invokeMistral7B(prompt); \\n  completions.forEach((completion) => { \\n    console.log(\"Completion:\"); \\n    console.log(completion); \\n    console.log(\"\\\\n\"); \\n  });\\n}\\n•For API details, see InvokeModel in AWS SDK for JavaScript API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke the Mixtral 8x7B foundation model to generate text.\\n    def invoke_mixtral_8x7b(self, prompt): \\n        \"\"\" \\n        Invokes the Mixtral 8c7B model to run an inference using the input \\n        provided in the request body. \\n        :param prompt: The prompt that you want Mixtral to complete. \\n        :return: List of inference responses from the model. \\n        \"\"\" \\n        try: \\n            # Mistral instruct models provide optimal results when \\n            # embedding the prompt into the following template: \\n            instruction = f\"<s>[INST] {prompt} [/INST]\" \\n            model_id = \"mistral.mixtral-8x7b-instruct-v0:1\" \\nActions 691Amazon Bedrock User Guide\\n            body = { \\n                \"prompt\": instruction, \\n                \"max_tokens\": 200, \\n                \"temperature\": 0.5, \\n            } \\n            response = self.bedrock_runtime_client.invoke_model( \\n                modelId=model_id, body=json.dumps(body) \\n            ) \\n            response_body = json.loads(response[\"body\"].read()) \\n            outputs = response_body.get(\"outputs\") \\n            completions = [output[\"text\"] for output in outputs] \\n            return completions \\n        except ClientError: \\n            logger.error(\"Couldn\\'t invoke Mixtral 8x7B\") \\n            raise\\n•For API details, see InvokeModel in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nScenarios for Amazon Bedrock Runtime using AWS SDKs\\nThe following code examples show you how to implement common scenarios in Amazon Bedrock \\nRuntime with AWS SDKs. These scenarios show you how to accomplish speciﬁc tasks by calling \\nmultiple functions within Amazon Bedrock Runtime. Each scenario includes a link to GitHub, where \\nyou can ﬁnd instructions on how to set up and run the code.\\nExamples\\n•Create a sample application that oﬀers playgrounds to interact with Amazon Bedrock foundation \\nmodels using an AWS SDK\\n•Invoke multiple large-language models (LLMs) on Amazon Bedrock\\nScenarios 692Amazon Bedrock User Guide\\n•Invoke multiple foundation models on Amazon Bedrock\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nCreate a sample application that oﬀers playgrounds to interact with Amazon \\nBedrock foundation models using an AWS SDK\\nThe following code examples show how to create playgrounds to interact with Amazon Bedrock \\nfoundation models through diﬀerent modalities.\\n.NET\\nAWS SDK for .NET\\n.NET Foundation Model (FM) Playground is a .NET MAUI Blazor sample application that \\nshowcases how to use Amazon Bedrock from C# code. This example shows how .NET and \\nC# developers can use Amazon Bedrock to build generative AI-enabled applications. You \\ncan test and interact with Amazon Bedrock foundation models by using the following four \\nplaygrounds:\\n•A text playground.\\n•A chat playground.\\n•A voice chat playground.\\n•An image playground.\\nThe example also lists and displays the foundation models you have access to and their \\ncharacteristics. For source code and deployment instructions, see the project in GitHub .\\nServices used in this example\\n•Amazon Bedrock Runtime\\nJava\\nSDK for Java 2.x\\nThe Java Foundation Model (FM) Playground is a Spring Boot sample application that \\nshowcases how to use Amazon Bedrock with Java. This example shows how Java developers \\ncan use Amazon Bedrock to build generative AI-enabled applications. You can test and \\ninteract with Amazon Bedrock foundation models by using the following three playgrounds:\\nScenarios 693Amazon Bedrock User Guide\\n•A text playground.\\n•A chat playground.\\n•An image playground.\\nThe example also lists and displays the foundation models you have access to, along with \\ntheir characteristics. For source code and deployment instructions, see the project in GitHub .\\nServices used in this example\\n•Amazon Bedrock Runtime\\nPython\\nSDK for Python (Boto3)\\nThe Python Foundation Model (FM) Playground is a Python/FastAPI sample application \\nthat showcases how to use Amazon Bedrock with Python. This example shows how Python \\ndevelopers can use Amazon Bedrock to build generative AI-enabled applications. You can \\ntest and interact with Amazon Bedrock foundation models by using the following three \\nplaygrounds:\\n•A text playground.\\n•A chat playground.\\n•An image playground.\\nThe example also lists and displays the foundation models you have access to, along with \\ntheir characteristics. For source code and deployment instructions, see the project in GitHub .\\nServices used in this example\\n•Amazon Bedrock Runtime\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke multiple large-language models (LLMs) on Amazon Bedrock\\nThe following code example shows how to invoke multiple large-language-models (LLMs) on \\nAmazon Bedrock.\\nScenarios 694Amazon Bedrock User Guide\\n•Generate text with Anthropic Claude.\\n•Generate text with AI21 Labs Jurassic-2.\\n•Generate text with Meta Llama 2 Chat.\\nPHP\\nSDK for PHP\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke multiple LLMs on Amazon Bedrock.\\nnamespace BedrockRuntime;\\nclass GettingStartedWithBedrockRuntime\\n{ \\n    protected BedrockRuntimeService $bedrockRuntimeService; \\n    public function runExample() \\n    { \\n        echo \"\\\\n\"; \\n        echo \\n \"---------------------------------------------------------------------\\\\n\"; \\n        echo \"Welcome to the Amazon Bedrock Runtime getting started demo using \\n PHP!\\\\n\"; \\n        echo \\n \"---------------------------------------------------------------------\\\\n\"; \\n        $clientArgs = [ \\n            \\'region\\' => \\'us-east-1\\', \\n            \\'version\\' => \\'latest\\', \\n            \\'profile\\' => \\'default\\', \\n        ]; \\n        $bedrockRuntimeService = new BedrockRuntimeService($clientArgs); \\n        $prompt = \\'In one paragraph, who are you?\\'; \\nScenarios 695Amazon Bedrock User Guide\\n        echo \"\\\\nPrompt: \" . $prompt; \\n        echo \"\\\\n\\\\nAnthropic Claude:\"; \\n        echo $bedrockRuntimeService->invokeClaude($prompt); \\n        echo \"\\\\n\\\\nAI21 Labs Jurassic-2: \"; \\n        echo $bedrockRuntimeService->invokeJurassic2($prompt); \\n        echo \"\\\\n\\\\nMeta Llama 2 Chat: \"; \\n        echo $bedrockRuntimeService->invokeLlama2($prompt); \\n        echo \\n \"\\\\n---------------------------------------------------------------------\\\\n\"; \\n        $image_prompt = \\'stylized picture of a cute old steampunk robot\\'; \\n        echo \"\\\\nImage prompt: \" . $image_prompt; \\n        echo \"\\\\n\\\\nStability.ai Stable Diffusion XL:\\\\n\"; \\n        $diffusionSeed = rand(0, 4294967295); \\n        $style_preset = \\'photographic\\'; \\n        $base64 = $bedrockRuntimeService->invokeStableDiffusion($image_prompt, \\n $diffusionSeed, $style_preset); \\n        $image_path = $this->saveImage($base64, \\'stability.stable-diffusion-xl\\'); \\n        echo \"The generated images have been saved to $image_path\"; \\n        echo \"\\\\n\\\\nAmazon Titan Image Generation:\\\\n\"; \\n        $titanSeed = rand(0, 2147483647); \\n        $base64 = $bedrockRuntimeService->invokeTitanImage($image_prompt, \\n $titanSeed); \\n        $image_path = $this->saveImage($base64, \\'amazon.titan-image-generator-\\nv1\\'); \\n        echo \"The generated images have been saved to $image_path\"; \\n    } \\n    private function saveImage($base64_image_data, $model_id): string \\n    { \\n        $output_dir = \"output\"; \\n        if (!file_exists($output_dir)) { \\n            mkdir($output_dir); \\n        } \\nScenarios 696Amazon Bedrock User Guide\\n        $i = 1; \\n        while (file_exists(\"$output_dir/$model_id\" . \\'_\\' . \"$i.png\")) { \\n            $i++; \\n        } \\n        $image_data = base64_decode($base64_image_data); \\n        $file_path = \"$output_dir/$model_id\" . \\'_\\' . \"$i.png\"; \\n        $file = fopen($file_path, \\'wb\\'); \\n        fwrite($file, $image_data); \\n        fclose($file); \\n        return $file_path; \\n    }\\n}\\n•For API details, see InvokeModel in AWS SDK for PHP API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nInvoke multiple foundation models on Amazon Bedrock\\nThe following code example shows how to invoke multiple foundation models on Amazon Bedrock.\\n•Generate text with Anthropic Claude.\\n•Generate text with AI21 Labs Jurassic-2.\\n•Generate text with Meta Llama 2 Chat.\\n•Asynchronously process the response stream from Anthropic Claude.\\n•Generate an image with the Amazon Titan Image Generator.\\nScenarios 697Amazon Bedrock User Guide\\nGo\\nSDK for Go V2\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke multiple foundation models on Amazon Bedrock.\\n// InvokeModelsScenario demonstrates how to use the Amazon Bedrock Runtime client\\n// to invoke various foundation models for text and image generation\\n//\\n// 1. Generate text with Anthropic Claude 2\\n// 2. Generate text with AI21 Labs Jurassic-2\\n// 3. Generate text with Meta Llama 2 Chat\\n// 4. Generate text and asynchronously process the response stream with Anthropic \\n Claude 2\\n// 5. Generate and image with the Amazon Titan image generation model\\ntype InvokeModelsScenario struct { \\n sdkConfig             aws.Config \\n invokeModelWrapper    actions.InvokeModelWrapper \\n responseStreamWrapper actions.InvokeModelWithResponseStreamWrapper \\n questioner            demotools.IQuestioner\\n}\\n// NewInvokeModelsScenario constructs an InvokeModelsScenario instance from a \\n configuration.\\n// It uses the specified config to get a Bedrock Runtime client and create \\n wrappers for the\\n// actions used in the scenario.\\nfunc NewInvokeModelsScenario(sdkConfig aws.Config, questioner \\n demotools.IQuestioner) InvokeModelsScenario { \\n client := bedrockruntime.NewFromConfig(sdkConfig) \\n return InvokeModelsScenario{ \\n  sdkConfig:             sdkConfig, \\n  invokeModelWrapper:    actions.InvokeModelWrapper{BedrockRuntimeClient: \\n client}, \\n  responseStreamWrapper: \\n actions.InvokeModelWithResponseStreamWrapper{BedrockRuntimeClient: client}, \\nScenarios 698Amazon Bedrock User Guide\\n  questioner:            questioner, \\n }\\n}\\n// Runs the interactive scenario.\\nfunc (scenario InvokeModelsScenario) Run() { \\n defer func() { \\n  if r := recover(); r != nil { \\n   log.Printf(\"Something went wrong with the demo: %v\\\\n\", r) \\n  } \\n }() \\n log.Println(strings.Repeat(\"=\", 77)) \\n log.Println(\"Welcome to the Amazon Bedrock Runtime model invocation demo.\") \\n log.Println(strings.Repeat(\"=\", 77)) \\n log.Printf(\"First, let\\'s invoke a few large-language models using the \\n synchronous client:\\\\n\\\\n\") \\n text2textPrompt := \"In one paragraph, who are you?\" \\n log.Println(strings.Repeat(\"-\", 77)) \\n log.Printf(\"Invoking Claude with prompt: %v\\\\n\", text2textPrompt) \\n scenario.InvokeClaude(text2textPrompt) \\n log.Println(strings.Repeat(\"-\", 77)) \\n log.Printf(\"Invoking Jurassic-2 with prompt: %v\\\\n\", text2textPrompt) \\n scenario.InvokeJurassic2(text2textPrompt) \\n log.Println(strings.Repeat(\"-\", 77)) \\n log.Printf(\"Invoking Llama2 with prompt: %v\\\\n\", text2textPrompt) \\n scenario.InvokeLlama2(text2textPrompt) \\n log.Println(strings.Repeat(\"=\", 77)) \\n log.Printf(\"Now, let\\'s invoke Claude with the asynchronous client and process \\n the response stream:\\\\n\\\\n\") \\n log.Println(strings.Repeat(\"-\", 77)) \\n log.Printf(\"Invoking Claude with prompt: %v\\\\n\", text2textPrompt) \\n scenario.InvokeWithResponseStream(text2textPrompt) \\n log.Println(strings.Repeat(\"=\", 77)) \\n log.Printf(\"Now, let\\'s create an image with the Amazon Titan image generation \\n model:\\\\n\\\\n\") \\nScenarios 699Amazon Bedrock User Guide\\n text2ImagePrompt := \"stylized picture of a cute old steampunk robot\" \\n seed := rand.Int63n(2147483648) \\n log.Println(strings.Repeat(\"-\", 77)) \\n log.Printf(\"Invoking Amazon Titan with prompt: %v\\\\n\", text2ImagePrompt) \\n scenario.InvokeTitanImage(text2ImagePrompt, seed) \\n log.Println(strings.Repeat(\"=\", 77)) \\n log.Println(\"Thanks for watching!\") \\n log.Println(strings.Repeat(\"=\", 77))\\n}\\nfunc (scenario InvokeModelsScenario) InvokeClaude(prompt string) { \\n completion, err := scenario.invokeModelWrapper.InvokeClaude(prompt) \\n if err != nil { \\n  panic(err) \\n } \\n log.Printf(\"\\\\nClaude     : %v\\\\n\", strings.TrimSpace(completion))\\n}\\nfunc (scenario InvokeModelsScenario) InvokeJurassic2(prompt string) { \\n completion, err := scenario.invokeModelWrapper.InvokeJurassic2(prompt) \\n if err != nil { \\n  panic(err) \\n } \\n log.Printf(\"\\\\nJurassic-2 : %v\\\\n\", strings.TrimSpace(completion))\\n}\\nfunc (scenario InvokeModelsScenario) InvokeLlama2(prompt string) { \\n completion, err := scenario.invokeModelWrapper.InvokeLlama2(prompt) \\n if err != nil { \\n  panic(err) \\n } \\n log.Printf(\"\\\\nLlama 2    : %v\\\\n\\\\n\", strings.TrimSpace(completion))\\n}\\nfunc (scenario InvokeModelsScenario) InvokeWithResponseStream(prompt string) { \\n log.Println(\"\\\\nClaude with response stream:\") \\n _, err := scenario.responseStreamWrapper.InvokeModelWithResponseStream(prompt) \\n if err != nil { \\n  panic(err) \\n } \\n log.Println()\\nScenarios 700Amazon Bedrock User Guide\\n}\\nfunc (scenario InvokeModelsScenario) InvokeTitanImage(prompt string, seed int64) \\n { \\n base64ImageData, err := scenario.invokeModelWrapper.InvokeTitanImage(prompt, \\n seed) \\n if err != nil { \\n  panic(err) \\n } \\n imagePath := saveImage(base64ImageData, \"amazon.titan-image-generator-v1\") \\n fmt.Printf(\"The generated image has been saved to %s\\\\n\", imagePath)\\n}\\n•For API details, see the following topics in AWS SDK for Go API Reference.\\n•InvokeModel\\n•InvokeModelWithResponseStream\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nBuild and orchestrate generative AI applications with Amazon Bedrock and Step \\nFunctions\\nThe following code example shows how to build and orchestrate generative AI applications with \\nAmazon Bedrock and Step Functions.\\nPython\\nSDK for Python (Boto3)\\nThe Amazon Bedrock Serverless Prompt Chaining scenario demonstrates how AWS Step \\nFunctions, Amazon Bedrock, and Agents for Amazon Bedrock can be used to build and \\norchestrate complex, serverless, and highly scalable generative AI applications. It contains \\nthe following working examples:\\n•Write an analysis of a given novel for a literature blog. This example illustrates a simple, \\nsequential chain of prompts.\\nScenarios 701Amazon Bedrock User Guide\\n•Generate a short story about a given topic. This example illustrates how the AI can \\niteratively process a list of items that it previously generated.\\n•Create an itinerary for a weekend vacation to a given destination. This example illustrates \\nhow to parallelize multiple distinct prompts.\\n•Pitch movie ideas to a human user acting as a movie producer. This example illustrates \\nhow to parallelize the same prompt with diﬀerent inference parameters, how to backtrack \\nto a previous step in the chain, and how to include human input as part of the workﬂow.\\n•Plan a meal based on ingredients the user has at hand. This example illustrates how \\nprompt chains can incorporate two distinct AI conversations, with two AI personas \\nengaging in a debate with each other to improve the ﬁnal outcome.\\n•Find and summarize today\\'s highest trending GitHub repository. This example illustrates \\nchaining multiple AI agents that interact with external APIs.\\nFor complete source code and instructions to set up and run, see the full project on GitHub .\\nServices used in this example\\n•Amazon Bedrock\\n•Amazon Bedrock Runtime\\n•Agents for Amazon Bedrock\\n•Agents for Amazon Bedrock Runtime\\n•Step Functions\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nCode examples for Agents for Amazon Bedrock using AWS SDKs\\nThe following code examples show how to use Agents for Amazon Bedrock with an AWS software \\ndevelopment kit (SDK).\\nActions  are code excerpts from larger programs and must be run in context. While actions show you \\nhow to call individual service functions, you can see actions in context in their related scenarios and \\ncross-service examples.\\nAgents for Amazon Bedrock 702Amazon Bedrock User Guide\\nScenarios  are code examples that show you how to accomplish a speciﬁc task by calling multiple \\nfunctions within the same service.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nGet started\\nHello Agents for Amazon Bedrock\\nThe following code example shows how to get started using Agents for Amazon Bedrock.\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  BedrockAgentClient, \\n  GetAgentCommand, \\n  paginateListAgents,\\n} from \"@aws-sdk/client-bedrock-agent\";\\n/** \\n * @typedef {Object} AgentSummary \\n */\\n/** \\n * A simple scenario to demonstrate basic setup and interaction with the Bedrock \\n Agents Client. \\n * \\nAgents for Amazon Bedrock 703Amazon Bedrock User Guide\\n * This function first initializes the Amazon Bedrock Agents client for a \\n specific region. \\n * It then retrieves a list of existing agents using the streamlined paginator \\n approach. \\n * For each agent found, it retrieves detailed information using a command \\n object. \\n * \\n * Demonstrates: \\n * - Use of the Bedrock Agents client to initialize and communicate with the AWS \\n service. \\n * - Listing resources in a paginated response pattern. \\n * - Accessing an individual resource using a command object. \\n * \\n * @returns {Promise<void>} A promise that resolves when the function has \\n completed execution. \\n */\\nexport const main = async () => { \\n  const region = \"us-east-1\"; \\n  console.log(\"=\".repeat(68)); \\n  console.log(`Initializing Amazon Bedrock Agents client for ${region}...`); \\n  const client = new BedrockAgentClient({ region }); \\n  console.log(`Retrieving the list of existing agents...`); \\n  const paginatorConfig = { client }; \\n  const pages = paginateListAgents(paginatorConfig, {}); \\n  /** @type {AgentSummary[]} */ \\n  const agentSummaries = []; \\n  for await (const page of pages) { \\n    agentSummaries.push(...page.agentSummaries); \\n  } \\n  console.log(`Found ${agentSummaries.length} agents in ${region}.`); \\n  if (agentSummaries.length > 0) { \\n    for (const agentSummary of agentSummaries) { \\n      const agentId = agentSummary.agentId; \\n      console.log(\"=\".repeat(68)); \\n      console.log(`Retrieving agent with ID: ${agentId}:`); \\n      console.log(\"-\".repeat(68)); \\n      const command = new GetAgentCommand({ agentId }); \\nAgents for Amazon Bedrock 704Amazon Bedrock User Guide\\n      const response = await client.send(command); \\n      const agent = response.agent; \\n      console.log(` Name: ${agent.agentName}`); \\n      console.log(` Status: ${agent.agentStatus}`); \\n      console.log(` ARN: ${agent.agentArn}`); \\n      console.log(` Foundation model: ${agent.foundationModel}`); \\n    } \\n  } \\n  console.log(\"=\".repeat(68));\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  await main();\\n}\\n•For API details, see the following topics in AWS SDK for JavaScript API Reference.\\n•GetAgent\\n•ListAgents\\nCode examples\\n•Actions for Agents for Amazon Bedrock using AWS SDKs\\n•Create an Amazon Bedrock agent using an AWS SDK\\n•Create an Amazon Bedrock agent action group using an AWS SDK\\n•Create an Amazon Bedrock agent alias using an AWS SDK\\n•Delete an Amazon Bedrock agent using an AWS SDK\\n•Delete an Amazon Bedrock agent alias using an AWS SDK\\n•Get information about an Amazon Bedrock agent using an AWS SDK\\n•List the action groups for a Amazon Bedrock agent using an AWS SDK\\n•List the Agents for Amazon Bedrock belonging to an account using an AWS SDK\\n•List the knowledge bases associated with a Amazon Bedrock agent using an AWS SDK\\n•Prepare an Amazon Bedrock agent using an AWS SDK\\n•Scenarios for Agents for Amazon Bedrock using AWS SDKs\\nAgents for Amazon Bedrock 705Amazon Bedrock User Guide\\n•An end-to-end example showing how to create and invoke Amazon Bedrock agents using an \\nAWS SDK\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nActions for Agents for Amazon Bedrock using AWS SDKs\\nThe following code examples demonstrate how to perform individual Agents for Amazon Bedrock \\nactions with AWS SDKs. These excerpts call the Agents for Amazon Bedrock API and are code \\nexcerpts from larger programs that must be run in context. Each example includes a link to GitHub, \\nwhere you can ﬁnd instructions for setting up and running the code.\\nThe following examples include only the most commonly used actions. For a complete list, see the\\nAgents for Amazon Bedrock API Reference.\\nExamples\\n•Create an Amazon Bedrock agent using an AWS SDK\\n•Create an Amazon Bedrock agent action group using an AWS SDK\\n•Create an Amazon Bedrock agent alias using an AWS SDK\\n•Delete an Amazon Bedrock agent using an AWS SDK\\n•Delete an Amazon Bedrock agent alias using an AWS SDK\\n•Get information about an Amazon Bedrock agent using an AWS SDK\\n•List the action groups for a Amazon Bedrock agent using an AWS SDK\\n•List the Agents for Amazon Bedrock belonging to an account using an AWS SDK\\n•List the knowledge bases associated with a Amazon Bedrock agent using an AWS SDK\\n•Prepare an Amazon Bedrock agent using an AWS SDK\\nCreate an Amazon Bedrock agent using an AWS SDK\\nThe following code examples show how to create an Amazon Bedrock agent.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nActions 706Amazon Bedrock User Guide\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nCreate an agent.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { checkForPlaceholders } from \"../lib/utils.js\";\\nimport { \\n  BedrockAgentClient, \\n  CreateAgentCommand,\\n} from \"@aws-sdk/client-bedrock-agent\";\\n/** \\n * Creates an Amazon Bedrock Agent. \\n * \\n * @param {string} agentName - A name for the agent that you create. \\n * @param {string} foundationModel - The foundation model to be used by the agent \\n you create. \\n * @param {string} agentResourceRoleArn - The ARN of the IAM role with \\n permissions required by the agent. \\n * @param {string} [region=\\'us-east-1\\'] - The AWS region in use. \\n * @returns {Promise<import(\"@aws-sdk/client-bedrock-agent\").Agent>} An object \\n containing details of the created agent. \\n */\\nexport const createAgent = async ( \\n  agentName, \\n  foundationModel, \\n  agentResourceRoleArn, \\n  region = \"us-east-1\",\\n) => { \\n  const client = new BedrockAgentClient({ region }); \\nActions 707Amazon Bedrock User Guide\\n  const command = new CreateAgentCommand({ \\n    agentName, \\n    foundationModel, \\n    agentResourceRoleArn, \\n  }); \\n  const response = await client.send(command); \\n  return response.agent;\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  // Replace the placeholders for agentName and accountId, and roleName with a \\n unique name for the new agent, \\n  // the id of your AWS account, and the name of an existing execution role that \\n the agent can use inside your account. \\n  // For foundationModel, specify the desired model. Ensure to remove the \\n brackets \\'[]\\' before adding your data. \\n  // A string (max 100 chars) that can include letters, numbers, dashes \\'-\\', and \\n underscores \\'_\\'. \\n  const agentName = \"[your-bedrock-agent-name]\"; \\n  // Your AWS account id. \\n  const accountId = \"[123456789012]\"; \\n  // The name of the agent\\'s execution role. It must be prefixed by \\n `AmazonBedrockExecutionRoleForAgents_`. \\n  const roleName = \"[AmazonBedrockExecutionRoleForAgents_your-role-name]\"; \\n  // The ARN for the agent\\'s execution role. \\n  // Follow the ARN format: \\'arn:aws:iam::account-id:role/role-name\\' \\n  const roleArn = `arn:aws:iam::${accountId}:role/${roleName}`; \\n  // Specify the model for the agent. Change if a different model is preferred. \\n  const foundationModel = \"anthropic.claude-v2\"; \\n  // Check for unresolved placeholders in agentName and roleArn. \\n  checkForPlaceholders([agentName, roleArn]); \\n  console.log(`Creating a new agent...`); \\n  const agent = await createAgent(agentName, foundationModel, roleArn); \\n  console.log(agent);\\nActions 708Amazon Bedrock User Guide\\n}\\n•For API details, see CreateAgent in AWS SDK for JavaScript API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nCreate an agent.\\n    def create_agent(self, agent_name, foundation_model, role_arn, instruction): \\n        \"\"\" \\n        Creates an agent that orchestrates interactions between foundation \\n models, \\n        data sources, software applications, user conversations, and APIs to \\n carry \\n        out tasks to help customers. \\n        :param agent_name: A name for the agent. \\n        :param foundation_model: The foundation model to be used for \\n orchestration by the agent. \\n        :param role_arn: The ARN of the IAM role with permissions needed by the \\n agent. \\n        :param instruction: Instructions that tell the agent what it should do \\n and how it should \\n                            interact with users. \\n        :return: The response from Agents for Bedrock if successful, otherwise \\n raises an exception. \\n        \"\"\" \\n        try: \\n            response = self.client.create_agent( \\n                agentName=agent_name, \\n                foundationModel=foundation_model, \\n                agentResourceRoleArn=role_arn, \\n                instruction=instruction, \\nActions 709Amazon Bedrock User Guide\\n            ) \\n        except ClientError as e: \\n            logger.error(f\"Error: Couldn\\'t create agent. Here\\'s why: {e}\") \\n            raise \\n        else: \\n            return response[\"agent\"]\\n•For API details, see CreateAgent in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nCreate an Amazon Bedrock agent action group using an AWS SDK\\nThe following code example shows how to create an Amazon Bedrock agent action group.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nCreate an agent action group.\\n    def create_agent_action_group( \\n        self, name, description, agent_id, agent_version, function_arn, \\n api_schema \\n    ): \\nActions 710Amazon Bedrock User Guide\\n        \"\"\" \\n        Creates an action group for an agent. An action group defines a set of \\n actions that an \\n        agent should carry out for the customer. \\n        :param name: The name to give the action group. \\n        :param description: The description of the action group. \\n        :param agent_id: The unique identifier of the agent for which to create \\n the action group. \\n        :param agent_version: The version of the agent for which to create the \\n action group. \\n        :param function_arn: The ARN of the Lambda function containing the \\n business logic that is \\n                             carried out upon invoking the action. \\n        :param api_schema: Contains the OpenAPI schema for the action group. \\n        :return: Details about the action group that was created. \\n        \"\"\" \\n        try: \\n            response = self.client.create_agent_action_group( \\n                actionGroupName=name, \\n                description=description, \\n                agentId=agent_id, \\n                agentVersion=agent_version, \\n                actionGroupExecutor={\"lambda\": function_arn}, \\n                apiSchema={\"payload\": api_schema}, \\n            ) \\n            agent_action_group = response[\"agentActionGroup\"] \\n        except ClientError as e: \\n            logger.error(f\"Error: Couldn\\'t create agent action group. Here\\'s why: \\n {e}\") \\n            raise \\n        else: \\n            return agent_action_group\\n•For API details, see CreateAgentActionGroup in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nActions 711Amazon Bedrock User Guide\\nCreate an Amazon Bedrock agent alias using an AWS SDK\\nThe following code example shows how to create an Amazon Bedrock agent alias.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nCreate an agent alias.\\n    def create_agent_alias(self, name, agent_id): \\n        \"\"\" \\n        Creates an alias of an agent that can be used to deploy the agent. \\n        :param name: The name of the alias. \\n        :param agent_id: The unique identifier of the agent. \\n        :return: Details about the alias that was created. \\n        \"\"\" \\n        try: \\n            response = self.client.create_agent_alias( \\n                agentAliasName=name, agentId=agent_id \\n            ) \\n            agent_alias = response[\"agentAlias\"] \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t create agent alias. {e}\") \\n            raise \\n        else: \\n            return agent_alias\\nActions 712Amazon Bedrock User Guide\\n•For API details, see CreateAgentAlias in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nDelete an Amazon Bedrock agent using an AWS SDK\\nThe following code examples show how to delete an Amazon Bedrock agent.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nDelete an agent.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { checkForPlaceholders } from \"../lib/utils.js\";\\nimport { \\n  BedrockAgentClient, \\n  DeleteAgentCommand,\\n} from \"@aws-sdk/client-bedrock-agent\";\\n/** \\n * Deletes an Amazon Bedrock Agent. \\nActions 713Amazon Bedrock User Guide\\n * \\n * @param {string} agentId - The unique identifier of the agent to delete. \\n * @param {string} [region=\\'us-east-1\\'] - The AWS region in use. \\n * @returns {Promise<import(\"@aws-sdk/client-bedrock-\\nagent\").DeleteAgentCommandOutput>} An object containing the agent id, the status, \\n and some additional metadata. \\n */\\nexport const deleteAgent = (agentId, region = \"us-east-1\") => { \\n  const client = new BedrockAgentClient({ region }); \\n  const command = new DeleteAgentCommand({ agentId }); \\n  return client.send(command);\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  // Replace the placeholders for agentId with an existing agent\\'s id. \\n  // Ensure to remove the brackets (`[]`) before adding your data. \\n  // The agentId must be an alphanumeric string with exactly 10 characters. \\n  const agentId = \"[ABC123DE45]\"; \\n  // Check for unresolved placeholders in agentId. \\n  checkForPlaceholders([agentId]); \\n  console.log(`Deleting agent with ID ${agentId}...`); \\n  const response = await deleteAgent(agentId); \\n  console.log(response);\\n}\\n•For API details, see DeleteAgent in AWS SDK for JavaScript API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nActions 714Amazon Bedrock User Guide\\nDelete an agent.\\n    def delete_agent(self, agent_id): \\n        \"\"\" \\n        Deletes an Amazon Bedrock agent. \\n        :param agent_id: The unique identifier of the agent to delete. \\n        :return: The response from Agents for Bedrock if successful, otherwise \\n raises an exception. \\n        \"\"\" \\n        try: \\n            response = self.client.delete_agent( \\n                agentId=agent_id, skipResourceInUseCheck=False \\n            ) \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t delete agent. {e}\") \\n            raise \\n        else: \\n            return response\\n•For API details, see DeleteAgent in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nDelete an Amazon Bedrock agent alias using an AWS SDK\\nThe following code example shows how to delete an Amazon Bedrock agent alias.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nActions 715Amazon Bedrock User Guide\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nDelete an agent alias.\\n    def delete_agent_alias(self, agent_id, agent_alias_id): \\n        \"\"\" \\n        Deletes an alias of an Amazon Bedrock agent. \\n        :param agent_id: The unique identifier of the agent that the alias \\n belongs to. \\n        :param agent_alias_id: The unique identifier of the alias to delete. \\n        :return: The response from Agents for Bedrock if successful, otherwise \\n raises an exception. \\n        \"\"\" \\n        try: \\n            response = self.client.delete_agent_alias( \\n                agentId=agent_id, agentAliasId=agent_alias_id \\n            ) \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t delete agent alias. {e}\") \\n            raise \\n        else: \\n            return response\\n•For API details, see DeleteAgentAlias in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nActions 716Amazon Bedrock User Guide\\nGet information about an Amazon Bedrock agent using an AWS SDK\\nThe following code examples show how to get information about an Amazon Bedrock agent.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nGet an agent.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { checkForPlaceholders } from \"../lib/utils.js\";\\nimport { \\n  BedrockAgentClient, \\n  GetAgentCommand,\\n} from \"@aws-sdk/client-bedrock-agent\";\\n/** \\n * Retrieves the details of an Amazon Bedrock Agent. \\n * \\n * @param {string} agentId - The unique identifier of the agent. \\n * @param {string} [region=\\'us-east-1\\'] - The AWS region in use. \\n * @returns {Promise<import(\"@aws-sdk/client-bedrock-agent\").Agent>} An object \\n containing the agent details. \\n */\\nexport const getAgent = async (agentId, region = \"us-east-1\") => { \\nActions 717Amazon Bedrock User Guide\\n  const client = new BedrockAgentClient({ region }); \\n  const command = new GetAgentCommand({ agentId }); \\n  const response = await client.send(command); \\n  return response.agent;\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  // Replace the placeholders for agentId with an existing agent\\'s id. \\n  // Ensure to remove the brackets \\'[]\\' before adding your data. \\n  // The agentId must be an alphanumeric string with exactly 10 characters. \\n  const agentId = \"[ABC123DE45]\"; \\n  // Check for unresolved placeholders in agentId. \\n  checkForPlaceholders([agentId]); \\n  console.log(`Retrieving agent with ID ${agentId}...`); \\n  const agent = await getAgent(agentId); \\n  console.log(agent);\\n}\\n•For API details, see GetAgent in AWS SDK for JavaScript API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nGet an agent.\\n    def get_agent(self, agent_id, log_error=True): \\n        \"\"\" \\n        Gets information about an agent. \\nActions 718Amazon Bedrock User Guide\\n        :param agent_id: The unique identifier of the agent. \\n        :param log_error: Whether to log any errors that occur when getting the \\n agent. \\n                          If True, errors will be logged to the logger. If False, \\n errors \\n                          will still be raised, but not logged. \\n        :return: The information about the requested agent. \\n        \"\"\" \\n        try: \\n            response = self.client.get_agent(agentId=agent_id) \\n            agent = response[\"agent\"] \\n        except ClientError as e: \\n            if log_error: \\n                logger.error(f\"Couldn\\'t get agent {agent_id}. {e}\") \\n            raise \\n        else: \\n            return agent\\n•For API details, see GetAgent in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nList the action groups for a Amazon Bedrock agent using an AWS SDK\\nThe following code examples show how to list the action groups for a Amazon Bedrock agent.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nActions 719Amazon Bedrock User Guide\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the action groups for an agent.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { checkForPlaceholders } from \"../lib/utils.js\";\\nimport { \\n  BedrockAgentClient, \\n  ListAgentActionGroupsCommand, \\n  paginateListAgentActionGroups,\\n} from \"@aws-sdk/client-bedrock-agent\";\\n/** \\n * Retrieves a list of Action Groups of an agent utilizing the paginator \\n function. \\n * \\n * This function leverages a paginator, which abstracts the complexity of \\n pagination, providing \\n * a straightforward way to handle paginated results inside a `for await...of` \\n loop. \\n * \\n * @param {string} agentId - The unique identifier of the agent. \\n * @param {string} agentVersion - The version of the agent. \\n * @param {string} [region=\\'us-east-1\\'] - The AWS region in use. \\n * @returns {Promise<ActionGroupSummary[]>} An array of action group summaries. \\n */\\nexport const listAgentActionGroupsWithPaginator = async ( \\n  agentId, \\n  agentVersion, \\n  region = \"us-east-1\",\\n) => { \\nActions 720Amazon Bedrock User Guide\\n  const client = new BedrockAgentClient({ region }); \\n  // Create a paginator configuration \\n  const paginatorConfig = { \\n    client, \\n    pageSize: 10, // optional, added for demonstration purposes \\n  }; \\n  const params = { agentId, agentVersion }; \\n  const pages = paginateListAgentActionGroups(paginatorConfig, params); \\n  // Paginate until there are no more results \\n  const actionGroupSummaries = []; \\n  for await (const page of pages) { \\n    actionGroupSummaries.push(...page.actionGroupSummaries); \\n  } \\n  return actionGroupSummaries;\\n};\\n/** \\n * Retrieves a list of Action Groups of an agent utilizing the \\n ListAgentActionGroupsCommand. \\n * \\n * This function demonstrates the manual approach, sending a command to the \\n client and processing the response. \\n * Pagination must manually be managed. For a simplified approach that abstracts \\n away pagination logic, see \\n * the `listAgentActionGroupsWithPaginator()` example below. \\n * \\n * @param {string} agentId - The unique identifier of the agent. \\n * @param {string} agentVersion - The version of the agent. \\n * @param {string} [region=\\'us-east-1\\'] - The AWS region in use. \\n * @returns {Promise<ActionGroupSummary[]>} An array of action group summaries. \\n */\\nexport const listAgentActionGroupsWithCommandObject = async ( \\n  agentId, \\n  agentVersion, \\n  region = \"us-east-1\",\\n) => { \\n  const client = new BedrockAgentClient({ region }); \\n  let nextToken; \\nActions 721Amazon Bedrock User Guide\\n  const actionGroupSummaries = []; \\n  do { \\n    const command = new ListAgentActionGroupsCommand({ \\n      agentId, \\n      agentVersion, \\n      nextToken, \\n      maxResults: 10, // optional, added for demonstration purposes \\n    }); \\n    /** @type {{actionGroupSummaries: ActionGroupSummary[], nextToken?: string}} \\n */ \\n    const response = await client.send(command); \\n    for (const actionGroup of response.actionGroupSummaries || []) { \\n      actionGroupSummaries.push(actionGroup); \\n    } \\n    nextToken = response.nextToken; \\n  } while (nextToken); \\n  return actionGroupSummaries;\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  // Replace the placeholders for agentId and agentVersion with an existing \\n agent\\'s id and version. \\n  // Ensure to remove the brackets \\'[]\\' before adding your data. \\n  // The agentId must be an alphanumeric string with exactly 10 characters. \\n  const agentId = \"[ABC123DE45]\"; \\n  // A string either containing `DRAFT` or a number with 1-5 digits (e.g., \\'123\\' \\n or \\'DRAFT\\'). \\n  const agentVersion = \"[DRAFT]\"; \\n  // Check for unresolved placeholders in agentId and agentVersion. \\n  checkForPlaceholders([agentId, agentVersion]); \\n  console.log(\"=\".repeat(68)); \\n  console.log( \\n    \"Listing agent action groups using ListAgentActionGroupsCommand:\", \\n  ); \\nActions 722Amazon Bedrock User Guide\\n  for (const actionGroup of await listAgentActionGroupsWithCommandObject( \\n    agentId, \\n    agentVersion, \\n  )) { \\n    console.log(actionGroup); \\n  } \\n  console.log(\"=\".repeat(68)); \\n  console.log( \\n    \"Listing agent action groups using the paginateListAgents function:\", \\n  ); \\n  for (const actionGroup of await listAgentActionGroupsWithPaginator( \\n    agentId, \\n    agentVersion, \\n  )) { \\n    console.log(actionGroup); \\n  }\\n}\\n•For API details, see ListAgentActionGroups in AWS SDK for JavaScript API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the action groups for an agent.\\n    def list_agent_action_groups(self, agent_id, agent_version): \\n        \"\"\" \\n        List the action groups for a version of an Amazon Bedrock Agent. \\n        :param agent_id: The unique identifier of the agent. \\n        :param agent_version: The version of the agent. \\n        :return: The list of action group summaries for the version of the agent. \\n        \"\"\" \\nActions 723Amazon Bedrock User Guide\\n        try: \\n            action_groups = [] \\n            paginator = self.client.get_paginator(\"list_agent_action_groups\") \\n            for page in paginator.paginate( \\n                agentId=agent_id, \\n                agentVersion=agent_version, \\n                PaginationConfig={\"PageSize\": 10}, \\n            ): \\n                action_groups.extend(page[\"actionGroupSummaries\"]) \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t list action groups. {e}\") \\n            raise \\n        else: \\n            return action_groups\\n•For API details, see ListAgentActionGroups in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nList the Agents for Amazon Bedrock belonging to an account using an AWS SDK\\nThe following code examples show how to list the Agents for Amazon Bedrock belonging to an \\naccount.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nActions 724Amazon Bedrock User Guide\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the agents belonging to an account.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { fileURLToPath } from \"url\";\\nimport { \\n  BedrockAgentClient, \\n  ListAgentsCommand, \\n  paginateListAgents,\\n} from \"@aws-sdk/client-bedrock-agent\";\\n/** \\n * Retrieves a list of available Amazon Bedrock agents utilizing the paginator \\n function. \\n * \\n * This function leverages a paginator, which abstracts the complexity of \\n pagination, providing \\n * a straightforward way to handle paginated results inside a `for await...of` \\n loop. \\n * \\n * @param {string} [region=\\'us-east-1\\'] - The AWS region in use. \\n * @returns {Promise<AgentSummary[]>} An array of agent summaries. \\n */\\nexport const listAgentsWithPaginator = async (region = \"us-east-1\") => { \\n  const client = new BedrockAgentClient({ region }); \\n  const paginatorConfig = { \\n    client, \\n    pageSize: 10, // optional, added for demonstration purposes \\n  }; \\nActions 725Amazon Bedrock User Guide\\n  const pages = paginateListAgents(paginatorConfig, {}); \\n  // Paginate until there are no more results \\n  const agentSummaries = []; \\n  for await (const page of pages) { \\n    agentSummaries.push(...page.agentSummaries); \\n  } \\n  return agentSummaries;\\n};\\n/** \\n * Retrieves a list of available Amazon Bedrock agents utilizing the \\n ListAgentsCommand. \\n * \\n * This function demonstrates the manual approach, sending a command to the \\n client and processing the response. \\n * Pagination must manually be managed. For a simplified approach that abstracts \\n away pagination logic, see \\n * the `listAgentsWithPaginator()` example below. \\n * \\n * @param {string} [region=\\'us-east-1\\'] - The AWS region in use. \\n * @returns {Promise<AgentSummary[]>} An array of agent summaries. \\n */\\nexport const listAgentsWithCommandObject = async (region = \"us-east-1\") => { \\n  const client = new BedrockAgentClient({ region }); \\n  let nextToken; \\n  const agentSummaries = []; \\n  do { \\n    const command = new ListAgentsCommand({ \\n      nextToken, \\n      maxResults: 10, // optional, added for demonstration purposes \\n    }); \\n    /** @type {{agentSummaries: AgentSummary[], nextToken?: string}} */ \\n    const paginatedResponse = await client.send(command); \\n    agentSummaries.push(...(paginatedResponse.agentSummaries || [])); \\n    nextToken = paginatedResponse.nextToken; \\n  } while (nextToken); \\n  return agentSummaries;\\nActions 726Amazon Bedrock User Guide\\n};\\n// Invoke main function if this file was run directly.\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  console.log(\"=\".repeat(68)); \\n  console.log(\"Listing agents using ListAgentsCommand:\"); \\n  for (const agent of await listAgentsWithCommandObject()) { \\n    console.log(agent); \\n  } \\n  console.log(\"=\".repeat(68)); \\n  console.log(\"Listing agents using the paginateListAgents function:\"); \\n  for (const agent of await listAgentsWithPaginator()) { \\n    console.log(agent); \\n  }\\n}\\n•For API details, see ListAgents in AWS SDK for JavaScript API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the agents belonging to an account.\\n    def list_agents(self): \\n        \"\"\" \\n        List the available Amazon Bedrock Agents. \\n        :return: The list of available bedrock agents. \\n        \"\"\" \\n        try: \\n            all_agents = [] \\nActions 727Amazon Bedrock User Guide\\n            paginator = self.client.get_paginator(\"list_agents\") \\n            for page in paginator.paginate(PaginationConfig={\"PageSize\": 10}): \\n                all_agents.extend(page[\"agentSummaries\"]) \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t list agents. {e}\") \\n            raise \\n        else: \\n            return all_agents\\n•For API details, see ListAgents in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nList the knowledge bases associated with a Amazon Bedrock agent using an AWS \\nSDK\\nThe following code example shows how to list the knowledge bases associated with a Amazon \\nBedrock agent.\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nList the knowledge bases associated with an agent.\\nActions 728Amazon Bedrock User Guide\\n    def list_agent_knowledge_bases(self, agent_id, agent_version): \\n        \"\"\" \\n        List the knowledge bases associated with a version of an Amazon Bedrock \\n Agent. \\n        :param agent_id: The unique identifier of the agent. \\n        :param agent_version: The version of the agent. \\n        :return: The list of knowledge base summaries for the version of the \\n agent. \\n        \"\"\" \\n        try: \\n            knowledge_bases = [] \\n            paginator = self.client.get_paginator(\"list_agent_knowledge_bases\") \\n            for page in paginator.paginate( \\n                agentId=agent_id, \\n                agentVersion=agent_version, \\n                PaginationConfig={\"PageSize\": 10}, \\n            ): \\n                knowledge_bases.extend(page[\"agentKnowledgeBaseSummaries\"]) \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t list knowledge bases. {e}\") \\n            raise \\n        else: \\n            return knowledge_bases\\n•For API details, see ListAgentKnowledgeBases in AWS SDK for Python (Boto3) API \\nReference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nPrepare an Amazon Bedrock agent using an AWS SDK\\nThe following code example shows how to prepare an Amazon Bedrock agent for internal testing.\\nActions 729Amazon Bedrock User Guide\\nAction examples are code excerpts from larger programs and must be run in context. You can see \\nthis action in context in the following code example:\\n•Create and invoke an agent\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nPrepare an agent for internal testing.\\n    def prepare_agent(self, agent_id): \\n        \"\"\" \\n        Creates a DRAFT version of the agent that can be used for internal \\n testing. \\n        :param agent_id: The unique identifier of the agent to prepare. \\n        :return: The response from Agents for Bedrock if successful, otherwise \\n raises an exception. \\n        \"\"\" \\n        try: \\n            prepared_agent_details = self.client.prepare_agent(agentId=agent_id) \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t prepare agent. {e}\") \\n            raise \\n        else: \\n            return prepared_agent_details\\n•For API details, see PrepareAgent in AWS SDK for Python (Boto3) API Reference.\\nActions 730Amazon Bedrock User Guide\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nScenarios for Agents for Amazon Bedrock using AWS SDKs\\nThe following code examples show you how to implement common scenarios in Agents for \\nAmazon Bedrock with AWS SDKs. These scenarios show you how to accomplish speciﬁc tasks by \\ncalling multiple functions within Agents for Amazon Bedrock. Each scenario includes a link to \\nGitHub, where you can ﬁnd instructions on how to set up and run the code.\\nExamples\\n•An end-to-end example showing how to create and invoke Amazon Bedrock agents using an \\nAWS SDK\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nAn end-to-end example showing how to create and invoke Amazon Bedrock \\nagents using an AWS SDK\\nThe following code example shows how to:\\n•Create an execution role for the agent.\\n•Create the agent and deploy a DRAFT version.\\n•Create a Lambda function that implements the agent\\'s capabilities.\\n•Create an action group that connects the agent to the Lambda function.\\n•Deploy the fully conﬁgured agent.\\n•Invoke the agent with user-provided prompts.\\n•Delete all created resources.\\nScenarios 731Amazon Bedrock User Guide\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nCreate and invoke an agent.\\nREGION = \"us-east-1\"\\nROLE_POLICY_NAME = \"agent_permissions\"\\nclass BedrockAgentScenarioWrapper: \\n    \"\"\"Runs a scenario that shows how to get started using Agents for Amazon \\n Bedrock.\"\"\" \\n    def __init__( \\n        self, bedrock_agent_client, runtime_client, lambda_client, iam_resource, \\n postfix \\n    ): \\n        self.iam_resource = iam_resource \\n        self.lambda_client = lambda_client \\n        self.bedrock_agent_runtime_client = runtime_client \\n        self.postfix = postfix \\n        self.bedrock_wrapper = BedrockAgentWrapper(bedrock_agent_client) \\n        self.agent = None \\n        self.agent_alias = None \\n        self.agent_role = None \\n        self.prepared_agent_details = None \\n        self.lambda_role = None \\n        self.lambda_function = None \\n    def run_scenario(self): \\n        print(\"=\" * 88) \\n        print(\"Welcome to the Amazon Bedrock Agents demo.\") \\n        print(\"=\" * 88) \\nScenarios 732Amazon Bedrock User Guide\\n        # Query input from user \\n        print(\"Let\\'s start with creating an agent:\") \\n        print(\"-\" * 40) \\n        name, foundation_model = self._request_name_and_model_from_user() \\n        print(\"-\" * 40) \\n        # Create an execution role for the agent \\n        self.agent_role = self._create_agent_role(foundation_model) \\n        # Create the agent \\n        self.agent = self._create_agent(name, foundation_model) \\n        # Prepare a DRAFT version of the agent \\n        self.prepared_agent_details = self._prepare_agent() \\n        # Create the agent\\'s Lambda function \\n        self.lambda_function = self._create_lambda_function() \\n        # Configure permissions for the agent to invoke the Lambda function \\n        self._allow_agent_to_invoke_function() \\n        self._let_function_accept_invocations_from_agent() \\n        # Create an action group to connect the agent with the Lambda function \\n        self._create_agent_action_group() \\n        # If the agent has been modified or any components have been added, \\n prepare the agent again \\n        components = [self._get_agent()] \\n        components += self._get_agent_action_groups() \\n        components += self._get_agent_knowledge_bases() \\n        latest_update = max(component[\"updatedAt\"] for component in components) \\n        if latest_update > self.prepared_agent_details[\"preparedAt\"]: \\n            self.prepared_agent_details = self._prepare_agent() \\n        # Create an agent alias \\n        self.agent_alias = self._create_agent_alias() \\n        # Test the agent \\n        self._chat_with_agent(self.agent_alias) \\n        print(\"=\" * 88) \\n        print(\"Thanks for running the demo!\\\\n\") \\nScenarios 733Amazon Bedrock User Guide\\n        if q.ask(\"Do you want to delete the created resources? [y/N] \", \\n q.is_yesno): \\n            self._delete_resources() \\n            print(\"=\" * 88) \\n            print( \\n                \"All demo resources have been deleted. Thanks again for running \\n the demo!\" \\n            ) \\n        else: \\n            self._list_resources() \\n            print(\"=\" * 88) \\n            print(\"Thanks again for running the demo!\") \\n    def _request_name_and_model_from_user(self): \\n        existing_agent_names = [ \\n            agent[\"agentName\"] for agent in self.bedrock_wrapper.list_agents() \\n        ] \\n        while True: \\n            name = q.ask(\"Enter an agent name: \", self.is_valid_agent_name) \\n            if name.lower() not in [n.lower() for n in existing_agent_names]: \\n                break \\n            print( \\n                f\"Agent {name} conflicts with an existing agent. Please use a \\n different name.\" \\n            ) \\n        models = [\"anthropic.claude-instant-v1\", \"anthropic.claude-v2\"] \\n        model_id = models[ \\n            q.choose(\"Which foundation model would you like to use? \", models) \\n        ] \\n        return name, model_id \\n    def _create_agent_role(self, model_id): \\n        role_name = f\"AmazonBedrockExecutionRoleForAgents_{self.postfix}\" \\n        model_arn = f\"arn:aws:bedrock:{REGION}::foundation-model/{model_id}*\" \\n        print(\"Creating an an execution role for the agent...\") \\n        try: \\n            role = self.iam_resource.create_role( \\n                RoleName=role_name, \\n                AssumeRolePolicyDocument=json.dumps( \\nScenarios 734Amazon Bedrock User Guide\\n                    { \\n                        \"Version\": \"2012-10-17\", \\n                        \"Statement\": [ \\n                            { \\n                                \"Effect\": \"Allow\", \\n                                \"Principal\": {\"Service\": \\n \"bedrock.amazonaws.com\"}, \\n                                \"Action\": \"sts:AssumeRole\", \\n                            } \\n                        ], \\n                    } \\n                ), \\n            ) \\n            role.Policy(ROLE_POLICY_NAME).put( \\n                PolicyDocument=json.dumps( \\n                    { \\n                        \"Version\": \"2012-10-17\", \\n                        \"Statement\": [ \\n                            { \\n                                \"Effect\": \"Allow\", \\n                                \"Action\": \"bedrock:InvokeModel\", \\n                                \"Resource\": model_arn, \\n                            } \\n                        ], \\n                    } \\n                ) \\n            ) \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t create role {role_name}. Here\\'s why: {e}\") \\n            raise \\n        return role \\n    def _create_agent(self, name, model_id): \\n        print(\"Creating the agent...\") \\n        instruction = \"\"\" \\n            You are a friendly chat bot. You have access to a function called \\n that returns \\n            information about the current date and time. When responding with \\n date or time, \\n            please make sure to add the timezone UTC. \\n            \"\"\" \\nScenarios 735Amazon Bedrock User Guide\\n        agent = self.bedrock_wrapper.create_agent( \\n            agent_name=name, \\n            foundation_model=model_id, \\n            instruction=instruction, \\n            role_arn=self.agent_role.arn, \\n        ) \\n        self._wait_for_agent_status(agent[\"agentId\"], \"NOT_PREPARED\") \\n        return agent \\n    def _prepare_agent(self): \\n        print(\"Preparing the agent...\") \\n        agent_id = self.agent[\"agentId\"] \\n        prepared_agent_details = self.bedrock_wrapper.prepare_agent(agent_id) \\n        self._wait_for_agent_status(agent_id, \"PREPARED\") \\n        return prepared_agent_details \\n    def _create_lambda_function(self): \\n        print(\"Creating the Lambda function...\") \\n        function_name = f\"AmazonBedrockExampleFunction_{self.postfix}\" \\n        self.lambda_role = self._create_lambda_role() \\n        try: \\n            deployment_package = self._create_deployment_package(function_name) \\n            lambda_function = self.lambda_client.create_function( \\n                FunctionName=function_name, \\n                Description=\"Lambda function for Amazon Bedrock example\", \\n                Runtime=\"python3.11\", \\n                Role=self.lambda_role.arn, \\n                Handler=f\"{function_name}.lambda_handler\", \\n                Code={\"ZipFile\": deployment_package}, \\n                Publish=True, \\n            ) \\n            waiter = self.lambda_client.get_waiter(\"function_active_v2\") \\n            waiter.wait(FunctionName=function_name) \\n        except ClientError as e: \\n            logger.error( \\nScenarios 736Amazon Bedrock User Guide\\n                f\"Couldn\\'t create Lambda function {function_name}. Here\\'s why: \\n {e}\" \\n            ) \\n            raise \\n        return lambda_function \\n    def _create_lambda_role(self): \\n        print(\"Creating an execution role for the Lambda function...\") \\n        role_name = f\"AmazonBedrockExecutionRoleForLambda_{self.postfix}\" \\n        try: \\n            role = self.iam_resource.create_role( \\n                RoleName=role_name, \\n                AssumeRolePolicyDocument=json.dumps( \\n                    { \\n                        \"Version\": \"2012-10-17\", \\n                        \"Statement\": [ \\n                            { \\n                                \"Effect\": \"Allow\", \\n                                \"Principal\": {\"Service\": \"lambda.amazonaws.com\"}, \\n                                \"Action\": \"sts:AssumeRole\", \\n                            } \\n                        ], \\n                    } \\n                ), \\n            ) \\n            role.attach_policy( \\n                PolicyArn=\"arn:aws:iam::aws:policy/service-role/\\nAWSLambdaBasicExecutionRole\" \\n            ) \\n            print(f\"Created role {role_name}\") \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t create role {role_name}. Here\\'s why: {e}\") \\n            raise \\n        print(\"Waiting for the execution role to be fully propagated...\") \\n        wait(10) \\n        return role \\n    def _allow_agent_to_invoke_function(self): \\n        policy = self.iam_resource.RolePolicy( \\nScenarios 737Amazon Bedrock User Guide\\n            self.agent_role.role_name, ROLE_POLICY_NAME \\n        ) \\n        doc = policy.policy_document \\n        doc[\"Statement\"].append( \\n            { \\n                \"Effect\": \"Allow\", \\n                \"Action\": \"lambda:InvokeFunction\", \\n                \"Resource\": self.lambda_function[\"FunctionArn\"], \\n            } \\n        ) \\n        \\n self.agent_role.Policy(ROLE_POLICY_NAME).put(PolicyDocument=json.dumps(doc)) \\n    def _let_function_accept_invocations_from_agent(self): \\n        try: \\n            self.lambda_client.add_permission( \\n                FunctionName=self.lambda_function[\"FunctionName\"], \\n                SourceArn=self.agent[\"agentArn\"], \\n                StatementId=\"BedrockAccess\", \\n                Action=\"lambda:InvokeFunction\", \\n                Principal=\"bedrock.amazonaws.com\", \\n            ) \\n        except ClientError as e: \\n            logger.error( \\n                f\"Couldn\\'t grant Bedrock permission to invoke the Lambda \\n function. Here\\'s why: {e}\" \\n            ) \\n            raise \\n    def _create_agent_action_group(self): \\n        print(\"Creating an action group for the agent...\") \\n        try: \\n            with open(\"./scenario_resources/api_schema.yaml\") as file: \\n                self.bedrock_wrapper.create_agent_action_group( \\n                    name=\"current_date_and_time\", \\n                    description=\"Gets the current date and time.\", \\n                    agent_id=self.agent[\"agentId\"], \\n                    agent_version=self.prepared_agent_details[\"agentVersion\"], \\n                    function_arn=self.lambda_function[\"FunctionArn\"], \\n                    api_schema=json.dumps(yaml.safe_load(file)), \\n                ) \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t create agent action group. Here\\'s why: {e}\") \\nScenarios 738Amazon Bedrock User Guide\\n            raise \\n    def _get_agent(self): \\n        return self.bedrock_wrapper.get_agent(self.agent[\"agentId\"]) \\n    def _get_agent_action_groups(self): \\n        return self.bedrock_wrapper.list_agent_action_groups( \\n            self.agent[\"agentId\"], self.prepared_agent_details[\"agentVersion\"] \\n        ) \\n    def _get_agent_knowledge_bases(self): \\n        return self.bedrock_wrapper.list_agent_knowledge_bases( \\n            self.agent[\"agentId\"], self.prepared_agent_details[\"agentVersion\"] \\n        ) \\n    def _create_agent_alias(self): \\n        print(\"Creating an agent alias...\") \\n        agent_alias_name = \"test_agent_alias\" \\n        agent_alias = self.bedrock_wrapper.create_agent_alias( \\n            agent_alias_name, self.agent[\"agentId\"] \\n        ) \\n        self._wait_for_agent_status(self.agent[\"agentId\"], \"PREPARED\") \\n        return agent_alias \\n    def _wait_for_agent_status(self, agent_id, status): \\n        while self.bedrock_wrapper.get_agent(agent_id)[\"agentStatus\"] != status: \\n            wait(2) \\n    def _chat_with_agent(self, agent_alias): \\n        print(\"-\" * 88) \\n        print(\"The agent is ready to chat.\") \\n        print(\"Try asking for the date or time. Type \\'exit\\' to quit.\") \\n        # Create a unique session ID for the conversation \\n        session_id = uuid.uuid4().hex \\n        while True: \\n            prompt = q.ask(\"Prompt: \", q.non_empty) \\n            if prompt == \"exit\": \\n                break \\nScenarios 739Amazon Bedrock User Guide\\n            response = asyncio.run(self._invoke_agent(agent_alias, prompt, \\n session_id)) \\n            print(f\"Agent: {response}\") \\n    async def _invoke_agent(self, agent_alias, prompt, session_id): \\n        response = self.bedrock_agent_runtime_client.invoke_agent( \\n            agentId=self.agent[\"agentId\"], \\n            agentAliasId=agent_alias[\"agentAliasId\"], \\n            sessionId=session_id, \\n            inputText=prompt, \\n        ) \\n        completion = \"\" \\n        for event in response.get(\"completion\"): \\n            chunk = event[\"chunk\"] \\n            completion += chunk[\"bytes\"].decode() \\n        return completion \\n    def _delete_resources(self): \\n        if self.agent: \\n            agent_id = self.agent[\"agentId\"] \\n            if self.agent_alias: \\n                agent_alias_id = self.agent_alias[\"agentAliasId\"] \\n                print(\"Deleting agent alias...\") \\n                self.bedrock_wrapper.delete_agent_alias(agent_id, agent_alias_id) \\n            print(\"Deleting agent...\") \\n            agent_status = self.bedrock_wrapper.delete_agent(agent_id)\\n[\"agentStatus\"] \\n            while agent_status == \"DELETING\": \\n                wait(5) \\n                try: \\n                    agent_status = self.bedrock_wrapper.get_agent( \\n                        agent_id, log_error=False \\n                    )[\"agentStatus\"] \\n                except ClientError as err: \\n                    if err.response[\"Error\"][\"Code\"] == \\n \"ResourceNotFoundException\": \\n                        agent_status = \"DELETED\" \\nScenarios 740Amazon Bedrock User Guide\\n        if self.lambda_function: \\n            name = self.lambda_function[\"FunctionName\"] \\n            print(f\"Deleting function \\'{name}\\'...\") \\n            self.lambda_client.delete_function(FunctionName=name) \\n        if self.agent_role: \\n            print(f\"Deleting role \\'{self.agent_role.role_name}\\'...\") \\n            self.agent_role.Policy(ROLE_POLICY_NAME).delete() \\n            self.agent_role.delete() \\n        if self.lambda_role: \\n            print(f\"Deleting role \\'{self.lambda_role.role_name}\\'...\") \\n            for policy in self.lambda_role.attached_policies.all(): \\n                policy.detach_role(RoleName=self.lambda_role.role_name) \\n            self.lambda_role.delete() \\n    def _list_resources(self): \\n        print(\"-\" * 40) \\n        print(f\"Here is the list of created resources in \\'{REGION}\\'.\") \\n        print(\"Make sure you delete them once you\\'re done to avoid unnecessary \\n costs.\") \\n        if self.agent: \\n            print(f\"Bedrock Agent:   {self.agent[\\'agentName\\']}\") \\n        if self.lambda_function: \\n            print(f\"Lambda function: {self.lambda_function[\\'FunctionName\\']}\") \\n        if self.agent_role: \\n            print(f\"IAM role:        {self.agent_role.role_name}\") \\n        if self.lambda_role: \\n            print(f\"IAM role:        {self.lambda_role.role_name}\") \\n    @staticmethod \\n    def is_valid_agent_name(answer): \\n        valid_regex = r\"^[a-zA-Z0-9_-]{1,100}$\" \\n        return ( \\n            answer \\n            if answer and len(answer) <= 100 and re.match(valid_regex, answer) \\n            else None, \\n            \"I need a name for the agent, please. Valid characters are a-z, A-Z, \\n 0-9, _ (underscore) and - (hyphen).\", \\n        ) \\n    @staticmethod \\n    def _create_deployment_package(function_name): \\nScenarios 741Amazon Bedrock User Guide\\n        buffer = io.BytesIO() \\n        with zipfile.ZipFile(buffer, \"w\") as zipped: \\n            zipped.write( \\n                \"./scenario_resources/lambda_function.py\", f\"{function_name}.py\" \\n            ) \\n        buffer.seek(0) \\n        return buffer.read()\\nif __name__ == \"__main__\": \\n    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\") \\n    postfix = \"\".join( \\n        random.choice(string.ascii_lowercase + \"0123456789\") for _ in range(8) \\n    ) \\n    scenario = BedrockAgentScenarioWrapper( \\n        bedrock_agent_client=boto3.client( \\n            service_name=\"bedrock-agent\", region_name=REGION \\n        ), \\n        runtime_client=boto3.client( \\n            service_name=\"bedrock-agent-runtime\", region_name=REGION \\n        ), \\n        lambda_client=boto3.client(service_name=\"lambda\", region_name=REGION), \\n        iam_resource=boto3.resource(\"iam\"), \\n        postfix=postfix, \\n    ) \\n    try: \\n        scenario.run_scenario() \\n    except Exception as e: \\n        logging.exception(f\"Something went wrong with the demo. Here\\'s what: \\n {e}\")\\n•For API details, see the following topics in AWS SDK for Python (Boto3) API Reference.\\n•CreateAgent\\n•CreateAgentActionGroup\\n•CreateAgentAlias\\n•DeleteAgent\\n•DeleteAgentAlias\\n•GetAgent\\nScenarios 742Amazon Bedrock User Guide\\n•ListAgentActionGroups\\n•ListAgentKnowledgeBases\\n•ListAgents\\n•PrepareAgent\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nBuild and orchestrate generative AI applications with Amazon Bedrock and Step \\nFunctions\\nThe following code example shows how to build and orchestrate generative AI applications with \\nAmazon Bedrock and Step Functions.\\nPython\\nSDK for Python (Boto3)\\nThe Amazon Bedrock Serverless Prompt Chaining scenario demonstrates how AWS Step \\nFunctions, Amazon Bedrock, and Agents for Amazon Bedrock can be used to build and \\norchestrate complex, serverless, and highly scalable generative AI applications. It contains \\nthe following working examples:\\n•Write an analysis of a given novel for a literature blog. This example illustrates a simple, \\nsequential chain of prompts.\\n•Generate a short story about a given topic. This example illustrates how the AI can \\niteratively process a list of items that it previously generated.\\n•Create an itinerary for a weekend vacation to a given destination. This example illustrates \\nhow to parallelize multiple distinct prompts.\\n•Pitch movie ideas to a human user acting as a movie producer. This example illustrates \\nhow to parallelize the same prompt with diﬀerent inference parameters, how to backtrack \\nto a previous step in the chain, and how to include human input as part of the workﬂow.\\n•Plan a meal based on ingredients the user has at hand. This example illustrates how \\nprompt chains can incorporate two distinct AI conversations, with two AI personas \\nengaging in a debate with each other to improve the ﬁnal outcome.\\nScenarios 743Amazon Bedrock User Guide\\n•Find and summarize today\\'s highest trending GitHub repository. This example illustrates \\nchaining multiple AI agents that interact with external APIs.\\nFor complete source code and instructions to set up and run, see the full project on GitHub .\\nServices used in this example\\n•Amazon Bedrock\\n•Amazon Bedrock Runtime\\n•Agents for Amazon Bedrock\\n•Agents for Amazon Bedrock Runtime\\n•Step Functions\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nCode examples for Agents for Amazon Bedrock Runtime using \\nAWS SDKs\\nThe following code examples show how to use Agents for Amazon Bedrock Runtime with an AWS \\nsoftware development kit (SDK).\\nActions  are code excerpts from larger programs and must be run in context. While actions show you \\nhow to call individual service functions, you can see actions in context in their related scenarios and \\ncross-service examples.\\nScenarios  are code examples that show you how to accomplish a speciﬁc task by calling multiple \\nfunctions within the same service.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nCode examples\\n•Actions for Agents for Amazon Bedrock Runtime using AWS SDKs\\n•Invoke an Amazon Bedrock agent using an AWS SDK\\n•Scenarios for Agents for Amazon Bedrock Runtime using AWS SDKs\\nAgents for Amazon Bedrock Runtime 744Amazon Bedrock User Guide\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nActions for Agents for Amazon Bedrock Runtime using AWS SDKs\\nThe following code examples demonstrate how to perform individual Agents for Amazon Bedrock \\nRuntime actions with AWS SDKs. These excerpts call the Agents for Amazon Bedrock Runtime API \\nand are code excerpts from larger programs that must be run in context. Each example includes a \\nlink to GitHub, where you can ﬁnd instructions for setting up and running the code.\\nThe following examples include only the most commonly used actions. For a complete list, see the\\nAgents for Amazon Bedrock Runtime API Reference.\\nExamples\\n•Invoke an Amazon Bedrock agent using an AWS SDK\\nInvoke an Amazon Bedrock agent using an AWS SDK\\nThe following code examples show how to invoke an Amazon Bedrock agent.\\nJavaScript\\nSDK for JavaScript (v3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\\n// SPDX-License-Identifier: Apache-2.0\\nimport { \\n  BedrockAgentRuntimeClient, \\n  InvokeAgentCommand,\\n} from \"@aws-sdk/client-bedrock-agent-runtime\";\\n/** \\n * @typedef {Object} ResponseBody \\nActions 745Amazon Bedrock User Guide\\n * @property {string} completion \\n */\\n/** \\n * Invokes a Bedrock agent to run an inference using the input \\n * provided in the request body. \\n * \\n * @param {string} prompt - The prompt that you want the Agent to complete. \\n * @param {string} sessionId - An arbitrary identifier for the session. \\n */\\nexport const invokeBedrockAgent = async (prompt, sessionId) => { \\n  const client = new BedrockAgentRuntimeClient({ region: \"us-east-1\" }); \\n  // const client = new BedrockAgentRuntimeClient({ \\n  //   region: \"us-east-1\", \\n  //   credentials: { \\n  //     accessKeyId: \"accessKeyId\", // permission to invoke agent \\n  //     secretAccessKey: \"accessKeySecret\", \\n  //   }, \\n  // }); \\n  const agentId = \"AJBHXXILZN\"; \\n  const agentAliasId = \"AVKP1ITZAA\"; \\n  const command = new InvokeAgentCommand({ \\n    agentId, \\n    agentAliasId, \\n    sessionId, \\n    inputText: prompt, \\n  }); \\n  try { \\n    let completion = \"\"; \\n    const response = await client.send(command); \\n    if (response.completion === undefined) { \\n      throw new Error(\"Completion is undefined\"); \\n    } \\n    for await (let chunkEvent of response.completion) { \\n      const chunk = chunkEvent.chunk; \\n      console.log(chunk); \\n      const decodedResponse = new TextDecoder(\"utf-8\").decode(chunk.bytes); \\n      completion += decodedResponse; \\n    } \\nActions 746Amazon Bedrock User Guide\\n    return { sessionId: sessionId, completion }; \\n  } catch (err) { \\n    console.error(err); \\n  }\\n};\\n// Call function if run directly\\nimport { fileURLToPath } from \"url\";\\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \\n  const result = await invokeBedrockAgent(\"I need help.\", \"123\"); \\n  console.log(result);\\n}\\n•For API details, see InvokeAgent in AWS SDK for JavaScript API Reference.\\nPython\\nSDK for Python (Boto3)\\nNote\\nThere\\'s more on GitHub. Find the complete example and learn how to set up and run \\nin the AWS Code Examples Repository.\\nInvoke an agent.\\n    def invoke_agent(self, agent_id, agent_alias_id, session_id, prompt): \\n        \"\"\" \\n        Sends a prompt for the agent to process and respond to. \\n        :param agent_id: The unique identifier of the agent to use. \\n        :param agent_alias_id: The alias of the agent to use. \\n        :param session_id: The unique identifier of the session. Use the same \\n value across requests \\n                           to continue the same conversation. \\n        :param prompt: The prompt that you want Claude to complete. \\n        :return: Inference response from the model. \\n        \"\"\" \\nActions 747Amazon Bedrock User Guide\\n        try: \\n            response = self.agents_runtime_client.invoke_agent( \\n                agentId=agent_id, \\n                agentAliasId=agent_alias_id, \\n                sessionId=session_id, \\n                inputText=prompt, \\n            ) \\n            completion = \"\" \\n            for event in response.get(\"completion\"): \\n                chunk = event[\"chunk\"] \\n                completion = completion + chunk[\"bytes\"].decode() \\n        except ClientError as e: \\n            logger.error(f\"Couldn\\'t invoke agent. {e}\") \\n            raise \\n        return completion\\n•For API details, see InvokeAgent in AWS SDK for Python (Boto3) API Reference.\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nScenarios for Agents for Amazon Bedrock Runtime using AWS SDKs\\nThe following code examples show you how to implement common scenarios in Agents for \\nAmazon Bedrock Runtime with AWS SDKs. These scenarios show you how to accomplish speciﬁc \\ntasks by calling multiple functions within Agents for Amazon Bedrock Runtime. Each scenario \\nincludes a link to GitHub, where you can ﬁnd instructions on how to set up and run the code.\\nExamples\\n•Build and orchestrate generative AI applications with Amazon Bedrock and Step Functions\\nScenarios 748Amazon Bedrock User Guide\\nBuild and orchestrate generative AI applications with Amazon Bedrock and Step \\nFunctions\\nThe following code example shows how to build and orchestrate generative AI applications with \\nAmazon Bedrock and Step Functions.\\nPython\\nSDK for Python (Boto3)\\nThe Amazon Bedrock Serverless Prompt Chaining scenario demonstrates how AWS Step \\nFunctions, Amazon Bedrock, and Agents for Amazon Bedrock can be used to build and \\norchestrate complex, serverless, and highly scalable generative AI applications. It contains \\nthe following working examples:\\n•Write an analysis of a given novel for a literature blog. This example illustrates a simple, \\nsequential chain of prompts.\\n•Generate a short story about a given topic. This example illustrates how the AI can \\niteratively process a list of items that it previously generated.\\n•Create an itinerary for a weekend vacation to a given destination. This example illustrates \\nhow to parallelize multiple distinct prompts.\\n•Pitch movie ideas to a human user acting as a movie producer. This example illustrates \\nhow to parallelize the same prompt with diﬀerent inference parameters, how to backtrack \\nto a previous step in the chain, and how to include human input as part of the workﬂow.\\n•Plan a meal based on ingredients the user has at hand. This example illustrates how \\nprompt chains can incorporate two distinct AI conversations, with two AI personas \\nengaging in a debate with each other to improve the ﬁnal outcome.\\n•Find and summarize today\\'s highest trending GitHub repository. This example illustrates \\nchaining multiple AI agents that interact with external APIs.\\nFor complete source code and instructions to set up and run, see the full project on GitHub .\\nServices used in this example\\n•Amazon Bedrock\\n•Amazon Bedrock Runtime\\n•Agents for Amazon Bedrock\\n•Agents for Amazon Bedrock Runtime\\nScenarios 749Amazon Bedrock User Guide\\n•Step Functions\\nFor a complete list of AWS SDK developer guides and code examples, see Using this service with \\nan AWS SDK. This topic also includes information about getting started and details about previous \\nSDK versions.\\nScenarios 750Amazon Bedrock User Guide\\nAmazon Bedrock abuse detection\\nAWS is committed to the responsible use of AI. To help prevent potential misuse, Amazon Bedrock \\nimplements automated abuse detection mechanisms to identify potential violations of AWS’s\\nAcceptable Use Policy (AUP) and Service Terms, including the Responsible AI Policy or a third-party \\nmodel provider’s AUP.\\nOur abuse detection mechanisms are fully automated, so there is no human review of, or access to, \\nuser inputs or model outputs.\\nAutomated abuse detection includes:\\n•Categorize content — We use classiﬁers to detect harmful content (such as content that \\nincites violence) in user inputs and model outputs. A classiﬁer is an algorithm that processes \\nmodel inputs and outputs, and assigns type of harm and level of conﬁdence. We may run these \\nclassiﬁers on both Titan and third-party model usage. The classiﬁcation process is automated \\nand does not involve human review of user inputs or model outputs.\\n•Identify patterns — We use classiﬁer metrics to identify potential violations and recurring \\nbehavior. We may compile and share anonymized classiﬁer metrics with third-party model \\nproviders. Amazon Bedrock does not store user input or model output and does not share these \\nwith third-party model providers.\\n•Detecting and blocking child sexual abuse material (CSAM) — You are responsible for the \\ncontent you (and your end users) upload to Amazon Bedrock and must ensure this content is \\nfree from illegal images. To help stop the dissemination of CSAM, Amazon Bedrock may use \\nautomated abuse detection mechanisms (such as hash matching technology or classiﬁers) \\nto detect apparent CSAM. If Amazon Bedrock detects apparent CSAM in your image inputs, \\nAmazon Bedrock will block the request and you will receive an automated error message. \\nAmazon Bedrock may also ﬁle a report with the National Center for Missing and Exploited \\nChildren (NCMEC) or a relevant authority. We take CSAM seriously and will continue to update \\nour detection, blocking, and reporting mechanisms. You might be required by applicable laws to \\ntake additional actions, and you are responsible for those actions.\\nOnce our automated abuse detection mechanisms identify potential violations, we may request \\ninformation about your use of Amazon Bedrock and compliance with our terms of service or a \\nthird-party provider’s AUP. In the event that you are unwilling or unable to comply with these \\nterms or policies, AWS may suspend your access to Amazon Bedrock.\\n751Amazon Bedrock User Guide\\nContact AWS Support if you have additional questions. For more information, see the Amazon \\nBedrock FAQs.\\n752Amazon Bedrock User Guide\\nQuotas for Amazon Bedrock\\nYour AWS account has default quotas, formerly referred to as limits, for each AWS service. Unless \\notherwise noted, each quota is Region-speciﬁc within your AWS account. Some quotas may be \\nadjustable. The following list explains the meaning of the Adjustable column in the following \\ntables:\\n•If a quota is marked as Yes, you can adjust it by following the steps at Requesting a Quota \\nIncrease in the Service Quotas User Guide.\\n•If a quota is marked as No, you can submit a request through the limit increase form to be \\nconsidered for an increase.\\nSome quotas diﬀer by model. Unless speciﬁed otherwise, a quota applies to all versions of a model.\\nYour AWS account has the following quotas related to Amazon Bedrock. Select a topic to learn \\nmore about quotas for it.\\nTopics\\n•Runtime quotas\\n•Batch inference quotas\\n•Knowledge base quotas\\n•Agent quotas\\n•Model customization quotas\\n•Provisioned Throughput quotas\\nRuntime quotas\\nLatency diﬀers by model and is directly proportional to the following conditions.\\n•The number of input and output tokens\\n•The total number of ongoing on-demand requests by all customers at the time.\\nThe following quotas apply when you carry out model inference. These quotas consider the \\ncombined sum for InvokeModel and InvokeModelWithResponseStream requests.\\nRuntime quotas 753Amazon Bedrock User Guide\\nTo increase throughput, purchase Provisioned Throughput.\\nModel Requests processed \\nper minuteTokens processed \\nper minuteAdjustable\\nAI21 Labs Jurassic-2 \\nMid400 300,000 No\\nAI21 Labs Jurassic-2 \\nUltra100 200,000 No\\nAmazon Titan \\nEmbeddings G1 - \\nText2,000 300,000 No\\nAmazon Titan Image \\nGenerator G160 N/A No\\nAmazon Titan \\nMultimodal \\nEmbeddings G12,000 N/A No\\nAmazon Titan Text \\nG1 - Express400 300,000 No\\nAmazon Titan Text \\nG1 - Lite800 300,000 No\\nAnthropic Claude \\nInstant400 300,000 No\\nAnthropic Claude 2.x 100 200,000 No\\nAnthropic Claude 3 \\nSonnet100 200,000 No\\nAnthropic Claude 3 \\nHaiku400 300,000 No\\nCohere Command 400 300,000 No\\nRuntime quotas 754Amazon Bedrock User Guide\\nModel Requests processed \\nper minuteTokens processed \\nper minuteAdjustable\\nCohere Command \\nLight800 300,000 No\\nCohere Embed \\n(English)2,000 300,000 No\\nCohere Embed \\n(Multilingual)2,000 300,000 No\\nMeta Llama 2 13B 800 300,000 No\\nMeta Llama 2 70B 400 300,000 No\\nMistral AI Mistral 7B \\nInstruct800 300,000 No\\nMistral AI Mixtral \\n8X7B Instruct400 300,000 No\\nStable Diﬀusion XL 60 N/A No\\nSelect a tab to see model-speciﬁc inference quotas.\\nAmazon Titan Text models\\nDescription Value Adjustable\\nText prompt length, in \\ncharacters42,000 No\\nRuntime quotas 755Amazon Bedrock User Guide\\nAmazon Titan Image Generator G1\\nDescription Value Adjustable\\nText prompt length, in \\ncharacters1,024 No\\nInput image size 5 MB No\\nInput image height in pixels \\n(inpainting/outpainting)1,024 No\\nInput image width in pixels \\n(inpainting/outpainting)1,024 No\\nInput image height in pixels \\n(image variation)4,096 No\\nInput image width in pixels \\n(image variation)4,096 No\\nInput image total pixels 12,582,912 No\\nAmazon Titan Embeddings G1 - Text\\nDescription Value Adjustable\\nText input length, in \\ncharacters50,000 No\\nAmazon Titan Multimodal Embeddings G1\\nDescription Value Adjustable\\nText input length, in \\ncharacters100,000 No\\nRuntime quotas 756Amazon Bedrock User Guide\\nDescription Value Adjustable\\nBase64-encoded string of \\nimage, in characters25,000,000 No\\nBatch inference quotas\\nThe following quotas apply when you run batch inference. The quotas depend on the modality of \\nthe input and output data.\\nModality Minimum ﬁle size Maximum ﬁle size\\nText to embeddings 75 MB 500 MB\\nText to text 20 MB 150 MB\\nText/image to image 1 MB 50 MB\\nKnowledge base quotas\\nThe following quotas apply to Knowledge base for Amazon Bedrock.\\nDescription Maximum Adjustable\\nKnowledge bases per account \\nper region50 No\\nData source ﬁle size 50 MB No\\nData source chunk size (Titan \\nText G1 - Embeddings)8,192 No\\nData source chunk size \\n(Cohere Embed English)512 No\\nData source chunk size \\n(Cohere Embed Multilingual)512 No\\nBatch inference quotas 757Amazon Bedrock User Guide\\nAgent quotas\\nThe following quotas apply to Agents for Amazon Bedrock.\\nDescription Maximum Adjustable\\nAgents per account 50 Yes\\nAliases per Agent 10 No\\nCharacters in Agent instructi \\nons1,200 No\\nAction groups per Agent 5 No\\nNumber of APIs across action \\ngroups in an Agent5 No\\nLambda response payload \\nsize25 KB No\\nAssociated knowledge bases \\nper Agent2 No\\nModel customization quotas\\nThe following quotas apply to model customization.\\nDescription Maximum Adjustable\\nScheduled training jobs per \\naccount2 No\\nCustom models per account 100 Yes\\nTo see hyperparameter quotas, see Custom model hyperparameters.\\nAgent quotas 758Amazon Bedrock User Guide\\nSelect a tab to see model-speciﬁc quotas that apply to training and validation datasets used for \\ncustomizing diﬀerent foundation models.\\nAmazon Titan Text G1 - Express\\nDescription Maximum (Continue \\nd Pre-training)Maximum (Fine-tun \\ning)Adjustable\\nSum of input and \\noutput tokens when \\nbatch size is 14,096 4,096 No\\nSum of input and \\noutput tokens when \\nbatch size is 2, 3, or \\n42,048 2,048 No\\nCharacter quota per \\nsample in datasetToken quota x 6 Token quota x 6 No\\nRecords in a training \\ndataset100,000 10,000 Yes\\nRecords in a \\nvalidation dataset1,000 1,000 Yes\\nTraining dataset ﬁle \\nsize10 GB 1 GB Yes\\nValidation dataset \\nﬁle size100 MB 100 MB Yes\\nModel customization quotas 759Amazon Bedrock User Guide\\nAmazon Titan Text G1 - Lite\\nDescription Maximum (Continue \\nd Pre-training)Maximum (Fine-tun \\ning)Adjustable\\nSum of input and \\noutput tokens when \\nbatch size is 1 or 24,096 4,096 No\\nSum of input and \\noutput tokens when \\nbatch size is 3, 4, 5, \\nor 62,048 2,048 No\\nCharacter quota per \\nsample in datasetToken quota x 6 Token quota x 6 No\\nRecords in a training \\ndataset100,000 10,000 Yes\\nRecords in a \\nvalidation dataset1,000 1,000 Yes\\nTraining dataset ﬁle \\nsize10 GB 1 GB Yes\\nValidation dataset \\nﬁle size100 MB 100 MB Yes\\nAmazon Titan Image Generator G1\\nDescription Minimum (Fine-tun \\ning)Maximum (Fine-tun \\ning)Adjustable\\nText prompt length \\nin training sample, in \\ncharacters3 1,024 No\\nModel customization quotas 760Amazon Bedrock User Guide\\nDescription Minimum (Fine-tun \\ning)Maximum (Fine-tun \\ning)Adjustable\\nRecords in a training \\ndataset5 10,000 No\\nInput image size 0 50 MB No\\nInput image height \\nin pixels512 4,096 No\\nInput image width in \\npixels512 4,096 No\\nInput image total \\npixels0 12,582,912 No\\nInput image aspect \\nratio1:4 4:1 No\\nAmazon Titan Multimodal Embeddings G1\\nDescription Minimum (Fine-tun \\ning)Maximum (Fine-tun \\ning)Adjustable\\nText prompt length \\nin training sample, in \\ncharacters0 2,560 No\\nRecords in a training \\ndataset1,000 500,000 No\\nInput image size 0 5 MB No\\nInput image height \\nin pixels128 4096 No\\nModel customization quotas 761Amazon Bedrock User Guide\\nDescription Minimum (Fine-tun \\ning)Maximum (Fine-tun \\ning)Adjustable\\nInput image width in \\npixels128 4096 No\\nInput image total \\npixels0 12,528,912 No\\nInput image aspect \\nratio1:4 4:1 No\\nCohere Command & Meta Llama 2\\nDescription Maximum (Fine-tuning) Adjustable\\nInput tokens 4,096 No\\nOutput tokens 2,048 No\\nCharacter quota per sample \\nin datasetToken quota x 6 No\\nRecords in a training dataset 10,000 Yes\\nRecords in a validation \\ndataset1,000 Yes\\nTraining dataset ﬁle size ??? Yes\\nValidation dataset ﬁle size ??? Yes\\nProvisioned Throughput quotas\\nThe following quotas apply to Provisioned Throughput.\\nProvisioned Throughput quotas 762Amazon Bedrock User Guide\\nDescription Default Adjustable\\nModel units for a base model 0 Yes\\nModel units for a custom \\nmodel2 Yes\\nProvisioned Throughput quotas 763Amazon Bedrock User Guide\\nAPI reference\\nThe API Reference can be found here.\\n764Amazon Bedrock User Guide\\nDocument history for the Amazon Bedrock User Guide\\n•Latest documentation update: March 13th, 2024\\nThe following table describes important changes in each release of Amazon Bedrock. For \\nnotiﬁcation about updates to this documentation, you can subscribe to an RSS feed.\\nChange Description Date\\nNew model You can now use Anthropic \\nClaude 3 Haiku with Amazon \\nBedrock.March 13, 2024\\nNew model You can now use Anthropic \\nClaude 3 Sonnet with Amazon \\nBedrock.March 4, 2024\\nNew model You can now use Mistral AI \\nmodels with Amazon Bedrock.March 1, 2024\\nNew feature You can now customize the \\nsearch strategy in Knowledge \\nBase for Amazon OpenSearc \\nh Serverless vector stores that \\ncontain a ﬁlterable text ﬁeld.February 28, 2024\\nNew feature You can now detect images \\nwith a watermark from \\nAmazon Bedrock Titan Image \\nGenerator.February 14, 2024\\nUpdated AWS PrivateLink \\nsupportYou can now use AWS \\nPrivateLink to create interface \\nVPC endpoints for the Agents \\nfor Amazon Bedrock Build-tim \\ne service.February 9, 2024\\n765Amazon Bedrock User Guide\\nIAM role update You can now use the same \\nservice role across knowledge \\nbases and use roles without a \\npredeﬁned preﬁx.February 9, 2024\\nModel in legacy status Stable Diﬀusion XL v0.8 is \\nnow in legacy status. Migrate \\nto Stable Diﬀusion XL v1.x \\nbefore April 30, 2024.February 2, 2024\\nCode examples chapter added The Amazon Bedrock guide \\nnow includes code examples \\nacross a variety of Amazon \\nBedrock actions and scenarios \\n.January 25, 2024\\nNew feature Knowledge base for Amazon \\nBedrock now oﬀers you a \\nchoice between a production \\nand non-production account \\nwhen you choose to quick \\ncreate an Amazon OpenSearc \\nh Serverless vector store in \\nthe console.January 24, 2024\\nNew feature Agents for Amazon Bedrock \\nnow lets you view traces in \\nreal-time when you use the \\ntest window in the console.January 18, 2024\\nEmbed your data sources for \\nKnowledge base for Amazon \\nBedrock with more modelsKnowledge base for Amazon \\nBedrock now supports data \\nsource embeddings with \\nCohere Embed English and \\nCohere Embed Multilingual.January 17, 2024\\n766Amazon Bedrock User Guide\\nUse Agents for Amazon \\nBedrock with more modelsAgents for Amazon Bedrock \\nand Knowledge base for \\nAmazon Bedrock now \\nsupports Anthropic Claude \\n2.1.December 27, 2023\\nRegion expansion Amazon Bedrock is now \\navailable in AWS GovCloud \\n(US-West) (us-gov-west-1). \\nFor information on endpoints \\n, see Amazon Bedrock \\nendpoints and quotas .December 21, 2023\\nNew vector store supportYou can now create a \\nknowledge base in an Amazon \\nAurora database cluster. For \\nmore information, see Create \\na vector store in Amazon \\nAurora.December 21, 2023\\nNew managed policies Amazon Bedrock has added\\nAmazonBedrockFullA \\nccess to give users \\npermission to create, read, \\nupdate, and delete resources, \\nand AmazonBedrockReadO \\nnly to give users read-only \\npermissions for all actions.December 12, 2023\\nNew feature Amazon Bedrock now \\nsupports creating model \\nevaluation jobs using \\nautomatic metrics or human \\nworkers.November 29, 2023\\n767Amazon Bedrock User Guide\\nNew feature You can now monitor and \\ncustomize your  model \\nversions.November 29, 2023\\nNew Titan models New models from Titan \\ninclude Amazon Titan Image \\nGenerator G1 and Amazon \\nTitan Multimodal Embeddings \\nG1. For more information, see\\nTitan Models .November 29, 2023\\nNew feature With Continued Pre-training \\nyou can teach a model new \\ndomain knowledge. For more \\ninformation, see Custom \\nModels .November 28, 2023\\nNew feature You can now query \\nknowledge bases through \\nthe Retrieve and RetrieveA \\nndGenerate  APIs. For more \\ninformation, see Query a \\nknowledge base.November 28, 2023\\nGeneral release General release of the \\nKnowledge base for Amazon \\nBedrock service. For more \\ninformation, see Knowledge \\nbase for Amazon Bedrock.November 28, 2023\\nGeneral release General release of the Agents \\nfor Amazon Bedrock service. \\nFor more information, see\\nAgents for Amazon Bedrock.November 28, 2023\\n768Amazon Bedrock User Guide\\nCustomize more modelsYou can now customize \\nmodels from Cohere and \\nMeta. For more information, \\nsee Custom Models .November 28, 2023\\nNew model releases Updated documentation to \\ncover new Meta and Cohere \\nmodels. For more informati \\non, see Amazon Bedrock.November 13, 2023\\nDocumentation localization Amazon Bedrock documenta \\ntion is now available in\\nJapanese  and German .October 20, 2023\\nRegion expansion Amazon Bedrock is now \\navailable in Europe (Frankfur \\nt) (eu-central-1). For informati \\non on endpoints, see Amazon \\nBedrock endpoints and \\nquotas .October 19, 2023\\nRegion expansion Amazon Bedrock is now \\navailable in Asia Paciﬁc \\n(Tokyo) (ap-northeast-1). For \\ninformation on endpoints, see\\nAmazon Bedrock endpoints \\nand quotas .October 3, 2023\\nGated general releaseGated general release of the \\nAmazon Bedrock service. \\nFor more information, see\\nAmazon Bedrock.September 28, 2023\\n769Amazon Bedrock User Guide\\nAWS Glossary\\nFor the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.\\n770'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Text for Tokenization Compatibility:"
      ],
      "metadata": {
        "id": "HoSKYuAND5CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a CharacterTextSplitter to segment the extracted text into smaller chunks.\n",
        "# This approach ensures that each text chunk does not exceed the token size limit imposed by the model or application.\n",
        "# Parameters:\n",
        "# separator: Defines the character used to separate chunks, here set to a newline character.\n",
        "# chunk_size: The target size for each text chunk, set to 800 characters.\n",
        "# chunk_overlap: Allows for an overlap of 200 characters between consecutive chunks to maintain context.\n",
        "# length_function: The function used to measure the length of text, here simply using the built-in len function.\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "-6St9MU_cLh3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determining the Number of Text Chunks:"
      ],
      "metadata": {
        "id": "j7hBhjAHD_bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of chunks created after splitting the text.\n",
        "# This is useful for understanding the distribution and segmentation of the text for further processing.\n",
        "len(texts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDN5q4NKcOiK",
        "outputId": "499e6452-0336-49de-df84-9c101cdb53e4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1927"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing Embeddings from OpenAI:"
      ],
      "metadata": {
        "id": "kF0ouJKdEDml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the OpenAI embeddings.\n",
        "# This step involves setting up the OpenAIEmbeddings object to generate embeddings for text segments.\n",
        "# Embeddings are crucial for representing text in a form suitable for similarity searches and other vector-based operations.\n",
        "embeddings = OpenAIEmbeddings()\n"
      ],
      "metadata": {
        "id": "RQhNYHPecRAr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a FAISS Vector Store from Texts:"
      ],
      "metadata": {
        "id": "a4DSahxeEJQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a FAISS vector store to manage and search document embeddings.\n",
        "# This operation converts the text segments into embeddings and stores them in a FAISS index for efficient similarity searching.\n",
        "document_search = FAISS.from_texts(texts, embeddings)\n"
      ],
      "metadata": {
        "id": "5vLz4dUScTG_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting the Document Search Object:"
      ],
      "metadata": {
        "id": "3tlIFVmVESUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the document_search object.\n",
        "# This inspection is useful for verifying the successful creation of the FAISS vector store and its readiness for executing searches.\n",
        "document_search\n"
      ],
      "metadata": {
        "id": "odtuhsUgdcYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33ccf70-21b0-4537-b834-f6797dc55d73"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x7c2270a05720>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a Question Answering Chain:"
      ],
      "metadata": {
        "id": "AzM7qzhkEXyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a question answering (QA) chain using LangChain and OpenAI's model.\n",
        "# This chain is configured for processing input documents and questions to generate answers.\n",
        "# The 'chain_type' parameter specifies the configuration or model type to use, here indicated as \"stuff\".\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n"
      ],
      "metadata": {
        "id": "GRaOBtVGdnSe"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executing the QA Chain with a Specific Query:"
      ],
      "metadata": {
        "id": "QUlLdVS9EnMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a query and perform a similarity search to find relevant document segments.\n",
        "# The identified documents are then processed through the QA chain to generate an answer.\n",
        "query = \"How to add an action group to your agent in Amazon Bedrock\"\n",
        "docs = document_search.similarity_search(query)  # Find similar document segments to the query.\n",
        "chain.run(input_documents=docs, question=query)  # Process the documents and query through the QA chain.\n"
      ],
      "metadata": {
        "id": "8Z8Gt86JdfcT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2e4a357f-9890-4f06-f5d3-8204b2f518d3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' To add an action group to your agent in Amazon Bedrock, follow these steps: \\n1. Sign in to the AWS Management Console and open the Amazon Bedrock console at \\nhttps://console.aws.amazon.com/bedrock/.\\n2. Select Agents from the left navigation pane and choose an agent in the Agents section.\\n3. Choose an agent from the Agents section and then choose the Working draft in the Working Draft section.\\n4. Select Add in the Action groups section.\\n5. Fill out the action group details.\\n6. To define the schema for the action group, use the in-line OpenAPI schema editor. \\n7. Select Add and wait for the success banner to appear. \\n8. Select Prepare to apply the changes to your agent before testing it.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another Example of Executing the QA Chain:"
      ],
      "metadata": {
        "id": "KbFavY1kEtBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Do i need to pay for a foundation model in bedrock\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uVsNWrkO9ndR",
        "outputId": "17d7b2a0-fbfa-48fa-f99b-7c0cd49a786d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Yes, you do need to pay for a foundation model in Amazon Bedrock. Pricing is based on the volume of input tokens and output tokens, and on whether you have purchased provisioned throughput for the model. You can see the pricing for each model on the Model providers page in the Amazon Bedrock console.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7inWW51_XUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}